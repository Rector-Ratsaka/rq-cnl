url,research_question
https://aclanthology.org/2020.cl-1.1/,"How accurately do the representations learned by neural machine translation models capture word structure?"
https://aclanthology.org/2020.cl-1.1/,"Do multilingual NMT models learn a richer representation of linguistic information compared to their bilingual counterparts?"
https://aclanthology.org/2020.cl-1.2/,"How can Microsoft XiaoIce's emotional quotient be improved through the integration of affective computing and natural language processing techniques to enhance its empathetic responses to users, measured by the increase in Conversation-turns Per Session (CPS)?"
https://aclanthology.org/2020.cl-1.2/,"Can the dialogue manager and core chat components of XiaoIce be optimized for more efficient conversation flow and user engagement, using machine learning algorithms to predict and adapt to user intent and emotional states?"
https://aclanthology.org/2020.cl-1.3/,"Can probabilistic topic modeling be effectively utilized for crosslingual tasks when trained on small datasets?"
https://aclanthology.org/2020.cl-1.3/,How do the assumptions of different multilingual topic models impact their ability to extract multilingual features and facilitate knowledge transfer across languages?
https://aclanthology.org/2020.cl-1.4/,Can machine learning models be trained to accurately simplify English sentences while preserving their grammatical correctness and main idea? 
https://aclanthology.org/2020.cl-1.4/,Can deep learning techniques be used to improve the efficiency and effectiveness of sentence simplification tasks in the English language?
https://aclanthology.org/2020.cl-1.5/,Can the use of a standardized annotation scheme for negation in languages other than English improve the compatibility and reusability of annotated corpora for negation processing systems? 
https://aclanthology.org/2020.cl-1.5/,Does the evaluation of annotated corpora with different tokenization and annotation guidelines for negation elements impact the overall quality and accuracy of negation processing systems?
https://aclanthology.org/2020.cl-2.1/,Can the use of transformer-based architectures improve the performance of multilingual semantic representation models in handling out-of-vocabulary words and unseen linguistic phenomena?
https://aclanthology.org/2020.cl-2.1/,"Can semantic representation models using symbolic and neural approaches be combined to achieve better performance in NLP tasks, such as sentiment analysis and text classification?"
https://aclanthology.org/2020.cl-2.2/,Can adversarial autoencoders be used for unsupervised word translation tasks with high accuracy and stability?
https://aclanthology.org/2020.cl-2.2/,Can the use of Procrustes solution and symmetric re-weighting refinement procedures improve the performance of adversarial autoencoders in word translation tasks?
https://aclanthology.org/2020.cl-2.3/,Can multilingual lexical resources based on a sense inventory from a semantic network improve performance in conceptual similarity tasks compared to traditional approaches that rely on monolingual embeddings? 
https://aclanthology.org/2020.cl-2.3/,Does the use of a blended terminological vector for each term improve semantic text similarity in crosslingual settings?
https://aclanthology.org/2020.cl-2.4/,Can probing tasks be used to estimate the performance of multilingual word embedding models on downstream tasks in languages with rich morphological structures?
https://aclanthology.org/2020.cl-2.4/,Can probing tasks be used to identify linguistic features that predict the performance of multilingual word embedding models on a range of NLP tasks in diverse languages?
https://aclanthology.org/2020.cl-2.5/,"Can a multilingual translation model with an attention bridge improve the performance of trainable classification tasks when the size of the attention bridge is increased?"
https://aclanthology.org/2020.cl-2.5/,"Can the use of multilingual models lead to improved performance in non-trainable similarity tasks, and what is the impact of including additional languages on this improvement?"
https://aclanthology.org/2020.cl-2.6/,"What are the specific methods and algorithms used by the Grammatical Framework to scale up its capabilities for wide-coverage language processing?
https://aclanthology.org/2020.cl-2.6/,How do these methods contribute to the integration of data from other approaches such as Universal Dependencies and WordNets?"
https://aclanthology.org/2020.cl-2.6/,"Can GF's rule-based generation capabilities be used to augment data for other languages, and what are the implications of this approach for data-driven approaches to language processing?"
https://aclanthology.org/2020.cl-2.7/,What are the factors that contribute to the creation of biased analogies in word embeddings and how can they be mitigated?
https://aclanthology.org/2020.cl-2.7/,"Can word embeddings be trained to recognize and adapt to diverse perspectives, reducing the reliance on analogies as a bias detection tool?"
https://aclanthology.org/2020.cl-2.8/,"Can machine-generated text generated by neural language models be distinguished from human-written text using stylometry methods?"
https://aclanthology.org/2020.cl-2.8/,"Do machine-generated misinformation and legitimate uses of neural language models exhibit distinct stylistic differences in auto-completion and editing-assistance settings?"
https://aclanthology.org/2020.cl-3.1/,What are the formalized restrictions on the notation and interpretation of Lexical-Functional Grammar (LFG) that make it equivalent to linear context-free rewriting systems?
https://aclanthology.org/2020.cl-3.1/,How do these restrictions impact the computational complexity of LFG recognition and generation problems?
https://aclanthology.org/2020.cl-3.1/,"Can the introduction of these formalized restrictions on LFG notation and interpretation lead to more efficient algorithms for recognizing and generating natural languages?"
https://aclanthology.org/2020.cl-3.2/,"Can multilingual representations preserve linguistic relations without requiring etymological information?
https://aclanthology.org/2020.cl-3.2/,How do word-based and sentence-based models differ in their semantic drift between language families?"
https://aclanthology.org/2020.cl-3.2/,Can a measure of semantic drift between language families be used to identify unwanted characteristics of computational models and quantify linguistic phenomena across languages?
https://aclanthology.org/2020.cl-3.3/,"Can deep-syntactic frameworks based on linguistic theories differ from NLP-motivated approaches in their representation of sentence meaning, and what are the key characteristics of each framework?"
https://aclanthology.org/2020.cl-3.3/,"Can linguistic theories underpinning deep-syntactic frameworks impact the way language phenomena are treated in these frameworks, and how do NLP-motivated approaches address this issue?"
https://aclanthology.org/2020.cl-3.4/,Can a text-based model using a transformer architecture be used to predict NBA players' deviations from mean in-game actions with higher accuracy than a model trained only on performance metrics?
https://aclanthology.org/2020.cl-3.4/,Can a combination of text-based and performance metric-based models be used to predict NBA players' deviations from mean in-game actions with higher accuracy than either model type alone?
https://aclanthology.org/2020.cl-4.1/,What are the computational models and algorithms that can be applied to sparse transcription to improve the efficiency and effectiveness of transcription for endangered languages?
https://aclanthology.org/2020.cl-4.1/,How do these models compare to existing approaches such as automatic speech recognition and machine translation? 
https://aclanthology.org/2020.cl-4.1/,Can sparse transcription be used to create a more accurate and comprehensive phonetic transcription of spoken languages using a combination of linguistic and machine learning techniques?
https://aclanthology.org/2020.cl-4.2/,"Can weighted deduction systems with specific function composition rules enable the efficient computation of outside values in parsing algorithms?"
https://aclanthology.org/2020.cl-4.2/,Does the analysis of outside computation as function composition provide a unified framework for understanding the limitations and potential of weighted deduction systems in various parsing applications?
https://aclanthology.org/2020.cl-4.3/,Are neural NLP models able to capture the transitivity information of auxiliary verb constructions compared to finite main verbs? 
https://aclanthology.org/2020.cl-4.3/,Do recursive layers improve the capture of agreement information in neural parsers for auxiliary verb constructions compared to sequential models?
https://aclanthology.org/2020.cl-4.4/,What are the key factors that enable the proposed energy-based model to automate the learning of the feature function and reduce training data requirements for morphosyntactic tasks in Sanskrit?
https://aclanthology.org/2020.cl-4.4/,How does the proposed framework incorporate language-specific constraints to prune the search space and filter candidates during inference for Sanskrit?
https://aclanthology.org/2020.cl-4.5/,"Can word embeddings trained on Multi-SimLex data sets improve the performance of crosslingual semantic similarity tasks, particularly in low-resource languages?"
https://aclanthology.org/2020.cl-4.5/,"Can the creation of consistent, Multi-SimLex–style lexical resources using the presented data set creation protocol lead to significant improvements in multilingual lexical semantics and representation learning?"
https://aclanthology.org/2021.cl-1.1/,"Can machine learning algorithms be used to predict the likelihood of a paper being accepted for publication in a prestigious conference based on its content?"
https://aclanthology.org/2021.cl-1.1/,Can the use of a Transformer-based approach improve the accuracy of natural language processing tasks such as sentiment analysis or question answering?
https://aclanthology.org/2021.cl-1.2/,Can a combinatory categorial grammar (CCG) be used to model the structural complexity of human language with a computational complexity that grows less than the number of possible permutations of n elements? 
https://aclanthology.org/2021.cl-1.2/,Can the separable permutations of word order in nominal and verbal constructions be identified through computational methods that analyze the mathematical origins of this restriction in CCGs?
https://aclanthology.org/2021.cl-1.3/,What are the theoretical properties that distinguish knowledge-intensive and data-intensive ERS parsing models in terms of their ability to produce Elementary Dependency Structures?
https://aclanthology.org/2021.cl-1.3/,"How do the different types of errors produced by knowledge- and data-intensive models relate to their theoretical properties, and what are the implications for parser development?"
https://aclanthology.org/2021.cl-1.4/,What is the potential for spatially induced similarity judgments to better reflect human notions of word similarity in the context of lexical semantic similarity estimation?
https://aclanthology.org/2021.cl-1.4/,Can static word embedding methods outperform lexical representations emerging from pre-training methods for semantic clustering and word-level similarity evaluation on a large-scale verb dataset?
https://aclanthology.org/2021.cl-1.5/,What is the effect of contextual information on the performance of named entity recognition models?
https://aclanthology.org/2021.cl-1.5/,Do these models learn to recognize entities based solely on their surface-level representations or also on contextual cues?
https://aclanthology.org/2021.cl-1.5/,Are there opportunities for improving named entity recognition models by explicitly separating contextual and local token representations?
https://aclanthology.org/2021.cl-1.6/,Can neural language models be effectively used to predict readability in low-resource languages with limited labeled data?
https://aclanthology.org/2021.cl-1.6/,Can a neural classification architecture achieve high accuracy in readability classification using a combination of feature engineering and transfer learning from high-resource languages?
https://aclanthology.org/2021.cl-1.7/,Can a simple probabilistic context-free grammar induction model achieve accurate constituent boundary prediction using a limited working memory capacity compared to an unbounded model?
https://aclanthology.org/2021.cl-1.7/,Can the difference in grammatical complexity between child-directed speech and adult-directed speech be attributed to the constraints imposed by increasing working memory capacity?
https://aclanthology.org/2021.cl-2.9/,Can a weighted finite automaton be used to efficiently approximate a probabilistic source model and minimize the Kullback-Leibler divergence between the source model and the WFA target model?
https://aclanthology.org/2021.cl-2.9/,Does the proposed algorithm for approximating a probabilistic model as a weighted finite automaton reduce the computational complexity of tasks such as language modeling and character modeling?
https://aclanthology.org/2021.cl-2.11/,"Can the Universal Dependencies framework be adapted to effectively capture the morphological features of languages with complex grammatical structures?"
https://aclanthology.org/2021.cl-2.11/,Can the UD framework's reliance on morphological features and part-of-speech classes be further refined to improve the accuracy of cross-linguistic annotation and computational natural language understanding?
https://aclanthology.org/2021.cl-2.12/,"Can RYANSQL improve the accuracy of Text-to-SQL tasks for cross-domain databases by utilizing a sketch-based slot-filling approach to synthesize SELECT statements for Statement Position Code?"
https://aclanthology.org/2021.cl-2.12/,Can the proposed input manipulation methods in RYANSQL enhance the overall generation performance of the system by improving the quality of the synthesized SQL queries?
https://aclanthology.org/2021.cl-2.13/,"Can CausaLM effectively estimate the causal effect of a concept of interest on model performance by generating counterfactual examples?"
https://aclanthology.org/2021.cl-2.13/,Can CausaLM's fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks improve the language representation model's ability to distinguish between correlation and causation in text-based models?
https://aclanthology.org/2021.cl-2.14/,Can transformer-based language models like BERT accurately capture high-level sense distinctions in word senses with limited training data?
https://aclanthology.org/2021.cl-2.14/,Can a feature extraction strategy outperform fine-tuning in reducing sense bias and exploiting limited training data for word sense disambiguation tasks?
https://aclanthology.org/2021.cl-2.15/,Can the Transformer-based architecture of 𝕌niversal Discourse Representation Theory (𝕌DRT) improve crosslingual semantic parsing by leveraging linguistic input anchors?
https://aclanthology.org/2021.cl-2.15/,How does it compare to traditional many-to-one and one-to-many learning schemes in terms of accuracy and semantic resource quality? 
https://aclanthology.org/2021.cl-2.15/,Does the proposed 𝕌DRT approach achieve better results than strong baselines on the Parallel Meaning Bank for low-resource languages?
https://aclanthology.org/2021.cl-3.16/,"What is the degree of logography in a writing system, as measured by the ratio of attention outside the token to the total activation?"
https://aclanthology.org/2021.cl-3.16/,"How does the proposed attention-based sequence-to-sequence model perform in predicting the spelling of a token from its pronunciation in context?
https://aclanthology.org/2021.cl-3.16/,What are the implications of this for understanding the nature of logographic systems?"
https://aclanthology.org/2021.cl-3.17/,"Does the use of syntactic information in neural semantic role labeling models improve performance in monolingual and multilingual settings?"
https://aclanthology.org/2021.cl-3.17/,"Can the integration of syntactic information in SRL models lead to improved accuracy and reduced processing time for neural SRL tasks on large-scale benchmarks like CoNLL-2005, -2009, and -2012?"
https://aclanthology.org/2021.cl-3.18/,"Can event coreference resolution systems be developed that can generalize across different domains and event mentions without overfitting to a specific corpus? 
https://aclanthology.org/2021.cl-3.18/,Can feature-based and neural systems be combined to leverage the strengths of both approaches in CDCR tasks?"
https://aclanthology.org/2021.cl-3.19/,Can a coreference resolution system be trained to accurately identify and represent the gender identities of trans individuals without perpetuating biases in its annotations and representations?
https://aclanthology.org/2021.cl-3.19/,"Does the inclusion of sociolinguistic nuances in machine learning models improve the quality of coreference resolution for binary and non-binary trans users, particularly in reducing stereotyping and representation issues?"
https://aclanthology.org/2021.cl-3.20/,Can word embeddings capture and encode meaningful semantic features that are interpretable and aligned with human cognition?
https://aclanthology.org/2021.cl-3.20/,"How do different types of embeddings (e.g., Skip-Gram, GloVe, ELMo, BERT) encode these features differently?"
https://aclanthology.org/2021.cl-3.20/,Can the proposed method for mapping word embeddings onto interpretable vectors improve the performance of these embeddings in discriminating semantic categories and what are the most relevant features that contribute to this improvement?
https://aclanthology.org/2021.cl-4.24/,Can a deep neural network be made more interpretable by using a K-NN model derived from feature representations of pre-trained networks?
https://aclanthology.org/2021.cl-4.24/,Can a model's predictions be updated locally without re-training the full model by using a support set with known labels and matching to instances from the input?
https://aclanthology.org/2021.cl-4.25/,"How can a deep learning model that uses the self-attention mechanism to learn high-level features be combined with a relational logic network to explicitly exploit target interactions in joint inference tasks, and what are the implications of this combination on the performance of such models in terms of accuracy?"
https://aclanthology.org/2021.cl-4.25/,Can a variational deep logic network that incorporates both representation learning and relational reasoning via the variational EM algorithm outperform existing approaches that rely on predefined rules or implicit propagation of information in joint inference tasks such as entity extraction and relation prediction?
https://aclanthology.org/2021.cl-4.26/,Can a knowledge-based approach to pre-processing text improve the efficiency of sequence-to-sequence neural-based text summarization models when dealing with out-of-vocabulary words?
https://aclanthology.org/2021.cl-4.26/,Can a combination of deep learning and knowledge-based methodologies improve the accuracy of abstractive summaries by utilizing ontological knowledge resources and word sense disambiguation?
https://aclanthology.org/2021.cl-4.27/,"Can machine learning models achieve high correlation with human judgments on overall simplicity in sentence-level simplifications where multiple operations are applied, and what are the factors that affect the correlation between metric scores and human judgments in text simplification systems?"
https://aclanthology.org/2021.cl-4.27/,"Do existing operation-specific metrics for text simplification accurately assess the simplicity achieved by combining multiple operations such as lexical replacements, deletion, and splitting of sentences?"
https://aclanthology.org/2021.cl-4.28/,Can sequence-level evaluation metrics such as BLEU be used to train Non-Autoregressive Neural Machine Translation models and how can these metrics be effectively used to estimate the quality of NAT outputs?
https://aclanthology.org/2021.cl-4.28/,Can the Bag-of-N-grams training objective be used to improve the performance of Non-Autoregressive Neural Machine Translation models and what are its advantages over traditional word-level objectives?
https://aclanthology.org/2021.cl-4.29/,"What is the impact of different types of ellipses on the accuracy of Google NMT in translating English to Hindi and Telugu, and how does the frequency and reconstruction of ellipses affect translation adequacy? Does the morphological incongruity between source and target languages influence the translation of discourse devices like ellipses?"
https://aclanthology.org/2021.cl-4.30/,"Is it possible to determine whether a given f-structure is acyclic using only finite resources and computational methods, and what are the computational complexities of the methods used? Can off-line parsable LFG grammars be used to generate terminal strings with arbitrary f-structure?"
https://aclanthology.org/2022.cl-1.1/,"Can text augmentation improve the performance of dependency parsing on low-resource languages using mBERT, and how do the results vary across different language families and model architectures? Can text augmentation significantly enhance the performance of part-of-speech tagging and semantic role labeling on morphologically rich languages using pre-trained multilingual contextualized language models?"
https://aclanthology.org/2022.cl-1.2/,Is the proposed approach to document-level novelty detection using pre-trained Textual Entailment models effective in handling multiple source contexts and identifying semantic-level non-novelty?
https://aclanthology.org/2022.cl-1.2/,Can the multipremise entailment task be used to evaluate the novelty of documents in a way that is comparable to other related tasks such as paraphrasing and plagiarism detection?
https://aclanthology.org/2022.cl-1.3/,"Can the modified algorithm in Betty significantly improve the running time of the N-best trees problem compared to the original algorithm, and how does it compare to the state-of-the-art algorithm Tiburon in terms of memory efficiency? Can the modified algorithm be applied to real-world natural language processing tasks to extract the N best trees with improved performance and efficiency?"
https://aclanthology.org/2022.cl-1.4/,Can speech transcripts of Hungarian patients with mild cognitive impairment or mild Alzheimer's disease be effectively distinguished from healthy controls using syntactic features of spontaneous speech?
https://aclanthology.org/2022.cl-1.4/,"Can machine learning models using a combination of linguistic features, including semantic and pragmatic features, achieve high accuracy in distinguishing between Hungarian patients with mild cognitive impairment or mild Alzheimer's disease and healthy controls?"
https://aclanthology.org/2022.cl-1.5/,"Can deep neural models effectively control for politeness in text style transfer, and what are the key factors influencing their performance?"
https://aclanthology.org/2022.cl-1.5/,"Can parallel and non-parallel data be used to train effective neural text style transfer models, and how do they compare in terms of evaluation metrics such as accuracy and fluency?"
https://aclanthology.org/2022.cl-1.6/,"Can probing classifiers accurately predict linguistic properties from transformer-based architectures, and how do their performance metrics compare to traditional methods?"
https://aclanthology.org/2022.cl-1.6/,"Can probing classifiers be used to identify the most informative features for natural language processing models, and what are the implications for model interpretability?"
https://aclanthology.org/2022.cl-1.7/,"Is it feasible to develop an ASR model that can learn from NLU errors and improve its performance over time, and what metrics would be most effective in measuring this improvement?"
https://aclanthology.org/2022.cl-1.7/,"Can a unified, end-to-end approach be designed for ASR and NLU systems that incorporate semantic annotations on spoken input, and how would this impact the overall performance of the dialog system?"
https://aclanthology.org/2022.cl-2.1/,How can affective computing systems be designed to mitigate the risk of exacerbating social inequalities and promoting social justice in emotion recognition and sentiment analysis applications?
https://aclanthology.org/2022.cl-2.1/,"What are the optimal strategies for ensuring the privacy and security of emotional data in affective computing systems, particularly for vulnerable populations such as dissidents and marginalized groups?"
https://aclanthology.org/2022.cl-2.2/,Can transformer-based models be used to improve the accuracy of query-focused text summarization systems by leveraging pre-trained language models and domain adaptation techniques?
https://aclanthology.org/2022.cl-2.2/,Can the application of distant supervision and weakly supervised learning methods enhance the performance of pre-trained transformer-based summarization models for the query-focused text summarization task?
https://aclanthology.org/2022.cl-2.3/,"Can a Transformer-based neural machine translation approach achieve high accuracy on short texts, and how can balancing data distribution and introducing contextual information improve the translation quality of such short texts? Can the incorporation of contextual information into NMT models for short texts reduce mistranslation errors and improve overall translation quality?"
https://aclanthology.org/2022.cl-2.4/,"Can machine learning models be trained to learn and adapt to different annotation schemes and data domains, and what are the most effective heuristics for ordering instances to be annotated in a way that minimizes annotation time while preserving quality, in the context of sentence- and paragraph-level annotation tasks? Can annotation curricula be adapted to specific tasks and expert annotation scenarios to improve data collection and annotation efficiency?"
https://aclanthology.org/2022.cl-2.5/,What is the effect of low arity and dependency length minimization on the distribution of formal properties of crossing dependencies in treebanks?
https://aclanthology.org/2022.cl-2.5/,Do cognitive metrics relating to information locality and working-memory limitations explain the distribution of crossing dependencies in natural languages?
https://aclanthology.org/2022.cl-2.6/,"Can a dual attention model for citation recommendation (DACR) effectively address the shortcomings of conventional citation recommendation methods by considering local context, structural context, and section headers in manuscript preparation? Does DACR improve citation accuracy by learning the importance of each word in the local context and structural context through additive attention and self-attention mechanisms?"
https://aclanthology.org/2022.cl-2.7/,"Can recurrent neural networks learn to understand language using sequential data processing inspired by humans, and what are the optimal learning settings required for compositional interpretation?"
https://aclanthology.org/2022.cl-2.7/,"Can LSTM and GRU networks generalize to compositional interpretation in natural language, and what is the impact of training data and composition direction on their performance?"
https://aclanthology.org/2022.cl-2.8/,"Can neural networks be trained to accurately normalize text with a high degree of accuracy, measured by the percentage of unrecoverable errors eliminated, using only supervised learning methods? Can neural models be designed to effectively handle the challenges of insufficient training data and faulty generalization in text normalization tasks, as evaluated by the system's ability to replace correct readings with alternative interpretations?"
https://aclanthology.org/2022.cl-3.1/,"Can a Monte Carlo procedure be used to estimate the expectation of the sum of dependency distances in random projective permutations of a sentence without incurring a time cost of O(Rn), and what are the implications of using this method for large-scale language analysis?"
https://aclanthology.org/2022.cl-3.1/,"What are the conditions under which star trees maximize the expectation of the sum of dependency distances in random projective permutations of a sentence, and how can these conditions be used to develop more efficient algorithms?"
https://aclanthology.org/2022.cl-3.2/,"Is there a statistically significant correlation between the distribution of edge displacement in training and test data of a given treebank and the parsing performance of a language model, when controlling for covariants?"
https://aclanthology.org/2022.cl-3.2/,Can a measurement of edge displacement be used as a reference to establish lower and upper bounds for parsing performance of a given treebank using a sampling technique?
https://aclanthology.org/2022.cl-3.3/,"What are the factors that contribute to the effectiveness of contextual language adapters in improving the performance of multilingual parsers, and how do these adapters compare to traditional methods of language adaptation in terms of parsing accuracy and computational efficiency?"
https://aclanthology.org/2022.cl-3.3/,"How can the integration of linguistic typology features into multilingual parsing models using contextual language adapters lead to improved performance, particularly in low-resource languages, and what are the key factors that influence this improvement?"
https://aclanthology.org/2022.cl-3.4/,Can CCG parsing be carried out in polynomial time for grammars with a fixed maximum degree of composition?
https://aclanthology.org/2022.cl-3.4/,How does the inclusion of substitution rules in CCG affect its parsing complexity?
https://aclanthology.org/2022.cl-3.5/,"Are multilingual sentence encoders, such as LASER, M-BERT, XLM, and XLM-R, able to encode the patterns of cross-lingual similarity and variation with high accuracy for different languages and typological properties?"
https://aclanthology.org/2022.cl-3.5/,"Can the typological properties of languages, including lexical, morphological, and syntactic structure, be distributed across all layers of state-of-the-art multilingual models in a consistent and meaningful way?"
https://aclanthology.org/2022.cl-3.6/,"Can low-resource machine translation models achieve high accuracy using only a small amount of bilingual training data, and if so, what specific techniques can be used to improve their performance?"
https://aclanthology.org/2022.cl-3.6/,"Can the evaluation of low-resource machine translation models be improved using novel metrics that better reflect the complexities of real-world translation tasks, such as handling out-of-vocabulary words and nuanced cultural references?"
https://aclanthology.org/2022.cl-3.7/,Does the use of position encoding in Transformers improve their performance in sequential tasks such as language modeling or machine translation compared to their baseline models without position encoding? Can position encoding techniques be effectively integrated into existing Transformer models to enhance their ability to capture the nuances of sequential data?
https://aclanthology.org/2022.cl-4.9/,"Can a probabilistic frame semantics model improve the interpretation and generation of novel denominal verb usages compared to state-of-the-art language models, as demonstrated by a comparative analysis of contemporary English and historical data? Can the model effectively capture the shared knowledge between speaker and listener in semantic frames to facilitate more coherent and meaningful denominal verb usages?"
https://aclanthology.org/2022.cl-4.10/,Can pseudo-rehearsal methods using double language models improve the quality of pseudo samples for complex tasks with longer texts and can they be more efficient than traditional methods?
https://aclanthology.org/2022.cl-4.10/,Can the application of adapter modules and temporal ensembling improve the efficiency and quality of pseudo samples in pseudo-rehearsal methods?
https://aclanthology.org/2022.cl-4.11/,"Can dependency parsing models that incorporate a concept of nucleus, as inspired by Tesnière, improve the accuracy of syntactic analysis in languages with different typological characteristics?"
https://aclanthology.org/2022.cl-4.11/,"How does the composition of nuclei, as defined in Universal Dependencies, affect the parsing accuracy of neural transition-based dependency parsers, particularly for main predicates, nominal dependents, clausal dependents, and coordination structures?"
https://aclanthology.org/2022.cl-4.12/,"What are the features used to enhance the discrimination of queries in the proposed neural Q-LID model, and how are they fused by the multi-scale attention mechanism?"
https://aclanthology.org/2022.cl-4.12/,"How does the proposed machine translation-based strategy generate synthetic query-style data for low-resource languages, and what is the composition of the QID-21 test set?"
https://aclanthology.org/2022.cl-4.13/,Can Compositional Distributional Semantics models based on Information Theory improve the accuracy of text representation models in terms of correspondence between embedding and meaning spaces?
https://aclanthology.org/2022.cl-4.13/,Can parameterizable composition and similarity functions in ICDS outperform traditional approaches in textual similarity tasks with varying levels of lexical overlap?
https://aclanthology.org/2022.cl-4.14/,"Can a supervised machine learning model using a transformer-based architecture be trained to predict pragmatic tagging in journal-style post-publication open peer review with high accuracy, using a dataset of at least 10,000 annotated examples?"
https://aclanthology.org/2022.cl-4.14/,"Can the proposed intertextual model of text-based collaboration be evaluated for its ability to align long-document versions of articles in the field of computer science with a precision of at least 90%, using a dataset of at least 5,000 annotated examples?"
https://aclanthology.org/2022.cl-4.15/,"What are the key differences between the hierarchical approach of the proposed HINT model and the existing interpretable neural text classifiers that focus on word-level explanations, and how do these differences impact the interpretability of model predictions in text classification tasks? Can the HINT model be applied to other NLP tasks beyond text classification, and if so, how might its hierarchical approach to explanation generation impact the performance of those tasks?"
https://aclanthology.org/2022.cl-4.16/,Can NEA improve the coherence of LDA topic models by reducing the impact of noisy topics when the number of topics is large?
https://aclanthology.org/2022.cl-4.16/,"Does NEA provide more accurate vector-space embeddings for words, topics, documents, and authors than other state-of-the-art topic models?"
https://aclanthology.org/2022.cl-4.17/,"Can anonymization methods effectively conceal personal information in court cases, as measured by the number of correctly identified and anonymized identifiers, and what is the impact of anonymization on the semantic meaning of the text?"
https://aclanthology.org/2022.cl-4.17/,"Can text anonymization models preserve the utility of the original text while anonymizing personal information, as measured by the F1-score in terms of semantic category detection, and how do anonymization methods compare to traditional de-identification methods?"
https://aclanthology.org/2022.cl-4.18/,"Can a deep learning model accurately predict the optimal placement of diacritics in Arabic orthography to improve readability, and does this improvement extend to translation quality, and how does lookahead information influence the restoration of short vowels during reading?"
https://aclanthology.org/2022.cl-4.18/,Can a neural network that takes into account both the entire sentence and the text that has been read so far be more effective than a reading-order diacritizer in resolving ambiguities in Arabic text?
https://aclanthology.org/2022.cl-4.19/,"Is it possible to develop a standardized framework for assessing the reproducibility of NLP models using metrology-based definitions, and what implications would this have for the evaluation of results from reproduction studies in NLP?"
https://aclanthology.org/2022.cl-4.19/,Can the adoption of metrology-based definitions of repeatability and reproducibility lead to a more comparable and quantifiable assessment of reproducibility across different NLP studies?
https://aclanthology.org/2022.cl-4.20/,"Can the use of implicit training methods for non-expert annotators improve the accuracy of the annotation process compared to traditional explicit training methods in terms of processing time, and can the updated inequality symbol be verified using computational methods? Can the comparison of annotation times for control instances in the updated paper be accurately measured using statistical methods to determine if the p-value is indeed smaller than 0.05?"
https://aclanthology.org/2023.cl-1.1/,"Can appraisal concepts be reliably reconstructed by annotators from textual descriptions of events, and how do their reconstruction accuracy compare to human annotators? Do appraisal concepts help to improve the categorization of emotions in text when used in conjunction with text classification models?"
https://aclanthology.org/2023.cl-1.2/,"Can specialized transformer-based models such as BioBERT and BioMegatron encode large-scale biological knowledge with high accuracy in the biomedical domain, and can these models be fine-tuned to capture specific tasks such as genomic alterations interpretation in cancer precision medicine?"
https://aclanthology.org/2023.cl-1.2/,"Can the probing and clustering methods used to analyze the internal properties of embeddings for genes, variants, drugs, and diseases reveal biases and imbalances in the dataset that affect the models' performance in biomedical applications?"
https://aclanthology.org/2023.cl-1.3/,"Can the proposed approach improve the accuracy of relation extraction by jointly training a classifier and a sequence model to explain its decisions, and what is the performance metric used to evaluate the accuracy of the relation classifier? Does the sequence model improve the performance of the relation classifier when supervised and semi-supervised training strategies are used?"
https://aclanthology.org/2023.cl-1.4/,"Can machine learning-based annotation error detection methods perform consistently across different English datasets, and what are the key factors that influence their generalizability?"
https://aclanthology.org/2023.cl-1.4/,How do the proposed evaluation protocols and best practices improve the reliability of annotation error detection in natural language processing tasks?
https://aclanthology.org/2023.cl-1.5/,"Is it possible to design a more effective annotation scheme for Natural Language Inference that captures human uncertainty and subjective probability assessments, and how can this be achieved through the development of a taxonomy of annotation issues and guidelines?"
https://aclanthology.org/2023.cl-1.5/,Can a pre-trained language model be fine-tuned for improved performance on NLI tasks using an ordered sense space annotation that distinguishes between logical and common-sense inference?
https://aclanthology.org/2023.cl-2.1/,"Can massively multilingual models like mBERT and XLM-R effectively capture the nuances of number agreement across languages, and if so, what are the key neural units responsible for this ability?"
https://aclanthology.org/2023.cl-2.1/,"Do the latent dimensions that encode agreement in mBERT and XLM-R exhibit cross-lingual consistency, particularly in the intermediate layers of the network?"
https://aclanthology.org/2023.cl-2.2/,"Can machine learning algorithms be used to model and analyze the gradual lexical modifications that occur in languages, and what are the implications for understanding the evolution of vocabulary in a dialect?"
https://aclanthology.org/2023.cl-2.2/,Can a graph theory-based approach be applied to identify cognate terms in Malagasy dialects and measure the effects of lexical replacements versus gradual modifications on cognacy within a family of languages?
https://aclanthology.org/2023.cl-2.3/,"Can active learning with human-in-the-loop be used to improve machine translation systems by selecting the most informative queries for human feedback in real-time, without requiring a pool of pre-annotated data, and can combining multiple active learning strategies with prediction and expert advice lead to better results in low-resource settings?"
https://aclanthology.org/2023.cl-2.3/,"Can the proposed active learning approach with dynamic combination of multiple strategies using prediction with expert advice outperform traditional active learning methods in terms of convergence rate and human interaction required, in scenarios where feedback is provided in the form of ratings instead of edited translations?"
https://aclanthology.org/2023.cl-2.4/,What are the most significant words with usage bias for writers from different locations and how do these biases relate to word meaning and grammatical function?
https://aclanthology.org/2023.cl-2.4/,How do topics extracted from immediate and longer contexts impact the prediction of word usage for writers from different genders?
https://aclanthology.org/2023.cl-2.5/,"Can the proposed randomized smoothing method defend against adversarial synonym substitutions and character-level perturbations with a high degree of accuracy, measured by the proportion of certified texts that remain robust to attacks, and what is the required proportion of words to mask in the input text to achieve this level of robustness on the AGNEWS dataset?"
https://aclanthology.org/2023.cl-2.6/,"Can lexical semantics of arguments contribute to the explicit and implicit signaling of contrast and concession relations in discourse, and how do different parts of speech contribute to these semantic relations?"
https://aclanthology.org/2023.cl-2.6/,Can a computational model of discourse relations based on synonymy and antonymy of arguments provide transparent and explainable insights into the signaling of explicit and implicit relations in discourse?
https://aclanthology.org/2023.cl-2.7/,"Can contextualized language models be used to derive high-quality word type embeddings by aggregating their internal representations of individual word instances, and what metrics can be used to evaluate the quality of these embeddings?"
https://aclanthology.org/2023.cl-2.7/,"Can contextualized representations be used to probe and interpret lexical semantic knowledge, and what strategies can be employed to extract meaningful insights from these representations?"
https://aclanthology.org/2023.cl-3.1/,What is the impact of selectively masking words versus randomly masking words on the performance of depression classification models in terms of F1-score?
https://aclanthology.org/2023.cl-3.1/,Can reconstructing the masked words during the pre-training phase improve the performance of depression classification models compared to fine-tuning phase?
https://aclanthology.org/2023.cl-3.2/,Can semi-supervised learning improve the diversity of text generated by a data-to-text system when a large-scale language model is also supplemented?
https://aclanthology.org/2023.cl-3.2/,Can semi-supervised learning approaches with data augmentation or pseudo-labeling improve the output quality of text generated by a data-to-text system when a large-scale language model is also used?
https://aclanthology.org/2023.cl-3.3/,How do dynamic subnetworks for language-specific parameter sharing impact the performance of multilingual language models during fine-tuning?
https://aclanthology.org/2023.cl-3.3/,Can dynamic subnetworks combined with meta-learning improve cross-lingual transfer by reducing conflicts and increasing positive transfer for multilingual models?
https://aclanthology.org/2023.cl-3.4/,"What are the linguistic challenges in the task of Grammatical Error Correction, and what are the most popular datasets available for English and other languages?"
https://aclanthology.org/2023.cl-3.4/,"What metrics are most reliable for evaluating the performance of machine learning-based approaches to Grammatical Error Correction, and what are the challenges in addressing subjective human judgments in this evaluation?"
https://aclanthology.org/2023.cl-3.5/,Can machine learning algorithms be trained to accurately decipher ancient languages with a success rate of at least 90% for at least 50 different scripts?
https://aclanthology.org/2023.cl-3.5/,Can active collaboration between humanities scholars and machine learning engineers lead to significant improvements in the accuracy of ancient text restoration and translation results?
https://aclanthology.org/2023.cl-3.6/,"What are the implications of adopting a Bayesian approach to assessing NLP models, and how might this shift impact institutional policies within the NLP community?"
https://aclanthology.org/2023.cl-3.6/,"Can a plurality of criteria, including scientific explanation, be effectively used to evaluate the performance of NLP models, and what are the potential benefits and drawbacks of this approach?"
https://aclanthology.org/2023.cl-4.1/,"Can a machine learning-based approach be used to improve the accuracy of linguistic analysis in computational linguistics journals, measured by the reduction in error rate, and can it be applied to the current journal within the next two years? Can the current editorial structure of the journal be optimized to increase the reader's engagement, as measured by the increase in comments and shares on social media, within the next six months?"
https://aclanthology.org/2023.cl-4.2/,Can a two-stage annotation pipeline for AIS improve the accuracy of natural language generation models by 20% compared to a traditional annotation approach on a conversational QA dataset?
https://aclanthology.org/2023.cl-4.2/,"Does the use of AIS lead to a significant reduction in model drift after 1000 iterations, as measured by a 15% decrease in syntactic correctness on a summarization dataset?"
https://aclanthology.org/2023.cl-4.3/,Can graph extension grammar with logical formulas in counting monadic second-order logic enable the modeling of non-structural reentrancies in semantic graphs in a linguistically meaningful way?
https://aclanthology.org/2023.cl-4.3/,Does the polynomial time parsing algorithm for local graph extension grammars provide a suitable solution for efficient parsing of graph languages generated by this formalism?
https://aclanthology.org/2023.cl-4.4/,"How can the proposed embedding approach mitigate the sparsity issues in language use data when modeling small areas, and what are the implications of this approach for sociolinguistic research in Texas?"
https://aclanthology.org/2023.cl-4.4/,"Can the embedding models developed in this study accurately map dialects and lexical preferences, and how can these mappings be used to identify sociological variables and their connections to linguistic phenomena?"
https://aclanthology.org/2023.cl-4.5/,"Can BPE subwords for languages with rich inflectional morphology be compressed more efficiently than those for languages with less inflectional morphology, and what are the key morphological patterns that contribute to this difference?"
https://aclanthology.org/2023.cl-4.5/,"Can the proposed BPE subword characterization approach, based on morphological productivity, be used to create language vectors that capture typological knowledge from raw text data without requiring annotated linguistic data or external knowledge?"
https://aclanthology.org/2023.cl-4.6/,Can neural network models learn generalizations about language structure through multilingual training and how can we accurately evaluate these generalizations?
https://aclanthology.org/2023.cl-4.6/,Do existing language representations and typological features match the generalizations learned by neural models?
https://aclanthology.org/2024.cl-1.1/,"What are the core research areas of computational lexical semantics that have been explored in the last 50 years, and how have they been applied to support natural language understanding in various domains?"
https://aclanthology.org/2024.cl-1.1/,"Can machine learning-based approaches using word embeddings and deep learning architectures improve the accuracy of natural language processing tasks, such as sentiment analysis and text classification, in computational lexical semantics?"
https://aclanthology.org/2024.cl-1.2/,"Can a combination of masked language modeling and back-translation improve the performance of machine translation models in low-resource languages, as measured by bilingual word alignment and translation fluency?"
https://aclanthology.org/2024.cl-1.2/,"Does pre-training with monolingual data and multi-task learning significantly enhance the performance of machine translation models on extremely low-resource languages, as evaluated by source language comprehension and accuracy?"
https://aclanthology.org/2024.cl-1.3/,Can Transformer-based language models effectively represent the semantic relations between the head nouns and modifier words of English noun-noun compounds and can distinguish between compounds with the same thematic relation?
https://aclanthology.org/2024.cl-1.3/,Do Transformer-based language models elicit a strong signal of the semantic relations used in noun-noun compounds in both compositional and non-compositional settings?
https://aclanthology.org/2024.cl-1.4/,Can the universal generation problem for Optimality Theory be solved more efficiently than PSPACE when the number of constraints is bounded?
https://aclanthology.org/2024.cl-1.4/,Does the complexity of universal generation for Optimality Theory depend on the specific structure of the constraints rather than their overall number?
https://aclanthology.org/2024.cl-1.5/,"How do transformer models, specifically BERT, RoBERTa, and XLNet, perform on semantic faithfulness when their representations are intervened with deletion and negation, and what is the effectiveness of an intervention-based training regime in mitigating the effects of deletion intervention?"
https://aclanthology.org/2024.cl-1.5/,"Can InstructGPT models handle deletion and negation interventions and capture predicate-argument structure in texts, and how does their performance compare to transformer models in this aspect?"
https://aclanthology.org/2024.cl-1.6/,"Does the use of fine-grained morphological features in training contextual lemmatizers improve performance in downstream NLP applications, and do modern contextual word representations implicitly encode enough morphological information to obtain competitive lemmatizers without explicit morphological signal?"
https://aclanthology.org/2024.cl-1.6/,Can simple UPOS tags or lemmatizers trained without morphology achieve competitive performance in out-of-domain settings for lemmatization tasks?
https://aclanthology.org/2024.cl-1.7/,"What is the most effective way to incorporate Dempster Shafer Theory into a stance detection model to generate explanations for the predicted stance, and what are the key factors that influence the quality of the generated explanations?"
https://aclanthology.org/2024.cl-1.7/,"How can rhetorical parsing be used to construct an evidence tree that provides a clear and informative stance explanation, and what are the benefits of using this approach compared to other methods?"
https://aclanthology.org/2024.cl-1.8/,"Can large language models be used to effectively annotate social science data without human intervention, and what are the performance metrics that would indicate their success? Can large language models generate high-quality explanations for social science phenomena that are comparable to those produced by human annotators and researchers?"
https://aclanthology.org/2024.cl-1.9/,"Can transformer-based language models be fine-tuned to reduce unfactual responses while maintaining or improving their overall text quality, and what specific input features or surface characteristics contribute to this challenge?"
https://aclanthology.org/2024.cl-1.9/,Do large language models' ability to recognize and respond to social biases and commonsense errors correlate with the complexity of their training data and the scale of their parameters?
https://aclanthology.org/2024.cl-1.10/,Can hybrid models that combine elements from different theoretical approaches to explain patterns and idiosyncrasies in the processing of polysemous words be used to improve the accuracy of large language models by capturing a wider spectrum of polysemous sense similarity?
https://aclanthology.org/2024.cl-1.10/,"Can the use of contextualized language models and large-scale annotation efforts provide a more comprehensive understanding of polysemy, enabling the development of benchmarks and testing paradigms for evaluating the performance of language models in handling polysemous words?"
https://aclanthology.org/2024.cl-2.1/,What types of differences appear in AMRs of different languages and what are the causes of these differences in cross-lingual text-to-AMR parsing?
https://aclanthology.org/2024.cl-2.1/,Can AMR capture meaning in cross-lingual pairs as effectively as string-based representations of cross-lingual sentence pairs?
https://aclanthology.org/2024.cl-2.2/,How do large pretrained language models fine-tuned on simulated parallel data improve transliteration accuracy from Latin to native script for full sentences in the Dakshina dataset?
https://aclanthology.org/2024.cl-2.2/,"What is the effect of incorporating contextual information from non-parallel resources, such as mono-script text collections, on transliteration performance for full sentences in South Asia?"
https://aclanthology.org/2024.cl-2.3/,Can a Universal Grammar-inspired approach to event nominals improve the accuracy of event-reading nominalizations in non-inflectional languages like Mandarin Chinese?
https://aclanthology.org/2024.cl-2.3/,Can the application of UG-inspired schema to nominal semantic role labeling increase inter-annotator agreement for event nominals in multilingual data representation?
https://aclanthology.org/2024.cl-2.4/,"Is the use of hierarchical Bayesian modeling a viable alternative to single-number metrics for detecting bias in word embeddings, and what are the implications for evaluating debiasing techniques in this context? Can hierarchical Bayesian modeling provide a more nuanced understanding of bias in word embeddings compared to existing methods?"
https://aclanthology.org/2024.cl-2.5/,"Can a neural topic model incorporating semantic similarity measures outperform traditional LDA in detecting latent topics, especially those that include uncommon words or neologisms in large text corpora?"
https://aclanthology.org/2024.cl-2.5/,Can the proposed evaluation metrics based on intruder words and semantic similarity measures provide a more accurate and comprehensive assessment of topic modeling performance than existing methods?
https://aclanthology.org/2024.cl-2.6/,"Can an end-to-end neural NLP model be designed to provide faithful explanations that accurately represent its reasoning process, and if so, what are the key characteristics of such models?"
https://aclanthology.org/2024.cl-2.6/,"Does the use of similarity-based methods in NLP model explanation effectively promote faithfulness, and what are the limitations of these approaches?"
https://aclanthology.org/2024.cl-2.7/,"Can machine learning algorithms be used to improve the decipherment of the Archanes script and the Archanes formula, specifically by analyzing the distribution of symbols and their frequency of occurrence in the corpus of inscriptions?"
https://aclanthology.org/2024.cl-2.7/,"Can the computational model proposed in this article be used to simulate the decipherment of the Phaistos Disk, and what are the potential limitations and challenges in applying this model to other scripts such as Linear A and Cypriot scripts?"
https://aclanthology.org/2024.cl-2.8/,"What methods can be developed to improve the alignment between linguists and NLP researchers in the prediction of typological features, and how can these methods be evaluated using metrics such as accuracy, precision, and recall?"
https://aclanthology.org/2024.cl-2.8/,"Can the use of language representations, such as word embeddings or dependency parse trees, be used to encapsulate and probe typological features in a way that is both linguistically meaningful and computationally efficient?"
https://aclanthology.org/2024.cl-2.9/,Can pre-registration of NLP experiments reduce the prevalence of coding errors in human evaluation experiments?
https://aclanthology.org/2024.cl-2.9/,Can better code development practices and increased testing and piloting reduce the occurrence of flaws in reported numerical results in NLP evaluation experiments?
https://aclanthology.org/2024.cl-2.10/,"Can a logic-based approach be developed to evaluate the accuracy of hallucination and omission in data-text NLG models, and how does it compare to existing classification frameworks? Can the proposed logic-based synthesis improve the understanding of hallucination and omission in NLG, and what are its implications for Large Language Models?"
https://aclanthology.org/2024.cl-3.1/,Can the application of quality management practices in dataset creation for natural language processing significantly impact the accuracy and reliability of the models trained on those datasets?
https://aclanthology.org/2024.cl-3.1/,Does the use of automated annotation tools in dataset creation for natural language processing lead to a significant reduction in the number of errors and inconsistencies in the dataset?
https://aclanthology.org/2024.cl-3.2/,Can LLMs be used effectively to improve the accuracy of dialogue-level dependency parsing in Chinese through word-level data augmentation?
https://aclanthology.org/2024.cl-3.2/,Can LLMs be used to enhance the diversity and accuracy of dialogue-level dependency parsing in Chinese through discourse-level data augmentation?
https://aclanthology.org/2024.cl-3.3/,"What is the impact of sampling approach on the correlation between automated coherence metrics and human judgment in evaluating topic models, considering the reliability of human response at the group and individual level?"
https://aclanthology.org/2024.cl-3.3/,Does the proposed user study design and analysis of human response against a generic corpus provide a reliable and comprehensive understanding of human perception of coherence in topic models?
https://aclanthology.org/2024.cl-3.4/,"Can a Greedy Maximum Entropy sampler improve the quality of the training sets for Relation Extraction models in the biomedical domain, and how does it compare to standard fine-tuning methods?"
https://aclanthology.org/2024.cl-3.4/,"Can the use of open Large Language Models as synthetic data generators improve the performance of Relation Extraction models, and what are the key factors that influence their effectiveness?"
https://aclanthology.org/2024.cl-3.5/,Can transformer-based models achieve high accuracy in cross-lingual cross-temporal summarization of historical texts using a zero-shot summarizer like GPT-3.5?
https://aclanthology.org/2024.cl-3.5/,Can the performance of GPT-3.5 in cross-lingual cross-temporal summarization be improved by incorporating domain-specific fine-tuning tasks?
https://aclanthology.org/2024.cl-3.6/,What types of task instructions exist and how can they be modeled in a way that enables effective task instruction following?
https://aclanthology.org/2024.cl-3.6/,What factors influence the performance of instruction following systems and how can they be evaluated using relevant metrics?
https://aclanthology.org/2024.cl-3.7/,Can large language models learn and perpetuate social biases through their training data and how can they be formally evaluated for fairness in a way that considers multiple facets of harm and social groups?
https://aclanthology.org/2024.cl-3.7/,"Can existing datasets for bias evaluation be effectively used to develop and train LLMs that produce fair and inclusive text, and what are the challenges in creating new datasets to address emerging social biases?"
https://aclanthology.org/2024.cl-3.8/,"Can a novel alignment-based approach improve the accuracy of constituent parsing results by aligning tokens and sentences in gold and system parse trees, and how does this approach compare to existing evaluation techniques in terms of processing time and accuracy?"
https://aclanthology.org/2024.cl-3.8/,"Does the proposed algorithm for sentence and word alignment enable more reliable evaluation of constituent parsing results by aligning tokens and sentences, and how can this be achieved through the use of pseudo-code and empirical proof?"
https://aclanthology.org/2024.cl-3.10/,"Can language models' words achieve ""word-to-world"" connections, as they refer to external entities or concepts, or are they merely generating coherent but nonsensical strings? Do language models' ability to generate coherent text imply that their words can refer to real-world entities or are they simply mimicking language use?"
https://aclanthology.org/2024.cl-4.1/,"Can Large Language Models be designed to learn from human-like sensory experiences, and if so, how can their learning mechanisms be compared to human cognition?"
https://aclanthology.org/2024.cl-4.1/,"Can the findings from cognitive science be applied to improve the performance of Large Language Models, particularly in terms of grounding and modality access?"
https://aclanthology.org/2024.cl-4.2/,"Can LLMs accurately capture the nuances of generics in language, including the distinction between universally quantified statements and generic generalizations, and can they reason about exceptions and property inheritance in a way that is similar to human cognition? Do LLMs exhibit similar overgeneralization behavior to humans when considering property inheritance from generics?"
https://aclanthology.org/2024.cl-4.3/,"Can large language models capture the essence of human language acquisition through text-based input, and what are the implications of this design choice on their performance in tasks such as logical and pragmatic reasoning and bias detection?"
https://aclanthology.org/2024.cl-4.3/,"Can a situated and communicative approach to language modeling, which incorporates artificial agents participating in interactive dialogues, lead to more human-like language processing in machines, and what benefits can be expected in terms of data efficiency and generalizability?"
https://aclanthology.org/2024.cl-4.4/,"Can humans construct explicit and declarative semantic content for unfamiliar pseudoword forms using a flexible form-to-meaning mapping system based on statistical regularities in the language environment, and can this system accommodate novel lexical entries as soon as they are encountered? Does the use of human-generated definitions for pseudowords result in definitions that are closer to their respective pseudowords than definitions for actual words?"
https://aclanthology.org/2024.cl-4.5/,"What are the roles of sounds, gestures, and linguistic units in the speech acquisition and control of humans, and how can self-supervised deep learning methods be used to uncover the underlying relationships between these factors?"
https://aclanthology.org/2024.cl-4.5/,Can a self-supervised deep learning approach using vector-quantized variational autoencoders improve the intelligibility of speech productions by a computational agent that controls a virtual vocal apparatus and integrates articulatory and acoustic models?
https://aclanthology.org/2024.cl-4.6/,"Can a minimal cognitive architecture with reinforcement learning be used to induce grammar rules from a stream of words, and what are the implications of this approach for understanding human language acquisition? Does the use of sequence memory in the model enhance its ability to generalize to new linguistic contexts?"
https://aclanthology.org/2024.cl-4.7/,"How do Multimodal Large Language Models (MLLMs) integrate distinct modalities, and what is the degree of integration that mirrors the mechanisms believed to underpin grounding in humans?"
https://aclanthology.org/2024.cl-4.7/,"Do MLLMs, particularly ViLT and CLIP architectures, accurately predict human responses to sensorimotor features, and if so, what is the impact on their predictive power?"
https://aclanthology.org/2024.cl-4.8/,"Can large language models process recursively nested grammatical structures as reliably as humans when evaluated comparably, and what are the implications of this finding for the broader challenge of comparing human and model capabilities? Does the use of a simple prompt with less content than human training significantly affect the performance of large language models on this task?"
https://aclanthology.org/2024.cl-4.9/,"Can EEG signals be used to predict the temporally tuned MT-LSTM embeddings with high accuracy for both near and distant words, and what is the optimal time window for prediction across different timescales?"
https://aclanthology.org/2024.cl-4.9/,"Can the neural mechanisms of the brain process short timescale information in a way that is distinct from the vicinity of word onset, and how do computational models such as MT-LSTMs capture this discrepancy?"
https://aclanthology.org/2024.cl-4.10/,"Can large language models achieve consistent understanding of a concept across different languages and paraphrases, as measured by their ability to provide accurate and coherent responses to a range of tasks, including factual queries and natural language inference? Does the training data of large language models on text only limit their ability to generalize and understand the nuances of human language?"
https://aclanthology.org/2024.cl-4.11/,"Can Wav2Vec2 accurately recognize assimilated sounds in speech, and if so, what linguistic context cues does it rely on to compensate for these sounds? Does the model's final layers interpret assimilated sounds in their underlying form, and if so, how does this interpretation improve the model's overall speech recognition accuracy?"
https://aclanthology.org/2025.cl-1.1/,Can the development of a more efficient indexing algorithm for the journal's digital archives improve the search functionality and user experience of the Computational Linguistics online platform within the next two years? Can the integration of machine learning-based approaches to content analysis and recommendation enhance the overall quality and discoverability of published articles in the journal by 2026?
https://aclanthology.org/2025.cl-1.2/,How can the Proteus Project's collaborative model be evaluated for its impact on knowledge sharing among its members?
https://aclanthology.org/2025.cl-1.2/,Can the use of artificial intelligence in facilitating knowledge sharing among researchers be compared to traditional collaborative models in the Proteus Project?
https://aclanthology.org/2025.cl-1.3/,"Can the enhanced rhetorical structure theory (eRST) improve the accuracy of discourse relation graph construction in non-projective and concurrent relations, as measured by the number of correct relations identified? Can the eRST framework increase the explainability of discourse analysis by incorporating implicit and explicit signals, as evaluated by the proportion of rationales that align with human annotators' judgments?"
https://aclanthology.org/2025.cl-1.4/,"Can metrics be designed to effectively identify the range of translation accuracy errors, including those based on discourse and real-world knowledge, in machine translation systems? Can large language models be used as reliable evaluators of machine translation metrics, particularly when the target language is similar to the source language?"
https://aclanthology.org/2025.cl-1.5/,"Can vector-based and syntax-based models of compositionality capture the nuanced patterns of human semantic similarity judgments when tested on a large, diverse dataset?"
https://aclanthology.org/2025.cl-1.5/,Can the combination of syntax- and vector-based components in a hybrid model improve its performance in capturing human semantic similarity when compared to individual models?
https://aclanthology.org/2025.cl-1.6/,"Can the proposed framework effectively preserve style and meaning in synthetic user-generated content while minimizing divergence from real-world language patterns, and how do generation strategies impact the quality of synthetic data in terms of style, meaning, and downstream performance?"
https://aclanthology.org/2025.cl-1.6/,"Can the evaluation framework's metrics accurately measure the quality of synthetic user-generated content in terms of style preservation, meaning preservation, and divergence, and how do the results inform the development of high-quality synthetic language data for various applications?"
https://aclanthology.org/2025.cl-1.7/,Can a neural model trained on a hierarchical lexical ontology achieve better performance on out-of-vocabulary concepts compared to a model trained on a traditional meaning representation format?
https://aclanthology.org/2025.cl-1.7/,"Does a compositional symbolic representation based on a neural ""taxonomical"" parser outperform a traditional neural semantic parser in terms of interpretability and semantic accuracy?"
https://aclanthology.org/2025.cl-1.8/,What are the limitations of existing datasets used for Large Language Model (LLM)-generated text detection and how can they be strengthened to better address the challenges posed by evolving LLMs?
https://aclanthology.org/2025.cl-1.8/,"How can the detection of LLM-generated text be improved through the integration of human-assisted methods and neural-based detectors, and what are the potential applications of such advancements in safeguarding domains like artistic expression and social networks?"
https://aclanthology.org/J17-1000/,"How can a hybrid symbolic/statistical approach be designed to improve the fluency of verbalized knowledge base queries, as measured by user satisfaction ratings, by effectively integrating handwritten grammar, statistical hypertagging, and surface realization algorithms?"
https://aclanthology.org/J17-1000/,"Can a hybrid approach combining symbolic and statistical methods outperform a purely symbolic approach in terms of processing speed and coverage when verbalizing knowledge base queries, as evaluated through quantitative metrics such as accuracy and latency?"
https://aclanthology.org/J17-1001/,What is the most effective way to incorporate distributional information into the word sense disambiguation model to weigh the influence of each word on the decisions of others in an evolutionary game theory framework?
https://aclanthology.org/J17-1001/,How can the model be adapted to accommodate different scenarios and tasks by analyzing the combination of similarity measures that yield the best results in word sense disambiguation?
https://aclanthology.org/J17-1002/,How do different levels of supervision affect the accuracy of metaphorical association patterns discovered by a machine learning algorithm in flat and hierarchical clustering settings?
https://aclanthology.org/J17-1002/,Can statistical methods with little or no annotation facilitate the scalability and adaptability of metaphorical association models across languages from different language groups?
https://aclanthology.org/J17-1003/,"What are the most effective machine learning methods for identifying argument components in user-generated Web discourse, considering the complexity of registers, domains, and noise in the data?"
https://aclanthology.org/J17-1003/,How can argumentation models adapted from normative theories be applied to real-world user-generated Web discourse to improve the accuracy of argument component identification?
https://aclanthology.org/J17-1004/,"Has the proposed algorithm's accuracy in disambiguating hashtags is comparable to or surpasses that of existing methods, as measured by the F1-score on a large-scale dataset of micro-blogs?"
https://aclanthology.org/J17-1004/,"Can the algorithm be adapted to handle the variability in language and time period, and its performance be evaluated using metrics such as precision and recall in a real-world scenario?"
https://aclanthology.org/J17-1005/,"Does the inclusion of linguistic insights in sentiment analysis systems improve their accuracy in capturing the nuances of human evaluation, measured by the F1-score of the system?"
https://aclanthology.org/J17-1005/,"Can the application of update functions in sentiment analysis systems account for the dynamic nature of evaluation, incorporating contextual factors and improving the extraction of sentiment from evaluative words and expressions?"
https://aclanthology.org/J17-2000/,"Can bilingual lexicon induction be improved by incorporating more features that capture contextual and temporal information in the training data, and can a discriminative approach outperform a generative approach in terms of translation quality for low-frequency words? Does the use of larger seed bilingual dictionaries and monolingual training corpora impact the accuracy of bilingual lexicon induction?"
https://aclanthology.org/J17-2001/,How can a stack-based LSTM architecture be used to improve the efficiency of transition-based parsers in handling out-of-vocabulary words in morphologically rich languages?
https://aclanthology.org/J17-2001/,"Can a character-based word representation approach be used to enhance the robustness of transition-based parsers in handling errors, and what are the implications for training with dynamic oracles?"
https://aclanthology.org/J17-2002/,"Can the proposed model be applied to other language pairs with varying levels of transliteration noise, and what are the potential challenges and limitations of its use in such cases? Can the model be fine-tuned to improve its performance on specific language pairs with high transliteration noise?"
https://aclanthology.org/J17-2003/,Can a machine learning model using acoustic cues and parse tree structures to identify verbal indicators of confusion in Alzheimer's patients with an accuracy of at least 90%?
https://aclanthology.org/J17-2003/,Can a partially observable Markov decision process be used to develop a dialogue strategy that avoids confusion in speech with an accuracy of at least 96.1% for individuals with middle-stage AD?
https://aclanthology.org/J17-2004/,"What is the role of psycholinguistic concreteness norms in the proposed question answering approach, and how do these norms contribute to the construction of answer justifications?"
https://aclanthology.org/J17-2004/,How does the proposed method evaluate justification quality and what metrics are used to assess the performance of the answer justifications?
https://aclanthology.org/J17-2005/,Can referential overspecification of object attributes affect the processing time of target object recognition in REG tasks when the overspecified attribute is a visual feature versus a semantic attribute? Does referential overspecification of visual features lead to more accurate object recognition than overspecification of semantic features in REG tasks?
https://aclanthology.org/J17-3000/,"What are the implications of using hybrid grammars to separate discontinuity in parsing algorithms for non-projective dependency structures, and how can they be optimized for efficient parsing in a time complexity of O(n)?"
https://aclanthology.org/J17-3000/,"Can hybrid grammars effectively handle the complexities of discontinuous phrase structures by integrating lexical elements from synchronous grammars, and what are the potential limitations of this approach in terms of accuracy and parse failure rates?"
https://aclanthology.org/J17-3001/,"Can we develop a hierarchical alignment scheme that reduces translation divergences by eliminating conflicts and redundancies between word alignments and syntactic parses in Chinese-English parallel trees, and evaluate its effectiveness in identifying and categorizing translation divergences?"
https://aclanthology.org/J17-3001/,Can we extract syntax-based translation rules from the Hierarchically Aligned Chinese–English Parallel Treebank (HACEPT) and assess their expressiveness in capturing translation divergences between Chinese and English?
https://aclanthology.org/J17-3002/,Can a nonparametric approach using Reproducing Kernel Hilbert Space (RKHS) representations improve the accuracy of quantifying geographical language variation in dialectal analysis compared to existing parametric models?
https://aclanthology.org/J17-3002/,"Does the proposed test statistic based on geotagged observations perform better in detecting linguistic variables in different types of data, such as tweets, syntactic atlases, and letters to the editor, compared to existing methods?"
https://aclanthology.org/J17-3003/,"Can AutoExtend improve the performance of word embeddings by incorporating semantic information from WordNet, GermaNet, and Freebase for non-word objects like synsets and entities compared to traditional word embeddings, measured by Word-in-Context Similarity task accuracy?"
https://aclanthology.org/J17-3003/,"Does the use of a sparse tensor formalization in AutoExtend enable efficient and parallelizable encoding and decoding of word embeddings that incorporate semantic information from various resources, such as WordNet, GermaNet, and Freebase?"
https://aclanthology.org/J17-3004/,"Can the proposed model achieve higher accuracy in identifying argument components by utilizing pre-training on a larger corpus of annotated persuasive essays, and can the use of Integer Linear Programming improve the detection of argumentative relations in discourse?"
https://aclanthology.org/J17-3005/,"Can a variation of the γcat coefficient be used to assess the agreement on categorization of predefined units in a continuum, and how does it compare to existing measures such as Krippendorff's α in terms of accuracy and processing time?"
https://aclanthology.org/J17-3005/,"Can the proposed γcat coefficient be used to evaluate the agreement on unitization in tasks that involve continuous positioning and categorization, and what are the implications for the evaluation of annotators' performance?"
https://aclanthology.org/J17-4000/,How can discourse-aware similarity measures using all-subtree kernels improve the correlation between machine translation evaluation metrics and human judgments at the segment level and at the system level?
https://aclanthology.org/J17-4000/,Can the inclusion of discourse elements and relations from the Rhetorical Structure Theory parse trees enhance the accuracy of machine translation evaluation metrics?
https://aclanthology.org/J17-4001/,Can a machine learning model trained on native English data with a small annotated sample of non-native writer errors achieve state-of-the-art performance in text correction tasks?
https://aclanthology.org/J17-4001/,"Can a generative or discriminative classifier be adapted to incorporate knowledge of error regularities from a small annotated sample of non-native writer errors, and how does this adaptation impact performance on text correction tasks?"
https://aclanthology.org/J17-4002/,What linguistic structures do recurrent neural networks learn and how do they contribute to the final prediction in a multi-task gated recurrent network architecture?
https://aclanthology.org/J17-4002/,"Can language models selectively pay attention to lexical categories, grammatical functions, or syntactic constructions when predicting the next word in a sentence?"
https://aclanthology.org/J17-4003/,Can a hypernymy-hypernym model utilizing a transformer-based architecture be able to accurately capture the typicality and strength of lexical entailment relations as perceived by human participants in a crowdsourced evaluation?
https://aclanthology.org/J17-4003/,Can the application of human-annotated graded lexical entailment datasets improve the performance of distributional and representation learning models in predicting human-graded lexical entailment relations?
https://aclanthology.org/J17-4004/,"Can MWE processing be achieved with high accuracy using a deep learning-based approach that integrates MWE discovery and identification, and if so, what are the optimal parameters for such an approach?"
https://aclanthology.org/J17-4004/,How do the timing of MWE processing with respect to parsing and machine translation use cases impact the design of MWE-aware systems in terms of accuracy and efficiency?
https://aclanthology.org/J18-1000/,"Can probabilistic finite-state automata be used to improve the accuracy of speech recognition systems by optimizing the entropy of their state sequences, and how can the derivational entropy be computed efficiently for weighted finite-state automata with a normalized model?"
https://aclanthology.org/J18-1001/,"Can a coherence-based approach to processing underspecified representations improve the efficiency of existing algorithms for handling quantifier scope in natural language sentences, and can it cover all previously identified tractable sets of representations? Can a coherence-based approach to processing underspecified representations reduce the computational complexity of solving constraint-based underspecified representations of quantifier scope to a polynomial time algorithm?"
https://aclanthology.org/J18-1002/,What is the relationship between the size of the cache and the type of graphs that can be produced through tree decomposition?
https://aclanthology.org/J18-1002/,Can small cache sizes effectively cover a high percentage of sentences in existing semantic corpora?
https://aclanthology.org/J18-1003/,"Can the use of DAG automata for natural language processing lead to more accurate linguistic models by capturing the complex relationships between words and their contexts, and can the proposed extension to graphs with unbounded node degree improve the scalability of these models?"
https://aclanthology.org/J18-1003/,"Can a practical recognition algorithm for DAG automata be developed to facilitate inference and learning in natural language processing, and how can this algorithm be applied to extend the formalism to graphs with unbounded node degree?"
https://aclanthology.org/J18-2000/,"Does the adoption of a dependency perspective on RST structures improve the evaluation of RST discourse parsers, and what are the implications for the implementation of RST parsers in terms of headedness?"
https://aclanthology.org/J18-2000/,Can a unified evaluation framework that combines constituency and dependency metrics effectively compare and contrast the performance of RST parsers using different parsing strategies?
https://aclanthology.org/J18-2001/,What is the effectiveness of a two-stage statistical global inference method in bridging anaphora recognition using a cascading collective classification approach?
https://aclanthology.org/J18-2001/,Can semantic and salience features for antecedent selection improve the performance of bridging antecedent selection in joint inference models?
https://aclanthology.org/J18-2002/,"What is the mathematical structure of the derivations in displacement calculus, and how does it relate to multiplicative spurious ambiguity?"
https://aclanthology.org/J18-2002/,"Can proof nets for additives in displacement calculus be characterized, and what implications does this have for addressing polymorphism in grammar?"
https://aclanthology.org/J18-2003/,What is the computational complexity of learning stress patterns using state-merging in k-testable languages with varying amounts of context?
https://aclanthology.org/J18-2003/,"Can stress patterns in languages be effectively learned using a k-testable language learner that considers both left and right context, and what is the optimal amount of context required for successful learning?"
https://aclanthology.org/J18-2004/,"Can the proposed probabilistic hierarchical clustering model be applied to hierarchical clustering of other types of data besides morphological segmentation, and what are the potential benefits and limitations of such applications?"
https://aclanthology.org/J18-2004/,"Can the hierarchical Dirichlet process used in the model be used to improve the performance of existing supervised morphological segmentation systems, and what would be the evaluation metric for such improvements?"
https://aclanthology.org/J18-3000/,Does BLEU scores correlate with the real-world utility and user satisfaction of machine translation systems?
https://aclanthology.org/J18-3000/,Does BLEU scores have any correlation with the evaluation of individual texts outside of machine translation systems?
https://aclanthology.org/J18-3001/,Can ensemble methods using multiple classifiers improve the accuracy of Native Language Identification by leveraging different machine learning algorithms for each language classification task?
https://aclanthology.org/J18-3001/,"Can the application of meta-classification models in ensemble-based approaches lead to state-of-the-art results in Native Language Identification, especially when using different ensemble architectures such as classifier stacking?"
https://aclanthology.org/J18-3002/,"What is the impact of including the size of the grammar in the analysis of the time complexity of parsing in Combinatory Categorial Grammar, and how does this affect the overall parsing time?"
https://aclanthology.org/J18-3002/,"Does a mildly context-sensitive version of Combinatory Categorial Grammar exist, and what features would make such a version more efficient than the current formalism?"
https://aclanthology.org/J18-3003/,Can unsupervised methods leveraging distributional similarity be used to identify meaningful multi-word expressions in languages with limited annotated data?
https://aclanthology.org/J18-3003/,Can a dense neural-based distributional semantic model outperform sparse count-based methods in the task of decomposing close compounds into their constituent parts?
https://aclanthology.org/J18-3004/,Can the proposed log-linear model with latent variables be effectively optimized using contrastive divergence for decipherment tasks with large vocabularies?
https://aclanthology.org/J18-3004/,Can the proposed log-linear model with latent variables preserve its accuracy when trained on low-resource language pairs?
https://aclanthology.org/J18-3005/,"Can non-nominal-antecedent anaphora be accurately annotated and resolved using machine learning algorithms that can effectively identify non-nominal antecedents, and how does this approach compare to existing methods for nominal-antecedent anaphora?"
https://aclanthology.org/J18-3005/,"Can the computational resolution of non-nominal-antecedent anaphora be improved by incorporating linguistic properties and annotation efforts into machine translation, summarization, and question answering systems?"
https://aclanthology.org/J18-4000/,"Can the Language Resource Switchboard (LRS) effectively recommend language processing tools that meet the specific needs of users based on their available resources and tasks, measured by the accuracy of tool selection and the speed of processing?"
https://aclanthology.org/J18-4000/,Can the LRS efficiently integrate and invoke the selected tools to process the identified resources in a way that minimizes the required tool parameterization and maximizes the overall processing speed?
https://aclanthology.org/J18-4001/,"Is it possible to develop a more efficient method for authors to share their code and data in computational linguistics papers, and if so, what specific tools or platforms would be most effective in facilitating this process?"
https://aclanthology.org/J18-4001/,"Can the reproducibility of computational linguistics research be improved by implementing a system that automatically checks for and verifies the availability of source code and data, and if so, what are the potential benefits and challenges of such a system?"
https://aclanthology.org/J18-4002/,"Can the application of deep learning-based approaches to improve the accuracy of information extraction for entities, relations, and/or events be justified given the current state of the field and the existing practical deployments? Does the development of more robust and efficient algorithms for handling complex scenarios and edge cases significantly impact the overall performance of information extraction systems?"
https://aclanthology.org/J18-4003/,"Can a contextualized approach incorporating both linguistic and meta-data features improve the accuracy of sentiment analysis on social media text, as measured by the F1-score? Does the use of multimodal context, including user profiles and social network interactions, enhance the performance of topic modeling on social media data, evaluated by the number of accurately identified topics?"
https://aclanthology.org/J18-4004/,"Can a machine learning model using bag-of-words features accurately predict the extremes of affect, investment, and alignment stancetaking in online conversations based on lexical features?"
https://aclanthology.org/J18-4004/,Can the linguistic properties of stancetaking in online conversations be characterized using a small labeled training set of annotated conversation threads?
https://aclanthology.org/J18-4005/,"Can a hierarchical topic modeling approach that incorporates discourse roles and latent topics improve topic extraction from short microblog messages, as compared to conventional topic models? Does the proposed model achieve better coherence and topic modeling performance in comparison to existing models on large-scale microblog corpora?"
https://aclanthology.org/J18-4006/,Does modeling conversation context improve the accuracy of sarcasm detection in social media discussions and what specific aspects of conversation context contribute to this improvement? Can LSTM models with attention identify the sentence that triggered a sarcastic reply in a multi-sentence post?
https://aclanthology.org/J18-4007/,"Can implicit sentiment analysis improve the accuracy of irony detection in natural language text, and how does the integration of a lexico-semantic knowledge base affect the performance of a state-of-the-art irony classifier?"
https://aclanthology.org/J18-4007/,Does the incorporation of implicit sentiment information into an irony detection system using data-driven methods lead to better handling of nuanced and context-dependent expressions?
https://aclanthology.org/J18-4008/,"Can a deep learning method for relation-based argument mining be used to determine whether news articles support tweets and extract argumentative relations of attack and support, and how does it perform in fact-checking settings? Can a method for extracting bipolar argumentation frameworks from reviews be used to detect whether they are deceptive, and what are the advantages of using this method in combination with other features in supervised classifiers?"
https://aclanthology.org/J18-4009/,Can a hybrid approach combining LSTM-RNN with CRF model achieve higher accuracy in speech act recognition in asynchronous conversations compared to using LSTM-RNN alone?
https://aclanthology.org/J18-4009/,Can the use of domain adversarial training of neural networks improve the domain-invariant representations of LSTM-RNN models for speech act recognition in asynchronous conversations?
https://aclanthology.org/J19-1000/,"Can distributional semantic models accurately capture idiomaticity in nominal compounds across languages, and how do model and corpus parameters affect this ability, while also considering the impact of morphological variation and corpus size? Can the uniform combination of components in a compound improve the accuracy of compositionality prediction in different languages?"
https://aclanthology.org/J19-1001/,"Can the proposed neural semantic parser achieve high accuracy in mapping natural language utterances to logical forms using a combination of generic tree-generation algorithms and domain-general grammars, and what is the impact of the attention mechanisms on the parser's performance in handling mismatches between natural language and logical form tokens?"
https://aclanthology.org/J19-1002/,"What is the most effective method for representing grammatical information in Mandarin Chinese using directed dependency graphs, considering both local and long-distance dependencies?"
https://aclanthology.org/J19-1002/,"How can data-driven models, specifically graph-based and transition-based parsing, be used to improve the accuracy of Chinese grammatical relation analysis using the Chinese TreeBank?"
https://aclanthology.org/J19-1003/,"Can a machine learning algorithm using a network approach be able to accurately infer sound correspondence patterns across multiple languages, and if so, what metrics can be used to evaluate its performance? Can the proposed method effectively identify the core of regularly recurring sound correspondences by excluding patterns that occur in only a few cognate sets?"
https://aclanthology.org/J19-1004/,"Can a sequential convolutional network improve the accuracy of response selection for multi-turn conversation in retrieval-based chatbots by effectively capturing the relationships among utterances in a conversation context, as measured by the F1-score of the matched response candidates? Can sequential attention networks leverage the interaction between utterances and response candidates to improve the contextual understanding and matching performance in retrieval-based chatbots, as evaluated by the precision of the matched response candidates?"
https://aclanthology.org/J19-2001/,"Can a Bayesian model learn good latent representations of languages that can accurately infer typological features from incomplete data, and what is the impact of using phylogenetically and/or spatially related languages on the model's performance in recovering missing values?"
https://aclanthology.org/J19-2001/,"Can the proposed model's ability to handle complex dependencies among features in an implicit manner be improved by incorporating additional clues from phylogenetic and/or spatial relationships, and what is the effect of this incorporation on the model's overall accuracy?"
https://aclanthology.org/J19-2002/,"What are the most accurate methods for detecting and classifying historical events in text, given the newly introduced 22-class annotation guidelines, and what is the processing time required for these methods to achieve high accuracy?"
https://aclanthology.org/J19-2002/,"How can the proposed annotation guidelines and models for event detection and classification be used to improve the efficiency of historians in processing historical texts, and what are the potential applications of these tools in the field of Natural Language Processing?"
https://aclanthology.org/J19-2003/,Can a tree-to-sequence NMT model with attention mechanism be more accurate than a traditional sequence-to-sequence model in Chinese-to-Japanese translation when the training data set is small?
https://aclanthology.org/J19-2003/,Can a bi-directional encoder be more effective than a tree-to-sequence model with syntactic structure as the size of the training data set increases?
https://aclanthology.org/J19-2004/,"What are the effectiveness of using finite-state covering grammars to improve the accuracy of text normalization in text-to-speech synthesis, and how can the learning of such grammars be integrated into the training and decoding process of neural network models?"
https://aclanthology.org/J19-2004/,"Can the integration of finite-state covering grammars into the training and decoding process of neural network models for text normalization in text-to-speech synthesis improve the overall accuracy and efficiency of the models, and what are the implications for the handling of ""unrecoverable"" errors in verbalizations?"
https://aclanthology.org/J19-2005/,Can the proposed algorithms for extracting Hyperedge Replacement Grammar rules from a graph be generalized to handle graphs with dynamic vertex orders?
https://aclanthology.org/J19-2005/,Can the proposed polynomial-time algorithms for parsing based on Hyperedge Replacement Grammars be evaluated for their ability to accurately represent complex semantic structures in natural language?
https://aclanthology.org/J19-2006/,"Can a multilingual neural language model trained on a translated text corpus capture linguistic structural similarities between languages, and how does this relate to genetic and geographical similarities?"
https://aclanthology.org/J19-2006/,Do multilingual neural language models learn to represent languages in a way that is more closely tied to their genetic and geographical characteristics than their structural similarities?
https://aclanthology.org/J19-3001/,"Can a compositional distributional method using monolingual corpora effectively generate contextualized senses of words and identify their appropriate translations in target languages, measured by the accuracy of translations?"
https://aclanthology.org/J19-3001/,"Can the bilingual vector space created through transfer rules and a bilingual dictionary facilitate the translation of phrases in restricted syntactic domains, such as phrasal verbs, using nearest neighbor search and incremental composition?"
https://aclanthology.org/J19-3002/,"Can the Watset algorithm be optimized to reduce its computational complexity, while maintaining its competitive results in various applications, using techniques such as parallel processing or distributed computing?"
https://aclanthology.org/J19-3002/,"Does the use of hard clustering in the Watset algorithm improve the accuracy of fuzzy graph clustering, as measured by the number of correctly identified clusters, compared to other clustering methods?"
https://aclanthology.org/J19-3003/,Can the application of Zipf’s law to n-gram language models improve their accuracy in capturing the global structure of natural language text?
https://aclanthology.org/J19-3003/,Does the exponent of Taylor’s law serve as a reliable indicator of model quality for computational models of natural language?
https://aclanthology.org/J19-3004/,"What is the effect of translation quality on the performance of existing automatic machine translation evaluation metrics, and can a local dependency measure improve their performance?"
https://aclanthology.org/J19-3004/,Can neural machine translation systems benefit from using a metric that is specifically designed to evaluate nuanced quality distinctions in low-quality translations?
https://aclanthology.org/J19-3005/,"Can machine learning algorithms be adapted to effectively utilize the continuous nature of typological features, improving NLP system performance, as measured by accuracy, and how can recent data-driven methods for inducing typological knowledge be integrated with NLP techniques to achieve this goal? Can the existing typological databases be improved to provide more granular and relevant features for NLP applications, and what are the computational methods required to achieve this?"
https://aclanthology.org/J19-4001/,"What role do discourse features in multimedia text play in conveying meaning, and how can they be effectively leveraged in NLP tasks? Can the structure of multimedia text improve the accuracy and explainability of a geometry problem solver?"
https://aclanthology.org/J19-4002/,"Can a machine learning approach using orthographic alignment and machine learning algorithms improve the accuracy of cognate detection in historical linguistics, and what are the underlying linguistic factors that contribute to this improvement?"
https://aclanthology.org/J19-4002/,"Can a machine learning method for reconstructing proto-words using ensemble systems and leveraging information from multiple languages be able to improve upon previous results in historical linguistics, and what are the requirements for achieving such improvements?"
https://aclanthology.org/J19-4003/,Can a recursive neural network based on dependency trees improve aspect and opinion term extraction accuracy in cross-domain scenarios when paired with a sequence labeling classifier?
https://aclanthology.org/J19-4003/,Can a conditional domain adversarial network effectively reduce domain distribution differences in word-level representations using syntactic relations as a pivot for transfer learning in fine-grained opinion mining?
https://aclanthology.org/J19-4004/,Can the proposed modular pipeline-based approach to data-to-text generation using monolingual corpora and basic off-the-shelf NLP tools improve the scalability and domain adaptability of existing end-to-end statistical and neural architectures in generating natural language descriptions from structured data?
https://aclanthology.org/J19-4004/,"Can the sentence compounding and co-reference replacement modules in the proposed system effectively generate coherent and fluent paragraph descriptions from canonicalized structured data, and what are the key performance metrics for evaluating their effectiveness?"
https://aclanthology.org/J19-4005/,Is there an effective method to automatically identify and extract the structure of inference and reasoning expressed in financial news articles using machine learning algorithms?
https://aclanthology.org/J19-4005/,Can natural language processing models be able to accurately extract the underlying arguments and reasoning in social media posts?
https://aclanthology.org/J19-4006/,"Can the proposed temporal distance of one to one-and-a-half millennia be used as a reliable criterion for distinguishing between language and dialect pairs, and if so, how does it impact our understanding of language evolution and change? Does the bimodal distribution of linguistic distances in the database support the idea that languages are not static entities, but rather dynamic systems that evolve over time?"
https://aclanthology.org/J74-1000/,"What are the key differences in the microfiche viewing equipment guide and the computer-assisted lexicography bibliography, and how do these differences impact the accuracy and efficiency of lexicographic tasks?"
https://aclanthology.org/J74-1000/,"Can the computer-assisted lexicography system be improved to reduce its reliance on human intervention and increase its overall processing time, and if so, what modifications would be necessary to achieve this improvement?"
https://aclanthology.org/J74-2000/,Can a machine learning approach using a transformer-based architecture improve the accuracy of a rule-based system for sentiment analysis in text data?
https://aclanthology.org/J74-2000/,Can a natural language processing technique be developed to automatically generate accurate and relevant metadata for digital libraries?
https://aclanthology.org/J74-3000/,"Can a supervised learning algorithm using a Recurrent Neural Network (RNN) architecture be used to improve the accuracy of sentiment analysis for text classification in the humanities, measured by the F1 score, and what are the key challenges in adapting RNNs for this task?"
https://aclanthology.org/J74-3000/,"Can a text summarization system utilizing a long short-term memory (LSTM) network be designed to reduce the processing time of literary texts to 30 seconds or less, and how can the performance of the system be evaluated using a combination of human evaluation and automated metrics such as ROUGE and BLEU?"
https://aclanthology.org/J74-3001/,"What is the feasibility of using a machine learning model to automate the process of generating reports from unstructured text, specifically the Secretary-Treasurer's report and Editor's report, and how can its accuracy be measured?"
https://aclanthology.org/J74-3001/,"Can a natural language processing technique be developed to improve the efficiency and effectiveness of the report generation process, leveraging the features of the Secretary-Treasurer's report and Editor's report, and what metrics would be most suitable for evaluation?"
https://aclanthology.org/J74-3002/,Can a deep learning approach utilizing a transformer-based architecture be applied to improve the accuracy of a named entity recognition system for handling out-of-vocabulary words in a large corpus of text data?
https://aclanthology.org/J74-3002/,Can the use of transfer learning and fine-tuning of a pre-trained language model on a smaller dataset be an effective strategy for adapting to domain-specific terminology in a text classification task?
https://aclanthology.org/J75-1000/,"Is the proposed document access system based on existing information retrieval techniques, and how will its performance be measured in terms of query accuracy and response time? Can a supervised machine learning approach using a transformer-based architecture improve the indexing and retrieval capabilities of the proposed document access system?"
https://aclanthology.org/J75-2000/,Can machine translation systems utilizing machine learning techniques achieve higher accuracy rates in real-time applications compared to traditional rule-based systems when using a large corpus of training data?
https://aclanthology.org/J75-2000/,Can the integration of cognitive architectures and natural language processing techniques improve the effectiveness of machine translation systems in handling nuanced language nuances and idiomatic expressions?
https://aclanthology.org/J75-2001/,Can the implementation of a secure and efficient membership management system using blockchain technology improve the accuracy of dues collection in the AFIPS Constituent Societies? Can the use of a multi-agent system with machine learning algorithms improve the effectiveness of publications dissemination in the AFIPS Constituent Societies?
https://aclanthology.org/J75-3000/,Can a machine learning-based approach be applied to improve the accuracy of text classification in information retrieval systems using a transformer-based architecture and evaluating its performance through precision and recall metrics?
https://aclanthology.org/J75-3000/,"Can a bibliographic database be designed using a natural language processing technique to extract relevant information and provide a comprehensive cataloging system for digital libraries, measured by the number of extracted records and the average processing time?"
https://aclanthology.org/J75-3001/,Can machine learning models be trained to predict the likelihood of a user's interest in a product based on their past browsing behavior on a e-commerce website?
https://aclanthology.org/J75-3001/,Can a recommendation system utilizing a hybrid approach combining collaborative filtering and content-based filtering be effective in improving user engagement on social media platforms?
https://aclanthology.org/J75-4000/,Can the use of latent semantic analysis to improve the accuracy of part-of-speech tagging in machine translation systems be evaluated using a supervised learning approach with a dataset of bilingual texts?
https://aclanthology.org/J75-4000/,Can the application of a graph-based approach to modeling the relationships between concepts in historical linguistics be assessed using a combination of computational lexicography and corpus linguistics?
https://aclanthology.org/J75-4001/,Can machine learning algorithms be used to improve the accuracy of speech recognition systems using a combination of natural language processing and multiple-valued logic techniques?
https://aclanthology.org/J75-4001/,Can speech understanding systems be optimized for real-time processing by developing more efficient algorithms for parsing and analyzing linguistic structures in spoken language?
https://aclanthology.org/J76-1000/,"Can the use of natural language processing techniques improve the accuracy of abstracting and indexing of academic papers in libraries, measured by the reduction in time taken to complete this task?"
https://aclanthology.org/J76-1000/,"Does the application of a computer-aided transcription system improve the efficiency of stenotype transcription, as measured by the increase in transcription speed compared to manual methods?"
https://aclanthology.org/J76-1001/,"What is the impact of incorporating ACL membership data on the accuracy of editor's reports, and how does it relate to the survey of members in the IEEE Tutorials context?"
https://aclanthology.org/J76-1001/,How can the IEEE Tutorials be optimized to leverage the benefits of ACL membership data in improving user satisfaction and processing time?
https://aclanthology.org/J76-1002/,Can a machine learning model using a combination of rule-based and deep learning techniques be able to accurately classify handwritten digits with a high level of syntactic correctness?
https://aclanthology.org/J76-1002/,Can the application of natural language processing techniques to analyze and understand the syntax and semantics of programming languages improve the development of formal methods for software verification?
https://aclanthology.org/J76-2000/,Does the use of cognitive science theories in computer-based instruction have a significant impact on student satisfaction and learning outcomes in the classroom?
https://aclanthology.org/J76-2000/,"Can a parser-based approach be effective in improving the accuracy of machine translation, as demonstrated by experiments with a powerful parser?"
https://aclanthology.org/J76-2001/,Can a machine learning model using a transformer-based architecture be developed to improve the reading speed and accuracy of a Kurzweil Reading Machine for individuals with dyslexia?
https://aclanthology.org/J76-2001/,Can the use of natural language processing and machine learning algorithms be evaluated for its impact on the reading speed and comprehension of individuals with dyslexia?
https://aclanthology.org/J76-2002/,"What are the factors that affect the accuracy of a supervised classification model using a Transformer-based architecture in predicting customer churn, measured by accuracy and precision, in a dataset containing sensitive personal information?"
https://aclanthology.org/J76-2002/,"Can a privacy-preserving approach be developed using homomorphic encryption and secure multi-party computation to protect user data while enabling collaborative data analysis in the information processing industry, measured by the reduction in data breaches and increase in user trust?"
https://aclanthology.org/J76-3000/,Can machine learning algorithms be used to improve the accuracy of speaker recognition systems in noisy environments?
https://aclanthology.org/J76-3000/,Can the use of data-driven approaches impact the performance of natural language processing models in handling out-of-vocabulary words?
https://aclanthology.org/J76-3001/,"What are the most effective methods for automatically annotating geological images to improve the accuracy of geologist's visual inspections and classification tasks in the field, and how can these methods be integrated with existing workflows to measure their impact on processing time and user satisfaction? Can the application of deep learning techniques such as convolutional neural networks to improve the accuracy of geological image classification be further validated using real-world datasets and field trials?"
https://aclanthology.org/J76-4000/,"Can machine learning algorithms be applied to improve the accuracy of human-computer interaction systems, specifically in terms of processing time and user satisfaction, in a linguistics and literary analysis context? Can the use of interactive techniques in graphics and technical visualization improve the effectiveness of undergraduate curricula in computer science?"
https://aclanthology.org/J76-4001/,"Can machine learning models be trained to accurately predict the likelihood of data breaches in a cloud-based system using a combination of natural language processing and graph-based algorithms, and what is the optimal balance between accuracy and computational time? Can a blockchain-based approach be used to improve the security of cloud storage by analyzing the metadata of stored files and detecting potential vulnerabilities?"
https://aclanthology.org/J77-1000/,"Can a supervised learning algorithm using a neural network architecture improve the accuracy of text classification tasks in natural language processing, as measured by the F1-score, compared to a traditional rule-based approach? Can the implementation of a fuzzy logic system to optimize data retrieval in a knowledge base be compared to the efficiency of a traditional relational database system, measured by query processing time?"
https://aclanthology.org/J77-1001/,Can a deep learning model using a transformer architecture improve the accuracy of a natural language processing task by 20% on a benchmark dataset compared to a traditional rule-based approach?
https://aclanthology.org/J77-1001/,Can a hybrid approach combining reinforcement learning and deep learning methods reduce the training time of a computer vision task by 50% on a standard benchmark compared to a single deep learning approach?
https://aclanthology.org/J77-1002/,Is it possible to develop a machine learning model that can accurately classify images of handwritten digits using a convolutional neural network with a precision of 95% or higher and a processing time of less than 500 milliseconds? Can an ensemble learning approach using a combination of support vector machines and random forests improve the accuracy of sentiment analysis on social media text data by at least 15% compared to a single support vector machine?
https://aclanthology.org/J77-1003/,"What are the implications of applying machine learning algorithms to the parsing of spoken language for human-computer interaction, considering factors such as accuracy and user satisfaction?"
https://aclanthology.org/J77-1003/,"How can the design of natural language processing models improve the efficiency of text retrieval systems, particularly in the context of information retrieval and semantic search?"
https://aclanthology.org/J77-2000/,"How can the use of machine learning algorithms improve the accuracy of speech recognition in noisy environments, measured by the reduction in error rate, and what are the optimal feature extraction techniques for this task?"
https://aclanthology.org/J77-2000/,"Can a deep learning approach using a convolutional neural network be applied to analyze the structural patterns in poetry, specifically to identify the relationship between poetic devices and their impact on the overall meaning, as measured by the Flesch-Kincaid readability test?"
https://aclanthology.org/2020.conll-1.0/,Can the proposed model capture the nuances of semantic meaning changes across different time periods and geographical locations in a way that is comparable to existing state-of-the-art models for time-specific and location-specific embeddings?
https://aclanthology.org/2020.conll-1.0/,Does the model's ability to learn location-aware word embeddings improve the accuracy of time-series analysis and sentiment analysis in natural language processing tasks?
https://aclanthology.org/2020.conll-1.1/,"Can neural networks with attention mechanisms learn human-like visual attention through the use of eye-tracking data in machine reading comprehension, and how do different architectures such as LSTM, CNN, and Transformer perform in mimicking human attention?"
https://aclanthology.org/2020.conll-1.1/,"Does the similarity between neural and human attention correlate with the performance of different machine reading comprehension models, and what can be learned from the comparison between the LSTM, CNN, and Transformer architectures?"
https://aclanthology.org/2020.conll-1.2/,"Can a neural variant of proof nets based on Sinkhorn networks improve the accuracy of syntactic parsing in linear logic derivations, and can it be used to develop more efficient neuro-symbolic parsers for formalizing and analyzing natural language structures?"
https://aclanthology.org/2020.conll-1.2/,"Can the proposed neural variant of proof nets achieve a higher accuracy than existing approaches in parsing linear logic derivations, and can it be applied to other type-logical languages to improve parsing efficiency?"
https://aclanthology.org/2020.conll-1.3/,"Can pre-trained Transformer-based neural architectures generalise well across different taxonomic categories in the NLI task, and do they achieve strong performance on the most challenging categories, or are there specific categories where they struggle?"
https://aclanthology.org/2020.conll-1.3/,"Does the introduction of a new taxonomy-based dataset like TaxiNLI improve the generalization of pre-trained Transformer models on NLI, and what are the performance differences between the new dataset and the existing ones?"
https://aclanthology.org/2020.conll-1.4/,How do linguistic features of crime reports influence readers' subjective guilt judgments?
https://aclanthology.org/2020.conll-1.4/,Can predictive models trained on the SuspectGuilt Corpus accurately capture the impact of genre on guilt perceptions?
https://aclanthology.org/2020.conll-1.5/,"Does the use of UPOS tags as features for neural parsers require a high tagging accuracy to achieve optimal parsing performance, and what are the key linguistic aspects that impact parsing accuracy when using predicted UPOS tags?"
https://aclanthology.org/2020.conll-1.5/,"Can the inclusion of gold tags in neural parsers improve parsing performance in a non-linear manner, and what specific linguistic features are most influential in determining parsing accuracy when using gold tags?"
https://aclanthology.org/2020.conll-1.6/,"Can the proposed method for classifying syntactic errors in learner language be accurately applied to languages with vastly different grammatical structures, and what are the implications for the analysis of learner English and learner Russian?"
https://aclanthology.org/2020.conll-1.6/,Can the proposed methodology improve the evaluation of Grammatical Error Correction systems by providing a more comprehensive understanding of the types of errors they produce?
https://aclanthology.org/2020.conll-1.7/,"Can sentence encoders' representations capture linguistic knowledge in lesser-resourced languages, and how do different probing task designs influence the results of these representations?"
https://aclanthology.org/2020.conll-1.7/,"What are the implications of probing task results transferring across languages, and how can fairer and more comprehensive sentence-level probing evaluations be achieved?"
https://aclanthology.org/2020.conll-1.8/,"What impact do examples of a lexical relation have on the ability of neural word embeddings to complete analogies involving that relation, and how do these findings inform our understanding of the role of co-occurrence information in semantic relation modeling?"
https://aclanthology.org/2020.conll-1.8/,"Can the removal of known examples of a lexical relation from training corpora affect the performance of neural word embeddings in analogy completion tasks, and what are the implications of this finding for the design of semantic relation-aware models?"
https://aclanthology.org/2020.conll-1.9/,"Can a machine learning model trained on a large annotated corpus achieve higher accuracy in resolving one-anaphora than a model trained on a smaller corpus with annotated instances of the word ""one"" in different syntactic environments?"
https://aclanthology.org/2020.conll-1.9/,"Can the use of linguistic theory in annotating and training a neural model for one-anaphora resolution improve the model's ability to identify the correct antecedents of the word ""one""?"
https://aclanthology.org/2020.conll-1.10/,Can human gaze during reading comprehension be effectively utilized to improve the performance of machine reading comprehension models on multiple choice question answering tasks?
https://aclanthology.org/2020.conll-1.10/,Can the fixation times over relevant parts of the text during reading comprehension be used as a signal to inform the design of more human-like reading comprehension models?
https://aclanthology.org/2020.conll-1.11/,"Can state-of-the-art summarization models achieve high accuracy in generating accurate and informative table-of-contents entries for chemistry journal articles, and what specific metrics would be most effective to evaluate their performance in this task?"
https://aclanthology.org/2020.conll-1.11/,"How do the characteristics of short author-written blurbs in open access publications compare to those in other types of academic texts, and what can be learned from this comparison in terms of summarization methods?"
https://aclanthology.org/2020.conll-1.12/,"Can LSTM networks accurately capture grammatical abstraction in child-directed input, and how does the level of abstraction change over time in the generated output?"
https://aclanthology.org/2020.conll-1.12/,How does the training of LSTM on child-directed input affect the model's ability to generate grammatically correct sentences compared to learning from unrealistic corpora?
https://aclanthology.org/2020.conll-1.13/,"Can pragmatic reasoning strategies improve communication efficiency by reducing computational costs in ambiguous situations, and what is the optimal balance between computational burden and interaction time to achieve successful communication?"
https://aclanthology.org/2020.conll-1.13/,"Does other-initiated repair mechanisms lead to more efficient communication with lower computational costs, and how do they compare to pragmatic reasoning strategies in terms of communicative success?"
https://aclanthology.org/2020.conll-1.14/,Can unsupervised neural networks learn phonemic structure from unlabeled speech data based on local signals that are plausible within the constraints of human working memory?
https://aclanthology.org/2020.conll-1.14/,Can the incremental learning process of the proposed model contribute to the acquisition of linguistic content by both remembering the past and predicting the future?
https://aclanthology.org/2020.conll-1.15/,"Can a semi-supervised learning approach be used to identify incorrect labels in the CoNLL-2003 corpus with high accuracy, and what are the types of errors commonly found in this corpus that can be improved through corrections?"
https://aclanthology.org/2020.conll-1.15/,"Can the use of corrected CoNLL-2003 corpus labels improve the performance of state-of-the-art named entity recognition models, measured by their accuracy or processing time?"
https://aclanthology.org/2020.conll-1.16/,"What are the contextual implications of using BERT's token-level knowledge for type-level tasks and lexical semantics, and how does this relate to the abstractness of lexical items?"
https://aclanthology.org/2020.conll-1.16/,"Can layer 7 of BERT's contextual language model approximate semantic similarity, and if so, what are the limitations of this approximation in terms of relatedness estimation?"
https://aclanthology.org/2020.conll-1.17/,"Can a more robust entropy-based Uniform Information Density measure be developed to accurately predict the typological distribution of transitive word orders across languages, and how would such a measure differ from the surprisal-based UID measure used by Maurits, Navarro, and Perfors (2010)? Can the addition of more data, particularly from less studied languages, improve the predictive power of the UID measures for transitive word orders in the Universal Dependencies project?"
https://aclanthology.org/2020.conll-1.18/,"What impact do the most frequent error types in misleading translations have on the overall comprehensibility and adequacy of the translated text, and how can they be addressed using machine translation algorithms?"
https://aclanthology.org/2020.conll-1.18/,"Can machine learning-based models improve the detection of misleading translations that are fully comprehensible, and if so, what evaluation metrics can be used to measure their effectiveness?"
https://aclanthology.org/2020.conll-1.19/,"Can cross-linguistic word embeddings capture universal factors in gender assignment, and how do these factors compare to idiosyncratic factors across Indo-European and Afro-Asiatic languages?"
https://aclanthology.org/2020.conll-1.19/,Do the performance of cross-linguistic gender classification models decrease significantly as the phylogenetic distance between languages increases?
https://aclanthology.org/2020.conll-1.20/,"Can a neural model using density matrices be able to accurately learn word senses that are etymologically unrelated, or homonymy, from a corpus, and if so, how can it be compared to existing vector-based compositional models in this regard? Can a compositional distributional model of meaning using density matrices be able to accommodate a wider range of word senses than existing models using vectors?"
https://aclanthology.org/2020.conll-1.21/,"What are the effects of introducing phone, syllable, or word boundary information on the performance of a neural model of Visually Grounded Speech trained on a speech-image retrieval task?"
https://aclanthology.org/2020.conll-1.21/,How does the level of the network's architecture where such information is introduced impact the performance of the neural model of Visually Grounded Speech?
https://aclanthology.org/2020.conll-1.22/,Can a text embedding method using a 3D spatial representation of the human body be used to improve the accuracy of medical text classification tasks by capturing spatially aware relationships between organs?
https://aclanthology.org/2020.conll-1.22/,Can a self-supervised approach to projecting medical text into a 3D space be compared to a classification-based method for improving the robustness of medical text analysis?
https://aclanthology.org/2020.conll-1.23/,Can the use of multilinear maps in word representation learning improve the performance of verb similarity and disambiguation tasks compared to traditional vector-based methods?
https://aclanthology.org/2020.conll-1.23/,Can the addition of grammatical type information to skipgram algorithm improve the performance of sentence representation learning and relatedness classification on the SICK dataset?
https://aclanthology.org/2020.conll-1.24/,"Can recent natural language representations (word embedding vectors) converge to a Gaussian distribution as the representation size p and database size n increase, and how does this convergence impact the performance of machine learning algorithms for natural language data?"
https://aclanthology.org/2020.conll-1.24/,"Does the concentration of measure phenomenon in word embedding vectors affect the accuracy of supervised learning models for text classification, and what are the implications for model design and optimization?"
https://aclanthology.org/2020.conll-1.25/,"Can neural networks develop efficient communication strategies by avoiding long messages, and what is the impact of listener impatientness on the emergence of optimal and ZLA-compatible messages in communication systems? Can a modified communication system, such as LazImpa, effectively balance the trade-off between message length and transmission efficiency?"
https://aclanthology.org/2020.conll-1.26/,"Can a computational model learn to denote, master the lexicon, and model language use on others with limited data, and if so, what is the optimal data size required for this task?"
https://aclanthology.org/2020.conll-1.26/,Can the presentation format and nature of the data used to train a computational model affect its ability to acquire semantic competence in a human-like manner?
https://aclanthology.org/2020.conll-1.27/,"Can a more standardized annotation style in the media domain improve the accuracy of Named Entity Linking tools when processing creative work names, and how do the differences in annotation styles affect the performance of existing tools?"
https://aclanthology.org/2020.conll-1.27/,"Does the use of relaxed annotation guidelines with overlap styles result in better performance across all NEL tools, and can these guidelines be used to mitigate the impact of divergent views on creative work names?"
https://aclanthology.org/2020.conll-1.28/,"Can word embeddings capture linguistic regularities by representing word meanings as simple vector translations, and how do class-wise offset concentration and pairing consistency impact the accuracy of such models? Do popular word embeddings encode linguistic regularities that distinguish between words from different broad classes?"
https://aclanthology.org/2020.conll-1.29/,"How do word embeddings, particularly contextualized and uncontextualized, replicate human word association patterns in terms of association rank and asymmetry of similarity?"
https://aclanthology.org/2020.conll-1.29/,"Do contextualized word embeddings replicate human association norms by violating the triangle inequality, and how do they compare to human association spaces in this regard?"
https://aclanthology.org/2020.conll-1.30/,"Can TrClaim-19's labeled dataset improve the development of Turkish fact-checking systems by providing a more comprehensive understanding of the characteristics of check-worthy claims in Turkish, and how do the topics and possible negative impacts of claims affect their check-worthiness in Turkish tweets? Does the use of TrClaim-19 improve the accuracy of fact-checking systems in Turkish compared to existing datasets for English?"
https://aclanthology.org/2020.conll-1.31/,"Can transformer and long short-term memory language models accurately capture implicit causality in discourse structure, and does this ability affect their performance on reference resolution tasks? Does the ability of language models to capture syntactic agreement in discourse influence their overall performance on syntactic processing tasks?"
https://aclanthology.org/2020.conll-1.32/,"Can a neural language model adapt and generalize linguistic conventions learned from a generic language model to effectively communicate with a human partner in new contexts, and how can we measure the efficiency of this adaptation process in terms of accuracy and processing time? Can a regularized continual learning framework improve the ability of a language model to learn and apply new linguistic conventions in real-time, and what is the optimal balance between adaptation and consistency in this context?"
https://aclanthology.org/2020.conll-1.33/,"Can an embedding of a scene graph improve the generation of diverse and coherent narratives in image sequences by explicitly modeling object relations, and how does it compare to global features from an object classifier? Does the use of narratively-salient image features and reference-based metrics improve the overall quality of generated stories?"
https://aclanthology.org/2020.conll-1.34/,"Can a hierarchical stack of Transformers improve the accuracy of named entity recognition for historical texts with OCR errors and linguistic variations, as compared to state-of-the-art models on modern datasets? Does the proposed model's performance degrade when applied to modern datasets with fewer linguistic and formatting issues?"
https://aclanthology.org/2020.conll-1.35/,Can the input embeddings of the softmax classification layer be compared to the output embeddings for semantic representation in sequence learning tasks such as language modeling?
https://aclanthology.org/2020.conll-1.35/,Can the newly constructed word embeddings using the output embeddings outperform other state-of-the-art distributional models in word similarity benchmarks?
https://aclanthology.org/2020.conll-1.36/,Is a transformer architecture with positional masking and without positional encoding Turing-complete and how does it compare to the traditional transformer model?
https://aclanthology.org/2020.conll-1.36/,Can a particular type of residual connection be necessary for a transformer to be Turing-complete and what are its implications on machine translation tasks?
https://aclanthology.org/2020.conll-1.37/,"Can the proposed statistical model effectively distinguish between cognate pairs and non-cognate pairs based on observed word pairs and latent variables, and how does it compare to existing systems in terms of accuracy? Can the expectation-maximisation algorithm be improved to better estimate the unknown global parameters of the model and lead to better performance on larger datasets?"
https://aclanthology.org/2020.conll-1.38/,"Can recurrent neural networks learn to distinguish between abstract syntactic constraints and surface heuristics, and do they generalize these representations to unseen data?"
https://aclanthology.org/2020.conll-1.38/,Can the use of cumulative priming in RNN language models help to identify shared underlying grammatical constraints governing filler-gap dependencies in English?
https://aclanthology.org/2020.conll-1.39/,Is it possible to design a non-autoregressive parser using the insertion transformer that outperforms the state-of-the-art autoregressive sequence-to-sequence model in terms of decoding speed and cross-lingual transfer learning for low-resource languages?
https://aclanthology.org/2020.conll-1.39/,Can a non-autoregressive parser based on the insertion transformer improve the accuracy of semantic parsing in zero-shot cross-lingual transfer learning settings compared to the autoregressive baseline?
https://aclanthology.org/2020.conll-1.40/,Can a Nondeterministic Stack RNN trained on deterministic tasks converge more reliably to algorithmic behavior than existing stack RNNs?
https://aclanthology.org/2020.conll-1.40/,Can a Nondeterministic Stack RNN achieve lower cross-entropy on inherently nondeterministic tasks compared to existing stack RNNs?
https://aclanthology.org/2020.conll-1.41/,Can a Switching Linear Dynamical System (SLDS) model with explicit narrative structure outperform existing language models on generating coherent narratives with controlled sentiment and discourse states?
https://aclanthology.org/2020.conll-1.41/,Can a semi-supervised training approach using both labeled and unlabeled data improve the narrative generation capabilities of the SLDS model?
https://aclanthology.org/2020.conll-1.42/,"What is the feasibility of using multi-axis event process typing for inferring the intent and affected object type in event understanding, as evaluated by accuracy on a validation set?"
https://aclanthology.org/2020.conll-1.42/,Can a hybrid learning framework with indirect supervision from glosses and joint learning-to-rank framework improve the fine-grained typing of action and object types in event processes?
https://aclanthology.org/2020.conll-1.43/,Can the proposed corpus be used to train a machine learning model to extract entities such as disease and host from news articles with high accuracy and in a reasonable processing time?
https://aclanthology.org/2020.conll-1.43/,"Can the proposed corpus be used to develop a rule-based approach to extract relations among entities, such as geographic location and disease, with a high precision and recall?"
https://aclanthology.org/2020.conll-1.44/,"Can pretrained language models learn factual knowledge through memorization, and what is the role of schema conformity and frequency in this process?"
https://aclanthology.org/2020.conll-1.44/,Do pretrained language models effectively apply symbolic reasoning rules to learn and utilize factual knowledge?
https://aclanthology.org/2020.conll-1.45/,Can a machine learning model that incorporates code-switching techniques be able to adapt to user responses and adjust its language choice to improve the conversational flow in a multilingual setting?
https://aclanthology.org/2020.conll-1.45/,"Does the incorporation of code-switching strategies in a human-machine dialogue system improve the linguistic accommodation of users and agents, as measured by the proposed metrics?"
https://aclanthology.org/2020.conll-1.46/,"Can machine learning algorithms using bi-directional LSTMs with convolutional features accurately distinguish people with Parkinson's disease from age-matched controls in typing tasks, and what are the effects of linguistic content on this distinction?"
https://aclanthology.org/2020.conll-1.46/,"Can natural language processing methods improve the early detection of Parkinson's disease by analyzing typing patterns in English and Spanish, and how do these methods compare to existing approaches focused solely on keypress timing?"
https://aclanthology.org/2020.conll-1.47/,"Can we design a model-agnostic approach to debias a neural NLI model to be robust to multiple distinct adversarial attacks while maintaining its generalization power, and how can we compare its performance with model-level ensemble methods? Can we effectively merge heterogeneous training data to strengthen NLI models and combat multiple biases using data augmentation techniques?"
https://aclanthology.org/2020.conll-1.48/,How do contemporary autoregressive language models perform in human next-word prediction tasks and what is the relationship between corpus probabilities and human next-word predictions?
https://aclanthology.org/2020.conll-1.48/,Can the proposed Cloze Distillation method improve the reading time prediction and generalization of pre-trained language models to human cloze data?
https://aclanthology.org/2020.conll-1.49/,Can an LSTM encoder-decoder architecture with language ID and part of speech embeddings improve the accuracy of predicting sound change patterns in Indo-Aryan languages?
https://aclanthology.org/2020.conll-1.49/,Does the use of word embeddings in conjunction with language ID and part of speech embeddings further enhance the model's ability to capture variation in Indo-Aryan sound change?
https://aclanthology.org/2020.conll-1.50/,"Can the proposed dataset improve the recognition accuracy of signs by incorporating non-manual features, and how does this compare to the performance of manual gesture recognition approaches?"
https://aclanthology.org/2020.conll-1.50/,"Can the inclusion of non-manual markers in sign language recognition systems lead to real-time interpretation, and what are the potential challenges associated with this approach?"
https://aclanthology.org/2020.conll-1.51/,"Does the use of dual-source models improve performance on the WikiReading Information Extraction and Machine Reading Comprehension dataset compared to existing state-of-the-art models, as measured by accuracy on the test set?"
https://aclanthology.org/2020.conll-1.51/,"Can the proposed WikiReading Recycled dataset effectively capture the complexity of multiple-property extraction tasks, as evaluated by the accuracy of models trained on this dataset compared to those trained on the original WikiReading dataset?"
https://aclanthology.org/2020.conll-1.52/,"Can recurrent neural networks be trained to accurately predict the amplitude of the N400 using word surprisal as a feature, and how do the results compare to the existing literature on N400? Can word surprisal be used to identify the neural mechanisms underlying the N400 response, and what are the implications for our understanding of human language processing?"
https://aclanthology.org/2020.conll-shared.0/,Can the use of a deep learning-based approach to represent sentence meaning in a directed graph improve the performance of a Meaning Representation Parsing system in English?
https://aclanthology.org/2020.conll-shared.0/,Can the application of a graph abstraction and serialization framework to the representation of sentence meaning in four additional languages increase the diversity of the data used in the task?
https://aclanthology.org/2020.conll-shared.1/,"Can we develop a method to convert Discourse Representation Structures into directed labeled graphs that preserve the logical entailment relations between DRS nodes, and what would be the implications of this conversion on the unified models for several semantic graph frameworks?"
https://aclanthology.org/2020.conll-shared.1/,Does the proposed conversion procedure for DRSs to directed labeled graphs affect the semantic accuracy of the DRT framework in comparison to other graph-based meaning representation frameworks?
https://aclanthology.org/2020.conll-shared.2/,What is the evaluation metric used to assess the quality of the Prague Tectogrammatical Graphs (PTG) in the context of the CoNLL 2020 shared task on Cross-Framework Meaning Representation Parsing (MRP)?
https://aclanthology.org/2020.conll-shared.2/,"How does the conversion of Prague treebanks to PTG affect the annotation, and what aspects of the annotation are included in the PTG representation?"
https://aclanthology.org/2020.conll-shared.3/,"Can a unified text-to-graph-notation transduction approach, leveraging Transformers and biaffine attentions, improve parsing performance across different languages and graph types?"
https://aclanthology.org/2020.conll-shared.3/,Can the proposed Plain Graph Notation (PGN) handle complex graph structures and reduce the need for framework-specific modifications in graph parsing?
https://aclanthology.org/2020.conll-shared.4/,"Can PERIN's permutation-invariant architecture improve the performance of semantic parsing across different frameworks in terms of accuracy and processing time, and how does it compare to existing state-of-the-art methods?"
https://aclanthology.org/2020.conll-shared.4/,"Does the use of a universal, language-independent approach like PERIN enhance the robustness and generalizability of semantic parsing models in various frameworks and languages?"
https://aclanthology.org/2020.conll-shared.5/,"Can the proposed transition-based parser for frameworks UCCA, EDS, and PTG improve the accuracy of graph-based meaning representation parsing compared to the baseline system in the Cross-Framework Track of the CoNLL 2020 shared task?"
https://aclanthology.org/2020.conll-shared.5/,Can the iterative inference parser for frameworks DRG and AMR achieve higher macro-averaged MRP F1 scores than the baseline system in the Cross-Lingual Track of the CoNLL 2020 shared task?
https://aclanthology.org/2020.conll-shared.6/,"Can the proposed system utilizing TUPA and HIT-SCIR parser improve the performance of transition-based parsing in the 2020 CoNLL MRP shared task, and can multitask learning enhance the robustness of the system to different MRP frameworks and languages?"
https://aclanthology.org/2020.conll-shared.6/,"Does the integration of BERT contextualized embeddings in transition-based parsers lead to better performance in MRP tasks, and can the proposed system generalize to support new MRP frameworks and languages?"
https://aclanthology.org/2020.conll-shared.7/,What is the effect of updating a single joint state vector during the graph-sequence inference process on the performance of the abstract meaning representation framework?
https://aclanthology.org/2020.conll-shared.7/,Can the proposed joint state model improve the processing time of the graph-sequence inference process compared to the original model in Cai and Lam (2020)?
https://aclanthology.org/2021.conll-1.0/,"What mental models do users form about their AI-dialog partners during collaborative dialog systems, and how do these mental models impact the success of the dialog?"
https://aclanthology.org/2021.conll-1.0/,Can the use of a collaborative communication-based puzzle game and explanatory dialog system improve user perception of AI systems and facilitate successful dialogs?
https://aclanthology.org/2021.conll-1.1/,Can a word concreteness-based model improve the performance of constituency-structure grammar induction by leveraging visual information in a way that is not restricted by language-specific heuristics?
https://aclanthology.org/2021.conll-1.1/,"Can the incorporation of word concreteness and visual semantic role labels in constituency and dependency parsing outperform the current state-of-the-art visually grounded models in constituency parsing, even with a smaller grammar size?"
https://aclanthology.org/2021.conll-1.2/,Can the use of grid or region features in the Modular Co-Attention Network (MCAN) significantly impact the correlation between human and neural attentive strategies in visual question answering (VQA)?
https://aclanthology.org/2021.conll-1.2/,"Does the integration of multimodal attention mechanisms in VQA models improve the correlation between human and neural attentive strategies on text, as indicated by the correlation with human attention on text?"
https://aclanthology.org/2021.conll-1.3/,Is a more empathetic and human-like conversational agent that uses a warm and friendly language style more effective in building user trust and rapport compared to a more formal and objective information exchange?
https://aclanthology.org/2021.conll-1.3/,"Can a conversational agent's use of personal pronouns and language style influence users' perceptions of the agent's gender, and what are the ethical implications of such perceptions?"
https://aclanthology.org/2021.conll-1.4/,"Does the use of standard language models outperform distributionally robust models in predicting grammatical and lexical features in Creole languages, and what are the implications of this finding for language modeling in under-resourced languages? Can the performance of standard language models be improved through the development of more robust models that can adapt to the unique characteristics of Creole languages?"
https://aclanthology.org/2021.conll-1.5/,"Can pretrained transformer-based language models accurately capture the nuances of telicity interpretations in human language, and what linguistic cues influence their preference for telic versus atelic interpretations?"
https://aclanthology.org/2021.conll-1.5/,"Do pretrained transformer-based language models exhibit consistent performance across different linguistic cues, and can these models be fine-tuned to better understand the complexities of telicity in human language?"
https://aclanthology.org/2021.conll-1.6/,"Does the linear geometry of contextualized word representations in ELMO and BERT accurately capture linguistic features such as tense and syntactic role, and if so, how does this geometry relate to the model's performance on downstream tasks?"
https://aclanthology.org/2021.conll-1.6/,"Can low-dimensional subspaces in word representations be used to fine-grainedly manipulate the output distribution of BERT, and what are the causal implications of these subspaces for model behavior?"
https://aclanthology.org/2021.conll-1.7/,"Can recurrent neural networks acquire the complex German plural system through feature extraction and representation learning, and how do they compare to human generalisation in this domain?"
https://aclanthology.org/2021.conll-1.7/,"Do the shortcut learning mechanisms used by recurrent neural networks to learn the German plural system hinder their ability to generalise to novel, unseen data in a way that is cognitively plausible?"
https://aclanthology.org/2021.conll-1.8/,"Can a pre-trained language model accurately capture the topological structure of color terms in the CIELAB color space and how does this relate to the perceptual structure of colors, particularly in terms of warmer and cooler colors?"
https://aclanthology.org/2021.conll-1.8/,Do color collocationality and syntactic usage influence the alignment of color terms with the perceptual color space in pre-trained language models?
https://aclanthology.org/2021.conll-1.9/,"What is the feasibility of incorporating a taxonomy of 32 emotion categories and 8 additional emotion regulating intents into an existing dialog generation model, and how does it impact the overall performance of the model?"
https://aclanthology.org/2021.conll-1.9/,Can the proposed model learn subtle interactions directly from a large-scale emotional dialog dataset and produce empathetic responses that exhibit a sense of caring and a desire to help?
https://aclanthology.org/2021.conll-1.10/,What is the impact of incorporating sensorimotor norms and image vectors on the performance of language models in capturing holistic linguistic meaning?
https://aclanthology.org/2021.conll-1.10/,How do the pre-trained ELECTRA model and fine-tuned RoBERTa model perform in the GLUE and Visual Dialog benchmarks when enriched with Lancaster norms and image vectors?
https://aclanthology.org/2021.conll-1.11/,Can word embeddings be trained to capture both abstract and concrete word meanings by leveraging visual information in a way that respects the different processing pathways in the brain?
https://aclanthology.org/2021.conll-1.11/,Can a multi-task learning approach improve the performance of word embeddings by implicitly aligning textual and visual representations without requiring explicit joint space mappings?
https://aclanthology.org/2021.conll-1.12/,Can multimodal training of vision models using large image-caption datasets improve their performance in unsupervised clustering tasks compared to standard supervised visual training?
https://aclanthology.org/2021.conll-1.12/,Can the semantic grounding provided by multimodal training improve the adversarial robustness of vision models in zero-shot and few-shot learning settings?
https://aclanthology.org/2021.conll-1.13/,"Can a Transformer-based model trained on Conceptual Captions outperform a model trained on Visual Genome when generating object-focused captions for unseen images, and how does the quality of these captions compare to those generated by a model trained on a balanced dataset? Does the incorporation of guiding text improve the model's ability to generalize to out-of-domain data, and what role does style diversity play in this improvement?"
https://aclanthology.org/2021.conll-1.14/,"Do BERT models of different sizes consistently use their representations of relative clauses to capture the grammatical rules of English, as measured by the accuracy of word prediction?"
https://aclanthology.org/2021.conll-1.14/,Can AlterRep's intervention-based method accurately identify the causal effect of linguistic features on word prediction behavior in BERT models?
https://aclanthology.org/2021.conll-1.15/,Can language models achieve high accuracy in answering questions about world states using verb-like encodings of activity from a closed domain with limited training data?
https://aclanthology.org/2021.conll-1.15/,Can verb-like encodings of activity from a closed domain enable the evaluation of language models on fine-grained analysis of question-answering tasks with naturally arising distributions?
https://aclanthology.org/2021.conll-1.16/,"Can noisy data augmentation methods effectively introduce real error patterns into clean text data to improve the performance of grammatical error correction tasks, and do linguistic knowledge-based data augmentation methods outperform traditional methods in generating representative and diverse synthetic data?"
https://aclanthology.org/2021.conll-1.17/,Can a clear definition of quality criterion improve the inter-annotator agreement in human evaluation of machine translation output?
https://aclanthology.org/2021.conll-1.17/,Can the evaluation of linguistic phenomena that span over several words or phrases be improved by providing more precise and detailed instructions to annotators?
https://aclanthology.org/2021.conll-1.18/,"Can multilingual language models accurately detect and reason with negation cues in counter-examples without relevant semantic cues, and what is the impact on their overall performance in this scenario? Can multilingual language models generalize their performance on English to other languages such as Bulgarian, German, French and Chinese?"
https://aclanthology.org/2021.conll-1.19/,What are the key differences between the proposed method and the fine-tuned T5 and Seq2Seq models in terms of performance and accuracy on the Natural Language Context to Command task?
https://aclanthology.org/2021.conll-1.19/,Can the proposed transformer-based solution effectively incorporate tree structure information from Bash Abstract Syntax Trees and manual pages to improve the accuracy of command generation from natural language invocations?
https://aclanthology.org/2021.conll-1.20/,"Does increased exposure lead to the convergence of register-specific grammars in language learning simulations, and to what degree does it happen in languages with different grammatical structures? Does the amount of exposure impact the rate of convergence across languages with varying register characteristics?"
https://aclanthology.org/2021.conll-1.21/,Can deep learning models with a bidirectional component be used to improve the accuracy of tokenization repair in natural language text with missing or spurious spaces?
https://aclanthology.org/2021.conll-1.21/,Can training models on text with spelling errors enhance the effectiveness of tokenization repair methods in identifying and correcting tokenization errors?
https://aclanthology.org/2021.conll-1.22/,"Can a two-stage coarse-to-fine labeling framework improve the joint word segmentation, part-of-speech tagging, and constituent parsing by reducing computational costs and ensuring legal trees in Chinese text, as evaluated by precision and recall metrics? Can the proposed framework handle conflicting production rules and improve model evaluation reliability in joint WS-POS-PAR tasks?"
https://aclanthology.org/2021.conll-1.23/,What is the extent to which token alignments used by ROUGE and BERTScore can be interpreted as measuring information overlap in summaries?
https://aclanthology.org/2021.conll-1.23/,How does the recently proposed QAEval metric compare to current summarization evaluation metrics in capturing information quality in summaries?
https://aclanthology.org/2021.conll-1.24/,Can the use of proposition-level alignment in summary-source alignment improve the quality of salience detection training data compared to heuristic unsupervised methods?
https://aclanthology.org/2021.conll-1.24/,Can a supervised classification approach for proposition-level alignment outperform unsupervised methods in aligning sentences in reference summaries with their source counterparts?
https://aclanthology.org/2021.conll-1.25/,"Can deep pretrained models effectively generate metaphoric paraphrases that capture the nuances of human language, and how do different evaluation metrics impact the quality of these paraphrases?"
https://aclanthology.org/2021.conll-1.25/,"Do control mechanisms for metaphoric paraphrasing improve the generation of novel and fluent metaphors, and what are the trade-offs in terms of training data requirements?"
https://aclanthology.org/2021.conll-1.26/,"How do the proposed contrastive learning framework and CharacterBERT model improve the ability of sentence embeddings to capture high-level semantic information, such as relations between entities in text?"
https://aclanthology.org/2021.conll-1.26/,"Can the proposed method learn a different space for named entity recognition using a contrastive learning objective, and how can it be combined with the existing representation space for entity-relation tasks?"
https://aclanthology.org/2021.conll-1.27/,Can transformer-based models accurately predict human inferences involving presupposition triggers in simple conversational contexts?
https://aclanthology.org/2021.conll-1.27/,Do transformer-based models capture complex interactions between context and presupposition triggers in exceptional cases where human judgments reveal nuanced inferences?
https://aclanthology.org/2021.conll-1.28/,"Can pre-trained language models effectively predict discourse connectives based on pragmatic cues in naturally-occurring data, and can they generalize this ability to controlled contexts?"
https://aclanthology.org/2021.conll-1.28/,"Do pre-trained language models exhibit humanlike temporal preferences for discourse connectives, as indicated by their ability to understand implicatures and predict temporal dynamics?"
https://aclanthology.org/2021.conll-1.29/,"Is it possible to develop a machine learning model that can accurately predict the readability of text based on scrolling behavior, and what features of a reader's background can be used to improve the model's performance? Can scrolling behavior be used to identify text levels and predict the reading difficulty of a given text?"
https://aclanthology.org/2021.conll-1.30/,"Can a production-based learning model trained on a large corpus of crowd-sourced images with corresponding descriptions outperform a perception-based learning model on word-level semantics, and what is the processing time required for such a model to achieve optimal performance?"
https://aclanthology.org/2021.conll-1.30/,"Can a production-based learning model trained on a large corpus of crowd-sourced images with corresponding descriptions be able to converge on more balanced semantic knowledge when alternated with perception-based learning, and how does this synergy affect its overall performance on sentence-level semantics?"
https://aclanthology.org/2021.conll-1.31/,"Can an RNN language model be used to extract meaningful lexical representations from a corpus of artificial language, and what is the effect of redundancy in the training data on the quality of these representations?"
https://aclanthology.org/2021.conll-1.31/,How can redundant information in the training data be mitigated to improve the induction of atomic internal states in RNN language models?
https://aclanthology.org/2021.conll-1.32/,How can grammatical profiling based on morphosyntactic changes be used to improve semantic change detection in linguistic research?
https://aclanthology.org/2021.conll-1.32/,Can grammatical profiling be used to detect semantic changes in words by analyzing changes in morphosyntactic behavior that are not reflected in distributional word representations?
https://aclanthology.org/2021.conll-1.33/,"Can minimalist grammars effectively eliminate syntactic redundancies in linguistic data, and if so, what is the impact on the accuracy of linguistic generalizations?"
https://aclanthology.org/2021.conll-1.33/,"Can a computational approach to grammar optimization improve the description of the English auxiliary system, passives, and raising verbs, and what evaluation metrics would be necessary to measure this improvement?"
https://aclanthology.org/2021.conll-1.34/,Can the proposed relation-aware graph neural network effectively capture contextual information from both entities and relations in commonsense question answering tasks?
https://aclanthology.org/2021.conll-1.34/,Can the dynamic updating of relations with contextual information from multiple external knowledge sources improve the performance of the bidirectional reasoning module in commonsense question answering?
https://aclanthology.org/2021.conll-1.35/,Can a machine learning model that uses masked coreference resolution to predict referent predictability improve the accuracy of identifying pronouns versus full noun phrases in context?
https://aclanthology.org/2021.conll-1.35/,Can the use of a masked coreference resolution system affect the morphosyntactic type and length of referring expressions in a way that is correlated with the predictability of the referent?
https://aclanthology.org/2021.conll-1.36/,"Can the Polar Embedding approach be extended to represent hierarchical relationships in multi-modal data, such as text and images, and if so, what are the challenges and opportunities in adapting it to such diverse modalities?"
https://aclanthology.org/2021.conll-1.36/,"Can the optimization method for learning angles in polar coordinates be used to improve the performance of other embedding models, such as word2vec, in low-dimensional Euclidean space?"
https://aclanthology.org/2021.conll-1.37/,Does ConceptNet's structured relational database offer a more efficient means of retrieving situational commonsense knowledge compared to SWOW's knowledge graph derived from crowd-sourced word associations?
https://aclanthology.org/2021.conll-1.37/,"Can the use of large-scale word association data, such as those obtained through crowd-sourcing, improve the performance of automatic reasoning systems on commonsense reasoning benchmarks compared to text-only baselines?"
https://aclanthology.org/2021.conll-1.38/,"Can the proposed dense annotation approach for cross-document event coreference improve the accuracy of event coreference resolution by increasing the amount of annotated data, and can it help to better capture quasi-identity relations between events in different documents?"
https://aclanthology.org/2021.conll-1.38/,"Can the use of overlapping event contexts, including time, location, and participants, in the annotation process enhance the understanding of the relation between identity decisions and context in cross-document event coreference?"
https://aclanthology.org/2021.conll-1.39/,Can a gap-masked self-attention model effectively capture contextual information around zero pronouns while preserving sequential information in tokens?
https://aclanthology.org/2021.conll-1.39/,Does the two-stage interaction mechanism improve the performance of zero pronoun resolution and coreference resolution jointly in the proposed end-to-end neural model?
https://aclanthology.org/2021.conll-1.40/,"Does a negation-instance based approach to evaluating negation resolution improve the comparability of systems in the field of natural language processing, and can it be applied to other NLP tasks?"
https://aclanthology.org/2021.conll-1.40/,"Can a more intuitive evaluation metric for negation resolution, based on per-instance scores, lead to more accurate and reliable results for downstream tasks such as question answering and text classification?"
https://aclanthology.org/2021.conll-1.41/,"Can a text-to-speech system be trained to convey fine-grained prosodic features, such as prosodic prominence, contextually appropriate emotions, and contrastive focus, directly from the input text using control tokens?"
https://aclanthology.org/2021.conll-1.41/,"Can a dataset be designed to enable the accurate learning of prosodic patterns, such as variations of Formant (Fo), Intensity, and Duration, in text-to-speech systems?"
https://aclanthology.org/2021.conll-1.42/,"Can machine learning models using pre-trained language models effectively detect abusive language in Reddit posts with a high degree of accuracy and precision, and what are the key characteristics of such models that contribute to their performance in this task?"
https://aclanthology.org/2021.conll-1.42/,"Can a hierarchical annotation approach using crowdsourcing improve the efficiency and effectiveness of annotating abusive language datasets, and how does it impact the performance of pre-trained language understanding models on such datasets?"
https://aclanthology.org/2021.conll-1.43/,"Can MirrorWiC improve the performance of word-in-context (WiC) representations in pre-trained language models (PLMs) on monolingual, multilingual, and cross-lingual benchmarks using only raw texts from Wikipedia?"
https://aclanthology.org/2021.conll-1.43/,Can MirrorWiC achieve comparable or even better results than supervised models fine-tuned with in-task data and sense labels on standard WiC benchmarks?
https://aclanthology.org/2021.conll-1.44/,Can large language models fine-tuned on multilingual datasets like IndoRE achieve comparable accuracy to monolingual models for relation classification in Indian languages?
https://aclanthology.org/2021.conll-1.44/,Does the use of expensive gold instances versus cost-effective silver instances impact the accuracy-efficiency tradeoff in multilingual relation classification models?
https://aclanthology.org/2021.conll-1.45/,"Can the accuracy of semantic representations extracted from corpora be evaluated using free association tasks such as FAST, and what metrics would be most suitable for measuring their effectiveness?"
https://aclanthology.org/2021.conll-1.45/,How can the Edinburgh Associative Thesaurus and the University of South Florida Free Association Norms be rigorously sampled to create a high-quality free association dataset for evaluating semantic representations?
https://aclanthology.org/2021.conll-1.46/,"Can ARETA accurately annotate Arabic errors in a blind test using a manually annotated dataset, and what is the average F1 score achieved by ARETA on this test?"
https://aclanthology.org/2021.conll-1.46/,"Does the use of a large Arabic morphological analyzer in ARETA improve its performance in error type annotation, and how does it compare to other error correction systems?"
https://aclanthology.org/2021.conll-1.47/,"Is the shape bias in language emergence and persistence primarily driven by the need for efficient communication among humans, or is it an independent phenomenon that arises from other factors? Does the persistence of the shape bias across generations require the presence of communicative pressures, or can it be explained by other mechanisms?"
https://aclanthology.org/2021.conll-1.48/,Can BabyBERTa acquire grammatical knowledge comparable to pre-trained RoBERTa-base with significantly fewer parameters and words?
https://aclanthology.org/2021.conll-1.48/,Does the proposed novel grammar test suite for BabyBERTa effectively measure the learnability of grammar from child-directed input?
https://aclanthology.org/2021.conll-1.49/,"Can rational information transmission strategies be accurately modeled in written and spoken communication, considering the impact of discourse context on sentence information content and production costs?"
https://aclanthology.org/2021.conll-1.49/,Can the application of production costs and goal-oriented rewards improve the accuracy of rational information transmission models in spoken and written communication?
https://aclanthology.org/2021.conll-1.50/,"What is the relationship between native language and phoneme assimilation in speech perception, and how can it be better predicted using computational models?"
https://aclanthology.org/2021.conll-1.50/,Can a fine-grained phonetic representation tuned to the statistics of the native language improve speech perception accuracy for non-native speakers?
https://aclanthology.org/2021.conll-1.51/,Can a phonetic-based spellchecker that incorporates regional pronunciation variation be more effective in correcting misspellings of Irish children than a standard phonetic-based spellchecker?
https://aclanthology.org/2021.conll-1.51/,Can adapting a standard English phonetic-based spellchecker to Irish Accented English improve the performance of the spellchecker for children from different regions in Ireland?
https://aclanthology.org/2022.conll-1.0/,"Can the proposed multilingual bag-of-entities model improve the performance of zero-shot cross-lingual text classification when trained on a resource-rich language, and does it achieve this improvement consistently across different languages and datasets?"
https://aclanthology.org/2022.conll-1.0/,Does the use of shared embeddings for entities described in multiple languages enhance the model's ability to generalize and perform well on entity typing tasks?
https://aclanthology.org/2022.conll-1.1/,"Do contemporary transformer language models exhibit a processing advantage for highly anomalous words when they are semantically related to the preceding context or to the most probable continuation, similar to humans?"
https://aclanthology.org/2022.conll-1.1/,"Do the predictions of humans and transformer language models share common factors influencing their processing of upcoming words, such as predictability and semantic context?"
https://aclanthology.org/2022.conll-1.2/,"Is there a significant difference in the linguistic patterns of hate speech targeting different demographic categories such as gender, sex, race, or ethnicity, and how do these patterns relate to stereotypes and social contexts associated with these identities?"
https://aclanthology.org/2022.conll-1.2/,"Do classifiers trained on hate speech datasets targeting specific identity groups generalize well to other targeted identities, and what are the implications of this lack of generalization for automated hate speech classification?"
https://aclanthology.org/2022.conll-1.3/,"Does the proposed attention calibration mechanism in the NLP transformer model effectively reduce catastrophic forgetting in online continual learning, and what is the impact of attention calibration on the overall performance of the model for tasks with varying difficulty levels? Can the proposed approach be extended to other sequence-to-sequence language generation tasks that require more complex and nuanced attention mechanisms?"
https://aclanthology.org/2022.conll-1.4/,Can we design and evaluate the effectiveness of a deep learning model using the CARE method to predict the affective responses to social media posts based on the annotations provided in the CARE DB dataset?
https://aclanthology.org/2022.conll-1.4/,Can the CARE DB dataset be used to train and compare the performance of different BERT-based models for emotion detection and affective response prediction tasks?
https://aclanthology.org/2022.conll-1.5/,"Can saliency methods using the Transformer-based architecture outperform traditional feature-based methods in terms of interpretability for sentiment analysis tasks, as measured by the consistency between token-level rationales before and after perturbations?"
https://aclanthology.org/2022.conll-1.5/,"Can the proposed benchmark accurately evaluate the interpretability of neural models and saliency methods on textual similarity tasks, as indicated by the effectiveness of token-level rationales in capturing the underlying linguistic relationships?"
https://aclanthology.org/2022.conll-1.6/,"Can the use of artificially generated languages with hierarchical Pitman-Yor processes improve the realism of linguistic models, and do these models achieve better performance when trained on natural language corpora compared to current weighted context-free grammars? Does the introduction of hierarchical Pitman-Yor processes lead to more accurate inductive biases of linguistic models?"
https://aclanthology.org/2022.conll-1.7/,"Can multilingual language models' ability to perform subject-verb agreement be improved by increasing the number of layers in the model, and to what extent does this impact the performance of masked language models versus autoregressive multilingual language models?"
https://aclanthology.org/2022.conll-1.7/,"Do counterfactual perturbations on neuron activations in multilingual language models reveal a significant difference in the extent of syntactic agreement encoding between languages, and if so, what is the optimal layer-wise configuration for optimal syntactic agreement in multilingual language models?"
https://aclanthology.org/2022.conll-1.8/,"Can our proposed method for unsupervised cognate identification be applied to other language pairs with varying levels of linguistic similarity, and how do the results compare to traditional orthography-based approaches in terms of accuracy and processing time?"
https://aclanthology.org/2022.conll-1.8/,"Can the use of noisy bilingual embeddings in conjunction with orthographic cues improve the performance of cognate detection in low-resource languages, and what is the impact of the level of noise in the embeddings on the overall performance of the method?"
https://aclanthology.org/2022.conll-1.9/,"Can transformer-based models accurately detect social biases in toxic language datasets, specifically in the categories of gender, race/ethnicity, religion, political, and LGBTQ, and can they be mitigated effectively?"
https://aclanthology.org/2022.conll-1.9/,"Can the proposed dataset, ToxicBias, be used to develop a comprehensive framework for systematic extraction of social bias data from toxic language datasets and evaluate its impact on bias identification and mitigation?"
https://aclanthology.org/2022.conll-1.10/,"Can neural language models accurately capture the incremental processing of ungrammatical structures, and if not, what are the properties of training data that contribute to this limitation?"
https://aclanthology.org/2022.conll-1.10/,How do humans' use of Principle B in coreference processing differ from the processing behavior of GPT-based language models?
https://aclanthology.org/2022.conll-1.11/,Can the proposed constraint-based parser for Minimalist Grammars successfully identify syntactic derivations that meet interface conditions using the Satisfiability Modulo Theories framework and the Z3 SMT-solver?
https://aclanthology.org/2022.conll-1.11/,"Can the parser's output derivations differ meaningfully when the input interface conditions are partially versus fully specified, and what implications does this have for the parser's extensibility and linguistic applications?"
https://aclanthology.org/2022.conll-1.12/,"Can a language model trained on Gricean data be able to accurately predict entailment judgments, and if so, how can these predictions be decoded to extract semantic information from the model?"
https://aclanthology.org/2022.conll-1.12/,"Can the use of Gricean agents in training data enable language models to capture more nuanced semantic relationships between sentences, and what are the implications for understanding natural language semantics?"
https://aclanthology.org/2022.conll-1.13/,"Can neural machine translation models accurately capture syntactic distinctions at the neuron level, and how does the similarity in word choice and sentence length influence the correlation between activation patterns of paraphrases in machine translation systems? Does manipulating neuron activations allow for control over the syntactic form of the output in machine translation systems?"
https://aclanthology.org/2022.conll-1.14/,"Can the proposed methodology effectively quantify the amount of information exchanged between participants during free conversations, and how does it relate to the thematic structuring introduced by the speaker?"
https://aclanthology.org/2022.conll-1.14/,"Does the proposed methodology account for the dynamics of information exchanges, and how does it measure the common ground instantiation using metrics derived from information theory?"
https://aclanthology.org/2022.conll-1.15/,"Can multilingual large language models achieve comparable performance in metaphor detection when trained on large datasets of naturally occurring metaphors in Spanish compared to their English counterparts, and what are the most informative features extracted by these models that contribute to their performance? Can supervised metaphor detection systems be effectively fine-tuned on the newly created CoMeta dataset for multilingual metaphor detection with high accuracy and robustness across different linguistic and domain contexts?"
https://aclanthology.org/2022.conll-1.16/,"Can a neural text simplification model be trained to prioritize cognitive accessibility features in addition to readability, and how can this be evaluated using a benchmark dataset specifically designed for cognitive simplification tasks?"
https://aclanthology.org/2022.conll-1.16/,"Does the use of inductive bias regarding simplification operations improve the performance of a text simplification model on cognitive simplification tasks, and how does it compare to traditional text simplification benchmarks?"
https://aclanthology.org/2022.conll-1.17/,Can a text-based feature space approach using only shorter distances be more precise in predicting the success of cross-lingual transfer of parsing models than syntactic typological distances extracted from URIEL for languages with significant linguistic differences?
https://aclanthology.org/2022.conll-1.17/,"Does the coverage of typological databases impact the success of cross-lingual transfer of parsing models, and can alternative feature spaces be more effective in explaining this relationship?"
https://aclanthology.org/2022.conll-1.18/,"Can we develop a method to automatically parse images into Abstract Meaning Representation (AMR) graphs, improving the representation of visual entities and their relations, and measuring its performance through the accuracy of extracted entities and relations? Can we create a framework for generating meta-AMR graphs from multiple image descriptions, allowing for a unified representation of visual information and evaluating its effectiveness through user satisfaction and semantic recall?"
https://aclanthology.org/2022.conll-1.19/,Is the use of language models to estimate the cost of word and syntactic predictability in garden path sentences sufficient to account for the magnitude of human garden path effects?
https://aclanthology.org/2022.conll-1.19/,Can language models accurately capture the weighting of syntactic factors in human predictions of garden path sentences?
https://aclanthology.org/2022.conll-1.20/,Can a language model-based approach using indirect supervision from textual entailment datasets and weak supervision from data generated by pre-trained language models effectively generalize to unseen topics and domains in open-domain zero-shot stance detection?
https://aclanthology.org/2022.conll-1.20/,"Can the proposed method achieve higher performance on open-domain stance detection compared to supervised methods, as demonstrated by its superiority on three popular datasets?"
https://aclanthology.org/2022.conll-1.21/,What is the optimal level of structural information required for creating robust text representations for pairwise similarities between political parties using claim span and claim category annotations versus document structure-based heuristics?
https://aclanthology.org/2022.conll-1.21/,Can heuristics that maximize within-party over between-party similarity and a normalization step achieve reliable party similarity prediction without manual annotation of claim span and claim category annotations in text representations?
https://aclanthology.org/2022.conll-1.22/,"Can a cue-based retrieval model that incorporates the Lexical Bottleneck Hypothesis be used to accurately predict the gender of German possessive pronouns in real-time for second language learners, and how does this model compare to a model based on the Interference Hypothesis in terms of accuracy and processing time?"
https://aclanthology.org/2022.conll-1.22/,Does the match effect in L2 speakers differ significantly from that of native speakers when using a model that implements the Lexical Bottleneck Hypothesis to process German possessive pronouns?
https://aclanthology.org/2022.conll-1.23/,"Can PIE-QG's use of Open Information Extraction to generate synthetic training questions for a BERT-based QA system improve the performance of supervised QA systems compared to existing state-of-the-art QA systems that rely on human-labeled data, as measured by accuracy, and how does this approach affect the number of documents required for training?"
https://aclanthology.org/2022.conll-1.23/,"Can the incorporation of Open Information Extraction in the generation of synthetic training questions for a BERT-based QA system lead to a significant reduction in training data required compared to traditional supervised QA systems, and what are the implications of this reduction on the overall performance of the QA system?"
https://aclanthology.org/2022.conll-1.24/,"Can pre-trained language models accurately identify subject-verb agreement errors in a masked language model, and can the results be improved by fine-tuning the model on a specific dataset related to subject-verb agreement errors?"
https://aclanthology.org/2022.conll-1.24/,Can the performance of language models on subject-verb agreement error detection vary significantly when the probe is trained on different training sets or evaluated on different syntactic constructions?
https://aclanthology.org/2022.conll-1.25/,"Can the proposed alignment-based approach to segmentation similarity scoring improve the accuracy of text segmentation in comparison to the current metrics B and WindowDiff, as measured by the F1-score of the Gold Standard? Can the proposed alignment-based approach be applied to real-world text datasets and what are the implications for the field of text segmentation similarity scoring?"
https://aclanthology.org/2022.conll-1.26/,"How can incorporating Universal Dependencies syntax into machine translation models using a transition-based approach improve syntactic generalization in text decoders, and what are the benefits of this approach compared to vanilla Transformer decoders?"
https://aclanthology.org/2022.conll-1.26/,"Can a transition-based approach to tree decoding improve the performance of machine translation models on test sets that focus on syntactic generalization, while maintaining comparable performance on standard MT benchmarks?"
https://aclanthology.org/2022.conll-1.27/,"Can transformers implement a working memory system that can retrieve individual token representations across arbitrary delays, and how does this ability affect their performance on text classification tasks?"
https://aclanthology.org/2022.conll-1.27/,"Can LSTMs maintain a semantic gist of prior tokens, and what are the implications of this for their performance in tasks that require precise retrieval of specific tokens?"
https://aclanthology.org/2023.conll-1.0/,"What are the factors that contribute to the increased likelihood of language models aligning with human judgments of being ""tricked"" by the negative polarity item illusion, and how can they be improved to better mimic human behavior in complex language processing?"
https://aclanthology.org/2023.conll-1.0/,What are the specific structural dependencies that require sophisticated semantic understanding and affect the behavior of language models in comparative and depth-charge illusions?
https://aclanthology.org/2023.conll-1.1/,"Can large language models (LLMs) effectively demonstrate Theory of Mind (ToM) by comprehending the mental states of distinct individuals in a consistent manner, and can be evaluated using the proposed ToMChallenges dataset and auto-grader?"
https://aclanthology.org/2023.conll-1.1/,"Can the design of ToM tasks and prompts significantly impact the performance of LLMs in demonstrating ToM abilities, and how can these tasks be optimized to better assess the models' capacity for Theory of Mind?"
https://aclanthology.org/2023.conll-1.2/,"Can machine learning algorithms with high accuracy be used to distinguish between human languages and other symbolic and non-symbolic systems, and what are the key features that contribute to this distinction?"
https://aclanthology.org/2023.conll-1.2/,"Does the statistical fingerprint of human languages, including large unit inventories, high entropy, and few repetitions of adjacent units, provide a reliable basis for classification and can be used to improve the performance of classification algorithms?"
https://aclanthology.org/2023.conll-1.3/,"What are the structural modeling methods that are suitable for semantic parsing of both natural and formal languages, and how do they perform in compositional and i.i.d. generalizations?"
https://aclanthology.org/2023.conll-1.3/,Can a combination of structural modeling methods from both source and target sides be used to improve the performance of semantic parsing on specific datasets and domains?
https://aclanthology.org/2023.conll-1.4/,"Can language models trained on next-word prediction tasks exhibit divergent performance with humans when presented with repeated text spans, and what is the impact of adding a power-law recency bias to the attention heads of these models on their performance in aligning with human behavior?"
https://aclanthology.org/2023.conll-1.4/,"Can the addition of a power-law recency bias to the attention heads of LMs improve their performance in simulating human next-word predictions, particularly in scenarios where in-context learning plays a role?"
https://aclanthology.org/2023.conll-1.5/,"Can a supervised classification model using a multi-modal feature set be trained to predict concreteness ratings with high accuracy on mid-scale words, and can the model's performance be improved by fine-tuning the features before training?"
https://aclanthology.org/2023.conll-1.5/,"Can a hard clustering algorithm be used to identify patterns of systematic disagreement among raters for mid-scale words, and can the clusters be used to inform a filtering approach to reduce variability in concreteness ratings?"
https://aclanthology.org/2023.conll-1.6/,"Can ArchBERT improve the performance of neural architecture search tasks when compared to state-of-the-art methods using a single textual query for neural architecture retrieval and generation, and what are the benefits of using the Masked Architecture Modeling (MAM) pre-training strategy in joint learning of neural architectures and natural languages?"
https://aclanthology.org/2023.conll-1.7/,"Can eye-tracking data be used to improve the accuracy of natural language processing models by providing a more nuanced understanding of human linguistic understanding of style, and how does it compare to human annotation methods? Does the saliency data from eye-tracking align with model-based importance scores in evaluating the cognitive plausibility of models that interpret style?"
https://aclanthology.org/2023.conll-1.8/,Can a supervised learning approach using DeBERTa be able to accurately capture the variability of projectivity in presupposition across different linguistic triggers and environments?
https://aclanthology.org/2023.conll-1.8/,"How can a dataset like PROPRES be used to evaluate the performance of natural language understanding models on pragmatic inferences, including projectivity, and what features or metrics would be most informative for model evaluation?"
https://aclanthology.org/2023.conll-1.9/,"What is the impact of utilizing admissible actions in reinforcement learning for text-based games on the performance of the agent, measured by the average reward received over 10 games from Jericho?"
https://aclanthology.org/2023.conll-1.9/,"How does the proposed text-based actor-critic agent perform in comparison to strong baselines and state-of-the-art agents that utilize knowledge graphs and language models, in terms of the average reward received across 10 games from Jericho?"
https://aclanthology.org/2023.conll-1.10/,Can grounding the presence of a prior sentence improve the disambiguation of Dutch relative clauses in a proof net-based parser compared to a universal dependency-based parser?
https://aclanthology.org/2023.conll-1.10/,Does the use of grounding to resolve relative clause ambiguities in neural parsers increase the effectiveness of data bias correction in both architectures?
https://aclanthology.org/2023.conll-1.11/,Can TOR pretraining objectives improve the performance of language models on word-order sensitive tasks compared to masked language modeling objectives?
https://aclanthology.org/2023.conll-1.11/,Does the incorporation of Graph Isomorphism Network on top of the BERT encoder enhance the ability of language models to leverage topological signal from the encoded representations?
https://aclanthology.org/2023.conll-1.12/,They can help researchers develop a comprehensive framework for modal verb sense categorization by analyzing the inter-annotator agreements between Quirk and Palmer frameworks on a large-scale dataset like MoVerb.
https://aclanthology.org/2023.conll-1.12/,Can fine-tuning RoBERTa-based classifiers on MoVerb improve the accuracy of modal verb sense disambiguation by reducing the impact of polysemy and increasing inter-annotator agreement among different frameworks?
https://aclanthology.org/2023.conll-1.13/,Can the proposed Information Quantifier (IQ) model effectively balance the trade-off between translation quality and latency in Simultaneous Translation by accurately quantifying the information available to the offline model?
https://aclanthology.org/2023.conll-1.13/,Does the incorporation of the IQ model into Simultaneous Translation systems lead to improved generalization and better control over the quality-latency trade-off compared to existing approaches?
https://aclanthology.org/2023.conll-1.14/,Can a neural machine translation approach leveraging human judgements improve the quality of code-mixed sentences for NLP downstream tasks?
https://aclanthology.org/2023.conll-1.14/,Can a multi-lingual encoder-decoder model fine-tuned on filtered data outperform current systems for code-mixed generation in low-resource languages?
https://aclanthology.org/2023.conll-1.15/,What is the effect of using different evaluation metrics on the accuracy of large language models in following user instructions in the context of grounded query-based summarization?
https://aclanthology.org/2023.conll-1.15/,How do reference-free evaluation methods compare to established baselines in terms of quantifying instruction-following abilities of LLMs in real-world datasets?
https://aclanthology.org/2023.conll-1.16/,"Can Transformer-based language models with syntactic inductive bias effectively compensate for data sparseness in low-resource languages such as Uyghur, Wolof, Maltese, Coptic, and Ancient Greek?"
https://aclanthology.org/2023.conll-1.16/,Can the use of syntactic inductive bias in pretraining reduce the required data volume for low-resource languages compared to state-of-the-art models without such bias?
https://aclanthology.org/2023.conll-1.17/,"Does a language model trained on large amounts of written fluent language produce human-like levels of repetition in dialogue, and what are the processing mechanisms related to lexical re-use used during comprehension?"
https://aclanthology.org/2023.conll-1.17/,Can humans and language models distinguish between human-like repetition in dialogue and repetition that is penalized by evaluation metrics?
https://aclanthology.org/2023.conll-1.18/,"How do compositional splitting strategies impact the performance of NLP models across different datasets, measured by the accuracy of compositional generalization splits?"
https://aclanthology.org/2023.conll-1.18/,"Can human-designed datasets outperform synthetic datasets in evaluating compositional generalization, considering the impact of specific lexical items on evaluation metrics?"
https://aclanthology.org/2023.conll-1.19/,What is the impact of spurious correlations between input distributions and labels on the robustness of language models adapted via in-context learning and instruction tuning in different prompting setups?
https://aclanthology.org/2023.conll-1.19/,"How do the design choices of model architecture, training data, and hyperparameters affect the stability and consistency of language model predictions in different scaling factors of instructed language models?"
https://aclanthology.org/2023.conll-1.20/,"What are the performance differences between the LLMs' ability to reason and retrieve information when facing memory-based hallucination tests in the Med-HALT dataset, and what can be improved to mitigate these differences?"
https://aclanthology.org/2023.conll-1.20/,"How effective are the proposed Med-HALT benchmark and dataset in evaluating the hallucination capabilities of LLMs in the medical domain, and what are the implications for the development of safer and more reliable language models?"
https://aclanthology.org/2023.conll-1.21/,Do incremental sequence labelling models benefit from revising their output hypothesis when the probability of regressions and skips in human reading eye-tracking data exceeds a certain threshold?
https://aclanthology.org/2023.conll-1.21/,Can generalized mixed-effects models effectively predict revisions in incremental sequence labelling models using human reading eye-tracking data?
https://aclanthology.org/2023.conll-1.22/,"Can the syntactic complexity of stories told by children in ChiSCor be used to predict their age, and what are the implications of this finding for language development research?"
https://aclanthology.org/2023.conll-1.22/,"Can the Zipfian distribution of words in ChiSCor be used to model language use in free speech, and how does this relate to the social context of the stories?"
https://aclanthology.org/2023.conll-1.23/,"Can ITM models be improved by training on Hard Negative Captions (HNC) for fine-grained cross-modal comprehension in Vision and Language, and what metrics can be used to evaluate their performance?"
https://aclanthology.org/2023.conll-1.23/,Can the use of HNC lead to better zero-shot capabilities in detecting mismatches on diagnostic tasks and robustness under noisy visual input scenarios?
https://aclanthology.org/2023.conll-1.24/,"Can Large Language Models (LLMs) effectively reason about intentions and beliefs using non-literal language, and if so, to what extent do instruction-tuned LLMs outperform base-LLMs on this task? Can LLMs be benchmarked against children aged 7-10 on ToM tasks, and if so, what are the implications for their development and evaluation?"
https://aclanthology.org/2023.conll-1.25/,"How does the proposed MH sampler perform in terms of accuracy when generating text using a large language model, compared to traditional single-token proposal techniques?"
https://aclanthology.org/2023.conll-1.25/,"Can the proposed sampler enable more flexible and efficient text generation length determination, and if so, how does it compare to fixed-length generation in terms of downstream performance?"
https://aclanthology.org/2023.conll-1.26/,What is the impact of random and type-constrained entity replacements on the performance of state-of-the-art relation extraction models and how can they be improved?
https://aclanthology.org/2023.conll-1.26/,Can the design of entity replacement strategies enhance the robustness of relation extraction models to changes in entity names in the textual context?
https://aclanthology.org/2023.conll-1.27/,Can the JaSPICE metric improve the correlation between automatic and human evaluation of Japanese image captions compared to existing metrics such as BLEU and METEOR? Does the proposed method of generating a scene graph and extending it using synonyms improve the accuracy of automatic evaluation of Japanese image captions compared to the baseline methods?
https://aclanthology.org/2023.conll-1.28/,"Can MuLER effectively identify the most critical error types in machine translation tasks, such as translating names of locations, and how does its performance correlate with overall system performance for different languages?"
https://aclanthology.org/2023.conll-1.28/,"Can MuLER's methodology be adapted to other NLP tasks, such as summarization, and what are the trends in error analysis for different parts of speech tags in these tasks?"
https://aclanthology.org/2023.conll-1.29/,"Does familiarity with an object influence the degree of naming variation among speakers of Mandarin Chinese, and can computational methods be used to quantify this relationship? Does the relationship between familiarity and naming variation depend on the level of linguistic and cultural familiarity with the object?"
https://aclanthology.org/2023.conll-1.30/,"Can the proposed model achieve a high accuracy in identifying Intonation Unit (IU) boundaries on degraded speech data, and how does it compare to other existing transcription models?"
https://aclanthology.org/2023.conll-1.30/,Does the model's reliance on lexico-syntactic information inferenced from audio improve its performance on out-of-distribution data representing different dialects and transcription protocols?
https://aclanthology.org/2023.conll-1.31/,"Can a masked sequence model be trained to predict the most probable distribution of morphemes in a target language given a source language and context, and how does this approach compare to traditional methods for learning morphological segmentation and lexicon learning in character-based word translation tasks?"
https://aclanthology.org/2023.conll-1.31/,"Can a pointwise mutual information model be used to jointly localize referents and learn word meanings in visually grounded reference resolution, and what are the advantages of using this approach over traditional structured and neural baselines?"
https://aclanthology.org/2023.conll-1.32/,Can recurrent neural networks achieve better performance in dependency parsing when each token is represented by a sequence of vectors rather than a single vector? Does the use of multiple time steps to access token representations improve the accuracy of biaffine parsers?
https://aclanthology.org/2023.conll-1.33/,Can a convolution module improve the generalization ability of morphological inflection models for low-resource agglutinative languages by extracting syllable-like units from lemmas?
https://aclanthology.org/2023.conll-1.33/,Does the representation of lemma and feature labels separately in the input with marked position encoding of feature labels enhance the model's performance in morphological inflection tasks?
https://aclanthology.org/2023.conll-1.34/,"Can transformer models be effectively pre-trained with human-scale datasets of 5 million words or less, while retaining comparable downstream capabilities? Can model distillation be compared to pretraining reduced size transformer models in terms of performance and computational efficiency?"
https://aclanthology.org/2023.conll-1.35/,"Can unsupervised parsing models be trained on texts with no branching bias, and what are the implications for their performance on unseen data?"
https://aclanthology.org/2023.conll-1.35/,Can the inherent branching bias of unsupervised parsing models be detected and corrected using raw texts and tree-shape uncertainty metrics?
https://aclanthology.org/2023.conll-1.36/,Can we develop a causal intervention method to predict the token that will appear at position t+1 using only the hidden state of a single token at position t in a transformer network?
https://aclanthology.org/2023.conll-1.36/,"Can a single hidden state in a transformer network accurately predict the token output at position t+2, and if so, what is the average accuracy of such predictions?"
https://aclanthology.org/2023.conll-1.37/,"Can Large Language Models (LLMs) achieve comparable performance to human annotators in Cross-Document Event Coreference Resolution (CDEC) with minimal training data, and what are the implications for annotation workflows in the age of LLMs?"
https://aclanthology.org/2023.conll-1.37/,"Do GPT-4 models' tendencies of overconfidence in annotation decisions have significant effects on the accuracy and reliability of CDEC annotations, and how can these effects be mitigated?"
https://aclanthology.org/2023.conll-1.38/,What is the effect of removing biases from edge probing test datasets on the performance of large language models (LLMs) in encoding linguistic knowledge?
https://aclanthology.org/2023.conll-1.38/,"Does the use of information theoretic probes lead to a more accurate measurement of an LLM's capacity to encode knowledge, rather than the classifiers' ability to learn the problem?"
https://aclanthology.org/2023.conll-1.39/,How does the use of human highlights during training impact the faithfulness of the rationale extracted by REFER in comparison to previous baseline methods?
https://aclanthology.org/2023.conll-1.39/,"Can REFER improve the plausibility of rationale extracted explanations by jointly training the task model and the rationale extractor, as opposed to training them separately?"
https://aclanthology.org/2024.conll-1.0/,How can Coherence's use of strong sentence embeddings and keyword storage improve the performance of text segmentation tasks using Pk and WindowDiff scores as evaluation metrics?
https://aclanthology.org/2024.conll-1.0/,"Can Coherence's approach to using sentence embeddings to represent coherent blocks of text outperform unsupervised methods in terms of accuracy and efficiency, without requiring fine-tuning or large amounts of labeled training data?"
https://aclanthology.org/2024.conll-1.1/,"Can large language models (LLMs) accurately extract well-structured utterances from transcriptions of noisy dialogues, as measured by the percentage of correctly extracted utterances?"
https://aclanthology.org/2024.conll-1.1/,"Can LLMs acquire and apply syntactic-semantic rules to extract meaningful content from noisy utterances, as evaluated by the reduction in disfluencies and filled pauses in extracted utterances?"
https://aclanthology.org/2024.conll-1.2/,Can a GPT-3.5 Turbo based approach utilizing social factors and a large language model be used to automatically discover sociocultural norms in new cultures without relying on human annotations or real-world dialogue contents?
https://aclanthology.org/2024.conll-1.2/,Can the proposed Multi-cultural Norm Base (MNB) dataset and its associated fine-tuned Llama 3 model improve the accuracy of norm discovery tasks in various downstream applications?
https://aclanthology.org/2024.conll-1.3/,Does the Lossy Context Surprisal model accurately predict retention rates for relative clause processing tasks at different retention rates and can it capture task-dependent memory demands?
https://aclanthology.org/2024.conll-1.3/,Can LCS be used to reconcile the mixed results from behavioral experiments on relative clause processing by accounting for variations in memory demands across different tasks?
https://aclanthology.org/2024.conll-1.4/,"Can G-Pruner improve the inference latency of large language models by pruning the model's parameters more effectively than existing methods without requiring retraining? Does G-Pruner's global optimization strategy enhance the model's stability and adaptability to environmental changes, leading to improved performance on out-of-distribution data?"
https://aclanthology.org/2024.conll-1.5/,"Can large language models learn to retrieve in-context nouns verbatim after a certain point in the training process, and how does this ability correlate with the learning of more challenging zero-shot benchmarks?"
https://aclanthology.org/2024.conll-1.5/,"Does the ability of language models to retrieve in-context nouns verbatim correlate with the learning of more challenging zero-shot benchmarks, particularly with respect to concrete versus abstract nouns?"
https://aclanthology.org/2024.conll-1.6/,"Can pre-trained models perform editing tasks such as making text more cohesive and paraphrasing with comparable accuracy to supervised models, and if so, how can these models be improved to neutralize outdated information and update text style consistently?"
https://aclanthology.org/2024.conll-1.6/,"Can the use of different metrics for evaluating editing capabilities, such as coherence and paraphrasing, be aligned to better reflect the complexity of real-world editing tasks and improve model performance?"
https://aclanthology.org/2024.conll-1.7/,"Can Constrained Word2Vec (CW2V) outperform cross-lingual embeddings in initializing embeddings for new languages in multilingual continued pretraining of language models, and how does it compare to multivariate initialization?"
https://aclanthology.org/2024.conll-1.7/,"Does CW2V's simplicity and performance indicate that large-scale multilingual continued pretraining can be achieved with simpler initialization methods, and what are the implications for the development of more efficient language models?"
https://aclanthology.org/2024.conll-1.8/,"What are the most effective methods for instantiating CQs templates defined by Walton's argumentation theory for large-scale experimentation, and how can they be used to generate critical questions in a way that evaluates the validity of LLMs as CQ generators?"
https://aclanthology.org/2024.conll-1.8/,"Can LLMs be improved to generate critical questions that are more accurate and relevant to the arguments they are processing, and if so, what are the key factors that contribute to their success in this task?"
https://aclanthology.org/2024.conll-1.9/,Can a self-prompting-based question-answer generation process improve the generalizability of Large Language Models to new information in question-answer pairs pertaining to the updating information?
https://aclanthology.org/2024.conll-1.9/,"Can the proposed associative distillation methods effectively bridge the LM-logical discrepancy in language modeling probabilities and logical probabilities, leading to a more factual consistency score?"
https://aclanthology.org/2024.conll-1.10/,Can the use of Causal Average Treatment Effect (CATE) in language models improve the removal of spurious correlations between words and attributes in the training dataset?
https://aclanthology.org/2024.conll-1.10/,Does the application of CATE in toxicity mitigation in language models reduce inadvertent bias towards protected groups post detoxification?
https://aclanthology.org/2024.conll-1.11/,Can Large Language Models with world knowledge improve their performance in resolving sense ambiguities in word sense disambiguation tasks?
https://aclanthology.org/2024.conll-1.11/,How do the limitations of current word sense disambiguation datasets impact the evaluation of Large Language Models' reasoning capabilities?
https://aclanthology.org/2024.conll-1.12/,"What is the potential for using narrative elements as features to measure semantic similarity between stories, and how does this approach compare to traditional text similarity metrics?"
https://aclanthology.org/2024.conll-1.12/,Can the use of large language models to extract narrative elements and compute story similarity scores from film scripts improve human evaluation results?
https://aclanthology.org/2024.conll-1.13/,What are the implications of the Participial-Phase theory for human relative clause representations in the context of sentence processing and comprehension-to-production priming paradigm?
https://aclanthology.org/2024.conll-1.13/,How does the reanalysis mechanism in SPAWN influence the accuracy of priming predictions from different syntactic theories in modeling human sentence representation?
https://aclanthology.org/2024.conll-1.14/,Can IARSum improve the faithfulness degree of candidate summaries with respect to a source document compared to global learning methods?
https://aclanthology.org/2024.conll-1.14/,Does IARSum reduce lexical differences between candidate and reference summaries more effectively than existing abstractive summarization models?
https://aclanthology.org/2024.conll-1.15/,Can TpT-ADE outperform the state-of-the-art methods in identifying adverse reactions to medications using a shallow neural network architecture?
https://aclanthology.org/2024.conll-1.15/,Does the use of a POS embedding model improve the intensity of AE entities in the TpT-ADE model compared to other approaches?
https://aclanthology.org/2024.conll-1.16/,How do regime-specific surprisal estimates compare to standard surprisal estimates in predicting processing times in information seeking and repeated reading tasks?
https://aclanthology.org/2024.conll-1.16/,Do regime-specific surprisal estimates from context-matched contexts improve the predictive power of processing times in information seeking tasks?
https://aclanthology.org/2024.conll-1.17/,"Can hierarchical text classification models achieve high accuracy when using a simple but strong baseline and a theoretically motivated loss function, and how does this compare to the latest state-of-the-art models in terms of performance? Can the design of the evaluation methodology significantly impact the competitiveness of hierarchical text classification models with recent sophisticated models?"
https://aclanthology.org/2024.conll-1.18/,Can the NeLLCom-X framework accurately capture the emergence of a word-order/case-marking trade-off in simulated languages with realistic role-alternating agents and group communication?
https://aclanthology.org/2024.conll-1.18/,Can the replication of linguistic properties in NeLLCom-X be influenced by the interaction between agents and group size in simulated language evolution?
https://aclanthology.org/2024.conll-1.19/,Can chain-of-thought reasoning be effectively integrated with code transfer methods for mathematical problem-solving in Vietnamese without requiring sophisticated inference procedures?
https://aclanthology.org/2024.conll-1.19/,Can ViMath-InstructCode dataset be used to fine-tune large language models with less than 10 billion parameters for mathematical reasoning tasks in Vietnamese?
https://aclanthology.org/2024.conll-1.20/,Does a neural language model differentiate grammatically correct filler-gap dependencies from ungrammatical ones based on shared structural representations or superficial input properties? Can the incorporation of specific linguistic inductive biases improve the model's ability to generalize grammatical FGDs?
https://aclanthology.org/2024.conll-1.21/,"Can BERT and GPT models accurately capture human-like agreement attraction in Russian, as indicated by their performance in statistical testing of syncretic forms? Does the surface form of words influence the attraction phenomenon in models more than the underlying grammatical feature?"
https://aclanthology.org/2024.conll-1.22/,"Is the structure dependence in natural language crucial for its communicative efficiency, and can a linear reduction operation achieve similar results? Can structure-dependent grammar-internal operations be reduced to domain-general cognitive abilities that prioritize efficient communication?"
https://aclanthology.org/2024.conll-1.23/,Can large language models exhibit cognitive fan effects after being pre-trained on human textual data and what impact does removing uncertainty have on these effects? Does the fan effect occur consistently in LLMs whether it is induced in-context or in the pre-training data?
https://aclanthology.org/2024.conll-1.24/,"Can Continuous Attentive Multimodal Prompt Tuning model (CAMP) effectively reduce overfitting in few-shot multimodal sarcasm detection, as measured by accuracy on out-of-distribution data? Does the novel, continuous multimodal attentive prompt in CAMP improve knowledge assimilation from different input modalities, as indicated by the model's performance on few-shot multimodal sarcasm detection tasks?"
https://aclanthology.org/2024.conll-1.25/,"Are there settings in which the predictions of colexification-based and distributional methods can be directly compared and evaluated using a common metric, such as precision or recall, and what are the implications of their differences in predicting semantic domains?"
https://aclanthology.org/2024.conll-1.25/,"Can distributional methods capture a more fine-grained alignment than colexification-based methods in predicting kinship terms, and how does this impact their suitability for evaluating language lexicons across diverse languages?"
https://aclanthology.org/2024.conll-1.26/,"Can pre-trained language models accurately identify object affordances from in-the-wild sentences, and what are the performance metrics for such a task?"
https://aclanthology.org/2024.conll-1.26/,"Can pre-trained Vision-Language models effectively capture object affordances from in-the-wild sentences, and how does few-shot fine-tuning improve their performance?"
https://aclanthology.org/2024.conll-1.27/,"Can transformer-based language models distinguish metaphors from non-metaphors as accurately as they distinguish other types of analogies, and does model size impact this ability?"
https://aclanthology.org/2024.conll-1.27/,"Do larger transformer-based language models outperform smaller models in identifying metaphors in zero-shot generation settings, and if so, what is the relationship between model size and this ability?"
https://aclanthology.org/2024.conll-1.28/,Can frequency-aware sparse coding be used to compress the embedding layers of pre-trained language models while maintaining their accuracy on downstream tasks?
https://aclanthology.org/2024.conll-1.28/,Can frequency-aware sparse coding reduce the computational resource requirements of pre-trained language models by compressing the embedding layers of fine-tuned models while retaining common tokens and reconstructing rare tokens using local linear mapping?
https://aclanthology.org/2024.conll-1.29/,"Can LLMs accurately adapt source culture references to suit the target culture, and how does the quality of adaptation impact the overall translation performance, measured by syntactic correctness and user satisfaction?"
https://aclanthology.org/2024.conll-1.29/,"Can LLMs effectively exploit their cultural knowledge to handle nuanced cultural differences and cross-cultural references in multilingual applications, and what are the limitations of automatic adaptation methods?"
https://aclanthology.org/2024.conll-1.30/,"Can the proposed taxonomy of incorrect predictions help in identifying the linguistic phenomena that contribute most to the high rate of misclassification in the product review domain, and how can the model be improved to mitigate the impact of amplified words and contrastive markers on its predictions?"
https://aclanthology.org/2024.conll-1.30/,"Can the proposed taxonomy of incorrect predictions help in understanding the role of world knowledge and comparative sentences in the misclassification of movie reviews, and how can the model be improved to better utilize this knowledge and reduce the rate of incorrect labeling in the gold dataset?"
https://aclanthology.org/2024.conll-1.31/,"Can LLAVA's predictive attention be improved by incorporating domain-specific knowledge or linguistic patterns, and how does this impact its ability to attend to objects relevant to verbs?"
https://aclanthology.org/2024.conll-1.31/,Does the layer-wise analysis of LLAVA's attention weights provide insights into the relationship between its predictive capabilities and the complexity of its layers?
https://aclanthology.org/2024.conll-1.32/,Does the use of text gradients from a reflection and optimization engine in the Principled Reasoning and Acting (PRAct) framework improve the learning and enforcing of action principles in various environments?
https://aclanthology.org/2024.conll-1.32/,"Can the Reflective Principle Optimization (RPO) framework, which combines reflection and optimization, outperform other methods in adapting to task-specific requirements?"
https://aclanthology.org/2024.conll-1.33/,"How do visual language models capture the facilitatory effect of correct image context on language comprehension, and what is the relationship between perplexity and psychometric performance in visual language models?"
https://aclanthology.org/2024.conll-1.33/,Can a visual language model's surprisal measure accurately predict the facilitatory effect of correct image context on language comprehension in multimodal contexts?
https://aclanthology.org/2024.conll-1.34/,"Can SSL transformer-based architectures like wav2vec 2.0 effectively capture the linguistic property of language specificity in human speech perception, as evidenced by their performance on Hindi vs. English speech contrasts? Does the wav2vec 2.0 model exhibit a language specificity effect when tested on finer-grained differences in Hindi speech?"
https://aclanthology.org/2024.conll-1.35/,Can a linguistically-motivated redefinition of the grapheme that incorporates vowel and consonant count and word length improve the accuracy of Grapheme-to-Phoneme (G2P) correspondences in text-to-speech synthesis and automatic speech recognition tasks?
https://aclanthology.org/2024.conll-1.35/,"Can a multi-binary neural classification task be used as a proof-of-concept implementation for a more nuanced and accurate grapheme segmentation model, and how can it be further refined to achieve state-of-the-art results?"
https://aclanthology.org/2024.conll-1.36/,Can the development of a type-specific counterspeech tool using Flan-T5 improve the relevance of counterspeech responses while maintaining a high level of language quality?
https://aclanthology.org/2024.conll-1.36/,Can the use of type-specific prompts with DialoGPT enhance the accuracy of counterspeech responses while following instructions and adhering to specific counter-speech types?
https://aclanthology.org/2024.conll-1.37/,"How can the performance of language models on challenge sets like the Winograd Schema Challenge be used to evaluate their performance on more general tasks, and what are the limitations of this approach?"
https://aclanthology.org/2024.conll-1.37/,Can ensembling a prompted language model with a task-specific system improve the accuracy of resolving pronominal coreference across different datasets?
https://aclanthology.org/2024.conll-1.38/,"Can fuzzy logic-based sentiment classification models outperform traditional machine learning models in Arabic sentiment analysis tasks, and how does the incorporation of fuzzy logic affect the performance of sentiment analysis models on COVID-19-related Arabic text? Can the ArSen dataset serve as a comprehensive benchmark for Arabic sentiment analysis models, and what are the key challenges and future research directions for Arabic sentiment analysis given the current state-of-the-art model's performance?"
https://aclanthology.org/2024.conll-1.39/,Can Instance-Based Individualized Similarity (IBIS) metric with LLM embeddings effectively address the limitations of traditional cosine similarity in educational settings where biases and constraints impact similarity metrics?
https://aclanthology.org/2024.conll-1.39/,"Does the integration of IBL with LLM embeddings improve the accuracy of human categorizations of emails as phishing or safe, as measured by human judgements of category or preference?"
https://aclanthology.org/2024.conll-babylm.0/,Can hybrid causal-masked language models with improved training objectives outperform the baseline models on the BabyLM Challenge tasks using a 100M-word text-only dataset?
https://aclanthology.org/2024.conll-babylm.0/,Do multimodal vision language models achieve better performance on the BabyLM Challenge tasks when using a larger image-text dataset?
https://aclanthology.org/2024.conll-babylm.1/,What is the optimal vocabulary size for a language model inspired by human child language acquisition that balances performance and data efficiency?
https://aclanthology.org/2024.conll-babylm.1/,"Can curriculum learning enhance the performance of a language model when trained on a curated dataset of child-directed transcripts and TVR dialogues, and what are the implications for dataset selection and vocabulary scaling?"
https://aclanthology.org/2024.conll-babylm.2/,"Can the proposed method of combining self-distillation and reverse-distillation improve the training efficiency of large language models by reducing the number of tokens required during training, and how does this impact the accuracy of the trained models on the BLiMP and GLUE benchmarks?"
https://aclanthology.org/2024.conll-babylm.2/,"Can the use of ensemble models consisting of smaller and larger models improve the generalization and robustness of language models on unseen data, and what is the optimal configuration of model sizes for this approach?"
https://aclanthology.org/2024.conll-babylm.3/,Can phoneme-based training improve the performance of a language model on tasks that rely on phonological language acquisition?
https://aclanthology.org/2024.conll-babylm.3/,Can the conversion of text datasets into phonemes improve the performance of a model on sound-based tasks?
https://aclanthology.org/2024.conll-babylm.4/,What is the impact of character-level tokenization on the vocabulary size and performance of language models compared to subword-based tokenization in the context of the BabyLM challenge?
https://aclanthology.org/2024.conll-babylm.4/,"Can phoneme-converted character-based models achieve comparable grammatical performance to subword-based models, and what are the implications for language modeling techniques?"
https://aclanthology.org/2024.conll-babylm.5/,"Does curriculum learning improve the performance of multimodal models on tasks that combine text and image when compared to non-curriculum learning methods, and can pretraining with text-only data exacerbate or mitigate this effect? Does curriculum learning provide a significant advantage on text-only tasks for models with smaller trainable parameter counts compared to those with larger parameter counts?"
https://aclanthology.org/2024.conll-babylm.6/,"Can recurrent neural networks (RNNs) with HGRN2 architecture achieve comparable performance to transformer-based models in low-resource language modeling scenarios as measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks?"
https://aclanthology.org/2024.conll-babylm.6/,Does knowledge distillation improve the performance of HGRN2 models compared to transformer-based models in low-resource language modeling tasks?
https://aclanthology.org/2024.conll-babylm.7/,Can the use of reverse Kullback-Leibler divergence as the objective function in teacher-student distillation improve the performance of models when compared to the traditional mode-averaging approach?
https://aclanthology.org/2024.conll-babylm.7/,Does incorporating advanced optimization strategies enhance the robustness of single-teacher models in the context of teacher-student distillation?
https://aclanthology.org/2024.conll-babylm.8/,What is the impact of linguistically motivated biases on the performance of gated Recurrent Neural Networks in learning the relevant set of linguistic constraints for the BLiMP task?
https://aclanthology.org/2024.conll-babylm.8/,"How does the use of specifically gated RNNs, inspired by Minimalist Grammar intuitions, compare to standard RNN variants (LSTMs and GRUs) in terms of training loss and BLiMP accuracy?"
https://aclanthology.org/2024.conll-babylm.9/,What is the relationship between the emergence of modular components in large language models trained on cognitively plausible datasets and their ability to generalize to human-like language learning signals?
https://aclanthology.org/2024.conll-babylm.9/,"How do causal interpretability methods help understand the processing of multimodal vision-language models, particularly in relation to the specialization of neurons for related tasks and modal inputs?"
https://aclanthology.org/2024.conll-babylm.10/,"Can the inclusion of a parser network in the ELC-BERT architecture improve its performance on tasks requiring complex syntactic analysis, as measured by the evaluation metric of syntactic correctness, in the EWoK evaluation framework?"
https://aclanthology.org/2024.conll-babylm.10/,"Does the parser network's effect on learning different concepts in the ELC-BERT architecture differ across domains, and can it be quantified using metrics such as accuracy or processing time?"
https://aclanthology.org/2024.conll-babylm.11/,"Can BabyLM be effectively extended to Mandarin Chinese by leveraging existing linguistic resources and high-quality spontaneous speech corpora, and what evaluation metrics should be adopted to assess its performance in predicting production-related variables such as speech reductions and prosodic prominences?"
https://aclanthology.org/2024.conll-babylm.11/,"Can the use of cognitively sensitive models for predicting speech reductions, sequences co-occurring with listeners' backchannels, and disfluencies in spontaneous speech in French and English improve its performance compared to non-cognitively sensitive models?"
https://aclanthology.org/2024.conll-babylm.12/,Can a masked language model be trained to predict latent semantic classes of words more accurately than traditional masked language modeling by pre-training on the latent concepts extracted from the hidden representations of a student model using sparse coding?
https://aclanthology.org/2024.conll-babylm.12/,"Can a final stage of pre-training, which combines the benefits of both traditional masked language modeling and the use of latent semantic properties, improve the fine-tunability of the model on downstream tasks while preserving its language modeling capabilities?"
https://aclanthology.org/2024.conll-babylm.13/,"Does the use of explicit linguistic information from Wiktionary enhance the performance of L2 language models, and can training on a combination of paraphrase data and BabyLM pretraining data lead to improved results?"
https://aclanthology.org/2024.conll-babylm.13/,Can paraphrasing data provide a significant advantage over explicit linguistic information in L2 language learning tasks?
https://aclanthology.org/2024.conll-babylm.14/,"Can theoretical linguistic acquisition theories be used to develop fine-grained curriculum learning strategies for Small-Scale Language Models, and how can these strategies be tailored to replicate language acquisition theories for typologically distant language families?"
https://aclanthology.org/2024.conll-babylm.14/,Can fine-grained acquisition-inspired curricula using Child-Directed Speech outperform non-curriculum baselines in improving the performance of Small-Scale Language Models?
https://aclanthology.org/2024.conll-babylm.15/,"Can a curriculum learning approach improve the performance of a GPT-2 model on zero-shot tasks by progressively introducing more complex language patterns in the training data, as measured by the F1 score? Can the use of concreteness norms to assign scores to sentences in the training dataset lead to better fine-tuning performance, as evaluated by the accuracy of the model on a set of predefined tasks?"
https://aclanthology.org/2024.conll-babylm.16/,How does the use of weighted mutual learning in student model search improve the efficiency of data-efficient language model pretraining?
https://aclanthology.org/2024.conll-babylm.16/,Can online distillation of compact students in the inner loop achieve comparable performance to teacher-supervised approaches in language model pretraining?
https://aclanthology.org/2024.conll-babylm.17/,"How can quality estimation methods be used to effectively select and filter large datasets for pretraining neural language models, and what are the optimal strategies for balancing data quality and quantity in machine translation models? Can quality estimation be used to improve the performance of small-scale language models by selectively pretraining on high-quality data?"
https://aclanthology.org/2024.conll-babylm.18/,"How does the use of a novel dataset from Reddit's ""Explain Like I'm Five"" subreddit impact the evaluation scores of masked language modeling in the BabyLM Challenge?"
https://aclanthology.org/2024.conll-babylm.18/,"Does curriculum masking, a pre-training technique that incorporates child language acquisition principles, improve the learning rates of masked language models in the BabyLM Challenge?"
https://aclanthology.org/2024.conll-babylm.19/,"Can WhatIf improve the performance of small-scale language models by leveraging word vectors to enhance training data through targeted substitutions of semantically similar words, measured by downstream evaluation metrics such as accuracy and F1-score?"
https://aclanthology.org/2024.conll-babylm.19/,"Can WhatIf outperform other small-scale data augmentation techniques in terms of quantitative results, while maintaining comparable qualitative evaluation, and what are the tradeoffs between the two approaches?"
https://aclanthology.org/2024.conll-babylm.20/,What is the impact of using an uncertainty model in the Active Curriculum Language Modeling process on the fine-grained grammatical inference performance of the model?
https://aclanthology.org/2024.conll-babylm.20/,Can the ACLM process improve the performance of a pre-trained language model on world-knowledge tasks compared to official base-lines in the BabyLM 2024 task?
https://aclanthology.org/2024.conll-babylm.21/,"Can self-synthesis training with limited data be used to improve the language abilities of large language models, as demonstrated by their performance on tasks such as visual question answering and reasoning?"
https://aclanthology.org/2024.conll-babylm.21/,Can the integration of a vision encoder with a language model in the self-synthesis approach improve the model's ability to generate descriptive captions from unlabeled images?
https://aclanthology.org/2024.conll-babylm.22/,"Can the inclusion of Variation Sets in child-directed speech (CDS) improve the training data efficiency of large language models, as measured by the accuracy of the trained model on benchmark datasets such as BLiMP and GLUE?"
https://aclanthology.org/2024.conll-babylm.22/,"Does the optimal proportion of Variation Sets in CDS data affect the training efficiency of language models, and what are the specific factors that influence this effect, such as the number of epochs and the order of utterance presentation?"
https://aclanthology.org/2024.conll-babylm.23/,"Does the proposed hybrid model architecture improve the performance of masked language models by leveraging the strengths of causal language modeling, and does this improvement hold across different pretraining tasks and datasets?"
https://aclanthology.org/2024.conll-babylm.23/,Can the proposed hybrid model be effectively fine-tuned for specific downstream tasks such as question-answering or text classification using a standard transformer-based architecture?
https://aclanthology.org/2024.conll-babylm.24/,What is the effect of training small language models on diverse datasets versus complex datasets on their performance in a sample-efficient setting?
https://aclanthology.org/2024.conll-babylm.24/,How does the optimal dataset composition for training small language models change with the model size in a sample-efficient setting?
https://aclanthology.org/2024.conll-babylm.25/,"Can a distillation-based approach be used to improve the performance of large language models in low-resource settings, and if so, what is the optimal distillation strategy for such scenarios?"
https://aclanthology.org/2024.conll-babylm.25/,"Can distillation techniques be used to overcome the limitations of large models in low-resource data settings, and what is the relationship between distillation and hyperparameter selection in achieving better performance?"
https://aclanthology.org/2024.conll-babylm.26/,"Can smaller language models with knowledge distillation be trained to match the performance of larger models on the BLiMP, EWoK, and GLUE benchmarks, and what is the optimal balance between model size and training time in this context?"
https://aclanthology.org/2024.conll-babylm.26/,"Can contrastive loss and adversarial loss in knowledge distillation improve the performance of small language models compared to standard knowledge distillation methods, and how do they impact the trade-off between model size and training time?"
https://aclanthology.org/2024.conll-babylm.27/,What is the impact of synthetic story data on the performance of GPT-Neo models when trained on subsets of TinyStories with varying data amounts?
https://aclanthology.org/2024.conll-babylm.27/,How does the combination of synthetic story data with the BabyLM dataset affect the linguistic understanding of LTG-BERT encoder models?
https://aclanthology.org/2024.conll-babylm.28/,"How does the AntLM paradigm achieve faster convergence rates than the CLM and MLM paradigms in the BabyLM Challenge 2023, and what is the impact of the combined training objectives on the overall training performance of AntLMBabyLlama and AntLMLTG-BERT in the BabyLM Challenge 2024?"
https://aclanthology.org/K17-1000/,"Can recurrent neural networks accurately model hierarchical sentence structures, and do they rely too heavily on syntactic context or can they learn to make linguistically sensible generalizations?"
https://aclanthology.org/K17-1000/,Do phrase-structure trees and sentences generated by recurrent neural network grammars (RNNGs) surpass the performance of models that do not exploit linguistic structure in downstream semantic tasks?
https://aclanthology.org/K17-1001/,"Can statistical methods be developed to effectively account for the distortions in children's input data that affect language acquisition, and how can these methods be evaluated for accuracy in capturing the true linguistic structure of the target language? Can machine learning algorithms be designed to learn from children's input data while minimizing the impact of distortions, and what metrics can be used to measure their performance in capturing the statistical structure of the target language?"
https://aclanthology.org/K17-1002/,"Can RNNs improve their performance on complex sentence subject-verb agreement using a multi-task training approach, where the model is trained on both agreement and CCG supertagging tasks? Can the use of multi-task training with limited agreement data improve the performance of language models on other syntactic tasks?"
https://aclanthology.org/K17-1003/,"Can a linear classifier based on stylistic features accurately distinguish between different writing styles in a given story context, and can combining these features with language model predictions improve performance on the story cloze challenge? Can the task framing of a writing task significantly impact the writing style and quality of the generated text?"
https://aclanthology.org/K17-1004/,How can graph merging be used to improve the decomposition of complex dependency graphs into simple subgraphs?
https://aclanthology.org/K17-1004/,Can a data-driven approach using graph merging be used to achieve state-of-the-art performance in parsing complex grammatical relations?
https://aclanthology.org/K17-1005/,Can a neural network model leveraging radical-based eventive information improve the accuracy of metaphor detection in Chinese text by 1.7% compared to a Bag-of-word approach? Does the use of syntactic conditions based on radical groups facilitate the identification and classification of metaphorical events in Chinese text?
https://aclanthology.org/K17-1006/,"Does the collaborative partitioning algorithm outperform individual coreference resolvers on the CoNLL dataset when combining models with different architectures, and how does the performance improve when using a more robust similarity measure? Can the collaborative partitioning approach be applied to improve coreference resolution for ensembles of weak systems?"
https://aclanthology.org/K17-1007/,Can a deep learning model achieve higher accuracy in Named Entity Disambiguation on WikilinksNED dataset when trained with informative negative examples and novel word and entity embeddings compared to existing state-of-the-art methods?
https://aclanthology.org/K17-1007/,Does the use of a novel sampling method for generating negative examples improve the performance of a neural model in capturing the local context of noisy text fragments in the WikilinksNED dataset?
https://aclanthology.org/K17-1008/,Can a neural network architecture that uses answer ranking as an intermediate step to select informative justifications improve the overall performance of question answering systems and how does this approach impact the selection of answer justifications
https://aclanthology.org/K17-1008/,"Can the proposed approach using learned representations and explicit features to capture the connection between questions, answers, and answer justifications effectively improve justification ranking and answer selection in question answering systems"
https://aclanthology.org/K17-1009/,"Can a classifier be developed to identify essential terms in questions with a precision of 90% or higher, and if so, how can this improve the performance of state-of-the-art QA solvers for elementary-level science questions?"
https://aclanthology.org/K17-1009/,"Can the elimination of non-essential terms from questions significantly impact human ability to answer questions, particularly in difficult domains?"
https://aclanthology.org/K17-1010/,"Can a listwise learning framework be more effective than pairwise ranking methods for structure prediction problems in machine translation, and what are the implications of this approach for improving translation quality? Can the use of top-rank enhanced loss functions lead to significant improvements in translation accuracy, particularly at higher positions in the ranking?"
https://aclanthology.org/K17-1011/,"Can a jointly learned word and sense embedding model improve the separation of word meanings in vector spaces compared to existing word- and sense-based models, measured by semantic similarity and word sense disambiguation accuracy?"
https://aclanthology.org/K17-1011/,"Can the proposed model's ability to learn from large corpora and semantic networks enhance the overall performance of word embeddings in tasks such as text classification and sentiment analysis, compared to traditional word embedding methods?"
https://aclanthology.org/K17-1012/,What is the impact of using universal dependency relations on the performance of word representation models for different word classes in terms of Spearman's rho correlation?
https://aclanthology.org/K17-1012/,How does the proposed framework reduce the training time for word representation models by selecting class-specific context configurations based on dependency relations?
https://aclanthology.org/K17-1013/,Can the proposed word embedding model using SVM regression and quadratic kernel outperform the Skip-gram model in learning word regions for hypernym detection tasks?
https://aclanthology.org/K17-1013/,Can the ranking interpretation of word contexts in the proposed model be sufficient to match or surpass the performance of existing word vector-based methods in modeling word meaning?
https://aclanthology.org/K17-1014/,"Can predictive and count-based word embeddings trained on a custom-made language framework exhibit comparable performance in paradigmatic and syntagmatic tasks, and does additional training data improve the performance of each type of model in word similarity and relatedness inference? Can the impact of post-processing steps on word vectors obtained from predictive and count-based models be assessed using a combination of metrics such as semantic similarity and syntactic correctness?"
https://aclanthology.org/K17-1015/,"Can the use of trajectory softmax and LDA-derived regularizers improve word embeddings learned from conventional language models by leveraging external knowledge, and what is the impact on word similarity and sentiment classification tasks?"
https://aclanthology.org/K17-1015/,Does the incorporation of human-annotated dictionaries as regularizers in language model-based embedding learning lead to more accurate word embeddings and sentiment classification results?
https://aclanthology.org/K17-1016/,"Can the hierarchical sentence-document model with the attention mechanism achieve better performance than existing methods in automatic essay scoring by capturing the varying contributions of different parts of the essay? Does the attention mechanism improve the ability of neural networks to assign relative weights to words and sentences in an essay, leading to more accurate grading?"
https://aclanthology.org/K17-1017/,"Can the proposed method be applied to other NLP tasks, such as named entity recognition or topic modeling, and what would be the expected performance improvements?"
https://aclanthology.org/K17-1017/,"How does the proposed feature selection method handle out-of-domain data in general, and what are the limitations of this approach when applied to domain-specific tasks?"
https://aclanthology.org/K17-1018/,What is the effectiveness of jointly modeling semantic aspects of stories using a neural language model in terms of semantic sequence generation accuracy compared to word-level models?
https://aclanthology.org/K17-1018/,"Can a semantic language model that jointly represents frames, entities, and sentiments improve performance on story cloze test and shallow discourse parsing tasks compared to existing models?"
https://aclanthology.org/K17-1019/,Can a neural encoder-decoder model improve morphological segmentation accuracy by 4% or more compared to a character-level encoder-decoder baseline for learning canonical word structure in multilingual processing tasks?
https://aclanthology.org/K17-1019/,Does the inclusion of corpus counts in machine translation systems improve performance and is this improvement applicable to both encoder-decoder and classical statistical machine translation approaches?
https://aclanthology.org/K17-1020/,Can neural networks with context-aware sentence encoding outperform traditional summarization methods in summarizing complex scientific publications?
https://aclanthology.org/K17-1020/,Can a large-scale dataset of author-provided summaries be used to train more accurate summarization models in the computer science domain?
https://aclanthology.org/K17-1021/,"Can topic models be evaluated based on their ability to align with user preferences, and how does this approach differ from existing evaluation methods that focus solely on topic coherence?"
https://aclanthology.org/K17-1021/,"Can topic models be effectively evaluated using document-level metrics, and what are the implications of this approach for improving topic model quality?"
https://aclanthology.org/K17-1022/,"What is the impact of the proposed agglomerative convolutional neural network on coreference resolution, and how does it compare to other state-of-the-art systems in terms of accuracy?"
https://aclanthology.org/K17-1022/,"Can the entity linking model using cluster embeddings outperform previous work in character identification, as evidenced by the high F1 score and accuracy achieved by the proposed model?"
https://aclanthology.org/K17-1023/,Can a cross-language adversarial neural network be trained to improve question-question similarity reranking in community question answering for languages with labeled data for the source language and unlabeled data for the target language? Can the CLANN model achieve better performance than a non-adversarial system in cross-language adaptation for question-question similarity reranking?
https://aclanthology.org/K17-1024/,"Does the proposed knowledge tracing method effectively capture a student's acquisition and retention of knowledge during a foreign language phrase learning task, as measured by the student's accuracy on the final test, and does the gating mechanism improve the model's ability to learn complex patterns of retention and acquisition for each feature?"
https://aclanthology.org/K17-1024/,"Can the proposed log-linear parameterization of the knowledge tracing model provide an interpretable knowledge state that accurately reflects a student's knowledge acquisition and retention, as evaluated by the correlation between the model's output and the student's performance on a validation set?"
https://aclanthology.org/K17-1025/,"Can the proposed generative model be applied to other natural language tasks, such as question answering or text classification, and how would the grammar induction process impact the performance of these tasks?"
https://aclanthology.org/K17-1025/,"Can the semantic parser be evaluated using more comprehensive evaluation metrics, such as ROUGE score or human evaluation, to assess its ability to capture nuances of human language?"
https://aclanthology.org/K17-1026/,"Can a Siamese Network-based approach to learning word representations improve the contextual similarity of Tree Kernels, leading to better performance in question and sentiment classification tasks? Can the incorporation of neural-based similarity on tree lexical nodes using semantic Tree Kernels improve the exploitation of focused information in the context of text classification tasks?"
https://aclanthology.org/K17-1027/,"Can neural baseline systems for extractive question answering be improved by incorporating the awareness of question words into their architecture, and what are the benefits of using composition functions beyond bag-of-words modeling in this context?"
https://aclanthology.org/K17-1027/,"Can FastQA's approach to incorporating question word awareness and composition functions be replicated in other extractive question answering systems, and what are the implications for the design of future neural baseline systems?"
https://aclanthology.org/K17-1028/,"Can a deep learning-based question answering system trained on a large open-domain dataset achieve state-of-the-art results on factoid questions in a specific domain with limited data, and can it be adapted to handle list questions with a novel mechanism?"
https://aclanthology.org/K17-1028/,"Can a neural network architecture with biomedical word embeddings and a novel mechanism for handling list questions improve the performance of a question answering system in a domain with limited data, without relying on expensive domain-specific tools?"
https://aclanthology.org/K17-1029/,"Can the proposed divisive hierarchical clustering algorithm effectively identify phonemes or graphemes with high accuracy in unsupervised classification tasks, and what are the distinctive features that the algorithm is unable to detect neatly in certain classes of phonological features? Can the proposed algorithm be adapted to improve its performance in detecting coronal phonemes and consonant/vowel distinctions in NLP tasks?"
https://aclanthology.org/K17-1030/,Can the proposed method for learning a domain-specific sentiment lexicon from StockTwits data improve the accuracy of sentiment analysis in financial texts compared to existing general word embeddings?
https://aclanthology.org/K17-1030/,Can the use of sentiment-oriented word embeddings learned from StockTwits data outperform general word embeddings in predicting investor sentiment in the stock market?
https://aclanthology.org/K17-1031/,"Can a Convolutional Recurrent Neural Network (CRNN) architecture be used to effectively identify local features in biomedical text data, and how does it compare to traditional feature engineering in terms of accuracy?"
https://aclanthology.org/K17-1031/,"Can the use of attentive pooling techniques improve the performance of CRNN models on biomedical relation classification tasks, and what are the key differences between attentive and max pooling methods?"
https://aclanthology.org/K17-1032/,Can a dependency-based method for computing propositional idea density improve diagnostic classification of Alzheimer's disease on free-topic datasets?
https://aclanthology.org/K17-1032/,Can the combination of propositional idea density and semantic idea density improve the diagnostic classification of Alzheimer's disease on normative datasets?
https://aclanthology.org/K17-1033/,"Can a neural network model be trained to extract relations by answering simple reading comprehension questions, and what is the impact of this approach on the accuracy of relation extraction compared to traditional methods? Can a model trained on relation extraction tasks using distant supervision be fine-tuned for zero-shot learning on new, unseen relation types with acceptable accuracy levels?"
https://aclanthology.org/K17-1034/,"Can new algorithms that allow empty categories improve the accuracy of surface parsing in structured parsing models by reducing the approximation error and estimation error, while also mitigating structure-based overfitting through joint decoding and disambiguation models?"
https://aclanthology.org/K17-1034/,"Does the integration of empty elements into parsing models via joint decoding and disambiguation models lead to more accurate surface parsing in English and Chinese TreeBanks, and what is the optimal approach to balancing the benefits and drawbacks of incorporating empty elements?"
https://aclanthology.org/K17-1035/,"Does the use of entropy measure to detect metaphoric change in German be effective in capturing subtle linguistic shifts in meaning, measured by the accuracy of the model in identifying metaphorical extensions of hypernyms, compared to traditional methods? Can the proposed unsupervised approach to detecting metaphoric change be generalized to other languages and linguistic processes, such as idiomatic expression change?"
https://aclanthology.org/K17-1036/,Can the proposed model achieve phoneme representation accuracy by utilizing the features extracted from the speech signal in combination with the activations of the lower layers of the model?
https://aclanthology.org/K17-1036/,Can the use of the attention mechanism in the top recurrent layer improve the invariant encoding of phonological information in the utterance embeddings compared to the hierarchical clustering of phoneme representations learned by the network?
https://aclanthology.org/K17-1037/,Can a cross-lingual word embedding-based transfer learning approach improve the accuracy of semantic parsing systems for code-switching utterances in German compared to baseline domain adaptation techniques?
https://aclanthology.org/K17-1037/,Can a combination of English and German utterances in a sequence-to-sequence model improve the accuracy of semantic parsing systems for code-switching utterances that are not present in the training data?
https://aclanthology.org/K17-1038/,"Can a differentiable relaxation of coreference evaluation metrics improve the performance of competitive neural coreference systems compared to indirect approaches, and what is the impact on the training objective of such systems?"
https://aclanthology.org/K17-1038/,"Can the proposed approach be more computationally efficient than reinforcement learning or imitation learning for optimizing coreference evaluation metrics, and what are the computational costs associated with each method?"
https://aclanthology.org/K17-1039/,"Can the proposed model's ability to learn domain-invariant features using structural correspondence learning improve sentiment analysis on out-of-domain data, and what is the impact of incorporating pre-trained word embeddings on this improvement?"
https://aclanthology.org/K17-1039/,"Can the proposed model's ability to identify pivot features in low-dimensional representations improve the generalization of cross-domain sentiment classification tasks, and how does the incorporation of pre-trained word embeddings affect this ability?"
https://aclanthology.org/K17-1040/,"Does the proposed model's use of bidirectional LSTM encoder improve its accuracy in semantic role labeling when compared to traditional models without this feature, and how does the addition of automatically predicted part-of-speech tags affect its performance on out-of-domain data?"
https://aclanthology.org/K17-1041/,Can a multi-task learning framework improve the accuracy of part-of-speech tagging in morphologically rich languages such as Arabic by jointly modeling multiple morphosyntactic tagging tasks?
https://aclanthology.org/K17-1041/,Can combining word representations with representations of the sets of possible tags improve the performance of neural models in Arabic part-of-speech tagging tasks?
https://aclanthology.org/K17-1042/,"Can a unified segmentation model trained on a combination of Arabic dialects achieve higher accuracy than dialect-specific models, and how does the performance of a model trained on one dialect compare to those trained on other dialects in terms of linguistic relatedness?"
https://aclanthology.org/K17-1043/,"How does the proposed LSTM-based decoder in the Recurrent Neural Network architecture contribute to the generation of natural language sentences, and what are the key differences between the proposed decoder and traditional decoder approaches in NLG systems?"
https://aclanthology.org/K17-1043/,"Can the proposed model be generalized to handle out-of-domain and multi-domain natural language generation tasks, and how does the performance of the proposed generator compare to previous methods on unseen domains?"
https://aclanthology.org/K17-1044/,Can a Graph Convolutional Network (GCN) improve the salience estimation of sentence embeddings by incorporating relation graphs in neural multi-document summarization systems?
https://aclanthology.org/K17-1044/,Does the use of greedy heuristics for salient sentence extraction lead to more redundant or less informative summaries compared to traditional graph-based extractive approaches?
https://aclanthology.org/K17-3000/,Can machine learning-based approaches to learning dependency parsers outperform human-annotated models in a real-world setting for a large number of languages?
https://aclanthology.org/K17-3000/,Can the use of a unified annotation scheme improve the performance of dependency parsers in a shared task setting?
https://aclanthology.org/K17-3001/,What is the effect of incorporating character-based word representations on the performance of a neural dependency parser in handling rare words?
https://aclanthology.org/K17-3001/,"Can a more complex neural network architecture, such as a Transformer-based model, be used to improve the accuracy of the system's part of speech tagging and dependency parsing?"
https://aclanthology.org/K17-3002/,"Can an ensemble of global parsing paradigms outperform a single global parsing paradigm in parsing Universal Dependencies from raw text, and how does the choice of lexical feature extractor (in this case, character-level bi-directional LSTMs) affect the overall performance of the parsing system?"
https://aclanthology.org/K17-3002/,"Does the use of baseline tokenizers in the C2L2 system limit its potential for improvement, and how might incorporating more advanced tokenization methods impact the overall performance of the parsing system?"
https://aclanthology.org/K17-3003/,"Can the proposed ensemble approach to parsing improve the overall performance of a machine learning-based parser on languages with complex grammar rules, and can it reduce the processing time by leveraging the strengths of different parser architectures?"
https://aclanthology.org/K17-3003/,"Does the use of a CRF POS/morphological tagger and a neural tagger for preprocessing improve the accuracy of the final parsed output, and can it enhance the system's ability to handle languages with limited training data?"
https://aclanthology.org/K17-3004/,Can the character-based bidirectional LSTM networks used for tokenization and POS tagging in HIT-SCIR be improved upon to increase their accuracy in handling low-resource languages?
https://aclanthology.org/K17-3004/,Can the Stack-LSTM-based architecture used for transition state representation and prediction in HIT-SCIR be optimized to achieve better performance on cross-domain data?
https://aclanthology.org/K17-3005/,"Can the proposed multilingual dependency parser achieve higher LAS scores than the monolingual parser when trained on multilingual data for 10 additional languages, and how do the results compare to the overall LAS score of the best-performing multilingual model?"
https://aclanthology.org/K17-3005/,Can the addition of one-hot encodings for languages improve the parser's performance on 11 languages where the multilingual approach outperformed the monolingual approach?
https://aclanthology.org/K17-3006/,How does the proposed domain adaptation technique improve the performance of the graph-based parser compared to the official baseline model UDisPipe in terms of parsing accuracy?
https://aclanthology.org/K17-3006/,Can the proposed technique further improve the performance of the graph-based parser on treebanks with less training data from the same language domain?
https://aclanthology.org/K17-3007/,"How do context embeddings derived from a language model improve the accuracy of a transition-based parser, and what specific features of the language model are used by the MLP decision model to predict correct actions in the ArcHybrid parser?"
https://aclanthology.org/K17-3008/,Can UDPipe's multilingual pipeline achieve state-of-the-art results on the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies using a single trained model for all 50 languages?
https://aclanthology.org/K17-3008/,"Can the incorporation of additional external data improve the accuracy of UDPipe's multilingual pipeline on specific language pairs or tasks, as measured by F1-score or precision, in comparison to the baseline model?"
https://aclanthology.org/K17-3009/,Can a multilingual neural network-based parser achieve comparable or better performance to the state-of-the-art in low-resource languages by leveraging transfer learning across related languages and language families?
https://aclanthology.org/K17-3009/,Can the incorporation of bidirectional LSTM features in a graph-based neural network dependency parser improve the overall performance and robustness of the model in handling linguistic diversity across different languages?
https://aclanthology.org/K17-3010/,Can the proposed pseudo-projectivisation technique improve the performance of dependency parsing for languages with high percentages of non-projective dependency trees in multilingual dependency parsing tasks?
https://aclanthology.org/K17-3010/,Can the use of word embeddings in the BistParser system contribute to the overall improvement in performance in the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing?
https://aclanthology.org/K17-3011/,Can the performance of the UDPipe parser be improved by fine-tuning pre-trained word embeddings specifically for languages with small training sets?
https://aclanthology.org/K17-3011/,Can the effectiveness of pre-trained word embeddings in improving the UDPipe parser's performance on multilingual parsing be evaluated using a benchmarking framework that measures accuracy on a set of diverse treebanks?
https://aclanthology.org/K17-3012/,Can darc's transition-based parser outperform the baseline system in terms of accuracy on the CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3012/,Does the graph-based approach of mstnn provide better processing time compared to darc on the CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3013/,"Can the proposed neural network model outperform the state-of-the-art Stack-propagation model on joint POS tagging and dependency parsing tasks across multiple languages, and what are the key features that contribute to its superior performance?"
https://aclanthology.org/K17-3013/,Can the use of bidirectional LSTMs to learn shared feature representations improve the accuracy of POS tagging and dependency parsing tasks in different languages?
https://aclanthology.org/K17-3014/,Can a structured linear classifier outperform deep learning approaches in learning sparse features for sentence boundary prediction tasks?
https://aclanthology.org/K17-3014/,Can a second-order graph-based parser with linear tree CRF improve the accuracy of dependency parsing compared to traditional methods?
https://aclanthology.org/K17-3015/,What is the effect of incorporating dynamic oracle-based greedy parsing with a bidirectional LSTM approach on the performance of non-projective dependency parsing in CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3015/,Can the use of unsuffixed treebanks improve the performance of cross-treebank settings for non-projective dependency parsing in CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3016/,Can a combination of multiple views and resources improve the performance of low-resourced parsing for small treebanks in the CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3016/,Does the use of annotation consistency among UD treebanks affect the performance of low-resourced parsing models in the CoNLL 2017 UD Shared Task?
https://aclanthology.org/K17-3017/,"What is the most accurate method for tokenization of raw text in multilingual parsing, and how does the use of different corpora affect the results of the experiment?"
https://aclanthology.org/K17-3017/,Can a supervised learning approach using a Transformer-based architecture improve the parsing accuracy of raw text in the Universal Dependencies format?
https://aclanthology.org/K17-3018/,Can a combination of multiple treebanks using delexicalization method improve the performance of a parser for low-resource languages?
https://aclanthology.org/K17-3018/,Can the transformation of source language treebanks based on syntactic features of the low-resource language enhance the parser's performance on low-resource languages?
https://aclanthology.org/K17-3019/,What are the performance metrics used to evaluate the system's performance in the CoNLL 2017 Shared Task for multilingual parsing from raw text to Universal Dependencies?
https://aclanthology.org/K17-3019/,Can the use of transfer learning from related languages improve the system's performance for surprise languages in the CoNLL 2017 Shared Task for multilingual parsing from raw text to Universal Dependencies?
https://aclanthology.org/K17-3020/,Can UALing's corpus selection method using similarity measures be improved to achieve better performance in terms of accuracy compared to the baseline UDPipe system?
https://aclanthology.org/K17-3020/,"How does the reduction in training data size impact the processing time of the parsing task in the UALing approach compared to the naïve, complete corpus method?"
https://aclanthology.org/K17-3021/,Can a word embedding approach based on universal tag distributions improve the performance of a parser that bypasses part-of-speech tagging in parsing from raw text to universal dependencies?
https://aclanthology.org/K17-3021/,Can a joint word and sentence segmentation approach improve the overall performance of a parser in predicting dependency trees from raw words?
https://aclanthology.org/K17-3022/,Can the addition of CCG supertags as additional features improve the performance of a neural network-based dependency parser in terms of accuracy and processing time?
https://aclanthology.org/K17-3022/,Can a greedy transition approach to dependency parsing using a neural network-based parser be more effective than other parsing methods in handling multilingual text?
https://aclanthology.org/K17-3023/,"Is the proposed parsing system based on a transition-based neural network architecture, and if so, how has it been improved to increase speed and portability in the last decade? Can the proposed system achieve state-of-the-art results in the CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies?"
https://aclanthology.org/K17-3024/,Can a bidirectional-LSTM feature extractor improve the performance of a transition-based parser in terms of accuracy and processing time compared to a traditional parser in a multilingual dependency parsing task?
https://aclanthology.org/K17-3024/,Can the addition of a multi-layer perceptron (MLP) classifier to a transition-based parser enhance the parser's ability to correctly identify dependencies in treebanks while minimizing computational overhead?
https://aclanthology.org/K17-3025/,What are the most effective data-driven tokenization models for the French language that can be combined with various parsing models to achieve high accuracy in sentence parsing tasks?
https://aclanthology.org/K17-3025/,Can the integration of lexicon-based morphological analyzers with neural network-based parsing models improve the overall performance of the sentence parsing task in the French language?
https://aclanthology.org/K17-3026/,"Can a data-driven morphological analyzer using the Universal Dependencies training corpora achieve high accuracy in morphological disambiguation for Modern Hebrew, and what are the implications of using a lexicon-backed approach for low-resource languages?"
https://aclanthology.org/K17-3026/,"Can the integration of a joint morphological disambiguator and syntactic parser improve the performance of the parser on the CoNLL 2017 Shared Task, and what are the benefits of using UDPipe for sentence segmentation and surface-level tokenization?"
https://aclanthology.org/K17-3027/,Can a fully pipelined dependency parser with universal part-of-speech tags and deterministic rules achieve competitive results in cross-lingual transfer approaches?
https://aclanthology.org/K17-3027/,Does the use of delexicalized models and deterministic rules contribute to the improvement of syntactic similarities among languages in multilingual parsing?
https://aclanthology.org/K17-3028/,"Can MetaRomance's rule-based approach to parsing Romance languages outperform the performance of supervised systems in the CoNLL 2017 Shared Task, specifically in terms of accuracy on treebank parsing tasks? Can the performance of MetaRomance be improved by extending its rules using a transparent formalism, and what is the syntactic distance of each variety of a language from Romance languages using the Universal Dependencies annotation?"
https://aclanthology.org/K18-1000/,Does the proposed model's use of low-rank log-potential scoring matrices enable more efficient inference than traditional CRF models when dealing with complex non-local constraints?
https://aclanthology.org/K18-1000/,Can the proposed model's embedding space for hidden states improve the performance of sequence labeling tasks when combined with RNN features?
https://aclanthology.org/K18-1001/,"Can we develop a method to efficiently embed new domain-specific words into pre-trained generic word embeddings using a spectral algorithm, and how does it compare to existing methods in terms of processing time and accuracy in embedding new words into the original embedding space?"
https://aclanthology.org/K18-1002/,"Can a variational neural-based generation model be designed to effectively utilize limited labeled data for natural language generation tasks, and how can the proposed auxiliary auto-encoding method improve the performance of the model when training data is scarce?"
https://aclanthology.org/K18-1002/,Can the proposed variational inference and auto-encoding approach enhance the robustness and accuracy of a generator in natural language generation when the training dataset is limited?
https://aclanthology.org/K18-1003/,"Can a neural network-based approach using public attention as supervision improve entity representation learning in a dynamic setting where entities are involved in multiple relationships, and what is the key performance metric for evaluating the effectiveness of this approach? Can public attention as supervision be used to model complex entity relationships in real-world applications, and how does this approach compare to traditional unsupervised methods?"
https://aclanthology.org/K18-1004/,What is the most effective method for incorporating user network information into a neural network-based geolocation model for Twitter users?
https://aclanthology.org/K18-1004/,What is the impact of the attention mechanism on the performance of a bidirectional LSTM network in predicting Twitter users' locations?
https://aclanthology.org/K18-1005/,"Can a machine learning model be trained to induce thematic hierarchy from limited data, and what is the effect of the model's performance on cross-lingual applications?"
https://aclanthology.org/K18-1005/,Can a role-ranking strategy based on global thematic hierarchy induction improve the accuracy of NLP tasks on English and German full-text corpora?
https://aclanthology.org/K18-1006/,"Can a language model be trained to generate adversarial examples that violate a set of First-Order Logic constraints in Natural Language Inference (NLI) while being linguistically plausible, and how can this be achieved?"
https://aclanthology.org/K18-1006/,"Can adversarial training be used to improve the robustness of neural NLI models to adversarial examples, and what is the effect of this method on predictive accuracy and background knowledge violations?"
https://aclanthology.org/K18-1007/,"Is the neighborhood effect in word reading solely the result of internal representations, or does it also rely on transposition and deletion effects, as indicated by the new neighborhood measure rd20? Can the use of rd20 as a feature set explain more variance in Reaction Time measurements than traditional feature sets that do not account for transposition and deletion?"
https://aclanthology.org/K18-1008/,"Can the proposed model improve name tagging accuracy by leveraging document-level contextual information in addition to local contextual information, and how does this improvement vary across different languages and datasets?"
https://aclanthology.org/K18-1008/,"How do the proposed gating mechanisms impact the overall performance of the model in incorporating corpus-level contextual information, and what are the trade-offs between the importance of document-level and corpus-level contextual information?"
https://aclanthology.org/K18-1009/,"Can a 2D convolutional neural network with attention-like properties outperform state-of-the-art encoder-decoder systems in machine translation tasks, and what are the key factors contributing to its improved performance?"
https://aclanthology.org/K18-1009/,Can a single 2D convolutional neural network architecture effectively utilize the output sequence to re-code source tokens and yield comparable results to those of encoder-decoder systems in machine translation?
https://aclanthology.org/K18-1010/,"Can the proposed machine reading comprehension model's performance be evaluated using a benchmark that focuses on the accuracy of its ability to aggregate information from multiple sources, and does the two-staged attention mechanism significantly improve its overall performance compared to a single-staged attention architecture?"
https://aclanthology.org/K18-1010/,"Can adversarial examples be generated to assess the model's robustness to human-like errors, and does the model's performance generalize to unseen scenarios, as indicated by its ability to outperform human performance in a variety of cognitive science-inspired tasks?"
https://aclanthology.org/K18-1011/,"Can a neural network based approach effectively handle code-mixing in multi-lingual QA systems, and how can the performance of such an approach be evaluated using benchmark datasets such as SQuAD and MMQA?"
https://aclanthology.org/K18-1011/,"Can a linguistically motivated technique for code-mixed question generation improve the accuracy of code-mixed question answering systems, and what are the key characteristics of the code-mixed questions used in the proposed CMQA architecture?"
https://aclanthology.org/K18-1012/,"Can the proposed framework effectively learn semantic correspondence between text and its extracted semantic knowledge, and what are the key factors influencing this learning process?"
https://aclanthology.org/K18-1012/,"How can the embedding model facilitate analyzing and understanding relationships between unstructured texts and their corresponding structured semantic knowledge, and what are the potential applications in NLU?"
https://aclanthology.org/K18-1013/,"How can the proposed joint learning method improve the accuracy of commonsense knowledge base completion, and what specific confidence scores can be used to evaluate its performance in this task?"
https://aclanthology.org/K18-1013/,"Can the proposed joint learning method be used to generate new knowledge that is both reasonable and coherent, and what are the potential applications of this knowledge in improving the coverage of existing knowledge bases?"
https://aclanthology.org/K18-1014/,Can the use of attention mechanism in neural machine translation systems be leveraged to improve the efficiency of active learning in selecting relevant samples for human validation?
https://aclanthology.org/K18-1014/,Can active learning techniques based on the attention mechanism of neural machine translation systems effectively balance human effort and translation quality in real-time data streaming applications?
https://aclanthology.org/K18-1015/,"Can a machine learning model trained on a dataset of chatbot conversations be able to accurately detect churn intent in users who express their intention to leave a service, and what is the performance metric used to evaluate its effectiveness? Can bilingual word embeddings improve the detection of churn intent in chatbot conversations when trained on combined English and German data?"
https://aclanthology.org/K18-1016/,How do deep learning models trained on a large dataset with limited context representation perform in word expert named entity disambiguation tasks
https://aclanthology.org/K18-1016/,What is the impact of using transfer learning on the performance of word expert named entity disambiguation models trained on scarce training data versus larger datasets
https://aclanthology.org/K18-1017/,"Can a hierarchical attention-based mechanism effectively fuse the information of targets and contextual words in aspect-level sentiment analysis by considering the position information of the aspect, and what is the impact of position embeddings on the performance of this task?"
https://aclanthology.org/K18-1018/,"Can the proposed Bidirectional Generative Adversarial Network for Neural Machine Translation (BGAN-NMT) effectively alleviate the instability of GAN training by using a generator model as the discriminator, and what are the specific components of the generator and discriminator models used in BGAN-NMT? Can the proposed BGAN-NMT approach achieve significant improvements over baseline systems on German-English and Chinese-English translation tasks?"
https://aclanthology.org/K18-1019/,Can a neural model be designed to accurately extract latent entities from text descriptions of biological processes using a multi-task learning approach and novel task grouping algorithm?
https://aclanthology.org/K18-1019/,"Can the proposed model achieve high performance in identifying latent entities on a large biological dataset, particularly in handling the extraction of multiple entities jointly?"
https://aclanthology.org/K18-1020/,Can a modified approach to bilingual dictionary induction that projects languages onto a latent space improve the alignment accuracy for low-resource languages?
https://aclanthology.org/K18-1020/,Can a method be developed to incorporate supporting languages into the alignment process to further improve performance in low-resource settings?
https://aclanthology.org/K18-1021/,"What are the key factors that influence the accuracy of unsupervised keyphrase extraction methods, such as EmbedRank, in generalizing well to new domains and document types?"
https://aclanthology.org/K18-1021/,How does the introduction of an embedding-based maximal marginal relevance (MMR) technique in EmbedRank impact the diversity and coverage of the selected keyphrases?
https://aclanthology.org/K18-1022/,"What is the optimal approach to designing submodular functions for Timeline Summarization (TLS) models that balance the trade-off between summary length and the importance of selected dates, considering the interdependencies between daily summaries?"
https://aclanthology.org/K18-1022/,How can the performance of MDS optimization models be improved through the incorporation of temporal constraints and the adaptation of objective functions to accommodate the unique characteristics of TLS?
https://aclanthology.org/K18-1023/,What is the most effective way to automatically identify salient characters in a generated poem line to improve coherence in poetry composition?
https://aclanthology.org/K18-1023/,"How can a salient-clue mechanism be used to control the generated poem in different aspects, such as poetry style, to further enhance coherence in Chinese poetry composition?"
https://aclanthology.org/K18-1024/,Can a deep learning model using recursive multi-attention with a shared external memory updated over multiple gated iterations be able to accurately recognize emotions in face-to-face communication?
https://aclanthology.org/K18-1024/,Can the proposed approach using global contextualised memory with gated memory update outperform existing emotion recognition models on large multi-modal datasets?
https://aclanthology.org/K18-1025/,Can distributional models be improved by incorporating multimodal information from both text and image representations to create more accurate and interpretable semantic embeddings?
https://aclanthology.org/K18-1025/,"Can Joint Non-Negative Sparse Embedding successfully capture human-derived semantic knowledge through its sparse, interpretable vectors compared to human-derived behavioral and neuroimaging data?"
https://aclanthology.org/K18-1026/,Can the sd-CRP algorithms improve the accuracy of cognate detection in linguistically under-studied language families compared to existing methods such as InfoMap and UPGMA?
https://aclanthology.org/K18-1026/,Can the sd-CRP algorithms be applied to any language family without requiring a predefined threshold for detecting cognate sets?
https://aclanthology.org/K18-1027/,"Can an embedding model be fine-tuned to capture both semantic and syntactic aspects of words using a linear transformation without requiring external resources, and what are the implications for downstream tasks in supervised and unsupervised systems?"
https://aclanthology.org/K18-1027/,"Does the use of linear transformations to adjust the similarity order of embeddings improve evaluation metrics for unsupervised systems compared to supervised systems, and how does this relate to the intrinsic and extrinsic evaluation of word embeddings?"
https://aclanthology.org/K18-1028/,"Can the use of direct bigram collocational associations in a simplified version of Codenames improve listeners' ability to accurately identify target words, as measured by the percentage of correct word identification, compared to models relying on word-embedding or semantic knowledge graph-based associations?"
https://aclanthology.org/K18-1028/,"Can the level of pragmatic sophistication in Codenames affect the ability of listeners to make accurate inferences about the target words, as measured by the accuracy of inferred word meanings, compared to listeners who rely solely on direct bigram collocational associations?"
https://aclanthology.org/K18-1029/,"Can attention functions learned from human-derived data improve the performance of recurrent neural networks on sentiment analysis tasks, and what metrics can be used to evaluate the effectiveness of such approaches?"
https://aclanthology.org/K18-1029/,Can the use of human-derived attention functions in detecting grammatical errors and abusive language be optimized through the incorporation of additional training data from diverse linguistic sources?
https://aclanthology.org/K18-1030/,Can SLOR improve the fluency evaluation of natural language generation models compared to existing metrics such as ROUGE and word-overlap metrics?
https://aclanthology.org/K18-1030/,Does the use of a WordPiece-based language model in WPSLOR result in a more accurate fluency evaluation than traditional models like SLOR?
https://aclanthology.org/K18-1031/,"How can techniques be used to enforce sparseness in recurrent sequence models during training, and what are the potential benefits of doing so in NLP applications?"
https://aclanthology.org/K18-1031/,Can increasing hidden state sizes in recurrent layers without increasing the number of parameters improve the performance of language models?
https://aclanthology.org/K18-1032/,"Can a neural network-based active learning method be trained to select the most informative samples for machine translation tasks, and how can its performance be transferred to low-resource language pairs?"
https://aclanthology.org/K18-1032/,Can the use of simulations to learn sentence selection strategies for active learning in machine translation improve its effectiveness in handling varying language pairs and initial bitext amounts?
https://aclanthology.org/K18-1033/,Can the proposed post-OCR text correction approach for Romanised Sanskrit achieve a Character Recognition Rate (CRR) of at least 90% when trained on a dataset of 1000 images and evaluated on a separate test set?
https://aclanthology.org/K18-1033/,Can the proposed system improve the accuracy of OCR output for Romanised Sanskrit texts by at least 20% when compared to the current state of the art model for monotone sequence-to-sequence tasks?
https://aclanthology.org/K18-1034/,"Can a neural parser-ranker system achieve state-of-the-art results on weakly-supervised semantic parsing by using a scheduled training procedure to balance the contribution of two objectives, and can the inclusion of a neurally encoded lexicon improve parsing accuracy? Does the use of a neurally encoded lexicon enable the parser to capture prior domain knowledge and reduce the spuriousness of logical forms?"
https://aclanthology.org/K18-1035/,"Can neural morphological tagging models that explicitly model the internal structure of morphological tags outperform CRF-based approaches in terms of accuracy for 49 languages, and how does the choice of neural architecture impact the overall performance in morphological tagging tasks?"
https://aclanthology.org/K18-1036/,"Can a dataset's difficulty in text classification be accurately predicted by a simple and fast-to-calculate measure based on its underlying properties, and what are the key characteristics that determine this difficulty?"
https://aclanthology.org/K18-1036/,"How do the proposed difficulty measure and state-of-the-art datasets compare in terms of generalization to unseen data, and what are the implications for error analysis and model selection?"
https://aclanthology.org/K18-1037/,"Can neural-network-based word embeddings capture the property of long-distance dependencies in human languages, and what are the conditions under which they fail to do so?"
https://aclanthology.org/K18-1037/,Do word embeddings defined in similarity spaces accurately represent the notion of intervention similarity in long-distance dependencies?
https://aclanthology.org/K18-1038/,Can multilingual training improve the performance of grounded language learning models compared to bilingual training on low-resource languages? Does annotating the same set of images in multiple languages enhance the performance of these models further via an additional caption-caption ranking objective?
https://aclanthology.org/K18-1039/,"Can a denoising auto-encoder trained to recover compressed sentences from extended noise-added versions be able to learn meaningful summaries without paired training data, and how does its performance compare to a supervised baseline for grammatical correctness and retention of meaning?"
https://aclanthology.org/K18-1039/,"Can the use of unsupervised learning and noise-adding techniques improve the quality of sentence compression models, and how do the results compare to supervised models in terms of human evaluation metrics?"
https://aclanthology.org/K18-1040/,Can word embeddings generated from n-gram corpora with n > 3 exhibit high semantic quality compared to those with n <= 3?
https://aclanthology.org/K18-1040/,Do the semantic quality of word embeddings from n-gram corpora impact the performance of a natural language processing model?
https://aclanthology.org/K18-1041/,"Can a deep learning model with a bilateral attention mechanism achieve human-like performance on open-domain question answering by encoding questions and answer sentences simultaneously and integrating linguistic constituents into the network for phrasal answer extraction? Can the performance of this model be improved by optimizing the architecture for a more natural output generation, such as using constituency parser output directly in the network?"
https://aclanthology.org/K18-1042/,Can DIMSIM improve the performance of phonetic similarity algorithms for Chinese text processing compared to existing approaches?
https://aclanthology.org/K18-1042/,How do the learned encodings of initial and final phonemes in DIMSIM contribute to the overall phonetic similarity calculation?
https://aclanthology.org/K18-1043/,"What impact does the perceived effectiveness of news editorials have on readers' political orientations, measured by changes in their stance on issues?"
https://aclanthology.org/K18-1043/,"Do annotators' political orientations influence their annotation of argumentation quality in news editorials, as reflected in the discrepancies between their ratings?"
https://aclanthology.org/K18-1044/,"Can EARP improve the accuracy of analogical retrieval tasks by incorporating word order information in word vector embeddings compared to skip-gram with negative sampling, as demonstrated on the Bigger Analogy Test Set?"
https://aclanthology.org/K18-1044/,Does the application of random permutations to context vector representations during training lead to more effective word order-based embeddings in analogical retrieval tasks?
https://aclanthology.org/K18-1045/,What is the effect of incorporating local context information on the performance of short text entity linking models using the proposed Aggregated Semantic Matching framework?
https://aclanthology.org/K18-1045/,How does the interaction-based neural semantic matching model contribute to the overall performance of the proposed ASM framework in disambiguating entities in short texts?
https://aclanthology.org/K18-1046/,"Should adversarial training with Should-Not-Change strategies improve the performance of generative dialogue models on original inputs, and if so, what is the magnitude of this improvement?"
https://aclanthology.org/K18-1046/,Can adversarial training with Should-Change strategies enhance the robustness of generative dialogue models against subtle yet semantics-changing modifications?
https://aclanthology.org/K18-1047/,What is the impact of incorporating domain-specific knowledge into the context-level attention mechanism on the performance of the proposed neural network architecture for response selection in multi-turn conversational dialogue?
https://aclanthology.org/K18-1047/,How does the use of bi-directional Gated Recurrent Units for encoding context and responses affect the overall performance of the proposed model in terms of accuracy and response quality?
https://aclanthology.org/K18-1048/,"Can the Lifted Matrix-Space model outperform TreeLSTM on the Stanford NLI corpus in terms of accuracy, and what are the implications of the model's ability to scale with large vocabulary sizes? Can the Lifted Matrix-Space model improve the performance of tree-structured models on the Stanford Sentiment Treebank by reducing the number of parameters required for effective semantic composition?"
https://aclanthology.org/K18-1049/,"Can a neural network model achieve state-of-the-art performance in Entity Linking by jointly discovering and linking entities in a text document, using contextual similarity scores for mention detection and entity disambiguation?"
https://aclanthology.org/K18-1049/,Can a hybrid approach combining an end-to-end Entity Disambiguation model with a traditional Named Entity Recognition system improve Entity Linking accuracy when training and testing datasets have different annotation conventions?
https://aclanthology.org/K18-1050/,"What is the effect of using a bag-of-words representation on the quality of feature directions in semantic spaces, and how can this representation be improved to better model features as directions?"
https://aclanthology.org/K18-1050/,Can a fine-tuned semantic space using a bag-of-words representation improve the interpretability of interpretable classifiers and recommendation systems that rely on feature directions?
https://aclanthology.org/K18-1051/,"What is the performance metric used to evaluate the proposed multi-task learning approach versus the simple multi-task learning approach, and how does it compare to the proposed method?"
https://aclanthology.org/K18-1051/,Can the proposed method be effectively applied to tasks with a loose connection between the support and target classification schemes?
https://aclanthology.org/K18-1052/,Can an agent using a transformer-based architecture be able to discover and utilize user information to create more engaging conversations than traditional methods?
https://aclanthology.org/K18-1052/,Can the proposed algorithm for maximizing the proposed metric improve the perceived engagingness of a chit-chat dialogue agent beyond human baselines?
https://aclanthology.org/K18-1053/,What are the effects of incorporating linguistic generality encoded in English Resource Grammar on the performance of a neural Maximum Subgraph parser for cross-domain semantic dependency analysis in English and Chinese languages?
https://aclanthology.org/K18-1053/,Can the proposed data-oriented method improve parsing performance for cross-domain texts using a neural Maximum Subgraph parser on both English and Chinese datasets?
https://aclanthology.org/K18-1054/,"What is the impact of incorporating global information in the training process of neural networks using GI-Dropout on the accuracy of text classification tasks, and how does it compare to traditional dropout methods?"
https://aclanthology.org/K18-1054/,"How does the use of GI-Dropout improve the model's ability to identify inapparent features or patterns in text data, and what is the effect on the overall performance of the model in sentiment analysis and topic classification tasks?"
https://aclanthology.org/K18-1055/,"Can the proposed S2SMIX model improve the diversity of translations generated by the standard SEQ2SEQ model in terms of lexical and syntactic variations, and can it achieve this improvement without adding extra computational overhead?"
https://aclanthology.org/K18-1055/,Can the use of a soft clustering approach in the S2SMIX model's marginal log-likelihood optimization lead to more accurate and diverse translations compared to the standard beam search approach with diversity encouraged?
https://aclanthology.org/K18-2000/,Can a supervised learning approach using a pre-trained language model and a custom dataset be used to improve the accuracy of dependency parsing for a large number of languages in a real-world setting without gold-standard annotation on test input?
https://aclanthology.org/K18-2000/,"Can the use of new datasets added to the Universal Dependencies collection between mid-2017 and the spring of 2018 increase the difficulty of the task, and if so, how can this difficulty be measured and addressed by the participating systems?"
https://aclanthology.org/K18-2001/,"What are the effects of morpho-syntactic analysis on the performance of downstream applications in the context of parser evaluation, measured by accuracy metrics?"
https://aclanthology.org/K18-2001/,"Can the intrinsic evaluation results of parser performance correlate with observed downstream behavior in various tasks, such as question answering or text classification?"
https://aclanthology.org/K18-2002/,Can the proposed system be improved by incorporating additional linguistic features such as part-of-speech tagging and named entity recognition to enhance its performance in low-resource languages?
https://aclanthology.org/K18-2002/,Can the pre-trained state-of-the-art parser be fine-tuned for low-resource languages to achieve better results in morphology-aware dependency tree construction?
https://aclanthology.org/K18-2003/,"Can the proposed ICS PAS system's performance be improved by using a more advanced neural architecture, such as a transformer-based model, to extract features from raw text data? Does the use of self-training and an additional loss function contribute to the system's overall performance in the CoNLL 2018 shared task?"
https://aclanthology.org/K18-2004/,Can the use of deep contextualized word embeddings improve the accuracy of part-of-speech tagging in the HIT-SCIR system compared to the original Stanford system?
https://aclanthology.org/K18-2004/,Can ensembling parsers trained with different initializations lead to improved parsing performance in the HIT-SCIR system compared to single-parser approaches?
https://aclanthology.org/K18-2005/,"What is the performance of the tokenization component of the LeisureX system in the CoNLL 2018 Shared Task, and how does it compare to the official baseline model UDPipe?"
https://aclanthology.org/K18-2005/,How does the sampling method used for training low-resource languages in the LeisureX system impact the overall performance of the system in terms of LAS F1 score?
https://aclanthology.org/K18-2006/,"Can the use of cross-lingual techniques in low-resource languages improve the performance of the Phoenix system's parser in terms of accuracy and processing time, and how does it compare to the performance of the system when trained on native language data? Can the preprocessing steps of tokenization, lemmas, and morphology affect the overall performance of the Phoenix system's parser in terms of accuracy and processing time, and how do different preprocessing techniques impact the system's performance?"
https://aclanthology.org/K18-2007/,"What is the effect of incorporating a BiLSTM-based tagging component on the performance of the BIST graph-based dependency parser, measured by its UAS and LAS scores on the English Penn treebank?"
https://aclanthology.org/K18-2007/,How does the joint POS tagging and dependency parsing model compare to the baseline UDPipe model in terms of average POS tagging and LAS scores on the Universal Dependencies treebanks?
https://aclanthology.org/K18-2008/,"How does the proposed joint transition-based parser perform in terms of accuracy on the CoNLL 2018 Shared Task on Parsing Universal Dependencies, and what is the effect of combining character-based modeling with recursive composition on its performance?"
https://aclanthology.org/K18-2008/,"Does the Stack-LSTM based sentence segmentation neural architecture achieve better results compared to existing architectures in terms of overall ranking, and what specific aspects of the architecture contribute to its success?"
https://aclanthology.org/K18-2009/,Can TUPA achieve state-of-the-art results in the CoNLL 2018 UD parsing task by learning to recognize and recover enhanced dependencies?
https://aclanthology.org/K18-2009/,"Can TUPA effectively leverage its general parsing capabilities to improve the performance of the UD parsing task by learning to represent reentrancy, discontinuity, and non-terminal nodes?"
https://aclanthology.org/K18-2010/,Can the Uppsala system improve its performance on the CoNLL 2018 Shared Task by fine-tuning the joint word and sentence segmentation component using a larger dataset of related languages?
https://aclanthology.org/K18-2010/,"Can the Uppsala system's dependency tree prediction component achieve higher LAS and MLAS scores by incorporating more advanced machine learning models, such as Transformers or Recurrent Neural Networks?"
https://aclanthology.org/K18-2011/,What is the effect of incorporating tree-RNN in the tree-stack LSTM architecture on the performance of transition-based parsing models?
https://aclanthology.org/K18-2011/,Can the use of continuous dense feature vectors as input to LSTMs in the tree-stack LSTM model improve parsing performance in low-resource languages compared to previous models?
https://aclanthology.org/K18-2012/,"What is the effectiveness of the proposed end-to-end parsing pipeline in improving lemmatization accuracy compared to other state-of-the-art methods, and how does it perform in terms of morphological tagging accuracy?"
https://aclanthology.org/K18-2012/,How can the proposed system's lemmatization component be further optimized to achieve even higher accuracy in parsing and morphological tagging tasks?
https://aclanthology.org/K18-2013/,"How does the use of ELMo representations improve the performance of the SEx BiST parser in parsing tasks, and what is the average LAS score achieved by the parser when using only Treebank feature representations?"
https://aclanthology.org/K18-2013/,Can the integration of multilingual word representations into the SEx BiST parser lead to improved performance on parsing tasks compared to using only Treebank feature representations or ELMo representations alone?
https://aclanthology.org/K18-2014/,"Can SLT-Interactions improve the performance of word segmentation in low-resource languages using neural stacking, and how does the choice of LSTM architecture affect the overall parsing accuracy? Does the use of an arc-standard algorithm with Swap action improve the parsing results when combined with neural stacking for cross-domain parsing?"
https://aclanthology.org/K18-2015/,"Can a deep learning-based approach improve the performance of Stanford's system in tokenization and sentence segmentation tasks on low-resource treebanks, and what are the key factors that contribute to the improvement?"
https://aclanthology.org/K18-2015/,"Can the inclusion of a dependency parser in a neural pipeline system improve the overall performance of the system on the CoNLL 2018 UD Shared Task, and what are the optimal parameters for the parser to achieve the best results?"
https://aclanthology.org/K18-2016/,"Can NLP-Cube improve the accuracy of sentence splitting in low-resource languages by leveraging pre-trained word embeddings, and how does it compare to state-of-the-art methods in terms of processing time?"
https://aclanthology.org/K18-2016/,"Can NLP-Cube's lemmatization module achieve state-of-the-art results on compound word expansion in low-resource languages, and what is the effect of using different types of recurrent neural networks on the overall performance?"
https://aclanthology.org/K18-2017/,"How does the proposed multitask architecture of jointly training an LSTM-based neural network for lemmas, part-of-speech tags, and morphological features compare to traditional approaches in terms of accuracy?"
https://aclanthology.org/K18-2017/,"Can the UDPipe 1.2 baseline's performance on sentence segmentation, tokenization, and dependency parsing be improved by incorporating the proposed multitask architecture?"
https://aclanthology.org/K18-2018/,Can the proposed approach of using a combination of delexicalized parsers effectively improve parsing performance in low-resource languages with limited training data?
https://aclanthology.org/K18-2018/,Can morphological dictionaries be leveraged to enhance parsing accuracy in under-resourced languages by exploiting available morphological information?
https://aclanthology.org/K18-2019/,"How does the use of transformer-based architectures impact the performance of UDPipe in achieving high accuracy in sentence segmentation, tokenization, POS tagging, lemmatization, and dependency parsing in multilingual parsing from raw text to Universal Dependencies?"
https://aclanthology.org/K18-2019/,"Can UDPipe 2.0 improve the ranking of a multilingual parsing system in the CoNLL 2018 UD Shared Task, specifically in the MLAS, LAS, and BLEX rankings, using its enhanced capabilities in sentence segmentation, tokenization, POS tagging, lemmatization, and dependency parsing?"
https://aclanthology.org/K18-2020/,"Can yap's standalone dependency parser improve the performance of multilingual parsing in low-resource languages when combined with morphological disambiguation using UDPipe, and what are the benefits of using CoNLL-UL for accessing external lexical resources in such cases?"
https://aclanthology.org/K18-2021/,How does the addition of the SMeta module improve the biaffine parser's performance on the Italian-ISDT dataset in terms of LAS accuracy?
https://aclanthology.org/K18-2021/,Can the proposed Graph-Based Parsing model be adapted to improve the performance of the biaffine parser on Japanese-GSD dataset using different learning strategies?
https://aclanthology.org/K18-2022/,How does the incorporation of ELMo features improve the performance of the deep Biaffine parser in handling rare or unknown words?
https://aclanthology.org/K18-2022/,Can the addition of morphosyntactic features from lexicons to the ELMo-based parser improve the accuracy of the parser in handling complex morphology?
https://aclanthology.org/K18-2023/,"Can our morphology-based embedding models improve the parsing performance for agglutinative languages compared to character-based word embeddings like those proposed by Ballesteros et al. 2015, using a multilingual dependency parser?"
https://aclanthology.org/K18-2023/,Do morphology-based embedding models incorporating morphological features improve the parsing accuracy for agglutinative languages in the CoNLL 2018 Shared Task on raw text to universal dependencies?
https://aclanthology.org/K18-2024/,"What is the effect of using bidirectional LSTM in the word representation of the graph-based dependency parser in AntNLP, and how does it compare to other approaches?"
https://aclanthology.org/K18-2024/,"Can the use of bi-affine pointer networks to compute scores of candidate dependency edges in AntNLP improve the overall performance of the system, as measured by LAS F1 score?"
https://aclanthology.org/K18-2025/,Can a multilingual model that jointly trains on two similar languages using a simple re-parse algorithm achieve significant improvements in Universal Dependency Parsing compared to baseline methods?
https://aclanthology.org/K18-2025/,Can the use of ensemble methods on multilingual models improve parsing accuracy in CoNLL 2018 UD Shared Task by 4.4% on average?
https://aclanthology.org/K19-1000/,"Can recurrent neural language models leverage syntactic cues to improve their performance on syntactic agreement tasks, and what is the impact of model biases on this process?"
https://aclanthology.org/K19-1000/,Can contextual decomposition be used to disentangle the contributions of semantic heuristics and syntactic cues in predicting co-reference resolution outcomes?
https://aclanthology.org/K19-1001/,"What is the effect of using multi-task learning on the accuracy of Tree Adjoining Grammar (TAG) supertagging, measured by the number of correct supertags assigned?"
https://aclanthology.org/K19-1001/,"Does the deconstruction of complex supertags into auxiliary sequence prediction tasks improve the performance of TAG supertagging, as indicated by the comparison with the original supertagger on the Penn Treebank supertagging dataset?"
https://aclanthology.org/K19-1002/,"Can we design a more efficient mapping method that preserves the semantic relationships between word embeddings across languages, and how would it impact the performance of multilingual models on downstream tasks like sentiment analysis and topic classification? Can we improve the performance of multilingual models by using a combination of pre-trained cross-lingual word embeddings and a task-specific multilingual model, and how would this approach compare to existing methods that fix the embedding layers?"
https://aclanthology.org/K19-1003/,Can pre-trained contextualized embeddings be effectively aligned into a shared cross-lingual context-aware embedding space using context average type-level alignment and independently trained models?
https://aclanthology.org/K19-1003/,Can independently trained multilingual embeddings be better aligned than shared vocabulary-based alignment for cross-lingual contextualized embeddings?
https://aclanthology.org/K19-1004/,"Can we design a more diverse and efficient method for generating paraphrases using negative constraints and inference sampling, and how does this approach compare to existing beam search methods in terms of lexical and syntactic diversity?"
https://aclanthology.org/K19-1004/,Can a paraphrastic resource like ParaBank 2 be used to refine contextualized encoders and improve their performance in downstream tasks such as question answering and text classification?
https://aclanthology.org/K19-1005/,"Can the proposed dual encoder method improve the performance of pre-trained models for image captioning by aligning latent representations of audio and images, and can the proposed masked margin softmax loss function outperform the standard triplet loss in this task? Can the proposed method effectively utilize incidental matching of image-caption pairs in the dataset to improve the quality of the retrieved results?"
https://aclanthology.org/K19-1006/,"Can LSTM LMs accurately capture the hierarchical organization of syntactic representations in sentences with relative clauses, and how does this relate to their overall performance on tasks requiring sensitivity to syntactic structure?"
https://aclanthology.org/K19-1006/,"Does the proposed gradient similarity metric enable the identification of linguistically interpretable patterns in the syntactic representational space of LMs, and what are the implications for our understanding of their internal syntax?"
https://aclanthology.org/K19-1007/,"Can deep learning architectures be trained to detect atypical usage patterns of English indefinite pronouns with high accuracy, as measured by a minimum of 90% precision in identifying correct usage, among non-native speakers at different proficiency levels? Can a machine learning model incorporating linguistic features and contextual information be developed to predict the likelihood of atypical usage of English indefinite pronouns with 80% accuracy, in comparison to a baseline model without such features?"
https://aclanthology.org/K19-1008/,"Can image captioning models be improved by incorporating a mechanism to re-rank captions based on their similarity to the image, and does this approach lead to better generalization to unseen concepts? Can multi-task learning improve the compositional generalization performance of image captioning models by combining caption generation and image–sentence ranking?"
https://aclanthology.org/K19-1009/,"Can the new character embeddings effectively capture the nuances of character relationships and interactions in a dialogue, as measured by the character-relatedness task on the proposed dataset, and do these embeddings outperform traditional Word2Vec models in this task, as indicated by the experimental results? Can the new character embeddings be used to improve the performance of a visual question answering system, as demonstrated by the use of these embeddings in conjunction with the system, and do these embeddings provide better results than traditional models, as indicated by the experimental results?"
https://aclanthology.org/K19-1010/,Can the cross-lingual word embeddings space reflect the shared-translation effect observed in human bilingual lexicons?
https://aclanthology.org/K19-1010/,Can the similarity structure of the cross-lingual word embeddings space accurately model the coactivation effects of false and true friends in bilingual speakers?
https://aclanthology.org/K19-1011/,"Can federated learning be used to improve the accuracy of n-gram language models for virtual keyboards, and how can the trained models be efficiently deployed on client devices for fast inference?"
https://aclanthology.org/K19-1011/,What are the key challenges and algorithms required to handle large vocabularies and correct capitalization errors in user data for federated learning of n-gram language models?
https://aclanthology.org/K19-1012/,"Can a given vector space embedding be effectively decomposed into meaningful facets through unsupervised methods, and what are the key characteristics of these facets in terms of semantic similarity and structural properties?"
https://aclanthology.org/K19-1012/,Can the use of word embeddings as a prior knowledge guide for facet discovery improve the accuracy of the decomposition process and the resulting conceptual spaces in terms of semantic coherence and representational power?
https://aclanthology.org/K19-1013/,"Can a supervised learning approach using a transformer-based architecture be used to improve the accuracy of inflectional morphological reinflection systems, and what specific linguistic properties, such as animacy or affect, are most commonly mispredicted?"
https://aclanthology.org/K19-1013/,How can the quality of the gold data be evaluated and improved to reduce the number of errors attributed to data quality issues in morphological reinflection systems?
https://aclanthology.org/K19-1014/,Can the proposed model leverage bilingual dictionaries to improve the cross-lingual reverse dictionary retrieval task by utilizing different sentence encoding techniques and multi-task learning on different language bridges?
https://aclanthology.org/K19-1014/,Can the proposed model's dictionary model be jointly learned with a bilingual word embedding model to enhance the learning process on limited resources and improve bilingual paraphrase identification task performance?
https://aclanthology.org/K19-1015/,"Can the proposed reverse mapping bytepair encoding method improve the performance of the Generative Pre-trained Transformer (OpenAI GPT) in terms of accuracy on the Stories Cloze dataset, measured by the percentage of correctly completed stories? Can the multi-channel separate transformer architecture reduce the training time of the model on the SciTail dataset by at least 30% compared to the original GPT architecture?"
https://aclanthology.org/K19-1016/,Can the integration of lexicon-free annotation of semantic roles marked by prepositions with Universal Conceptual Cognitive Annotation be evaluated using machine learning algorithms for automatic parsing of the integrated representation?
https://aclanthology.org/K19-1016/,Can the compatibility of lexicon-free annotation of semantic roles with UCCA be assessed through comparative analysis of parsing results for English?
https://aclanthology.org/K19-1017/,"Can we design an algorithm that leverages static and time-varying word embeddings to identify the most influential events in a language's vocabulary over time, and how does this impact the semantic meaning of the words?"
https://aclanthology.org/K19-1017/,Can we develop a method to quantify the semantic changes in a word's meaning over time by analyzing the relationship between words and events in a historical timeline?
https://aclanthology.org/K19-1018/,"Can adversarial datasets be used to train models to generalize to unseen distributions and improve robustness, and what are the limitations of this approach in terms of syntactic complexity level? Can models trained on phenomenon-specific adversarial datasets generalize to different inference phenomena, such as dative alternation and numerical reasoning?"
https://aclanthology.org/K19-1019/,Can unsupervised crosslingual semantic textual similarity using BERT embeddings outperform supervised and weakly supervised methods on evaluating the similarity between text segments in different languages?
https://aclanthology.org/K19-1019/,Can the use of BERT-based contextual embeddings enable the development of more effective parallel corpus filtering and human translation equivalence assessment tools?
https://aclanthology.org/K19-1020/,What is the impact of subword information on the performance of word representation learning in low-data regimes for fine-grained entity typing in low-resource languages?
https://aclanthology.org/K19-1020/,Is the use of subword-informed word representation methods superior to subword-agnostic embeddings in morphological tagging tasks for languages with limited annotated data?
https://aclanthology.org/K19-1021/,"Do generative dependency models with bottom-up and top-down construction orders outperform non-syntactic LSTM language models in parsing tasks for English, Arabic, and Japanese languages?"
https://aclanthology.org/K19-1021/,"Can the construction order of generative dependency models affect their performance in language modeling tasks for English, Arabic, and Japanese languages?"
https://aclanthology.org/K19-1022/,Can a transition-based parsing method that utilizes a dependency tree and derivation graph to describe the construction of the parsing solution improve parsing accuracy compared to existing arc-hybrid systems?
https://aclanthology.org/K19-1022/,Can the proposed neural network architecture be trained to learn vertex representations and arc scores that enable more accurate parsing using local classifiers?
https://aclanthology.org/K19-1023/,"Is it possible to improve the accuracy of debate motion annotation using a fine-grained approach that incorporates the insights of BERT, a state-of-the-art deep language representation model, with limited amounts of training data?"
https://aclanthology.org/K19-1023/,"Can a simple lexical heuristic approach be effective in annotating debate motions with a pre-existing coding scheme, especially when compared to more complex methods such as similarity matching and neural classification?"
https://aclanthology.org/K19-1024/,"Can a discriminator-based approach that leverages semantic knowledge learned from bilingual sentence alignment improve the translation adequacy of Neural Machine Translation (NMT) models, and how can an adversarial learning framework be used to transfer this knowledge to the NMT model?"
https://aclanthology.org/K19-1024/,"Can the use of a gated self-attention based encoder for sentence embedding enhance the performance of NMT models in capturing lexical evidence and improving translation quality, particularly in low-resource languages?"
https://aclanthology.org/K19-1025/,Can the proposed sequence-to-sequence model with a copy mechanism improve the performance of code-switched language models by leveraging parallel monolingual translations and capturing linguistic constraints without relying on external word alignments or constituency parsers?
https://aclanthology.org/K19-1025/,"Can the proposed model's ability to identify and combine words from parallel sentences improve the quality of generated code-switching data, leading to better performance in end-to-end automatic speech recognition tasks?"
https://aclanthology.org/K19-1026/,How does the use of a reward function that incorporates both n-gram matching and semantic adequacy impact the quality of unsupervised neural machine translation?
https://aclanthology.org/K19-1026/,Can a variational inference network improve the consistency of translations in multiple languages by constraining shared latent semantic codes?
https://aclanthology.org/K19-1027/,Can the Transformer MT model be improved to better capture long-distance dependencies in machine translation systems?
https://aclanthology.org/K19-1027/,Can the proposed automatic approach for extracting challenge sets provide a reliable and scalable evaluation metric for assessing the performance of machine translation systems on syntactic phenomena?
https://aclanthology.org/K19-1028/,"Can multilingual contextual word representations improve dependency parsing accuracy for low-resource languages when shared parameters are used in the parser itself, and what is the effect of decontextual probes on crosslingual lexical correspondence in polyglot and aligned models?"
https://aclanthology.org/K19-1029/,"Can pre-trained multilingual models be improved to handle out-of-vocabulary words in low-resource languages by using a mixture mapping approach, and how does this approach affect the performance on sequence labeling tasks such as part-of-speech tagging and named entity recognition?"
https://aclanthology.org/K19-1029/,"Can the joint mapping approach be used to effectively address the out-of-vocabulary problem in multilingual settings, and what are the challenges and limitations of this approach for tasks such as machine translation quality estimation and machine reading comprehension?"
https://aclanthology.org/K19-1030/,"Can the use of relative position information in neural machine translation models improve their performance on long sentences, and does it mitigate the overfitting problem that arises from the use of absolute position information in these models?"
https://aclanthology.org/K19-1030/,"Can the proposed RNN-Transformer architecture effectively replace the positional encoding layer of the Transformer model, and does it yield better results in terms of accuracy and processing time for long sentence translations?"
https://aclanthology.org/K19-1031/,Can a recurrent neural network trained on spoken sentences reliably map visual referents to their correct word-like units based on the first phoneme of the target word?
https://aclanthology.org/K19-1031/,Does the gating paradigm reveal that certain frames in speech contribute more significantly to the final encoded representation of a word than others?
https://aclanthology.org/K19-1032/,Can EQUATE improve the performance of existing NLI models on numerical reasoning tasks by explicitly incorporating symbolic manipulation of quantities?
https://aclanthology.org/K19-1032/,Does EQUATE's ability to reason with quantities using symbolic manipulation improve the overall performance of NLI models on both numerical and verbal reasoning tasks?
https://aclanthology.org/K19-1033/,"Can deep learning systems effectively utilize syntactic features and lexical resources to automatically improve the quality of training data for metaphor detection, and what are the potential gaps and inconsistencies in current metaphor annotation datasets that can be addressed by this approach?"
https://aclanthology.org/K19-1033/,"Can the integration of syntactic features and lexical resources into deep learning frameworks lead to improved performance in word-level metaphor identification, and what evaluation metrics can be used to measure the effectiveness of this approach?"
https://aclanthology.org/K19-1034/,"Can adversarial training improve the accuracy of cross-lingual dependency parsing by leveraging unannotated sentences from auxiliary languages, and what is the optimal hyperparameter setting for this approach?"
https://aclanthology.org/K19-1034/,"Does the use of adversarial training result in invariant representations that are transferable across a wide range of languages, and how do these representations compare to those learned through traditional methods?"
https://aclanthology.org/K19-1035/,"Can the proposed dual-attention hierarchical recurrent neural network improve DA classification by leveraging the dependency between DAs and topics, and how does it compare to existing state-of-the-art methods in terms of DA classification performance on public datasets?"
https://aclanthology.org/K19-1035/,"Can the dual task-specific attention mechanism enable the model to effectively capture interactions between DAs and topics, and what is the impact on DA classification accuracy compared to modelling topics as an auxiliary task?"
https://aclanthology.org/K19-1036/,Can a dialogue agent's rephrased response improve user satisfaction when expressing sympathy or lack of knowledge in a customer support setting?
https://aclanthology.org/K19-1036/,Can a syntax-aware rule-based system or a seq2seq LSTM model with attention be comparable to human-generated response quality in a task of generating rephrasal responses?
https://aclanthology.org/K19-1037/,Is the proposed automated pyramid method more efficient than the existing methods in terms of processing time and accuracy on the new dataset of student summaries?
https://aclanthology.org/K19-1037/,Can the proposed method improve the transparency of the evaluation process by providing a clear and interpretable weighting scheme for the content units?
https://aclanthology.org/K19-1038/,"Can the use of automatic speech recognition (ASR) tokens in conjunction with visual features improve the performance of instructional video annotation tasks, and how does the combination of ASR and visual features compare to training individually on either modality?"
https://aclanthology.org/K19-1038/,Can the effectiveness of ASR tokens in annotating instructional videos be compared to that of visual features in terms of their ability to explain unstated background information and fine-grained distinctions?
https://aclanthology.org/K19-1039/,"Can a neural network learn to detect referring expression coreference between objects described by subtle visual properties and past referring expressions in an environment, improving the grounding of objects in visual scenes? Can a grounding model using coreference detection be trained to generalize to object categories not seen in the training data, while maintaining high accuracy?"
https://aclanthology.org/K19-1040/,What is the impact of multimodality on the performance of entity-aware neural comprehension models in capturing temporal and causal relations in text instructions?
https://aclanthology.org/K19-1040/,How does the incorporation of external relational memory units affect the accuracy of entity state updates in a dynamic reading comprehension model?
https://aclanthology.org/K19-1041/,Does the use of an oracle policy in Learning to Actively-Learn (LTAL) improve the performance of QA-SRL models when the optimization process significantly affects the selected examples?
https://aclanthology.org/K19-1041/,Can an interaction between optimization and oracle policy selection in LTAL lead to improved performance in learning semantic representations?
https://aclanthology.org/K19-1042/,"Does the presence of grammatical gender in word embeddings result in a clustering effect among nouns of the same gender, and can a method that neutralizes grammatical gender signals from the context improve the quality of word embeddings?"
https://aclanthology.org/K19-1042/,"Can embedding debiasing methods effectively remove grammatical gender bias from word embeddings, and if not, what language-specific morphological analyzers can be used to achieve this?"
https://aclanthology.org/K19-1043/,Does the use of Variational Autoencoders for query generation in Membership Query Synthesis improve the efficiency of Active Learning in NLP tasks compared to traditional pool-based sampling methods in terms of annotation time?
https://aclanthology.org/K19-1043/,"Does the ability to generate new, artificial instances via Membership Query Synthesis using Variational Autoencoders outperform traditional AL strategies in terms of accuracy for text classification tasks?"
https://aclanthology.org/K19-1044/,"Can the proposed approach to incorporate constraints into sequential inference algorithms using automata lead to improved performance in constituency parsing tasks, as evidenced by the algorithm's ability to generate valid output and only incur a small drop in performance compared to unconstrained approaches? Can the active set method used to incorporate constraints in the proposed algorithm result in a significant speed-up, as demonstrated by a 5.2x relative speed-up over a naive approach for semantic role labeling tasks?"
https://aclanthology.org/K19-1045/,"Can machine learning models achieve high accuracy in document retrieval, evidence extraction, stance detection, and claim validation on a substantially sized mixed-domain corpus with good quality annotations, and what are the challenges and opportunities for improving future models in such a setting?"
https://aclanthology.org/K19-1045/,"What is the impact of the proposed methodology for corpus creation and annotation on inter-annotator agreement and the development of future models, and how does it compare to existing fact-checking corpora?"
https://aclanthology.org/K19-1046/,"Can a machine learning model using a transformer-based architecture be trained to accurately detect frames in news headlines, and if so, what is the average accuracy of the model on a dataset of 88k news headlines related to gun violence in the U.S. between 2016 and 2018?"
https://aclanthology.org/K19-1046/,"Can the proposed frame detection approach be applied to other domains, such as environmental issues or social justice, to achieve comparable state-of-the-art performance in multiclass news frame detection?"
https://aclanthology.org/K19-1047/,"Can a deep structured model be trained to jointly identify all entity types appearing in multiple partially annotated datasets, and if so, what is the impact on robustness compared to multi-task learning baselines?"
https://aclanthology.org/K19-1047/,"Can the proposed model be applied to biomedical texts to improve the identification of genes, chemicals, and diseases in a single, unified framework?"
https://aclanthology.org/K19-1048/,"Can a dual encoder model trained on anchor-text links achieve state-of-the-art results on entity linking tasks, and how does it compare to other baseline methods such as discrete alias tables and BM25?"
https://aclanthology.org/K19-1048/,Does the use of an unsupervised negative mining algorithm improve the performance and generalizability of the dual encoder model for entity linking tasks?
https://aclanthology.org/K19-1049/,"What is the relationship between the cognitive lexical semantics of word embeddings and their performance on extrinsic NLP tasks, as evaluated by eye-tracking, EEG, and fMRI signals?"
https://aclanthology.org/K19-1049/,"Can word embeddings trained on different modalities (e.g. eye-tracking, EEG, fMRI) be compared using statistical significance testing to determine their semantic similarity and cognitive relevance?"
https://aclanthology.org/K19-1050/,"How can the addition of causal knowledge to semantic language models improve their ability to understand story sequences and predict events, and what are the most effective methods for obtaining causal knowledge from text data?"
https://aclanthology.org/K19-1050/,"Can KnowSemLM's joint training and inference approach be generalized to other domains, such as question answering or dialogue systems, to leverage causal knowledge and improve performance?"
https://aclanthology.org/K19-1051/,"Can the proposed Neural Attentive Bag-of-Entities model improve text classification accuracy by leveraging entities in a knowledge base, compared to traditional text classification models without entity information? Can the neural attention mechanism enhance the effectiveness of entity detection in the proposed model, particularly in identifying unambiguous and relevant entities in documents?"
https://aclanthology.org/K19-1052/,Can a neural network model using knowledge base embeddings and a neural network composition approach outperform a prior model using unigram features from news text for predicting the voting behavior of politicians with and without voting records?
https://aclanthology.org/K19-1052/,Does the use of news text augmentation in conjunction with a knowledge base embedding method improve the accuracy of a model's predictions for politicians with complete historical voting records compared to a model using only news text features?
https://aclanthology.org/K19-1053/,What is the effect of incorporating lexical cohesion in an unsupervised Bayesian setting on the performance of a joint segmentation and topic identification model?
https://aclanthology.org/K19-1053/,Can a dynamic Dirichlet prior that accounts for data contributions from other topics improve the smoothness of vocabulary changes between consecutive segments in a joint segmentation and topic identification model?
https://aclanthology.org/K19-1054/,"Can neural encoder-decoder models effectively handle overlapping entities in relational facts and produce all entity pairs in unstructured text, and how can their performance be improved?"
https://aclanthology.org/K19-1054/,"Can a binary CNN classifier and multi-head attention mechanism enhance the extraction of multiple relational facts and entity pairs in unstructured text, and what is the impact on overall performance?"
https://aclanthology.org/K19-1055/,"Can a distant-supervised model effectively identify the relation between two entities in a sentence when they are connected via an indirect link, and how does the proposed attention mechanism improve the model's performance in such cases?"
https://aclanthology.org/K19-1055/,"What is the impact of incorporating syntactic information on the performance of relation extraction models, particularly in capturing long-distance interactions among entities in a sentence?"
https://aclanthology.org/K19-1056/,Event detection models can utilize sequential features of entity types to improve performance. Can the sequential features of entity types be used to improve the accuracy of event detection models? How can the trigger-entity interaction learning module be designed to effectively combine sequential features of word sequences and entity type sequences?
https://aclanthology.org/K19-1057/,"Is there a glass ceiling for Named Entity Recognition models in terms of accuracy, and what types of errors are still hard or impossible to correct? Can new techniques for improving annotation, training process, and model quality and stability help overcome these limitations?"
https://aclanthology.org/K19-1058/,"Can quadratic statistics alone be used to improve the accuracy of document comparison tasks, and if so, what are the computational benefits of using these methods compared to traditional mean vector approaches? Can low-rank representations of quadratic statistics achieve state-of-the-art results in matching news articles to their comment threads and sentence comparison tasks?"
https://aclanthology.org/K19-1059/,Can a constraint-driven iterative algorithm improve the performance of neural networks in Named Entity Recognition on partially annotated data by downweighing false negatives and can a weighted NER model achieve higher F1 scores than non-weighted models on low-resource languages?
https://aclanthology.org/K19-1059/,"Can a weighted training set generated by a constraint-driven iterative algorithm improve the performance of NER models on noisy data from non-speakers, particularly in low-resource languages such as Bengali?"
https://aclanthology.org/K19-1060/,Can BERT-based models achieve state-of-the-art performance in event trigger extraction for low-resourced languages without relying on language-specific features?
https://aclanthology.org/K19-1060/,Can contextualized embeddings obtained using BERT improve event trigger extraction performance in multilingual settings for languages with limited annotated datasets?
https://aclanthology.org/K19-1061/,"Does the proposed deep structured learning framework for event temporal relation extraction learn robust features for the structured model by leveraging long-term contexts, and can the SSVM incorporate domain knowledge to make globally consistent decisions? Can the proposed model achieve better performance with pre-trained contextualized embeddings compared to the state-of-the-art methods on event temporal relation datasets?"
https://aclanthology.org/K19-1062/,Can BERT-based models learn all three steps of entity linking jointly and improve entity disambiguation and mention detection?
https://aclanthology.org/K19-1062/,Does additional entity knowledge improve BERT's performance in entity linking and other natural language processing tasks?
https://aclanthology.org/K19-1063/,Can the proposed unsupervised domain adaptation approach improve the accuracy of implicit discourse relation classification when compared to the baseline model?
https://aclanthology.org/K19-1063/,Can the addition of labeled data to the proposed system enhance the performance of the reconstruction component in adapting to new domains?
https://aclanthology.org/K19-1064/,Can deep probabilistic logic learning be applied to improve the interpretation of evidence sentences in multiple-choice machine reading comprehension tasks by incorporating both sentence-level and cross-sentence linguistic indicators?
https://aclanthology.org/K19-1064/,Can existing multiple-choice machine reading comprehension models be improved by using evidence sentences extracted from distant supervision and denoised using deep probabilistic logic learning?
https://aclanthology.org/K19-1065/,"Can the proposed approach to generating vector space representations of utterances using pair-wise similarity metrics improve the performance of conversational AI systems in terms of accuracy and user satisfaction, and can it be trained effectively with a limited amount of data without relying on external general-purpose ontologies? Can the proposed approach be applied to improve the performance of language understanding services in unsupervised, semi-supervised, and supervised learning tasks, and how do the performance gains compare to existing methods in these tasks?"
https://aclanthology.org/K19-1066/,How does the incorporation of interlocutor-aware contexts into the ICRED model impact the accuracy of the generated responses in a multi-party chatbot scenario?
https://aclanthology.org/K19-1066/,Does the use of an addressee memory in the ICRED model significantly improve the contextual understanding of the target addressee in multi-party dialogue interactions?
https://aclanthology.org/K19-1067/,Can Memory Graph Networks (MGN) improve the accuracy of question answering on episodic memory QA tasks by leveraging graph traversals to answer queries in multiple contexts and incorporate external knowledge?
https://aclanthology.org/K19-1067/,Does the proposed Episodic Memory QA Net with multiple module networks effectively handle various question types by providing a clear and interpretable explanation of its QA reasoning through graph walk paths and attention vectors?
https://aclanthology.org/K19-1068/,"Can TripleNet improve the response selection task by modeling the relationships between the context, query, and response at different levels, and how does it compare to existing methods in terms of accuracy? Does TripleNet's novel attention mechanism contribute to better performance in multi-turn response selection tasks?"
https://aclanthology.org/K19-1069/,Can the proposed relation module improve the F1 accuracy of MRC models on the SQuAD 2.0 task by leveraging multi-head self-attentive pooling for semantic extraction and relational information processing?
https://aclanthology.org/K19-1069/,"Can the proposed relation module be effectively integrated with different MRC models, such as BiDAF and BERT, to improve their non-answerability detection capabilities?"
https://aclanthology.org/K19-1070/,"Can a bidirectional LSTM architecture that incorporates web data and search engine click logs improve the slot tagging task in human-to-human conversations, and what is the effect of aggregating this information with expert feedback from human-to-machine models on the performance of the slot tagging model? Can a bidirectional LSTM architecture that incorporates previous utterances in the conversation outperform the model that aggregates web data, search engine click logs, and expert feedback in the restaurant and music domains?"
https://aclanthology.org/K19-1071/,Can a recurrent neural network with a distance-based aggregation procedure be used to improve the performance of shallow discourse parsing models when compared to baseline models without additional linguistic features?
https://aclanthology.org/K19-1071/,Does the use of a distance-based aggregation procedure allow for more accurate end-to-end argument labeling than models that rely on traditional linguistic features?
https://aclanthology.org/K19-1072/,"Can a neural language model effectively incorporate evolving topical influences from one text stream into another, and how does this approach impact the accuracy of text forecasting tasks?"
https://aclanthology.org/K19-1072/,Can the proposed Topical Influence Language Model (TILM) accurately capture the influences of evolving topics on text stream contents and enable cross-stream analysis of topical influences?
https://aclanthology.org/K19-1073/,"Can the proposed pretraining-based encoder-decoder framework outperform the existing state-of-the-art models in terms of accuracy on the text summarization task, and how does the use of BERT in the second stage of the decoder affect the performance of the model?"
https://aclanthology.org/K19-1073/,Can the two-stage approach of using a Transformer-based decoder followed by BERT improve the processing time and user satisfaction in text summarization tasks compared to single-stage models that rely solely on BERT?
https://aclanthology.org/K19-1074/,Can the proposed G-DuHA model be improved by incorporating additional attention mechanisms to better capture the nuances of interlocutor-level disparity in goal-oriented dialogues?
https://aclanthology.org/K19-1074/,Can the use of goal-oriented data augmentation in task-oriented dialog systems lead to significant improvements in performance and user satisfaction?
https://aclanthology.org/K19-1075/,Can a sequence-to-sequence model that incorporates both structure and semantics of the question being generated improve the quality of automatically generated questions by optimizing for both semantic and structural conformity?
https://aclanthology.org/K19-1075/,"Does the adoption of structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L in a QG framework lead to more accurate question generation results compared to cross-entropy loss?"
https://aclanthology.org/K19-1076/,"Can DivCNN Seq2Seq models achieve higher comprehensiveness in abstractive summarization tasks by incorporating Determinantal Point Processes methods for attention distribution, as compared to traditional Seq2Seq models?"
https://aclanthology.org/K19-1076/,"Can DivCNN Seq2Seq models improve the diversity of generated summaries while maintaining high ROUGE scores, and what are the key factors that contribute to this improvement in terms of attention distribution?"
https://aclanthology.org/K19-1077/,"How can reinforcement learning be used to incorporate psycho-linguistic preferences into abstractive text summarization models, and what evaluation metrics should be used to assess the effectiveness of such an approach?"
https://aclanthology.org/K19-1077/,"Can a reinforcement learning-based framework that incorporates stylistic feedback be used to generate both formal and informal summary variants of an input article, and what are the key challenges in achieving this goal?"
https://aclanthology.org/K19-1078/,"Can pretrained neural language models like OpenAI GPT2-117 outperform state-of-the-art neural story generation models in terms of text diversity, and what are the implications of their limitations on natural language generation tasks?"
https://aclanthology.org/K19-1078/,Do the automatic metrics used to evaluate the generated text provide an accurate representation of the models' ability to produce coherent and engaging narratives?
https://aclanthology.org/K19-1079/,Can a self-adaptive approach to designing residual structures for deep neural networks improve the accuracy of machine translation models on low-resource datasets and how does it compare to existing architectures in terms of processing time? Can the proposed Self-Adaptive Scaling (SAS) approach be integrated into existing residual-based models for image classification and captioning tasks with improved performance?
https://aclanthology.org/K19-1080/,"Can machine learning models achieve high accuracy in Named Entity Recognition (NER) and Taxa Recognition (TR) tasks for biodiversity research, and how can the quality of these models be evaluated and improved?"
https://aclanthology.org/K19-1080/,Can the use of a gold standard for Taxa Recognition (TR) in biodiversity literature impact the performance of downstream machine learning models for information extraction in biology texts?
https://aclanthology.org/K19-1081/,"Can deep learning models using bidirectional recurrent neural networks, conditional random fields, and multilayer perceptrons effectively identify slang in natural sentences, and do they outperform traditional linguistic features in sentence-level detection and token-level identification?"
https://aclanthology.org/K19-1081/,"Do multilayer perceptrons and conditional random fields contribute to improving the accuracy of slang detection and identification using linguistic features, and what are the optimal combinations of these models for sentence-level and token-level tasks?"
https://aclanthology.org/K19-1082/,"Can recurrent networks with overlapping data point composition improve performance in sequence modeling tasks by leveraging the full token order information, as measured by accuracy, compared to traditional discretization methods? Does the use of prime batch sizes in recurrent networks with overlapping data point composition reduce redundancies and improve performance in speech and text processing tasks, as evaluated by processing time?"
https://aclanthology.org/K19-1083/,"Can GAMs improve language modeling performance under small-data conditions compared to standard autoregressive models, and what is the effect of using global a priori features on perplexity reduction? Can the use of a distillation process to train a second autoregressive model improve inference speed while maintaining the accuracy of the standard model?"
https://aclanthology.org/K19-1084/,Can a neural network architecture be designed to learn dedicated sentence embeddings that capture analogical properties in the semantic space and improve answer selection performance on benchmark datasets?
https://aclanthology.org/K19-1084/,Can the proposed analogy-based question answering method outperform a similarity-based technique in terms of accuracy on benchmark datasets?
https://aclanthology.org/K19-1085/,"Can this method improve the performance of character-aware language models by injecting word-level information at the softmax function, compared to injecting at the input of a long short-term memory (LSTM) network?"
https://aclanthology.org/K19-1085/,Does the combination of character-aware language model and simple word-level language model improve the performance of language models when using the proposed injection method?
https://aclanthology.org/K19-1086/,"Can the use of Aggressive Stochastic Weight Averaging (ASWA) improve the consistency of model interpretations when using random seeds, and does it reduce the standard deviation of model performance?"
https://aclanthology.org/K19-1086/,Does the Norm-filtered Aggressive Stochastic Weight Averaging (NASWA) approach outperform ASWA in terms of model robustness and consistency over different random seeds?
https://aclanthology.org/K19-1087/,"Can a hierarchical annotation model improve the generalisability of abusive language detection models trained on datasets with a high proportion of non-abusive samples, and what is the optimal proportion of abusive samples required to achieve good generalisability in this context?"
https://aclanthology.org/K19-1088/,Can deep learning-based document embeddings be used to effectively reduce the number of candidate authors in large-scale authorship attribution problems?
https://aclanthology.org/K19-1088/,Can the application of common authorship attribution methods improve after reducing the number of candidate authors by document embeddings in large-scale scenarios?
https://aclanthology.org/K19-1089/,Can a semi-supervised Variational Autoencoder based on Transformer be used to improve the performance of aspect-term sentiment analysis by disentangling latent representation into aspect-specific sentiment and lexical context?
https://aclanthology.org/K19-1089/,Does the integration of a classifier-agnostic semi-supervised Variational Autoencoder with different supervised models lead to a significant improvement in aspect-term sentiment analysis on the SemEval 2014 task 4?
https://aclanthology.org/K19-1090/,Can a hard-selection approach that determines the start and end positions of the opinion snippet and selects words between these two positions outperform soft-selection approaches in aspect-based sentiment analysis tasks when handling multi-aspect sentences?
https://aclanthology.org/K19-1090/,"Can the use of self-critical reinforcement learning to detect the opinion snippet improve the performance of aspect-based sentiment analysis models, especially in multi-aspect sentences, compared to traditional methods?"
https://aclanthology.org/K19-1091/,What is the effectiveness of using Bi-directional Long Short-Term Memory (BiLSTM) for sentiment analysis in PolEmo 2.0 corpus compared to other deep learning approaches?
https://aclanthology.org/K19-1091/,How does the use of Bidirectional Encoder Representations from Transformers (BERT) improve the sentiment recognition accuracy on PolEmo 2.0 corpus compared to the current PolEmo 2.0 results?
https://aclanthology.org/K19-1092/,What is the feasibility of using a Hawkes process-based attention mechanism for modeling individual sentiment change over time in social media data?
https://aclanthology.org/K19-1092/,How does the proposed user-specific design with a modified attention mechanism improve the accuracy of sentiment modeling compared to traditional population-level models?
https://aclanthology.org/K19-1093/,"Can CNNs be used to improve the classification accuracy of short text classification tasks by incorporating word-level clustering, and what specific clustering methods can be used in conjunction with CNNs to achieve better results?"
https://aclanthology.org/K19-1093/,"Can the use of cluster-dependent gated convolutional layers improve the processing time of text classification models, and how can this be measured in terms of computational resources?"
https://aclanthology.org/2021.ranlp-1.0/,"Can a Transformer-based language model accurately detect the original limerick in corrupted versions of the poem, as indicated by its ability to assign a higher probability to the correct version?"
https://aclanthology.org/2021.ranlp-1.0/,"Can a language model utilizing end rhymes to generate poetry outperform human accuracy in detecting original limericks, and what are the implications for poetry evaluation in NLP research?"
https://aclanthology.org/2021.ranlp-1.1/,"Can the proposed semi-automatic strategy improve the performance of intent detection in dialogue systems when populating the domain ontology with FrameNet frames, compared to manual ontology engineering with linguistic expert knowledge?"
https://aclanthology.org/2021.ranlp-1.1/,"Can the use of multilingual resources in the proposed approach reduce the time and effort required to populate the domain ontology for different languages, compared to a non-semi-automatic strategy?"
https://aclanthology.org/2021.ranlp-1.2/,Can a classification model trained on one Indian language be reused for other Indian languages with high vocabulary overlap? Can exploiting lexical similarity in Indian languages improve the performance of a multilingual text classification model?
https://aclanthology.org/2021.ranlp-1.3/,Can Domain-Specific Back Translation Improve Translation Quality for Hindi-Telugu Neural Machine Translation in Technical Domains Using Out of Domain Words as Synthetic Data?
https://aclanthology.org/2021.ranlp-1.3/,Does the proposed Domain-Specific Back Translation method outperform traditional approaches in terms of BLEU scores for translating Hindi and Telugu texts into their respective languages in Chemistry and Artificial Intelligence domains?
https://aclanthology.org/2021.ranlp-1.4/,Can fine-tuning pre-trained Arabic BERT models improve the accuracy of Word Sense Disambiguation tasks in Arabic language?
https://aclanthology.org/2021.ranlp-1.4/,Can the use of supervised signals to emphasize target words in context enhance the performance of pre-trained Arabic BERT models in Word Sense Disambiguation tasks?
https://aclanthology.org/2021.ranlp-1.5/,"Can the proposed multilingual word alignment technique improve the accuracy of cross-language plagiarism detection in Arabic texts, and how does it compare to existing methods in terms of sentence-level classification?"
https://aclanthology.org/2021.ranlp-1.5/,Does the combination of word embedding and semantic features improve the performance of machine learning algorithms in detecting cross-language plagiarism in English-Arabic texts?
https://aclanthology.org/2021.ranlp-1.6/,"Can machine learning models effectively handle and learn from noisy user-generated content in social media platforms, and how can pre-processing strategies be tailored to mitigate the impact of such noise on NLP tasks?"
https://aclanthology.org/2021.ranlp-1.6/,"What is the impact of varying pre-processing techniques on the performance of NLP models when dealing with non-standard textual content, and how can these techniques be optimised for specific NLP applications?"
https://aclanthology.org/2021.ranlp-1.7/,"How can a semi-supervised approach using BERT outperform a supervised approach using SVM or logistic regression in genre analysis for software engineering articles, in terms of F-score accuracy?"
https://aclanthology.org/2021.ranlp-1.7/,Can logistic regression-based techniques with BERT be used to improve the efficiency of genre analysis in Introduction sections of software engineering articles by reducing the need for manual annotation?
https://aclanthology.org/2021.ranlp-1.8/,Can the Factored Transformer architecture improve the performance of the Transformer model in incorporating linguistic factors in machine translation systems by analyzing the effect of embedding level and encoder level combination strategies on the BLEU score?
https://aclanthology.org/2021.ranlp-1.8/,Can the Factored Transformer architecture outperform the baseline Transformer model in translating low-resourced and distant languages by utilizing linguistic factors and different combination strategies?
https://aclanthology.org/2021.ranlp-1.9/,"Can the multi-pass sieve coreference resolution model be improved for Indonesian language by incorporating machine learning techniques to increase its recall without sacrificing precision? How does the multi-pass sieve model perform in comparison to other state-of-the-art coreference resolution models on Indonesian language texts, measured by their MUC F-measure and BCUBED F-measure?"
https://aclanthology.org/2021.ranlp-1.10/,"Can a data augmentation technique improve the generalization of sequence-to-sequence models on the SCAN benchmark to unseen contexts, and what is the impact on their performance compared to the standard architecture without augmentation?"
https://aclanthology.org/2021.ranlp-1.10/,"Does a modified seq2seq architecture with attention achieve state-of-the-art results on all tasks from the SCAN benchmark, and can this result be improved upon with the proposed extension of the benchmark?"
https://aclanthology.org/2021.ranlp-1.11/,Can a unified framework utilizing fine-tuned Transformer-based language models significantly improve the performance of EuroVoc classification on multilingual legislative texts across twenty-two languages compared to a similar tool like JEX?
https://aclanthology.org/2021.ranlp-1.11/,Does the fine-tuning of pre-trained language models on EuroVoc improve the accuracy of the classification of legal descriptors in multilingual documents?
https://aclanthology.org/2021.ranlp-1.12/,"Is the proposed heuristic in the improved span-based extract-then-classify framework able to address the issue of sentiment inconsistency in the sequence tagging problem, and does it provide a more accurate sentiment analysis compared to the current state-of-the-art models? Does the proposed framework using the pseudo-labeled movie reviews dataset outperform the results on the novel Movie20 dataset?"
https://aclanthology.org/2021.ranlp-1.13/,Can the proposed IA-LSTM model outperform the state-of-the-art AB-LSTM-PC model in terms of accuracy on the Arabic hotel review dataset?
https://aclanthology.org/2021.ranlp-1.13/,Can the IA-LSTM model achieve better performance when using both right and left context for target-based sentiment analysis in the Arabic language?
https://aclanthology.org/2021.ranlp-1.14/,"Can Litescale effectively improve the quality of NLP datasets created through Best-worst Scaling annotation by reducing the time required for annotation tasks, and what metrics will be used to evaluate this improvement? Can Litescale's graphical Web-based interface provide a more engaging and efficient user experience compared to the textual console-based interface in terms of annotation completion rate and user satisfaction?"
https://aclanthology.org/2021.ranlp-1.15/,"Can a pre-trained language model perform emotion classification tasks with competitive accuracy using a zero-shot configuration, and how does its performance change when combined with a Bayesian aggregation method? Does training a model on few-shot data with biased annotators improve its performance compared to fully-supervised models?"
https://aclanthology.org/2021.ranlp-1.16/,"Can sub-word representations based on byte pair encoding be leveraged to improve the automatic generation of English definitions for Wolastoqey words, and how do they compare to baseline methods in terms of definition accuracy? Can the use of sub-word representations improve the overall efficiency of definition generation for low-resource languages like Wolastoqey?"
https://aclanthology.org/2021.ranlp-1.17/,"Can a neural generative summarizer achieve comparable performance to human-written summaries when trained on limited data with entropy filtering, measured by precision and recall rates, and does the filtering improve the summarization process in terms of accuracy and fluency? Does the proposed entropy filtering approach based on human-written summaries effectively limit the entropy of the input texts, and can it be generalized to other domains with limited data?"
https://aclanthology.org/2021.ranlp-1.18/,Can a sequence-to-sequence model trained on English and Brazilian Portuguese corpora achieve competitive results in split-and-rephrase task by utilizing a vocabulary built solely from grammatical classes and their recurrences?
https://aclanthology.org/2021.ranlp-1.18/,Does a cross-lingual split-and-rephrase pipeline utilizing BERT's masked language modeling be effective in reducing the amount of training data required for construction of symbolic vocabularies?
https://aclanthology.org/2021.ranlp-1.19/,Can a multi-label text classifier with per-label attention achieve high accuracy in classifying Electronic Health Records according to the International Classification of Diseases using the BERT Multilingual model for languages with limited resources?
https://aclanthology.org/2021.ranlp-1.19/,Can the per-label attention mechanism in a multi-label text classifier improve the ability to discriminate between similar diseases in Electronic Health Records using 157 labels from Chapter XI – Diseases of the Digestive System of the ICD?
https://aclanthology.org/2021.ranlp-1.20/,"Can a self-attention-based Transformer layer be used as a drop-in replacement for an LSTM layer in a GAN architecture, and what modifications are needed to adapt it for efficient text generation with limited computational resources?"
https://aclanthology.org/2021.ranlp-1.20/,"Does the performance of a text generative GAN with a Transformer-based architecture improve with the addition of a diversity-promoting mechanism, and what is the impact on stability and generated text quality?"
https://aclanthology.org/2021.ranlp-1.21/,Can a deep learning model using a combination of video features and user interaction data outperform traditional methods in predicting the factuality of news reporting on YouTube?
https://aclanthology.org/2021.ranlp-1.21/,Can the temporal evolution of user attention cycles in news media outlets' YouTube channels be used as a reliable indicator for evaluating their factuality and accuracy of reporting?
https://aclanthology.org/2021.ranlp-1.22/,Can a deep CNN–LSTM hybrid neural network improve the accuracy of OCR models on Swedish historical newspapers compared to traditional OCR models?
https://aclanthology.org/2021.ranlp-1.22/,Can a deep CNN–LSTM hybrid neural network achieve an average character accuracy rate of 97.43% or higher on 19th century Swedish newspaper text?
https://aclanthology.org/2021.ranlp-1.23/,Can machine learning models trained on part-of-speech features extracted from social media data accurately predict the likelihood of a user experiencing depression?
https://aclanthology.org/2021.ranlp-1.23/,Can the use of indices derived from part-of-speech analysis of social media discourse help in developing computational models to monitor and prevent mental illnesses?
https://aclanthology.org/2021.ranlp-1.24/,Can a deep contextualized model achieve state-of-the-art results in zero-shot intent classification and slot-filling tasks using pre-trained language models and natural language descriptions of user intents?
https://aclanthology.org/2021.ranlp-1.24/,"Can the proposed architecture enable cross-lingual adaptation for zero-shot learning in dialogue systems, improving the performance of pre-trained models on new languages with minimal additional training data?"
https://aclanthology.org/2021.ranlp-1.25/,Can an uncertainty-based query strategy with a weighted density factor using similarity metrics based on sentence embeddings significantly reduce the number of sentences that must be manually annotated to achieve a target F1 score in natural language corpora composed of entities and semantic relations?
https://aclanthology.org/2021.ranlp-1.25/,Can the pre-annotation strategy with highly accurate entities and semantic relations reduce the total annotation time by 24% in biomedical corpora while preserving the usefulness of the corpora for training machine learning algorithms?
https://aclanthology.org/2021.ranlp-1.26/,"Can unsupervised cross-lingual language modeling be used to achieve better style transfer results by incorporating content embeddings that capture human-specified groupings of subject matter, and how do these embeddings impact the performance of the model?"
https://aclanthology.org/2021.ranlp-1.26/,Can the use of classical stylometrics as a complementary evaluation metric for style transfer tasks improve the assessment of the model's performance and provide a more accurate representation of the results?
https://aclanthology.org/2021.ranlp-1.27/,Can a supervised transformer-based method trained with multiple languages and for multiple tasks be used to improve the performance of a Recognizing Question Entailment (RQE) approach in the domain of Diabetes Mellitus?
https://aclanthology.org/2021.ranlp-1.27/,"Can a combination of ensembles of methods, including light information retrieval methods, provide a competitive result with a novel large pre-trained language model in a RQE approach for Portuguese Community-Question Answering?"
https://aclanthology.org/2021.ranlp-1.28/,"Can transformer-based architectures achieve comparable question-answering performance with limited French language training data compared to English language training data, and what training strategies can improve the stability of these models in such scenarios?"
https://aclanthology.org/2021.ranlp-1.28/,"Can data augmentation, hyperparameter optimization, and cross-lingual transfer improve the usability of pre-trained transformer models for low-resource French language tasks, and how does the proposed compact model FrALBERT perform in such settings?"
https://aclanthology.org/2021.ranlp-1.29/,"Can contextual embedding models such as BERT and XLM-R effectively handle code-mixed social media data from languages with non-English scripts, and what is the impact of the level of code-mixing on their performance?"
https://aclanthology.org/2021.ranlp-1.29/,Can a Capsule+biGRU classifier outperform BERT and XLM-R when trained on a small dataset of 6500 samples for Sinhala-English code-mixed data?
https://aclanthology.org/2021.ranlp-1.30/,How can a character-based Thai word-segmentation model that uses multiple attentions to estimate the relationships among characters and various unit types improve performance compared to existing models?
https://aclanthology.org/2021.ranlp-1.30/,"Can the integration of word, subword, and character cluster information into a character-based Thai word-segmentation model lead to more accurate word boundary estimation than using only character units?"
https://aclanthology.org/2021.ranlp-1.31/,"Can pre-trained multilingual models achieve consistent results across different languages in cross-lingual similarity search tasks, and what factors influence the interpretation of language-agnostic properties of the LASER model?"
https://aclanthology.org/2021.ranlp-1.31/,"Can the use of multilingual embeddings effectively capture language similarities and translation paths in diverse scenarios, and how do these factors impact the accuracy of cross-lingual similarity search tasks?"
https://aclanthology.org/2021.ranlp-1.32/,What are the dominant word orders in the available languages in the Universal Dependencies 2.7 corpora and how do they compare to the results reported in WALS database and Ostling's work?
https://aclanthology.org/2021.ranlp-1.32/,"Can a graph rewriting tool, such as GREW, effectively identify implicit subjects and improve the accuracy of word order analysis in the Universal Dependencies 2.7 corpora?"
https://aclanthology.org/2021.ranlp-1.33/,"Can a supervised machine learning model using fastText achieve high accuracy for Emotion Detection in Romanian short texts, and how does it compare to classical machine learning models such as Multinomial Naive Bayes and Logistic Regression? Does fine-tuning the Romanian BERT for Emotion Detection from Romanian tweets outperform the performance of other models in terms of accuracy and processing time?"
https://aclanthology.org/2021.ranlp-1.34/,"Can transformer-based similarity calculations within the BET framework improve the performance of pre-trained models in automated paraphrase detection, and what is the optimal sample size for achieving this improvement?"
https://aclanthology.org/2021.ranlp-1.34/,"Does using smaller pre-trained models, such as RoBERTa base and Electra base, lead to F1 scores comparable to their larger counterparts in the GLUE benchmark, and how do these smaller models impact the efficiency of the proposed method?"
https://aclanthology.org/2021.ranlp-1.35/,"Can fine-tuned neural classification models be developed to accurately detect subjectivity and sentiment polarity in Maltese-English code-switched language, and how do these models compare to their English and Maltese counterparts?"
https://aclanthology.org/2021.ranlp-1.35/,"Can multiple social opinion dimensions be effectively extracted from user-generated content in Maltese and English languages, and what is the impact of language resources on the performance of these models?"
https://aclanthology.org/2021.ranlp-1.36/,"Can machine learning algorithms be used to accurately predict the etymology of Romanian words based on their lexical patterns and relationships, and what evaluation metrics would be most suitable to measure the success of such a system?"
https://aclanthology.org/2021.ranlp-1.36/,"Can the application of large-scale natural language processing techniques to Romanian etymology data improve the accuracy of word etymology extraction and classification, and what are the potential benefits and limitations of this approach?"
https://aclanthology.org/2021.ranlp-1.37/,"Can edit-based text simplification systems with graph convolutional network modules improve the accuracy of syntactic edit operations compared to traditional edit-based systems in English, Spanish, and Italian datasets? Does the addition of syntactic information enhance the overall performance of edit-based text simplification systems in complex sentences versus simple sentences?"
https://aclanthology.org/2021.ranlp-1.38/,"Can a fact-infused question generator be trained to produce more detailed questions by incorporating entities referenced in the original question, and how can this approach improve the robustness of question generation models? Can fact-infusion be used as a novel form of question paraphrasing to enhance the expressiveness of question generation models?"
https://aclanthology.org/2021.ranlp-1.39/,"Can a transformer-based model be used to accurately classify event triggers in news articles into different prominence classes, and how does its performance compare to a traditional Support Vector Machine baseline?"
https://aclanthology.org/2021.ranlp-1.39/,Can a transformer model be trained to identify multi-word event spans as syntactic clauses and achieve better performance than a Conditional Random Field approach in event-trigger word detection?
https://aclanthology.org/2021.ranlp-1.40/,"Can deep learning models such as BERT, RoBERTa, and XLNET be effective in accurately classifying mental health disorders from plain text data, and what are the differences in performance between these models on various mental health conditions?"
https://aclanthology.org/2021.ranlp-1.40/,"Can the classification of eating disorders be improved by leveraging discussions related to calories, diets, recipes, and other health-related topics in social media posts, and how does this compare to the classification of other mental health conditions?"
https://aclanthology.org/2021.ranlp-1.41/,Can the proposed joint learning approach improve the accuracy of language identification and part of speech tagging for code-mixed text compared to separate training of each task individually?
https://aclanthology.org/2021.ranlp-1.41/,Does the use of a Transformer with convolutional neural network architecture improve the performance of the joint learning method for code-mixed social media text compared to traditional architectures?
https://aclanthology.org/2021.ranlp-1.42/,Can we develop a more efficient Gromov-Hausdorff distance method to detect language interference in translations that is robust to variations in linguistic features and modeling conditions?
https://aclanthology.org/2021.ranlp-1.42/,Can embedding spaces resulting from translations into the same language be used to reconstruct phylogenetic trees without relying on explicit linguistic information or explicit linguistic features?
https://aclanthology.org/2021.ranlp-1.43/,"Can a decoupled transformer model reduce computational cost and latency for open-domain question answering systems while maintaining accuracy, and what are the implications of this approach on the storage requirements for the cache?"
https://aclanthology.org/2021.ranlp-1.43/,Does the proposed knowledge distillation objective and learned representation compression layers improve the efficiency of the decoupled transformer model in reducing computational cost and latency for online QA applications?
https://aclanthology.org/2021.ranlp-1.44/,What is the feasibility of applying de-identifying free-form text documents method to sensitive data in health and legal domains
https://aclanthology.org/2021.ranlp-1.44/,and how does it affect data utility for text classification tasks?
https://aclanthology.org/2021.ranlp-1.44/,Can the proposed method of redacting sensitive data in free-form text documents improve the accuracy of sequence labeling and question answering tasks?
https://aclanthology.org/2021.ranlp-1.45/,"Can general-purpose semantic models be used to accurately extract fine-grained knowledge from large scientific documents, measured by the precision of extracted facts? Can a text-mining pipeline using general-purpose semantic models achieve high accuracy in processing large volumes of scientific text, measured by the processing time?"
https://aclanthology.org/2021.ranlp-1.46/,"Can online learning approaches in neural machine translation effectively adapt to user-generated corrections without compromising model stability, and what is the optimal learning rate for achieving a balance between adaptation and stability? Can combining online learning with periodic batch fine-tuning improve the quality of machine translation models in different domains?"
https://aclanthology.org/2021.ranlp-1.47/,"Can character-aware neural language models be improved by forcing a character encoder to produce word-based embeddings under a Skip-gram architecture in a warm-up step, and how does this approach impact perplexity scores on typologically diverse languages?"
https://aclanthology.org/2021.ranlp-1.47/,"Can the proposed method alleviate the bias of character-aware neural language models towards surface forms, and what are the empirical results on improving perplexity scores on languages with many low-frequency or unseen words?"
https://aclanthology.org/2021.ranlp-1.48/,"Can the proposed interpretable classification approach using the Longformer architecture and ProSeNet structure achieve comparable results to traditional deep learning-based methods in detecting zero-day vulnerabilities from OSINT data, measured by F2-score, in a real-world setting with varying levels of noise and complexity? Can the proposed approach reduce the time and effort required for analysts to identify and address emerging vulnerabilities by automating the processing of large volumes of OSINT data?"
https://aclanthology.org/2021.ranlp-1.49/,"Can machine learning models achieve high accuracy in detecting offensive language in Marathi social media posts using a dataset compiled from existing data in Bengali, English, and Hindi, and what are the performance metrics that would be most informative for evaluating the effectiveness of such models?"
https://aclanthology.org/2021.ranlp-1.49/,Can the development of a zero-shot transfer learning approach using a pre-trained model trained on a small amount of labeled data in Marathi improve the detection of offensive language in Marathi social media posts compared to a model trained on a large corpus of labeled data in English?
https://aclanthology.org/2021.ranlp-1.50/,"Can pre-trained BERT models be improved by incorporating discourse structure information to enhance their ability to retrieve correct answers from detailed passages, and what types of linguistic information have the most significant impact on their performance in answering complex questions?"
https://aclanthology.org/2021.ranlp-1.51/,"Can a Dynamic Head Importance Computation Mechanism improve the performance of the Transformer model by dynamically calculating the importance of each attention head and pruning the least important ones, and how does it compare to traditional Transformer-based approaches in terms of accuracy, and what is the impact on model performance when training data is limited?"
https://aclanthology.org/2021.ranlp-1.51/,"Can the additional loss function in the proposed DHICM mechanism help prevent the model from assigning equal scores to all heads and identify more important heads, and how does it contribute to the overall improvement in model performance, especially in low-data scenarios?"
https://aclanthology.org/2021.ranlp-1.52/,Is the proposed model's accuracy of 94.0% in predicting book success solely based on lexical semantic relationships of a book's contents sufficient to be considered state-of-the-art? Can the model's performance be improved by incorporating additional features from Roget's Thesaurus to further refine the themes associated with successful books of a given genre?
https://aclanthology.org/2021.ranlp-1.53/,"Can word embedding-based topic modeling methods improve the coherence of topic models when used with SocialVisTUM, a proposed interactive visualization toolkit, compared to traditional topic modeling methods on social media texts?"
https://aclanthology.org/2021.ranlp-1.53/,"Does the use of SocialVisTUM's interactive visualization features, such as representative words and sentences of topics, enhance the exploration and understanding of topic models on large text collections?"
https://aclanthology.org/2021.ranlp-1.54/,What are the performance metrics used to compare the topic models and how do they relate to the intrinsic characteristics of the dataset?
https://aclanthology.org/2021.ranlp-1.54/,How do the results of the empirical evaluation of the topic models on different settings reflect the challenges of conducting a systematic comparison of their performance?
https://aclanthology.org/2021.ranlp-1.55/,"Can a GAN-based approach using multiple generator and discriminator pairs improve the accuracy of claim verification tasks on the FEVER dataset compared to state-of-the-art baselines, measured by F1 score, and can the use of a pre-trained language model enhance the performance of the proposed method?"
https://aclanthology.org/2021.ranlp-1.55/,"Can the proposed GAN-based model achieve a higher F1 score than the pre-trained language model alone on the FEVER 1.0 and FEVER 2.0 datasets, and what are the improvements in F1 score achieved by the proposed model over the baselines?"
https://aclanthology.org/2021.ranlp-1.56/,Can the proposed semi-supervised approach using machine translation to transfer existing sense annotations to other languages improve the accuracy of word sense disambiguation systems in languages with limited annotated data?
https://aclanthology.org/2021.ranlp-1.56/,Does the use of contextual and synset embeddings in unsupervised methods for refining sense annotations enhance the overall performance of word sense disambiguation systems?
https://aclanthology.org/2021.ranlp-1.57/,Can linear models effectively capture lexical signals for each dimension of the MBTI personality scheme in different datasets using various feature sets and learning algorithms?
https://aclanthology.org/2021.ranlp-1.57/,"Does the correlation between MBTI data and other traits such as Big-5 traits, emotion, sentiment, age, and gender provide evidence for the robustness of the data?"
https://aclanthology.org/2021.ranlp-1.58/,Can deep learning-based models achieve high accuracy in estimating semantic textual similarity between sentences in low-resource languages using publicly available datasets?
https://aclanthology.org/2021.ranlp-1.58/,Can the use of multimodal fusion techniques improve the performance of cross-lingual semantic textual similarity systems using a limited amount of labeled data?
https://aclanthology.org/2021.ranlp-1.59/,Can a combination of simpler pre-trained models outperform the state-of-the-art model on the GAD corpus in terms of extraction speed and accuracy?
https://aclanthology.org/2021.ranlp-1.59/,Can a combination of simpler pre-trained models reduce memory size to one sixth of BERT models on the ChemProt corpus while maintaining fast extraction speed?
https://aclanthology.org/2021.ranlp-1.60/,"Is it possible to develop a machine learning-based approach to predict the structure of a conversation by classifying each node pair as ""linked"" or ""not-linked"" using a two-step method, where the first step involves a link prediction task and the second step involves a link selection task? Can a score-based approach be used to improve the accuracy of link structure prediction by selecting the most relevant links in a conversation?"
https://aclanthology.org/2021.ranlp-1.61/,"Can a deep bidirectional transformer be used to accurately extract Myers-Briggs personality type from user-generated data on social media platforms, and what are the characteristics of the induced personality embeddings that contribute to this task's success?"
https://aclanthology.org/2021.ranlp-1.61/,"Can the use of personality embeddings in downstream text classification tasks, such as authorship verification, stance detection, and hyperpartisan detection, be evaluated using a combination of metrics including accuracy, precision, and recall?"
https://aclanthology.org/2021.ranlp-1.62/,"What is the effectiveness of the proposed classification procedure in automatically encoding clinical texts into SNOMED CT ontologies, measured by its accuracy in predicting SNOMED CT codes?"
https://aclanthology.org/2021.ranlp-1.62/,Can the proposed approach to automatically generating annotated datasets for SNOMED CT coding from public data and linked open data improve the quality and balance of the dataset for training machine learning models?
https://aclanthology.org/2021.ranlp-1.63/,"Does the current style classifier in existing text style transfer methods learn sentence syntax effectively, and can it be improved to enhance the overall performance of TST models? Can the proposed Syntax-Aware Controllable Generation (SACG) model effectively capture the sentence structure in text style transfer tasks?"
https://aclanthology.org/2021.ranlp-1.64/,Can transfer learning methods using BERT representation and fine-tuning improve the accuracy of Czech historical named entity recognition tasks when compared to traditional machine learning approaches?
https://aclanthology.org/2021.ranlp-1.64/,Can the combination of fine-tuning a BERT model with a simple classifier trained on a union of corpora outperform the state-of-the-art results on Czech historical named entity recognition tasks?
https://aclanthology.org/2021.ranlp-1.65/,"Can RFET improve the accuracy of personality trait identification tasks when compared to traditional feature extraction methods, such as those using Support Vector Machines? Does RFET's feature extraction capabilities provide a significant improvement in computational social science tasks compared to those using neural embedding features from Sentence-BERT?"
https://aclanthology.org/2021.ranlp-1.66/,Can the proposed lexicon-based pseudo-labeling method utilizing explainable AI approach improve the robustness of pseudo-labeling in sentiment analysis compared to existing methods?
https://aclanthology.org/2021.ranlp-1.66/,Does the use of a lexicon generated based on explainability scores improve the time efficiency of pseudo-labeling in sentiment analysis compared to existing methods?
https://aclanthology.org/2021.ranlp-1.67/,"Can a novel distillation procedure leveraging multiple teacher models improve the robustness of large language models while keeping computational time constraints, and what is the potential reduction in carbon footprint?"
https://aclanthology.org/2021.ranlp-1.67/,"Can the proposed procedure be applied to computer vision models, such as ResNet, to improve their performance and reduce computational time?"
https://aclanthology.org/2021.ranlp-1.68/,"Can BERT-based embeddings effectively serve as a substitute feature set for readability assessment in low-resource languages, and can they improve F1 performance by 12.4% over classical approaches? Can the use of BERT embeddings and handcrafted linguistic features improve readability assessment for low-resource languages like Filipino using limited semantic and syntactic NLP tools?"
https://aclanthology.org/2021.ranlp-1.69/,Can a machine learning-based approach using Abstract Meaning Representation for opinion summarization in Brazilian Portuguese outperform traditional methods in terms of summary quality and processing time?
https://aclanthology.org/2021.ranlp-1.69/,"Can the use of parsed graphs versus manually annotated graphs affect the quality of opinion summarization systems, particularly in terms of semantic representation and overall output?"
https://aclanthology.org/2021.ranlp-1.70/,"Can model-based Collaborative Filtering algorithms be used to predict the complement nouns for predicates with high accuracy, and if so, how do they compare to baseline methods in this task? Can quantizing the embedding vectors for verbs and nouns using k-means clustering improve the performance of the models on the task while reducing the number of clusters?"
https://aclanthology.org/2021.ranlp-1.71/,Efficiently learning an encoder that classifies token replacements accurately using the ELECTRA pretraining method can improve the accuracy of machine learning models when addressing domain shift in natural language processing tasks. Can the proposed ELECTRA pretraining model achieve comparable results to the original BERT model on a downstream task when fine-tuned on a target domain corpus? How can the computational efficiency of the ELECTRA pretraining method be evaluated and improved for practical use in real-world applications?
https://aclanthology.org/2021.ranlp-1.72/,Can BERT-PersNER achieve better performance than the existing supervised learning methods on the Arman and Peyma datasets using active learning approaches?
https://aclanthology.org/2021.ranlp-1.72/,Does the use of Conditional Random Field for tag decoding in BERT-PersNER improve the recognition accuracy of named entities in Persian language compared to other architectures?
https://aclanthology.org/2021.ranlp-1.73/,"Can a multilingual BERT-based model be fine-tuned to achieve state-of-the-art results in abstractive summarization for Arabic news articles, and what are the key factors that influence its performance?"
https://aclanthology.org/2021.ranlp-1.73/,Can a cross-lingual knowledge transfer approach improve the performance of pre-trained multilingual models originally trained for Hungarian/English or Russian in fine-tuning for Arabic abstractive summarization?
https://aclanthology.org/2021.ranlp-1.74/,"What is the impact of multilingual BERT on the proportion of semantically related words in masked language modeling tasks, and how does it compare to monolingual BERT models?"
https://aclanthology.org/2021.ranlp-1.74/,"How do linguistic phenomena such as semantic roles, presuppositions, and negations affect the performance of transformer-based language models in masked language modeling, particularly in non-English language models?"
https://aclanthology.org/2021.ranlp-1.75/,"Is it possible to develop an algorithm that can automatically detect and quantify the magnitude of bias in news articles using the proposed PoBiCo-21 corpus, and what metrics can be used to evaluate the performance of such an algorithm? Can a machine learning model be trained to classify news articles into the 10 bias categories using the proposed schema and what are the potential challenges in doing so?"
https://aclanthology.org/2021.ranlp-1.76/,"Can the mix-up method improve the accuracy of document classification when selecting documents with label shortages is prioritized, and how can the choice of documents for mix-up affect the overall performance of the proposed method? Can the use of bidirectional encoder representations from transformers in the mix-up method improve the performance of document classification, particularly when dealing with multi-sentence input data?"
https://aclanthology.org/2021.ranlp-1.77/,"Can a vector-based similarity evaluation method using Lucene improve the speed of retrieval from a large Translation Memory system, and how can it be scaled up for even larger translation memories?"
https://aclanthology.org/2021.ranlp-1.77/,"Can the use of vector models in similarity evaluation enable the development of a real-time retrieval system for large Translation Memory systems, and what are the potential limitations of such an approach?"
https://aclanthology.org/2021.ranlp-1.78/,Can a word sense disambiguation model be improved by incorporating an author's sense distribution into its training data to better capture the nuances of individual authors' writing styles?
https://aclanthology.org/2021.ranlp-1.78/,Can personalizing a word sense disambiguation system with knowledge of an author's predominant senses improve its performance on author-specific tasks?
https://aclanthology.org/2021.ranlp-1.79/,"Can the proposed ontology of visual objects and conventions for image selection facilitate efficient and accurate object detection in images using deep learning models, and how can the multilingual descriptions improve the performance of semantic segmentation tasks? Can the proposed annotation protocol be applied to other image datasets and domains to promote the development of more accurate and robust image annotation tools?"
https://aclanthology.org/2021.ranlp-1.80/,"Can ELERRANT accurately classify Greek errors, and how does its performance compare to the English version of ERRANT?"
https://aclanthology.org/2021.ranlp-1.80/,Do the grammatical and morphological differences between English and Greek affect the development and effectiveness of ELERRANT in annotating errors?
https://aclanthology.org/2021.ranlp-1.81/,"Can the proposed Neural Machine Translation model achieve high BLEU scores for Sinhala-English code-mixed text translation using the Encoder-Decoder framework with LSTM units and Teachers Forcing Algorithm, and how does it compare to existing translation systems in terms of accuracy and processing time? Can the creation of a parallel corpus for Sinhala-English code-mixed text significantly improve the translation accuracy of the proposed model?"
https://aclanthology.org/2021.ranlp-1.82/,Does the use of joint domain and language tags in multilingual NMT systems improve overall performance and how much does it improve over bilingual baselines?
https://aclanthology.org/2021.ranlp-1.82/,Can multistage fine-tuning of multilingual multi-domain NMT systems achieve significant performance gains in terms of BLEU scores for specific language pairs?
https://aclanthology.org/2021.ranlp-1.83/,Can machine learning algorithms achieve accuracy above 90% in distinguishing between literary texts in Russian and translations from languages other than Russian using frequency-based features?
https://aclanthology.org/2021.ranlp-1.83/,Can machine learning algorithms accurately identify translations from distant languages as opposed to same-family source languages using frequency-based features?
https://aclanthology.org/2021.ranlp-1.84/,Can a deep learning approach using a pre-trained language model and fine-tuning on the proposed Telugu-English Code-Mixing datasets improve the accuracy of Language Identification tasks compared to classical machine learning methods?
https://aclanthology.org/2021.ranlp-1.84/,Can the proposed word-level and sentence-level classification architectures for Language Identification in Code-Mixing data outperform existing models in terms of processing time and semantic understanding?
https://aclanthology.org/2021.ranlp-1.85/,How does the introduction of a novel unsupervised data normalization technique using a Multilayer Perceptron (MLP) model impact the accuracy of sentiment analysis on Code-Mixed Telugu-English Text (CMTET) compared to existing methods?
https://aclanthology.org/2021.ranlp-1.85/,"Can unsupervised data normalization be applied to improve the accuracy of sentiment analysis on Code-Mixed Text (CMTET) for tasks beyond sentiment analysis, such as named entity recognition or machine translation?"
https://aclanthology.org/2021.ranlp-1.86/,"Can a rule-based algorithm be more accurate than a machine learning algorithm in constituency-to-dependency conversion for Turkish language, and what specific features of the Turkish language make machine learning approach more accurate?"
https://aclanthology.org/2021.ranlp-1.86/,"What is the impact of human revision on the accuracy of automatic constituency-to-dependency conversion tool for Turkish language, and what metrics can be used to evaluate the effectiveness of such revisions?"
https://aclanthology.org/2021.ranlp-1.87/,"Can a machine learning model be trained to accurately predict the position of emojis in a tweet to improve the performance of emoji label prediction tasks, and how does the position of emojis impact the overall understanding of the text? Can the consideration of emoji position in irony detection tasks lead to better performance compared to emoji label prediction tasks?"
https://aclanthology.org/2021.ranlp-1.88/,"Can a deep learning model be trained to effectively adapt to changing domain knowledge by incorporating incremental updates to its training data, and how can these updates be optimized to improve the model's performance in dialogue state tracking?"
https://aclanthology.org/2021.ranlp-1.88/,"Can the proposed Dialogue Domain Adaptation methodology be extended to handle more complex slot-value changes, such as those involving multiple entities or nuanced relationships between them?"
https://aclanthology.org/2021.ranlp-1.89/,"Is it possible to improve the performance of a generic language model for the clinical domain through continued pretraining with clinical text, and how does this approach affect the accuracy of identifying protected health information, assigning ICD-10 diagnosis codes, and predicting sentence-level uncertainty?"
https://aclanthology.org/2021.ranlp-1.90/,"Can the open learner model with user modification capabilities outperform the graded approach in terms of user update effort for retrieving texts with optimal lexical complexity, and what are the conditions under which this occurs?"
https://aclanthology.org/2021.ranlp-1.90/,"Can the open learner model with user modification capabilities improve the retrieval of texts with varying new-word density levels, and how does this improvement relate to the amount of user update effort required?"
https://aclanthology.org/2021.ranlp-1.91/,"Can the proposed one-stage framework for generating utterances directly from Meaning Representation improve upon existing methods in terms of processing time, and can it be applied to other datasets with minimal additional data and techniques?"
https://aclanthology.org/2021.ranlp-1.91/,Can the use of flat conditions on slot and value pairs in the proposed model reduce the complexity of sentence structure and improve the performance of the system in terms of automated metrics such as accuracy?
https://aclanthology.org/2021.ranlp-1.92/,Can a neural-network-driven model using subword segmentation and non-lexical features improve the accuracy of annotating frustration intensity in tweets across different languages?
https://aclanthology.org/2021.ranlp-1.92/,Does the incorporation of non-lexical features into tweet representations using a bag-of-words encoding improve the model's performance in detecting frustration intensity in customer support tweets?
https://aclanthology.org/2021.ranlp-1.93/,"Does the proposed nonlinear integer programming method for combining grammatical error correction systems improve the F0.5 score of standalone systems, and does it perform better than another state-of-the-art system combination method?"
https://aclanthology.org/2021.ranlp-1.93/,Can the proposed method achieve a higher F0.5 score by selecting the best system for each grammatical error type in the data?
https://aclanthology.org/2021.ranlp-1.94/,Can multilingual word embeddings improve the accuracy of the Semantic Verbal Fluency Task (SVF) for Mild Cognitive Impairment (MCI) classification in older adults speaking different languages?
https://aclanthology.org/2021.ranlp-1.94/,Can the use of distinct word embeddings for each language improve the performance of multilingual SVF approaches and provide better cross-language generalization?
https://aclanthology.org/2021.ranlp-1.95/,"Is it possible to develop a more accurate automatic naturalness evaluation method for dialogue systems using pre-trained language models, and what is the optimal approach to fine-tune such models for this task?"
https://aclanthology.org/2021.ranlp-1.95/,Can the proposed method be extended to incorporate additional linguistic knowledge sources to further improve its performance in evaluating the naturalness of generated language?
https://aclanthology.org/2021.ranlp-1.96/,Can unsupervised question difficulty estimation from text be performed using the uncertainty of calibrated question answering models to reduce costs and time in educational settings?
https://aclanthology.org/2021.ranlp-1.96/,Can the proposed unsupervised approach leverage model uncertainty as a proxy for human-perceived difficulty in estimating the difficulty of questions in e-learning platforms?
https://aclanthology.org/2021.ranlp-1.97/,What is the effect of using POS Tags analysis of general-domain corpora on the query reformulation strategy in GeSERA for evaluating automatic summaries from the general domain?
https://aclanthology.org/2021.ranlp-1.97/,How does the use of article collections from AQUAINT-2 and Wikipedia impact the performance of GeSERA compared to SERA in evaluating summaries from the general domain?
https://aclanthology.org/2021.ranlp-1.98/,"Can machine learning models accurately distinguish between explicit and implicit abuse, and what are the implications of using lexicon-based approaches versus rule-based approaches for abusive language detection?"
https://aclanthology.org/2021.ranlp-1.98/,Can the use of a fine-grained annotation scheme impact the accuracy of abusive language detection models and how can it be addressed to achieve better classification results?
https://aclanthology.org/2021.ranlp-1.99/,What is the impact of incorporating nested named entities and relations on the performance of named entity recognition models in Russian language?
https://aclanthology.org/2021.ranlp-1.99/,Can event-based relation extraction improve the accuracy of relation extraction between nested named entities in Russian language?
https://aclanthology.org/2021.ranlp-1.100/,"Can a lightweight LSTM-based model be used effectively to detect existing relations in a real-world scenario with limited resources, and how does its performance compare to more complex models such as graph neural networks and BERT-based ones?"
https://aclanthology.org/2021.ranlp-1.100/,"Can the active-learning based pipeline improve the accuracy of relation extraction in a newspaper company with limited annotators and computing power, and which acquisition strategy yields the most cost-efficient results?"
https://aclanthology.org/2021.ranlp-1.101/,"Is it possible to develop an automatic system that can accurately detect and classify Romanian offensive language on social media with high inter-annotator agreement, using a combination of rule-based and machine learning approaches? Can the proposed system be scaled up to handle a large corpus of micro-blogging posts while maintaining its accuracy and reducing the annotation effort required?"
https://aclanthology.org/2021.ranlp-1.102/,"Can neural automatic summarization models be designed to ensure factual consistency and fact-checking accuracy in media monitoring applications, and how can this be achieved through validation procedures? Can the system be improved to handle copyright issues and style of the text while maintaining high accuracy and ethical norms in journalism?"
https://aclanthology.org/2021.ranlp-1.103/,Can a supervised machine learning approach using a transformer-based architecture be able to improve the accuracy of topic modeling for South-Slavic languages compared to traditional methods?
https://aclanthology.org/2021.ranlp-1.103/,"Can the distribution of topics in the Wikipedias of Bosnian, Bulgarian, Croatian, Macedonian, Serbian, Serbo-Croatian and Slovenian languages be effectively compared using clustering algorithms to identify regional differences?"
https://aclanthology.org/2021.ranlp-1.104/,What is the most accurate method for identifying loanwords in Persian language and their equivalents proposed by the Academy of Persian Language and Literature using association measures?
https://aclanthology.org/2021.ranlp-1.104/,How do the extracted multiword expressions (MWEs) containing loanwords compare to their equivalents in terms of linguistic and semantic meaning in the Persian language?
https://aclanthology.org/2021.ranlp-1.105/,"Does normalization of Persian text improve the performance of MWEs discovery in downstream NLP tasks by 26% compared to unnormalized text, and can open-source normalization tools be improved to enhance their association measures?"
https://aclanthology.org/2021.ranlp-1.106/,"How can the use of named entity recognition (NER) improve the performance of transformer-based models on Japanese document classification tasks and headline generation tasks, and what is the optimal number of named entities to use as input to these models?"
https://aclanthology.org/2021.ranlp-1.106/,"Can transformer-based models trained using large unlabeled text data be effectively fine-tuned for Japanese document classification and headline generation tasks using basic NLP information, such as named entities, and what is the impact of the amount of training data on the model's performance?"
https://aclanthology.org/2021.ranlp-1.107/,"Can the use of a multi-label CamemBERT classifier be evaluated for its effectiveness in annotating French tweets with language registers, and how does it compare to human-annotated labels in terms of accuracy?"
https://aclanthology.org/2021.ranlp-1.107/,"Can the linguistic traits extracted from the annotated corpus be used to improve the performance of NLP tasks, such as sentiment analysis or topic modeling, on French tweets?"
https://aclanthology.org/2021.ranlp-1.108/,"Can the proposed method effectively quantify the helpfulness of online reviews by leveraging the relevance, emotional intensity, and specificity of the reviews, and if so, what is the average improvement in helpfulness ranking compared to the baseline method?"
https://aclanthology.org/2021.ranlp-1.108/,"Can the proposed method's ranking of helpfulness be improved by incorporating additional features or techniques, such as sentiment analysis or topic modeling, to enhance the accuracy of the helpfulness assessment?"
https://aclanthology.org/2021.ranlp-1.109/,"What is the impact of word adaptation entropy on the speech intelligibility of Bulgarian and Russian, and can vowels and consonants be identified as predictors of speech intelligibility in these languages?"
https://aclanthology.org/2021.ranlp-1.109/,Can the use of the tool with incom.py 2.0 improve the accuracy of linguistic distance and asymmetry measurements in speech intelligibility studies of closely related languages?
https://aclanthology.org/2021.ranlp-1.110/,"Can linearizations of dependency parsing be designed to effectively utilize limited training data in low-resource setups, and what are the optimal strategies for achieving this goal?"
https://aclanthology.org/2021.ranlp-1.110/,Do different linearizations of dependency parsing exhibit distinct trade-offs between data efficiency and parsing performance in low-resource scenarios?
https://aclanthology.org/2021.ranlp-1.111/,Can a curriculum learning approach that gradually increases the block-size of input text for training the self-attention mechanism of BERT and its variants improve the convergence speed and final performance on downstream tasks compared to random sampling?
https://aclanthology.org/2021.ranlp-1.111/,Can the proposed curriculum learning method reduce the computational cost of training pre-trained language representation models like BERT and RoBERTa while maintaining their performance on downstream tasks?
https://aclanthology.org/2021.ranlp-1.112/,Can social media platforms effectively mitigate the spread of COVID-19 misinformation by implementing a fact-checking algorithm that can accurately identify and flag suspicious tweets within a reasonable processing time?
https://aclanthology.org/2021.ranlp-1.112/,Do partisan Facebook groups using social influence tactics to frame COVID-19 as a political issue can be effectively countered by promoting pro-public-interest and evidence-based content in these groups?
https://aclanthology.org/2021.ranlp-1.113/,"Can machine learning models be trained to effectively identify and counter anti-vaccine misinformation on social media, particularly in the Arabic language, with a focus on evaluating their accuracy using metrics such as F1 score and precision? Can propaganda techniques used in English vaccine-related tweets be analyzed using Natural Language Processing (NLP) tools to identify common patterns and sentiment analysis methods to understand the underlying motivations behind such messages?"
https://aclanthology.org/2021.ranlp-1.114/,"How can a two-hop relation extraction model improve upon existing sentence-level relation extraction models in terms of relation coverage, and what are the key components of the proposed hierarchical entity graph convolutional network (HEGCN) that contribute to this improvement?"
https://aclanthology.org/2021.ranlp-1.114/,"Can the proposed two-hop relation extraction dataset effectively capture the complexities of relation extraction in cross-document scenarios, and how does the hierarchical structure of the dataset support this goal?"
https://aclanthology.org/2021.ranlp-1.115/,"Can distant supervision models effectively utilize the relation-specific information in sentences when the presence of both entities is required, and how can a self-ensemble filtering mechanism improve the robustness of these models in relation extraction tasks?"
https://aclanthology.org/2021.ranlp-1.115/,Does the use of a self-ensemble filtering mechanism impact the performance of distant supervision models in terms of F1 scores and overall model robustness in relation extraction tasks?
https://aclanthology.org/2021.ranlp-1.116/,"What are the effects of pooling on the entity-likeness estimation of phrases in biomedical named entity recognition, and how does the proposed method outperform BioBERT-based NER in terms of accuracy?"
https://aclanthology.org/2021.ranlp-1.116/,Does the use of multiple approximate matches for a given phrase improve the estimation of entity-likeness and entity coverage in biomedical named entity recognition tasks?
https://aclanthology.org/2021.ranlp-1.117/,Can the adapted Text-to-Picto system for translating English and Spanish text into pictographs achieve an accuracy of at least 80% for medical communication between doctors and patients using Arasaac pictographs linked to WordNet 3.1?
https://aclanthology.org/2021.ranlp-1.117/,"Can the integration of WordNet 3.1 synsets and Arasaac pictographs improve the overall performance of the Text-to-Picto system in translating words into pictographs for French, compared to the original system for Dutch?"
https://aclanthology.org/2021.ranlp-1.118/,Can zero-shot cross-lingual transfer improve the performance of named entity recognition models when using different languages and entity types?
https://aclanthology.org/2021.ranlp-1.118/,How does the use of multilingual neural language models impact the performance of named entity recognition when fine-tuned on the Czech Named Entity Corpus?
https://aclanthology.org/2021.ranlp-1.119/,"Can fastText models achieve higher accuracy on word sense disambiguation tasks when optimized for non-English languages using a simple n-gram coverage model, compared to their default subword sizes?"
https://aclanthology.org/2021.ranlp-1.119/,"Can the use of a simple n-gram coverage model for subword size optimization improve the performance of fastText models on semantic text similarity tasks, compared to the default subword sizes?"
https://aclanthology.org/2021.ranlp-1.120/,"Can the use of supervised learning algorithms improve the accuracy of complex word identification in Spanish texts compared to unsupervised approaches, and what is the effect of different metrics on the complexity assessment of texts?"
https://aclanthology.org/2021.ranlp-1.121/,Can the proposed method for homograph disambiguation and wordform selection improve the accuracy of machine translation by addressing the challenge of terminological consistency in industrial translation systems?
https://aclanthology.org/2021.ranlp-1.121/,Does the proposed metric for measuring terminological consistency provide a reliable evaluation measure for assessing the quality of machine translation systems in terms of consistency and BLEU score?
https://aclanthology.org/2021.ranlp-1.122/,"Is the proposed corpus of manually labeled Spanish comments effective in detecting and classifying offensive language, as measured by accuracy, precision, and recall? Can the confidence scores attached to each label improve the performance of multi-class classification and multi-output regression models in offensive language detection and analysis on social media platforms?"
https://aclanthology.org/2021.ranlp-1.123/,Can machine learning models achieve higher accuracy in translating user reviews from English to Croatian and Serbian when trained on a combination of synthetic in-domain data and a selected subset of out-of-domain data compared to using only synthetic in-domain data?
https://aclanthology.org/2021.ranlp-1.123/,"Can the performance of neural machine translation systems differ significantly when translating IMDb movie reviews versus Amazon product reviews, and how can this impact the development of more effective review translation models?"
https://aclanthology.org/2021.ranlp-1.124/,Can a multilingual coreference resolution model trained on a dataset of harmonized annotations outperform a monolingual model in terms of accuracy for Slavic languages?
https://aclanthology.org/2021.ranlp-1.124/,Can a multilingual coreference resolution model trained on a dataset of harmonized annotations improve the performance of a model trained on separate language-specific data when evaluating user satisfaction and processing time for all languages combined?
https://aclanthology.org/2021.ranlp-1.125/,"Can a deep learning classifier trained on a corpus of abstracts from biomedical publications be able to accurately identify informative and important semantic triples in full-text articles, and if so, what is the accuracy of its performance on this task? Can a deep learning classifier trained on a corpus of abstracts from biomedical publications be able to generate an importance ranking for semantic triples extracted from full-text articles, and if so, how does this ranking correlate with the importance of the triples in the text?"
https://aclanthology.org/2021.ranlp-1.126/,"Can a multi-objective optimization approach be used to improve the performance of an existing neural network-based intent classifier on detecting completely unknown user intents without any prior knowledge of the intent classes, and how does it compare to existing state-of-the-art methods in terms of accuracy and processing time? Does the proposed post-processing method using multi-objective optimization be able to effectively handle intents that are similar to the predefined intents and those that are completely different?"
https://aclanthology.org/2021.ranlp-1.127/,Can transformer-based models achieve better performance than recurrent neural networks in sentiment polarity detection for Czech language?
https://aclanthology.org/2021.ranlp-1.127/,Can multilingual models effectively transfer knowledge from English to Czech and vice versa with zero-shot cross-lingual classification?
https://aclanthology.org/2021.ranlp-1.128/,What is the effect of using Metric Learning to derive task-specific distance measurements on the performance of document alignment techniques in multilingual settings?
https://aclanthology.org/2021.ranlp-1.128/,How do the supervised distance measurements derived from Metric Learning compare to the unsupervised distance measurements in terms of accuracy in document alignment for languages from different families?
https://aclanthology.org/2021.ranlp-1.129/,Can KB-BERT be improved to better handle the complexity of the 263 full ICD codes by incorporating additional training data or fine-tuning the model on a larger dataset?
https://aclanthology.org/2021.ranlp-1.129/,"Can KB-BERT achieve consistent performance across different ICD code blocks, reducing the need for manual post-processing and improving the accuracy of automated coding?"
https://aclanthology.org/2021.ranlp-1.130/,Can Siamese networks with XLM-R embeddings and gated recurrent units outperform bidirectional long short term memory networks in Malayalam language inference tasks using accuracy as the evaluation metric?
https://aclanthology.org/2021.ranlp-1.130/,Can the use of language agnostic embeddings in Siamese networks improve the classification performance for Malayalam language inference tasks compared to word embeddings alone?
https://aclanthology.org/2021.ranlp-1.131/,"Can the proposed authorship attribution experiments using the provided texts and methods be replicated and compared using existing machine learning algorithms, and what metrics would be most suitable for evaluating their performance in identifying distinct authors from contemporary non-fiction American English prose?"
https://aclanthology.org/2021.ranlp-1.131/,"Can the use of a homogeneous corpus in authorship attribution experiments be identified as a significant contributor to the lack of reproducibility in previous research, and what strategies could be employed to mitigate this issue in future studies?"
https://aclanthology.org/2021.ranlp-1.132/,"How can machine learning algorithms be used to identify and quantify stylistic variation in plain writing, as exemplified by the Plain Language Action and Information Network's (PLAIN) guidelines, and how do these variations compare to other types of accessible English writing styles?"
https://aclanthology.org/2021.ranlp-1.132/,"What is the impact of using uncombined measures of sentence length and word difficulty on the evaluation of plain writing, and how can these metrics be used to inform usability testing and document design considerations in government documents?"
https://aclanthology.org/2021.ranlp-1.133/,Can a 2-parameter IRT model with a discrimination parameter evaluated on question item selection be used to improve vocabulary prediction performance in a binary classification setting compared to a baseline based on word frequency?
https://aclanthology.org/2021.ranlp-1.133/,Can the effect of the discrimination parameter on prediction performance be generalised using word embeddings with a predictor network to word difficulty and discrimination in an information retrieval setting compared to out-of-dataset data?
https://aclanthology.org/2021.ranlp-1.134/,"How does the use of CamemBERT, a French variant of the RoBERTa model, impact the performance of the lexical simplification service FrenLys in terms of accuracy and processing time?"
https://aclanthology.org/2021.ranlp-1.134/,Can the frequency filter technique used in FrenLys be improved by incorporating additional linguistic resources or machine learning algorithms to enhance its effectiveness in selecting suitable substitutes for complex words in French sentences?
https://aclanthology.org/2021.ranlp-1.135/,Can a minimally-supervised model for spelling correction using a character-level statistical machine translation system with context-based re-ranking achieve higher accuracy than a model without context for candidate re-ranking on the Russian social media dataset?
https://aclanthology.org/2021.ranlp-1.135/,Can the performance of a minimally-supervised model for spelling correction on the foreign language learner dataset be compared to that of a model that uses context for candidate re-ranking on the same dataset?
https://aclanthology.org/2021.ranlp-1.136/,"Can a machine translation system accurately convey the sentiment of a user-generated content text, as measured by the correlation between the proposed sentiment-closeness measure and human evaluation, and how does this compare to existing quality metrics? Does the incorporation of the sentiment-closeness measure improve the correlation between the system's output and human judgment on the accuracy of sentiment translation?"
https://aclanthology.org/2021.ranlp-1.137/,"What is the impact of the number of documents on the precision and recall of the multilingual event extraction system in the DANIEL framework, and how can the proposed ontology-based approach improve the evaluation results?"
https://aclanthology.org/2021.ranlp-1.137/,How can the use of multilingual open information extraction for relation extraction and named entity recognition improve the accuracy of the event extraction process in the proposed system?
https://aclanthology.org/2021.ranlp-1.138/,Can BERT-based models be improved to accurately predict less frequent legal verdicts in landlord-tenant disputes using article-based features?
https://aclanthology.org/2021.ranlp-1.138/,Can transformer-based models be fine-tuned to address the limitations of accurately predicting rare legal outcomes in real-life scenarios?
https://aclanthology.org/2021.ranlp-1.139/,"Is a text-based approach using transformer models more effective than traditional methods in detecting hyperpartisan news in terms of accuracy, and what are the computational complexities involved?"
https://aclanthology.org/2021.ranlp-1.139/,"Can a text masking technique that compares style vs. topic-related features improve the detection of hyperpartisan news, and how does it impact the effectiveness of transformer-based models?"
https://aclanthology.org/2021.ranlp-1.140/,"Can the proposed CNN-based Named Entity Recognizer achieve better performance on the evaluation dataset than the existing model, and how does its F1 score compare to the existing one? Can the developed NER model be improved by incorporating additional entity types or more complex architectures such as Transformers?"
https://aclanthology.org/2021.ranlp-1.141/,Is it possible to develop a semi-supervised graph-based approach for detecting toxic comments in non-English languages and can it outperform existing transformer-based models in terms of accuracy?
https://aclanthology.org/2021.ranlp-1.141/,Can a heterogeneous graph-based method be used to classify toxic comments in the Portuguese language and how does it compare to existing approaches in terms of processing time?
https://aclanthology.org/2021.ranlp-1.142/,Can a supervised learning approach using Graph Neural Networks be used to improve the accuracy of argument quality assessment by incorporating domain-specific knowledge and features extracted from discourse units and relations?
https://aclanthology.org/2021.ranlp-1.142/,Can the use of discourse parsers and machine learning models enable the reconstruction of accurate argument graphs and improve the overall cogency assessment in argument quality evaluation?
https://aclanthology.org/2021.ranlp-1.143/,"Is the use of linguistic characteristics of reviews from different demographics a significant factor in sentiment analysis, and can a hybrid approach combining lexicon-based and machine learning methods improve performance without requiring labeled data? Can the proposed hybrid approach be adapted to accommodate reviews from various geographical regions and languages?"
https://aclanthology.org/2021.ranlp-1.144/,Can a supervised learning approach using word embeddings and part-of-speech tagging be used to develop a high-coverage Bengali obscene lexicon for detecting profane and obscene content in social media text?
https://aclanthology.org/2021.ranlp-1.144/,Can the proposed semi-automatic methodology for developing a Bengali obscene lexicon improve the accuracy of obscene content detection to 0.9 or higher in a real-world dataset?
https://aclanthology.org/2021.ranlp-1.145/,Can a deep learning model trained on a multi-modal dataset of movie trailers improve the accuracy of age-suitability ratings compared to a model trained on a unimodal dataset?
https://aclanthology.org/2021.ranlp-1.145/,"Can a combination of video, audio, and speech information improve the performance of age-suitability rating models compared to using only one modality?"
https://aclanthology.org/2021.ranlp-1.146/,"Is it possible to develop a deep learning model that can accurately detect deception in text across multiple domains, such as fake news, rumor tweets, and spam emails, using a domain-independent approach? Can the use of in-domain data improve the performance of a domain-independent deception detection model?"
https://aclanthology.org/2021.ranlp-1.147/,Can a supervised Paraphrase Identification model trained on a specific dataset generalize well to out-of-distribution domains using Optimal Transport-based framework?
https://aclanthology.org/2021.ranlp-1.147/,How does the use of Optimal Transport in a Paraphrase Identification framework impact the performance of the model in terms of syntactic correctness and processing time?
https://aclanthology.org/2021.ranlp-1.148/,"Can monolingual language representation models achieve better results than multilingual models on Czech language tasks, and what are the key factors that contribute to their superiority?"
https://aclanthology.org/2021.ranlp-1.148/,How can the training process of monolingual language representation models be improved to further establish state-of-the-art results on Czech language tasks?
https://aclanthology.org/2021.ranlp-1.149/,Can a pre-trained German language model achieve higher accuracy in text simplification tasks when trained on source labels versus when trained on standard German text only?
https://aclanthology.org/2021.ranlp-1.149/,Can the use of copy labels in a transformer-based architecture improve the model's ability to distinguish between sentences requiring further modification and those that can be copied as-is?
https://aclanthology.org/2021.ranlp-1.150/,"Can the use of active learning strategies to manually annotate a large dataset of Twitter posts for emotion detection improve the accuracy of Ekman's emotion model, as measured by F1-score, compared to traditional labeling approaches?"
https://aclanthology.org/2021.ranlp-1.150/,"Does the selection of a specific annotation strategy, such as crowdsourcing or in-house annotation, impact the reliability of the gold labels and subsequently the performance of the Ekman's emotion model on Twitter data?"
https://aclanthology.org/2021.ranlp-1.151/,Can a supervised learning approach using a pre-trained language model and fine-tuning on a small dataset of labeled MBTI annotations be effective in improving the accuracy of MBTI detection from short Twitter posts?
https://aclanthology.org/2021.ranlp-1.151/,"Can the proposed four-question method be generalized to other personality typing frameworks or models, such as the Big Five or Enneagram, through a similar annotation and machine learning pipeline?"
https://aclanthology.org/2021.ranlp-1.152/,"Can a transformer-based language model achieve chess-specific knowledge by learning from a large corpus of text data on recorded games, and how does the model's performance relate to the amount of training data and model capacity?"
https://aclanthology.org/2021.ranlp-1.152/,Does the evaluation of a transformer-based language model's performance on chess tasks require the use of custom metrics that go beyond standard measures of predictive accuracy and perplexity?
https://aclanthology.org/2021.ranlp-1.153/,"Is there an efficient way to leverage machine learning algorithms to automatically categorize and summarize disinformation content in social media posts, improving the accuracy of fact-checking efforts? Can the integration of multimodal information, such as text, images, and videos, in a hybrid approach enhance the effectiveness of human expert debunkers in identifying and mitigating the spread of disinformation?"
https://aclanthology.org/2021.ranlp-1.154/,Can the proposed BERT-based method for learning idiom embeddings outperform existing methods on the newly constructed evaluation dataset? Can the proposed BERT-based method improve the accuracy of Chinese idiom embeddings compared to existing methods?
https://aclanthology.org/2021.ranlp-1.155/,"Can pre-trained BERT models accurately distinguish between literal and idiomatic expressions in text, and to what extent can they encode the idiomatic meaning of such expressions in a given context?"
https://aclanthology.org/2021.ranlp-1.155/,"Can pre-trained BERT models effectively paraphrase idiomatic expressions while preserving their idiomatic meaning, and how do their performance vary across different datasets and tasks?"
https://aclanthology.org/2021.ranlp-1.156/,"How does the performance of Neural Topic Models vary when optimizing hyperparameters for different performance measures, and what is the effect of document length on their evaluation metrics?"
https://aclanthology.org/2021.ranlp-1.156/,Can a single-objective Bayesian optimization approach be effective in finding the optimal hyperparameters for Neural Topic Models across multiple evaluation metrics?
https://aclanthology.org/2021.ranlp-1.157/,"Can a deep learning-based approach using BERT to train a named entity recognition system achieve high accuracy on short search engine queries, and can the proposed extended label set improve the performance of the system on Turkish search engine queries? Can the use of BERT-based NER system on Turkish search engine queries outperform the results of the state-of-the-art Turkish NER systems?"
https://aclanthology.org/2021.ranlp-1.158/,"Can a contextual embedding approach using BERT variants and a recurrent neural network improve the accuracy of opinion prediction by leveraging user-specific reading history, as demonstrated by a 13% improvement in micro F1-score compared to previous approaches? Does the dynamic fingerprinting method proposed in this work outperform traditional topic-based sentiment analysis with time-series modeling and static embedding of text in predicting user reactions to unseen content?"
https://aclanthology.org/2021.ranlp-1.159/,Can multilingual models be trained to achieve similar or better performance in detecting false information on social media compared to monolingual models?
https://aclanthology.org/2021.ranlp-1.159/,Can multilingual models outperform monolingual models in detecting false information on social media across different languages?
https://aclanthology.org/2021.ranlp-1.160/,"Can a lexicon-based approach using implicit and explicit offensive and swearing expressions annotated with contextual information effectively improve hate speech detection on social media, particularly in Brazilian Portuguese?"
https://aclanthology.org/2021.ranlp-1.160/,"Can the proposed approach be generalized to other languages, such as English, while maintaining its effectiveness in detecting offensive language?"
https://aclanthology.org/2021.ranlp-1.161/,Can transformers fine-tuned on medical terminology for a rare language be more accurate than those fine-tuned on a more common language for the task of encoding medical diagnoses into ICD-10 codes?
https://aclanthology.org/2021.ranlp-1.161/,Can the use of multilingual models with a focus on Slavic languages improve the efficiency of fine-tuning for medical terminology in a non-English language?
https://aclanthology.org/2021.ranlp-1.162/,"How can a machine learning technique be designed to effectively provide feedback on the thought process behind student mistakes in a way that aligns with domain expert knowledge, and what NLP metrics can be used to evaluate its performance?"
https://aclanthology.org/2021.ranlp-1.162/,"Can a sequence-to-sequence network trained on domain expert feedback be able to identify and correct common mistakes in students' thought processes in linguistics assignments, and what are the outcomes of using this approach on a specific assignment studying Grimm's Law?"
https://aclanthology.org/2021.ranlp-1.163/,Can a simple n-gram based approach to error detection outperform more complex feature-based methods in Optical Character Recognition systems?
https://aclanthology.org/2021.ranlp-1.163/,Does a machine learning approach based solely on n-gram counts of a candidate token achieve state-of-the-art performance in OCR-error detection across multiple European languages?
https://aclanthology.org/2021.ranlp-1.164/,"Can a data-driven approach using machine learning algorithms be used to automatically identify and construct frames in a specific domain, such as law, with high accuracy and efficiency? How can the proposed methodology be evaluated and improved for semi-automatic frame construction in different domains, including but not limited to law?"
https://aclanthology.org/2021.ranlp-1.165/,What is the effect of using word embeddings learned from general-purpose text on the performance of a recurrent neural network for automatic extraction of linguistic features from textual descriptions of natural languages?
https://aclanthology.org/2021.ranlp-1.165/,How does the proposed deep learning system with semantic frames compare to a previously reported machine learning-based system in terms of F1 scores for the task of linguistic feature extraction?
https://aclanthology.org/2021.ranlp-1.166/,"Can machine learning models be used to automatically identify conditional sentences from technical documents with high precision and accuracy, and if so, what techniques would be the most effective for this task?"
https://aclanthology.org/2021.ranlp-1.166/,Can the application of natural language processing and machine learning techniques be used to categorize resultant clauses from extracted conditional sentences into Action or Consequence categories with high F1 scores?
https://aclanthology.org/2021.ranlp-1.167/,"Can a supervised machine learning approach utilizing a combination of natural language processing and deep learning techniques be effective in detecting propaganda messages on social media, and what are the most relevant linguistic features that characterize propaganda information in text? Can a text classification model using a transformer-based architecture be trained to classify propaganda messages according to the specific propaganda technique employed?"
https://aclanthology.org/2021.ranlp-1.168/,"Can ComboNER achieve comparable or better performance in part-of-speech tagging, dependency parsing, and named entity recognition tasks compared to the state-of-the-art transformers while requiring significantly fewer parameters?"
https://aclanthology.org/2021.ranlp-1.168/,Can ComboNER be fine-tuned for Polish language data to improve its overall performance on syntactic tasks while maintaining its lightweight model size?
https://aclanthology.org/2021.ranlp-1.169/,"Can the proposed methods effectively measure annotator bias in abusive language datasets by quantifying the impact of annotator's subjective perception on the classification model's performance, and what are the implications of this bias on the overall accuracy of the hate speech detection system?"
https://aclanthology.org/2021.ranlp-1.169/,Can the proposed approach identify and analyze different perspectives on abusive language by comparing the annotation processes of multiple annotators and what are the results of this analysis on the classification model's performance and the detection of hate speech?
https://aclanthology.org/2021.ranlp-1.170/,"Can a rule-based approach with a bi-RNN-based neural network hybrid model improve the accuracy of compound error correction in North Sámi, and what specific aspects of the model's performance can be improved?"
https://aclanthology.org/2021.ranlp-1.170/,Can the use of rule-based grammar checkers and machine learning models be combined to achieve higher recall and precision in compound error correction for low-resource languages like North Sámi?
https://aclanthology.org/2021.ranlp-1.171/,"Can global positional encoding for dependency trees improve the performance of Transformer-based neural machine translation systems by providing more accurate syntactic relations between words, and can the effectiveness of this approach be attributed to the incorporation of syntax information at lower layers of the model?"
https://aclanthology.org/2021.ranlp-1.171/,"Does the use of global positional encoding for dependency trees facilitate a more nuanced understanding of syntactic relations between words, and can this approach be applied to other NLP tasks that rely on contextual information?"
https://aclanthology.org/2021.ranlp-1.172/,"What is the feasibility of using semi-supervised learning for product identification on tobacco-related text from Reddit, and what is the improvement in accuracy compared to supervised learning?"
https://aclanthology.org/2021.ranlp-1.172/,"How do the F1 scores of sentiment identification on SentiSmoke-Twitter and SentiSmoke-Reddit datasets compare with state-of-the-art models, including BERT, RoBERTa, and DistilBERT?"
https://aclanthology.org/2021.ranlp-1.173/,"Can entailment prediction improve the retrieval of relevant evidence for claim verification, and how can it be used to enhance the ranking of evidence?"
https://aclanthology.org/2021.ranlp-1.173/,Does the use of entailment scores as a measure of relevancy for evidence retrieval in claim verification improve the accuracy of claim verification?
https://aclanthology.org/2021.ranlp-1.174/,"What is the most effective way to incorporate sentence structure information into Emphasis Selection using a graph neural network, and how can the word similarity graph be optimized to improve the performance of the proposed framework? Can the proposed framework be extended to handle sentences with more complex structures, such as multi-sentence documents or text with varying sentence lengths?"
https://aclanthology.org/2021.ranlp-1.175/,What is the impact of incorporating positional encoding in utterances on the performance of a neural network-based dialogue act recognition model on the Switchboard corpus?
https://aclanthology.org/2021.ranlp-1.175/,Does the use of positional encoding for utterance's absolute or relative position improve the accuracy of dialogue act recognition on the Switchboard dataset?
https://aclanthology.org/2021.ranlp-1.176/,"Can machine learning models predict annotator domain expertise based on predefined categories of sub-domains with high accuracy, and can distributed representations of documents effectively capture the implicit expertise of annotators in expert domains?"
https://aclanthology.org/2021.ranlp-1.177/,"Can a sequence-level reconstructor improve the performance of abstractive document summarization by directly reconstructing the target summary from the hidden layer of the target summary, while leveraging IDF weights to prioritize critical information? Can the word embedding-level reconstructor improve the performance of abstractive document summarization by rebuilding the average of word embeddings of the source at the target side and incorporating IDF weights to ensure critical information is included in the summary?"
https://aclanthology.org/2021.ranlp-1.178/,Can a machine learning model that uses linguistic features to detect deceptive language be trained to accurately identify the use of manipulative language features with an accuracy of at least 90%?
https://aclanthology.org/2021.ranlp-1.178/,Can the combination of a pre-trained language model with interpretable linguistic features improve the performance of a text classification model in detecting deceptive content to at least 95%?
https://aclanthology.org/2021.ranlp-1.179/,Does the proposed mechanism effectively reduce the repetition of generated tokens in encoder-decoder models for machine translation tasks by estimating the semantic difference between the source sentence before and after passing through the encoder-decoder model?
https://aclanthology.org/2021.ranlp-1.179/,Can the proposed mechanism improve the consistency between the source sentence and the generated output for response generation tasks by capturing the semantic difference between the source and generated text?
https://aclanthology.org/2021.ranlp-1.180/,"Can self-distillation with BERT improve tag representations for image privacy prediction tasks, and how does it compare to state-of-the-art models in terms of private image identification accuracy?"
https://aclanthology.org/2021.ranlp-1.180/,Can a semi-supervised learning approach using knowledge distillation achieve similar performance to supervised learning in improving tag representations for image privacy prediction with limited annotated data?
https://aclanthology.org/2021.ranlp-1.181/,"Is it possible to determine the most closely related language to Xibe through typological analysis using a similarity metric such as LangRank, and how does the choice of source language affect the performance of cross-lingual dependency parsing for Xibe?"
https://aclanthology.org/2021.ranlp-1.182/,"Can AutoChart's automatic chart generation and description framework effectively improve the accuracy of human evaluators in describing charts, as measured by the F1-score of their descriptions, and can the framework be scaled to handle complex charts with multiple components?"
https://aclanthology.org/2021.ranlp-1.182/,"Can the use of AutoChart's framework result in a significant reduction in the processing time required for chart description, compared to manual methods, as measured by the mean processing time of 1000 charts, and can this reduction be sustained over multiple iterations of chart generation and description?"
https://aclanthology.org/2021.ranlp-1.183/,"Does a fine-tuned T5 model perform better than a simple extractive algorithm in terms of ROUGE scores on EU legislation documents, and can it be adapted to work with long texts? Does the use of domain-specific words in EU legal documents improve the performance of text summarization algorithms, and can they be effectively handled by state-of-the-art extractive algorithms?"
https://aclanthology.org/2021.ranlp-1.184/,"What is the effect of incorporating semantic features from a topic model on the performance of a machine learning model in moderating reader comments in a topic-specific manner, measured by accuracy and processing time? Can topic-aware models improve the ability to detect comments that violate moderation rules, particularly in sections of the newspaper that are prone to inflammatory or sensitive content?"
https://aclanthology.org/2021.ranlp-srw.0/,"Can a machine learning model using word2vec embedding and attention-based bi-directional LSTM architecture be able to generate code-mixed Hindi-English humor with high accuracy, and if so, what are the key factors that influence the humor detection accuracy in code-mixed languages?"
https://aclanthology.org/2021.ranlp-srw.1/,"Can a multilingual sequence-to-sequence transformer model like mBART be used to generate coherent conversations in code-mixed languages such as Hindi-English, and what are the key factors that affect its performance?"
https://aclanthology.org/2021.ranlp-srw.1/,"Can a synthetic corpus like CM-DailyDialog, generated from an existing English-only dialog corpus, be effectively used to train and evaluate code-mixed dialog generation models?"
https://aclanthology.org/2021.ranlp-srw.2/,"Can multilingual pre-trained transformers like mBART and mT5 effectively translate code-mixed Hinglish to English, and how do their performance compare to baseline methods?"
https://aclanthology.org/2021.ranlp-srw.2/,"Can the BLEU scores of multilingual pre-trained transformers like mBART and mT5 on the PHINC dataset improve upon the baseline results, and what are the implications for code-mixed language translation?"
https://aclanthology.org/2021.ranlp-srw.3/,Can the use of character-level representations with the bidirectional long-short-term memory encoder improve the performance of part-of-speech tagging models in the low-resource Sindhi language?
https://aclanthology.org/2021.ranlp-srw.3/,Can the conditional random field model outperform the bidirectional long-short-term memory neural model with self-attention mechanism in part-of-speech tagging for the SiPOS dataset?
https://aclanthology.org/2021.ranlp-srw.4/,"Can a machine learning model be trained to accurately detect sarcasm in English language utterances within a real-time compilation corpus, and how can the model's performance be evaluated using metrics such as accuracy and precision?"
https://aclanthology.org/2021.ranlp-srw.4/,"Can a natural language processing technique be developed to automatically extract and classify sarcastic utterances from a large corpus of text data, and what are the computational resources required to achieve this task?"
https://aclanthology.org/2021.ranlp-srw.5/,"How can transformer-based approaches to NLG be improved to generate texts with accurate global discourse structure and meaningful sentences in terms of entity values, and what are the key discourse features that should be used in the fine-tuning procedure to achieve this?"
https://aclanthology.org/2021.ranlp-srw.5/,"Can a Web mining-based approach be developed to correct incorrect entity values in generated texts, and how can text alignment be used to improve the accuracy of discourse structure in NLG systems?"
https://aclanthology.org/2021.ranlp-srw.6/,"Can fuzzy matching algorithms improve the effectiveness of translation memory systems by reducing the edit distance for active/passive voice changes, word order rearrangements, and synonym substitutions in CAT tools?"
https://aclanthology.org/2021.ranlp-srw.6/,"Can the integration of linguistic processing techniques for ten transformation types, such as syntactic and semantic transformations, improve the retrieval of translations from translation memory systems in professional translators' workflows?"
https://aclanthology.org/2021.ranlp-srw.7/,"Can pre-trained language models and multitask fine-tuning improve the performance of an automated marking system for second language learners' written English by achieving higher accuracy and reducing errors, as measured by the F1-score, when compared to a single-task approach? Can the combination of pre-trained language models and multitask fine-tuning with different transformer architectures and datasets lead to more robust and generalizable automated marking systems, as evaluated by the processing time and user satisfaction metrics?"
https://aclanthology.org/2021.ranlp-srw.8/,"Can neural word embeddings be used to develop a system that extracts domain-specific terminology from comparable corpora with high accuracy for the English-Russian language pair, and what is the optimal approach to improve the processing time of such a system?"
https://aclanthology.org/2021.ranlp-srw.8/,"Can a bilingual access to information retrieval model be designed using comparable corpora for domain-specific extraction of terminology, and how can the model be fine-tuned for specific domain requirements?"
https://aclanthology.org/2021.ranlp-srw.9/,"What is the feasibility of developing a sentiment analysis tool for Kazakh-language reviews in Android Google Play Market, considering the challenges posed by emotional language, slang, and code-switching, using available computational methods and tools?"
https://aclanthology.org/2021.ranlp-srw.9/,"How can the aspect-based sentiment analysis method be evaluated and measured to determine its accuracy in capturing the nuances of Kazakh-language reviews, specifically in terms of sentiment intensity and topic modeling?"
https://aclanthology.org/2021.ranlp-srw.10/,How do monolingual BERT models perform in resolving grammatical number ambiguities compared to multilingual models?
https://aclanthology.org/2021.ranlp-srw.10/,Can BERT-based language representation models effectively handle grammatical gender ambiguities in different languages?
https://aclanthology.org/2021.ranlp-srw.11/,Can the proposed ensemble model using pre-trained BERT and multi-step fine-tuning improve temporal commonsense reasoning accuracy on the MC-TACO dataset compared to standard fine-tuning approaches?
https://aclanthology.org/2021.ranlp-srw.11/,Can the proposed temporal masked language model task enhance the generalization of the ensemble model on unseen temporal commonsense knowledge?
https://aclanthology.org/2021.ranlp-srw.12/,"What methods are typically used for text preprocessing in NLP, and how do they impact the metadata of the original data, specifically the types, locations, and times of registered datapoints?"
https://aclanthology.org/2021.ranlp-srw.12/,Can the systematic approach to cleaning text data described in this paper be applied to other Digital Humanities projects focused on cultural analytics?
https://aclanthology.org/2021.ranlp-srw.13/,"Can machine learning algorithms be used to automatically identify and classify the lexico-grammatical features of environmental texts in English with high accuracy, and how do these features impact the translation quality of specialized terminology units into Ukrainian?"
https://aclanthology.org/2021.ranlp-srw.13/,"Can the application of a transformer-based machine translation model be evaluated for its effectiveness in translating specialized terminological units from English to Ukrainian, taking into account the nuances of lexico-grammatical features and stylistic elements?"
https://aclanthology.org/2021.ranlp-srw.14/,"Can the doc2vec and SBERT algorithms be used to create more diverse and accurate multiple-choice questions by combining multiple sentences, and how does their performance compare on this task compared to existing single-sentence question generation methods?"
https://aclanthology.org/2021.ranlp-srw.14/,"How do the semantic similarity matches inspired by translation memory systems impact the performance of multiple-choice question generation using deep learning algorithms, and what are the implications for the development of more sophisticated question generation models?"
https://aclanthology.org/2021.ranlp-srw.15/,"What is the potential impact of using a Transformer-based lexical model on the efficiency of automatic lexical borrowing detection in monolingual wordlists, compared to a competing entropies approach?"
https://aclanthology.org/2021.ranlp-srw.15/,"Can a lexical donor model with an augmented wordlist outperform the Transformer-based approach in identifying lexical borrowings, and what specific improvements can be expected in terms of accuracy or processing time?"
https://aclanthology.org/2021.ranlp-srw.16/,Can local pruning of task-specific models achieve higher accuracy than global pruning in Aspect-based Sentiment Analysis tasks for both aspect extraction and sentiment analysis tasks?
https://aclanthology.org/2021.ranlp-srw.16/,Does local pruning of state-of-the-art models lead to better performance than over-parameterized models under different task settings?
https://aclanthology.org/2021.ranlp-srw.17/,"Can unlikelihood training and embedding matrix regularizers effectively reduce repetition in abstractive summarization, and do these techniques improve the informativeness of the summaries as measured by human evaluation? Does extending the coverage and temporal attention mechanisms to the token level reduce repetition in abstractive summarization and improve the informativeness of the summaries?"
https://aclanthology.org/2021.ranlp-srw.18/,Can the integration of commonsense knowledge into abstractive summarization models using methods inspired by generative commonsense reasoning improve the realism of generated text and reduce errors in commonsensical inferences?
https://aclanthology.org/2021.ranlp-srw.18/,Does the use of large pre-trained models with modified commonsense reasoning capabilities outperform baseline models on ROUGE scores and human evaluation metrics in natural language generation tasks?
https://aclanthology.org/2021.ranlp-srw.19/,"Can we develop an accurate depression severity evaluation model using machine learning algorithms that can identify the most severe cases from online forum posts and provide a metric to measure the severity of depression, and how does this approach compare to existing research on depression diagnosis from online forum data?"
https://aclanthology.org/2021.ranlp-srw.20/,"What is the feasibility of using the proposed method to address the challenge of avoiding the influence of EWN synset distinctions over Bulgarian, and what is the evaluation metric for this aspect?"
https://aclanthology.org/2021.ranlp-srw.20/,Can the new approach to representing nuances in sense within modifications functions improve the management of BTB-WN and enable more accurate encoding of idiosyncratic usages of derivation patterns?
https://aclanthology.org/2021.ranlp-srw.21/,"Can a fixed word order in natural languages provide a functional advantage, and if so, what are the specific characteristics of the language that make it optimal? Does the addition of case markers and noun-verb distinction reduce the need for fixed word order in language evolution?"
https://aclanthology.org/2021.ranlp-srw.22/,"Can machine learning models be trained to accurately detect the Persian emotion of Hatred from tweets, and what features of the text are most indicative of this emotion?"
https://aclanthology.org/2021.ranlp-srw.22/,Can the co-occurrence of different emotions in Persian tweets be analyzed to identify patterns that can improve sentiment analysis models for this language?
https://aclanthology.org/2021.ranlp-srw.23/,"Can a generic approach to entity extraction be developed that can effectively extract entity information from documents regardless of language, context, and structure, and can be trained on a limited dataset?"
https://aclanthology.org/2021.ranlp-srw.23/,"Can a framework be designed to analyze the hierarchical, semantic, and heuristic features of documents while minimizing the need for a massive training corpus?"
https://aclanthology.org/2021.ranlp-srw.24/,"How do Translation Memory systems perform when dealing with longer segments in terms of accuracy and syntactic correctness, and what are the implications of this on their overall effectiveness?"
https://aclanthology.org/2021.ranlp-srw.24/,"Can the use of longer segments in Translation Memory systems be improved through the development of new matching algorithms or techniques, and what metrics would be most suitable for evaluating their success?"
https://aclanthology.org/2021.ranlp-srw.25/,"Can a pattern matching deep learning model be adapted to accurately answer temporal questions within a text by leveraging a large corpus such as WikiWars, and what evaluation metric would be most suitable for measuring its performance?"
https://aclanthology.org/2021.ranlp-srw.25/,"Can temporal question answering be effectively addressed by utilizing an adapted dataset from SQuAD, and what are the challenges in designing such a dataset for this specific task?"
https://aclanthology.org/2021.ranlp-srw.26/,Can a supervised learning approach using a Transformer-based architecture be applied to construct a French corporate corpus that can effectively model and extract relevant threads from conversations generated using communication and collaboration tools?
https://aclanthology.org/2021.ranlp-srw.26/,Can the proposed pipeline for pseudo-anonymizing data meet the constraints of the General Data Protection Regulation GDPR and ensure the secrecy of correspondence in a corporate setting?
https://aclanthology.org/2021.ranlp-srw.27/,"Can a deep learning model be trained to generate a specified number of answer candidates for a given passage of text, and how can the performance of such a model be evaluated in terms of accuracy and relevance?"
https://aclanthology.org/2021.ranlp-srw.27/,"Can the proposed answer candidate generation model be used to generate questions that are grammatically correct, syntactically valid, and aligned with the content of a given passage of text, and how can the performance of such a model be measured in terms of user satisfaction and processing time?"
https://aclanthology.org/2021.ranlp-srw.28/,"Is the use of multilingual discourse-aware strategies effective in detecting fake news, and how do the newly introduced rhetorical relations INTERJECTION and IMPERATIVE impact the accuracy of fake news detection models? Can the proposed corpus be used to evaluate the performance of multilingual deceptive detection systems?"
https://aclanthology.org/2021.ranlp-srw.29/,Can the proposed hybrid method improve the accuracy of ICD-10 code extraction from clinical text for Bulgarian patients by 15% compared to the current state-of-the-art approach?
https://aclanthology.org/2021.ranlp-srw.29/,Can the rule-based approach for identifying patient symptoms in Bulgarian improve the precision of symptom identification by 20% compared to the existing rule-based system?
https://aclanthology.org/2023.ranlp-1.0/,"Can bipol accurately detect bias in multilingual datasets, and what is the effect of mT5 on bias in the new Swedish dataset?"
https://aclanthology.org/2023.ranlp-1.0/,Can the proposed multi-axes lexica for bias detection in Swedish improve the accuracy of bias detection in the Swedish CB dataset compared to the bipol metric?
https://aclanthology.org/2023.ranlp-1.1/,"How can the use of Wikidata as a knowledge base improve the coherence and structure of automatically generated Wikipedia articles in Hindi, and what are the key factors that contribute to the success of the proposed method in reducing the time and effort required to create Wikipedia articles in Hindi?"
https://aclanthology.org/2023.ranlp-1.2/,"Can multilingual language models like mBERT and XLM-RoBERTa be improved by fine-tuning the source data in the target language before transfer learning, and how does this approach affect the performance in terms of accuracy and F1-score compared to traditional zero-shot transfer?"
https://aclanthology.org/2023.ranlp-1.2/,"Does machine translation of target data into the source language improve the performance of cross-lingual transfer learning in crisis event classification tasks, and what are the benefits and limitations of this approach in terms of accuracy and F1-score?"
https://aclanthology.org/2023.ranlp-1.3/,What are the effects of incorporating a proprietary skill ontology and lexicon on the grammatical consistency of generated sentences in the sentence generation pipeline for job ads on Stepstone?
https://aclanthology.org/2023.ranlp-1.3/,"How does the approach of comparing lexical features of new input skills with existing sentences in the database impact the diversity and relevance of generated sentences in terms of tone of voice, experience level, and optionality?"
https://aclanthology.org/2023.ranlp-1.4/,"Can a multilingual BERT model improve the detection of racial hate speech in French tweets compared to the CamemBERT model in terms of accuracy, and how do different annotation resolution strategies affect the overall performance of the HateXplain model?"
https://aclanthology.org/2023.ranlp-1.4/,"Can the application of transfer learning with fine-tuning on the HateXplain model enhance the detection of non-racial hate speech in French tweets using the CamemBERT model, and what are the implications for improving hate speech detection in social media?"
https://aclanthology.org/2023.ranlp-1.5/,"What are the most effective methods for annotating Amharic hate speech tweets using human annotators versus machine learning algorithms, considering the impact on model performance and the feasibility of annotating large datasets?"
https://aclanthology.org/2023.ranlp-1.5/,"How can the design of contextual embedding models, such as AmFLAIR and AmRoBERTa, impact the accuracy of hate speech classification in Amharic language, and what are the key factors contributing to the performance of these models?"
https://aclanthology.org/2023.ranlp-1.6/,"How can machine learning algorithms be applied to develop a comprehensive wordnet for Bhojpuri, incorporating lexical anomalies and mismatch words, and what are the implications for natural language understanding and machine translation in Indian languages? Can the proposed wordnet improve the accuracy of sentiment analysis and word sense disambiguation in Bhojpuri language processing?"
https://aclanthology.org/2023.ranlp-1.7/,"What are the key properties of lexical resources that impact the behavior of NLP models trained and evaluated on them, and how can these properties be effectively utilized in downstream NLP tasks?"
https://aclanthology.org/2023.ranlp-1.7/,"Can the 3D-EX dataset be used to evaluate the impact of different lexical resource properties on NLP model performance, and what are the optimal characteristics for a lexical resource to achieve good performance in NLP tasks?"
https://aclanthology.org/2023.ranlp-1.8/,Can deep learning models using sensory experience as a feature extract a metaphor with an accuracy of 95% or higher on the VUAMC dataset? Can the combination of sensory experience and body-object interaction improve the F1 score of a sequence labeling model to 80% or higher on the MOH-X dataset?
https://aclanthology.org/2023.ranlp-1.9/,"Can the proposed datasets, HAQA and QUQA, improve the performance of Arabic language models in question-answering tasks by increasing the size and diversity of the training data? Will the QUQA dataset provide a more comprehensive evaluation metric for assessing the performance of Arabic question-answering systems compared to the HAQA dataset?"
https://aclanthology.org/2023.ranlp-1.10/,Can Arabic text analysis using ConfliBERT-Arabic significantly improve the accuracy of conflict detection in the Middle East compared to baseline BERT models?
https://aclanthology.org/2023.ranlp-1.10/,"Can pre-trained local language models enhance the performance of NLP models for Middle Eastern politics and conflict analysis, as measured by the reduction in processing time?"
https://aclanthology.org/2023.ranlp-1.11/,"Can generative language models effectively interpret and utilize knowledge from large knowledge graphs to improve their semantic understanding, and if so, what techniques can be used to validate and infer knowledge from graph structures in machine learning algorithms? Can unsupervised or semi-supervised methods for generating large knowledge graphs be combined with supervised learning techniques to improve the semantic understanding of generative language models?"
https://aclanthology.org/2023.ranlp-1.12/,"Can LLMs effectively capture contextual nuances in Holocaust testimonies, and what is the accuracy of their performance in extracting relationships in this domain compared to traditional methods such as manual or OCR-based approaches?"
https://aclanthology.org/2023.ranlp-1.12/,Can GPT3-based Subject-Object-Verb extraction outperform Semantic Role labeling-based triple extraction in relationship extraction from unstructured Holocaust testimonies?
https://aclanthology.org/2023.ranlp-1.13/,"Can emoji embeddings improve the accuracy of emotion classification for individual categories such as anger, fear, joy, and sadness? Does the use of emoji embeddings affect the intensity prediction of emotions in text?"
https://aclanthology.org/2023.ranlp-1.14/,"Is the use of pitch contour representations in discourse-meaning classification tasks more effective than other feature representations such as MFCCs, Mel-scale spectrograms, and chromagrams in Spanish speech signals?"
https://aclanthology.org/2023.ranlp-1.14/,Can the sensitivity of feature representation techniques to speaker information be improved through the use of means or other methods to reduce the dimensionality of the feature sets produced during the feature extraction process?
https://aclanthology.org/2023.ranlp-1.15/,"Can a machine learning model utilizing a corpus of Romanian texts written by non-native speakers and their teachers be trained to achieve high accuracy in error annotation and correction, and what are the key factors influencing the model's performance in this task?"
https://aclanthology.org/2023.ranlp-1.15/,What impact does the use of the LECOR corpus on the development of a query interface for error correction and annotation processes have on the efficiency and effectiveness of the NoSketch Engine?
https://aclanthology.org/2023.ranlp-1.16/,Can the proposed retriever-guided model with non-parametric memory improve the accuracy of multi-document summarization compared to the state-of-the-art ANN-based retriever in the MultiXScience dataset?
https://aclanthology.org/2023.ranlp-1.16/,Does the use of a copy mechanism in the summary generation process affect the performance of the proposed retriever-guided model in generating high-quality summaries for scientific articles?
https://aclanthology.org/2023.ranlp-1.17/,"Can a prompt-driven approach using an emotion classifier based on ELECTRA improve the emotional intelligence of ChatGPT by enabling it to generate more empathetic responses, as measured by the frequency and intensity of positive emotions in user interactions? Does using simple prompt engineering to take the user's emotion into consideration improve the emotional understanding of ChatGPT, as indicated by the frequency and intensity of positive emotions in user interactions compared to the standard version of ChatGPT?"
https://aclanthology.org/2023.ranlp-1.18/,"Can pre-trained language models like BERT, RoBERTa, and DistilBERT be improved to capture high-level semantic compositionality by augmenting them with semantic knowledge, and if so, what specific techniques can be used to achieve this? How do the performance improvements of these models on GLUE benchmark natural language understanding tasks compare to their performance on the proposed Wikidata dataset that highlights semantic inference tasks?"
https://aclanthology.org/2023.ranlp-1.19/,"Can the proposed model accurately answer questions that require understanding contextual information and background details in images, and how does it compare to other question answering models in terms of accuracy?"
https://aclanthology.org/2023.ranlp-1.19/,"Can the proposed model achieve high accuracy on complex and varied visual information, and what are the key factors that contribute to its performance?"
https://aclanthology.org/2023.ranlp-1.20/,"Can generative models perform consistently well in natural language generation tasks such as summarization and question-answering for Indic languages in zero-shot settings, and what are the limitations of these models in handling multilingual text generation?"
https://aclanthology.org/2023.ranlp-1.20/,"Do newer multilingual LLMs such as ChatGPT, mT0, and BLOOMZ achieve superior performance in manual quality-based evaluation for Indic languages compared to their zero-shot performance?"
https://aclanthology.org/2023.ranlp-1.21/,How can the performance of BERT-based neural translationese classifiers be evaluated to determine the extent to which their success is due to genuine translationese signals versus spurious correlations with topic information in the data?
https://aclanthology.org/2023.ranlp-1.21/,"Can a classifier's performance be improved by masking known spurious topic carriers in the data, and if so, what is the optimal approach for doing so?"
https://aclanthology.org/2023.ranlp-1.22/,Can a bootstrapping algorithm for creating a high-quality dataset improve the performance of fine-tuned language models in identifying changes in language or the world?
https://aclanthology.org/2023.ranlp-1.22/,"Can a dataset derived from timestamped Wikipedia definitions be effectively used for accelerating diachronic NLP tasks, specifically for training models to scan knowledge resources for core updates concerning a concept, an event, or a named entity?"
https://aclanthology.org/2023.ranlp-1.23/,"Can BERTabaporu be adapted to improve the performance of Twitter-based sentiment analysis for other languages, and what preprocessing techniques can be applied to increase its accuracy in handling diverse text genres on the platform?"
https://aclanthology.org/2023.ranlp-1.24/,"What is the effect of combining different NLP pipelines for multilingual entity linking on the overall performance, measured by the F1-score, and how can this combination be optimized for better results?"
https://aclanthology.org/2023.ranlp-1.24/,"Can existing multilingual entity linking models be improved by integrating knowledge graph-based methods with traditional NLP approaches, and what is the impact on the processing time and accuracy?"
https://aclanthology.org/2023.ranlp-1.25/,How does the proposed method for constructing the Romanian Academic Word List (Ro-AWL) compare to the methodology used for the English Academic Word List in terms of accuracy in identifying general and part-of-speech distribution of academic words?
https://aclanthology.org/2023.ranlp-1.25/,"What are the characteristics of the self-compiled expert academic writing corpus EXPRES that contribute to the development of the Ro-AWL, and how do they differ from the existing data such as the Romanian Frequency List based on the ROMBAC corpus?"
https://aclanthology.org/2023.ranlp-1.26/,Can a BERT-based stance classifier for Portuguese achieve improved performance when incorporating network-related information such as user's friends and followers into the input data?
https://aclanthology.org/2023.ranlp-1.26/,Can a BERT-based stance classifier for Portuguese be able to distinguish between stances with higher accuracy when using time-related information alongside text data?
https://aclanthology.org/2023.ranlp-1.27/,"Is it possible to develop a machine learning model that can accurately detect and replace biased language related to mental illness in text with a high level of accuracy, measured by the F1-score? Can a multilingual version of the proposed model be trained on a dataset that includes text from different languages to address global biases and stereotypes?"
https://aclanthology.org/2023.ranlp-1.28/,"Does BB25HLegalSum's use of BERT clusters and BM25 algorithm improve the efficiency of the judicial system by providing clear summaries of legal documents and highlighting important information, as measured by user satisfaction ratings and processing time? Does the clustering strategy employed by BB25HLegalSum effectively identify and combine relevant sentences to generate accurate summaries, as evaluated by precision and recall metrics on the BillSum dataset?"
https://aclanthology.org/2023.ranlp-1.29/,Can PTMs be used to improve the accuracy of stance detection on Twitter by leveraging their ability to capture nuances in linguistic expressions and semantic search capabilities? Can SSSD's semi-supervised approach to automatically labeling a large corpus of tweets for training a stance classification model outperform traditional supervised methods?
https://aclanthology.org/2023.ranlp-1.30/,Can machine learning models based on the Transformer architecture outperform those based on the Char BiLSTM architecture for formality classification in monolingual and multilingual text datasets?
https://aclanthology.org/2023.ranlp-1.30/,Can the use of cross-lingual knowledge transfer improve the stability of formality classification models in multilingual text datasets?
https://aclanthology.org/2023.ranlp-1.31/,"Can the proposed method for extracting datasets of Wikipedia biographies be applied to other languages with limited computational resources, and what would be the implications for understanding societal biases and cultural differences in those languages?"
https://aclanthology.org/2023.ranlp-1.31/,Does the use of topic modelling and embedding clustering reveal inherent biases in the representation of gendered terms in Wikipedia biographies across different languages and cultures?
https://aclanthology.org/2023.ranlp-1.32/,"Can an author manage to create believable characters with distinct styles, and can they be automatically classified with a high degree of accuracy? Can a machine learning model distinguish between the styles of different characters in a literary work with high precision?"
https://aclanthology.org/2023.ranlp-1.33/,Can the proposed approach using CodePTMs and AutoML outperform the existing JPlag plagiarism detection tool in detecting plagiarism in C/C++ source code and how can the cosine similarity scores of different CodePTMs be used as features to improve the classification accuracy in the detection of plagiarism in Java source code?
https://aclanthology.org/2023.ranlp-1.34/,Can a monolingual classifier using pre-trained language models achieve high accuracy in identifying semantic argument types in verbal predications compared to multilingual classifiers?
https://aclanthology.org/2023.ranlp-1.34/,Can a zero-shot cross-lingual approach using pre-trained language models effectively detect copredication in sentences using Food•Event nouns for 5 languages?
https://aclanthology.org/2023.ranlp-1.35/,"What is the impact of automatic text simplification tools on improving accessibility for individuals with cognitive impairment, and how can these tools be customized to meet the specific needs of this population? Can the use of machine learning algorithms and natural language processing techniques enhance the effectiveness of text simplification tools for language learners and children?"
https://aclanthology.org/2023.ranlp-1.36/,"What is the effectiveness of Vocab-Expander in improving concept-based information retrieval in technology and innovation management compared to existing methods, measured by accuracy and precision?"
https://aclanthology.org/2023.ranlp-1.36/,"How does the user interface of Vocab-Expander impact user satisfaction and engagement, as measured by the proportion of users who confirm or reject term suggestions within a specified time frame?"
https://aclanthology.org/2023.ranlp-1.37/,"Can word embeddings mitigate gender bias consistently across different metrics, and can they generalize well to unseen data, and can we develop debiasing techniques that can handle different types of biases, and how do the different debiasing techniques perform in terms of embedding coherence?"
https://aclanthology.org/2023.ranlp-1.38/,"Does the proposed algorithm accurately map explicit discourse relations between RST-DT and PDTB 3.0, as measured by the percentage of correctly aligned relations, and how does this mapping affect the unambiguity of explicit discourse relations alignment?"
https://aclanthology.org/2023.ranlp-1.38/,"Can the mapping of implicit discourse relations between RST-DT and PDTB 3.0 using the proposed algorithm be improved to increase the overall accuracy of the alignment, and what are the key factors contributing to the current unambiguity in explicit discourse relations alignment?"
https://aclanthology.org/2023.ranlp-1.39/,"Is it possible to develop a robust method for transferring in-domain performance to out-of-domain settings in conspiracy theory classification using transfer learning techniques, and how can we effectively identify the optimal source domains for this purpose? Can we design an efficient bleaching approach to steer classifiers away from topic-specific words and improve overall performance in out-of-domain settings?"
https://aclanthology.org/2023.ranlp-1.40/,Can machine learning models trained on child-generated data on Microsoft Teams accurately detect and classify safeguarding concerns with high precision and sensitivity?
https://aclanthology.org/2023.ranlp-1.40/,Can the use of Deep Learning models improve the monitoring of online communication technology in schools and enhance the detection of false alarms and true positives in safeguarding concerns?
https://aclanthology.org/2023.ranlp-1.41/,Can multilingual models using transformer architecture achieve higher accuracy in detecting misogynistic and racist hate speech in social media posts when pre-trained on a dataset that combines English and Italian text?
https://aclanthology.org/2023.ranlp-1.41/,Can the forecasting of hateful responses triggered by social media posts be improved through the use of masked language modeling and dataset merging techniques for Transformer-based models?
https://aclanthology.org/2023.ranlp-1.42/,"Can a machine learning model utilizing a deep learning-based approach with a semantic network framework be able to effectively extract relevant information from unstructured documents written in natural language, and what is the accuracy of this model in terms of F1 score? Can the proposed system be able to scale up to process large volumes of structured documents using its annotation scheme to extract relevant information and incorporate it into the semantic network?"
https://aclanthology.org/2023.ranlp-1.43/,"Can Explainable Machine Translation Systems effectively convey the nuances of culturally specific cuisine-related terms to non-native speakers, improving the accuracy of translations and user understanding?"
https://aclanthology.org/2023.ranlp-1.43/,"Can MT systems be designed to incorporate domain-specific definitions for culturally rooted terms, thereby enhancing the translational outcomes and user engagement in the food domain?"
https://aclanthology.org/2023.ranlp-1.44/,Can the use of learnable source factors in concatenation-based models improve translation accuracy for phenomena such as gender and register coherence in Basque-Spanish translation?
https://aclanthology.org/2023.ranlp-1.44/,Can concatenation-based models with learnable source factors outperform string-based markers in identifying and marking context information for Basque-Spanish contextual translation?
https://aclanthology.org/2023.ranlp-1.45/,Is it possible to design a more efficient evaluation metric for linear text segmentation that can accurately capture the complexity of the task without being biased by the limitations of existing metrics such as Pk?
https://aclanthology.org/2023.ranlp-1.45/,"Can a specific set of feature-based approaches be identified as the most effective for linear text segmentation, using a combination of supervised and unsupervised learning techniques?"
https://aclanthology.org/2023.ranlp-1.46/,Can we develop a reliable method to estimate the inter-rater reliability using only two data points in natural language processing tasks such as translation quality evaluation?
https://aclanthology.org/2023.ranlp-1.46/,Can the use of Student's t-Distribution improve the evaluation confidence in inter-rater reliability when only a limited number of observational scores are available?
https://aclanthology.org/2023.ranlp-1.47/,Can the proposed sequence-to-sequence model improve the accuracy of fake news detection on short news texts by minimizing the non-entailment probability between the original and generated texts?
https://aclanthology.org/2023.ranlp-1.47/,Does the use of a transformer-based sequence-to-sequence model with non-entailment probability as a loss function lead to a more accurate retention of the class label of the original text in fake news detection?
https://aclanthology.org/2023.ranlp-1.48/,"Can unsupervised semantic similarity models be effectively used to retrieve evidence from scientific publications to support claim verification in the healthcare domain, and what are the key factors influencing their performance in this task?"
https://aclanthology.org/2023.ranlp-1.48/,"How does the use of multilingual models such as XML-RoBERTa impact the accuracy of claim verification in the healthcare domain, and what are the benefits of using such models in this context?"
https://aclanthology.org/2023.ranlp-1.49/,"What are the parameters and methods used to annotate MWEs in the AlphaMWE-Arabic corpus, and how do they differ from those used in other parallel corpora?"
https://aclanthology.org/2023.ranlp-1.49/,"How do the machine translation errors in the current state-of-the-art systems relate to the content of Multiword Expressions in Arabic, and what insights can be gained from the human-in-the-loop metric HOPE?"
https://aclanthology.org/2023.ranlp-1.50/,"Can pre-trained models based on the BERT architecture perform well on Algerian Arabic dialects, and how do they compare to models trained on Modern Standard Arabic in terms of accuracy and processing time?"
https://aclanthology.org/2023.ranlp-1.50/,"Do social media data affect the performance of pre-trained models in identifying entities in Algerian Arabic dialects, and how can error analysis be improved to address the limitations of PTMs?"
https://aclanthology.org/2023.ranlp-1.51/,"Can the use of discourse relations in argumentative essays improve the CEFR-level of English language proficiency among learners, and does the frequency of these relations correlate with the level of linguistic complexity in the essays? Does the use of RST relations in argumentative essays predict the level of linguistic proficiency of learners as measured by the CEFR?"
https://aclanthology.org/2023.ranlp-1.52/,Can the use of Byte-Pair Encoding and data augmentation using Hungarian improve the accuracy of Inuktitut-to-English machine translation?
https://aclanthology.org/2023.ranlp-1.52/,Can the inclusion of the original script in the preprocessing pipeline result in higher BLEU scores compared to romanized scripts for Inuktitut-to-English machine translation?
https://aclanthology.org/2023.ranlp-1.53/,"Can the proposed intent pooling attention mechanism improve the performance of slot filling tasks in natural language understanding when combined with pre-trained contextualized models like ELMo and BERT? Does the fusion of intent distributions, word features, and token representations in the proposed architecture enhance the overall accuracy of slot filling models compared to the current state of the art?"
https://aclanthology.org/2023.ranlp-1.54/,Can multimodal sentiment classification models achieve comparable performance to their unimodal counterparts when trained on a dataset of labelled memes?
https://aclanthology.org/2023.ranlp-1.54/,"Can the incorporation of unimodal text data improve the performance of multimodal meme classifiers, and what is the optimal ratio of labelled meme data to unimodal data?"
https://aclanthology.org/2023.ranlp-1.55/,Can the proposed weakly-supervised method for event trigger detection improve the performance of state-of-the-art sentence-level event detection models using explanations extracted from these models?
https://aclanthology.org/2023.ranlp-1.55/,Can event triggers be reliably identified using a weakly-supervised approach based on feature attribution methods that assign relevance scores to the inputs?
https://aclanthology.org/2023.ranlp-1.56/,"Can we use small training corpora of text snippets to develop a robust medical text coding system using SNOMED CT and transformers, and how does the F1-score compare to that of large language models in morphology and topography coding tasks?"
https://aclanthology.org/2023.ranlp-1.56/,"Can the proposed approach with clustering and filtering of candidates improve the performance of support vector classification using transformer embeddings for medical text coding tasks, and what is the accuracy achieved on a real clinical dataset?"
https://aclanthology.org/2023.ranlp-1.57/,"What is the level of agreement among existing meaning/content error taxonomies for NLP tasks, and how does it impact the development of a standardized error taxonomy?"
https://aclanthology.org/2023.ranlp-1.57/,Can a compact standardized error taxonomy on meaning/content errors in generated text be derived from the identified consensus at the highest taxonomic level and applied across different generation tasks and application domains?
https://aclanthology.org/2023.ranlp-1.58/,"Can the Mondrian Conformal Predictor be effectively used to mitigate the issue of imbalanced datasets in medical text classification, and how does it impact the accuracy of a Naïve Bayes classifier?"
https://aclanthology.org/2023.ranlp-1.58/,"Does the use of the Mondrian Conformal Predictor improve the uncertainty quantification in medical text classification, and what is the evaluation metric for measuring its performance?"
https://aclanthology.org/2023.ranlp-1.59/,What is the effect of pretraining a BERT model on a large-scale language resource on its performance in the materials science domain for entity and relation extraction in Japanese?
https://aclanthology.org/2023.ranlp-1.59/,Can a BERT model pretrained on automatically translated Japanese texts from a resource-rich language outperform the general BERT model in terms of F1 scores for entity and relation extraction in the materials science domain?
https://aclanthology.org/2023.ranlp-1.60/,"Can a deep learning-based approach using a transformer architecture be used to effectively classify COVID-19 misinformation into assertion, commentary, or questioning categories with high accuracy and precision?"
https://aclanthology.org/2023.ranlp-1.60/,"Can the performance of a deep learning-based approach using a transformer architecture on COVID-19 misinformation classification be significantly improved through the use of a large-scale, diverse, and well-balanced dataset?"
https://aclanthology.org/2023.ranlp-1.61/,"Can a unified segmentation approach improve the efficiency of pretraining language models by reducing the need for separate pretraining on subword and character-level segmentation, and how can this approach be implemented in existing transformer-based architectures? Can the proposed unified segmentation method be applied to other NLP tasks that require character-level segmentation, such as text classification and sentiment analysis?"
https://aclanthology.org/2023.ranlp-1.62/,"Can data augmentation methods, such as mention-replacement and generative models, improve the performance of transformer-based models for medication identification in clinical notes when training sets are small?"
https://aclanthology.org/2023.ranlp-1.62/,Does the use of GPT-3 for generating synthetic training examples with data augmentation significantly enhance the generalizability of transformer-based models for medication identification in clinical notes?
https://aclanthology.org/2023.ranlp-1.63/,"Can the proposed method be generalized to handle text classification tasks beyond topical classification, and what is the computational complexity of this approach compared to existing transformer-based models? Does the method's ability to learn context-dependent relationships between topic labels and text content improve accuracy in scenarios where topic labels are not explicitly provided?"
https://aclanthology.org/2023.ranlp-1.64/,What is the effect of the proposed taxonomy on the performance of unsupervised approaches for predicting primary clinical indicators in the context of prior approval for spinal imaging?
https://aclanthology.org/2023.ranlp-1.64/,Can the proposed taxonomy improve the accuracy of supervised classification models for prior approval for spinal imaging by leveraging the expertise of professional nurses in creating a taxonomy-based classification system?
https://aclanthology.org/2023.ranlp-1.65/,Can the use of language models to measure information density/surprisal in translation and interpreting be a feasible method for evaluating the effectiveness of mediation modes in language pairs?
https://aclanthology.org/2023.ranlp-1.65/,Does the relationship between source and target information density/surprisal in translation and interpreting vary significantly depending on the source delivery mode and speech rate in interpreting?
https://aclanthology.org/2023.ranlp-1.66/,"Can GPT-3-based models effectively address the needs of patients in medical question-answering, and what are the limitations of these models in providing accurate and safe medical information? Can manually designed patient queries be used to stress-test the high-risk limitations of LLMs in MedQA systems?"
https://aclanthology.org/2023.ranlp-1.67/,"Can self-training methods using weakly-labelled examples and textual data augmentation techniques improve the detection of offensive and hateful comments on social media, and how do different BERT architectures and augmentation techniques impact the performance of these methods?"
https://aclanthology.org/2023.ranlp-1.67/,Do noisy self-training approaches with textual data augmentations effectively reduce the impact of adversarial attacks on hate-speech detection models?
https://aclanthology.org/2023.ranlp-1.68/,What is the most effective approach to designing discrete prompts for large language models to achieve high accuracy in text classification tasks?
https://aclanthology.org/2023.ranlp-1.68/,How does the use of optimization algorithms impact the performance of LLMs when using continuous prompts for sentiment analysis?
https://aclanthology.org/2023.ranlp-1.69/,"Can a machine learning approach be used to accurately categorize vaccine-related online narratives, and what are the specific factors that contribute to the development of vaccine hesitancy among the minority classes in COVID-19 vaccine narratives?"
https://aclanthology.org/2023.ranlp-1.70/,How do deep learning models with NLP can improve the accuracy of hand gesture recognition in American Sign Language compared to pure Computer Vision techniques?
https://aclanthology.org/2023.ranlp-1.70/,Can the application of NLP to the Sign-to-Text program enhance the robustness of the system in handling custom signs and varying lighting conditions?
https://aclanthology.org/2023.ranlp-1.71/,"Can a Classification-Aware Neural Topic Model (CANTM-IA) be optimized to improve its interpretability and classification accuracy for conflict information classification, and what metrics should be used to evaluate its performance? Can the interpretation analysis feature in CANTM-IA be used to provide a deeper understanding of the relationships between classification results and discovered topics in conflict information?"
https://aclanthology.org/2023.ranlp-1.72/,"Can data augmentation significantly improve the accuracy of fake review detection models by up to 7.65 percentage points on Amazon Test, and can it increase the accuracy by 0.31 percentage points on DeRev Test?"
https://aclanthology.org/2023.ranlp-1.72/,"Can the use of data augmentation methods enhance the performance of fake review detection models by leveraging the increased dataset size and diversity, leading to improved model accuracy and robustness?"
https://aclanthology.org/2023.ranlp-1.73/,"Can a knowledge-based multi-stage model with schema acquisition, plot generation, and surface realization modules improve the coherence of generated stories compared to traditional language models?"
https://aclanthology.org/2023.ranlp-1.73/,Can the incorporation of high-relevant structured knowledge into the story generation process enhance the comprehensibility of generated stories in terms of global coherence and reduced repetition?
https://aclanthology.org/2023.ranlp-1.74/,How can the integration of neuro-physiological signals with multimodal conversational data improve the accuracy of conversational AI models and what evaluation metrics would be most suitable to assess this improvement?
https://aclanthology.org/2023.ranlp-1.74/,Can the use of BrainKT corpus facilitate the development of more accurate models of common ground instantiation in conversation by analyzing the relationship between neural activity and linguistic features?
https://aclanthology.org/2023.ranlp-1.75/,"Can a deep learning approach using sequence labeling be used to improve the accuracy of identifying the scope of industry requirements in natural language text, and how can incorporating document context information enhance the performance of scope detection in this task?"
https://aclanthology.org/2023.ranlp-1.75/,"What is the impact of using few-shot learning on the identification of semantic components in industry requirements, specifically the scope, condition, and demand, and how can this approach be adapted for real-world applications?"
https://aclanthology.org/2023.ranlp-1.76/,"Is it possible to train a lightweight language model for Bulgarian that can effectively mitigate gender, racial, and other biases in the data using a lexicon-based approach? Can the proposed method improve the robustness of the model by incorporating new data from various domains?"
https://aclanthology.org/2023.ranlp-1.77/,Can the use of pre-trained RoBERTa embeddings and ensemble learning techniques improve the performance of fake reviews detection and review helpfulness prediction tasks when employed concurrently?
https://aclanthology.org/2023.ranlp-1.77/,"Can a multi-task learning approach utilizing document-level data representation and a combination of deep learning models including Bi-LSTM, LSTM, GRU, and CNN enhance the accuracy of fake reviews detection and review helpfulness prediction?"
https://aclanthology.org/2023.ranlp-1.78/,"What is the impact of incorporating different data representations on the performance of machine learning models for fake reviews detection, and which data representation yields the best results?"
https://aclanthology.org/2023.ranlp-1.78/,How does the combination of early and late data fusion techniques improve the prediction performance of fake reviews detection using different data representations?
https://aclanthology.org/2023.ranlp-1.79/,"What is the feasibility of using GoodReads ratings as a proxy for reader-appreciation in predicting narrative text quality, and how does this proxy impact the accuracy of stylistic and semantic feature-based models? Can stylistic features outperform semantic features in predicting reader-appreciation in literary texts of different complexity and sentiment?"
https://aclanthology.org/2023.ranlp-1.80/,Does the use of transformer-based architectures improve the accuracy of clickbait detection in Bangla language compared to traditional neural network models like LSTM and GRU?
https://aclanthology.org/2023.ranlp-1.80/,Can a semi-supervised generative adversarial network (SS-GAN) achieve better performance than linguistic feature-based models in detecting clickbait titles in Bangla articles?
https://aclanthology.org/2023.ranlp-1.81/,"What is the impact of using TreeSwap on the performance of neural machine translation models on low-resource language pairs, measured by accuracy and syntactic correctness?"
https://aclanthology.org/2023.ranlp-1.81/,"Does TreeSwap improve the quality of generated sentences for domain-specific corpora such as law, medical, and IT data, as measured by user satisfaction and processing time?"
https://aclanthology.org/2023.ranlp-1.82/,"Can a multimodal and multitask transformer model effectively evaluate the CEFR level of students' spontaneous spoken language proficiency by accurately scoring speech quality, content, and coherence, and measuring user satisfaction with the assessment system?"
https://aclanthology.org/2023.ranlp-1.82/,Does the proposed model's ability to leverage multiple features and modality attention improve its performance in capturing the interactions between audio and text modalities in spontaneous speech assessment?
https://aclanthology.org/2023.ranlp-1.83/,"Can a supervised learning approach using a pre-trained language model be used to accurately identify medical concept mentions in social media text, measured by precision and recall on a given dataset?"
https://aclanthology.org/2023.ranlp-1.83/,"Can the proposed model be effectively evaluated and generalized to different domains, such as Measles, using transfer learning techniques on a large corpus of text?"
https://aclanthology.org/2023.ranlp-1.84/,"What is the impact of incorporating dialog history on the performance of module selection models in modular dialog systems, measured by the accuracy of the selected module?"
https://aclanthology.org/2023.ranlp-1.84/,"Does the use of contextual features, including both the current user turn and dialog history, improve the robustness of module selection models in handling multi-turn dialogs?"
https://aclanthology.org/2023.ranlp-1.85/,"Can deep neural networks with CNN architecture achieve better results in text classification compared to traditional methods for certain values, and what are the key factors that influence this improvement?"
https://aclanthology.org/2023.ranlp-1.85/,"Can the bilingual corpus created from consumer reviews be effectively utilized for marketing purposes, and what specific metrics would be used to evaluate its effectiveness?"
https://aclanthology.org/2023.ranlp-1.86/,Can the use of Word2Vec and fastText models improve the precision of medical translations into pictographs in communication between doctors and patients with intellectual disabilities? Can the application of CamemBERT and its variants in medical word sense disambiguation contribute to more accurate pictograph translations in this context?
https://aclanthology.org/2023.ranlp-1.87/,"Can neural machine translation systems be designed to effectively evaluate and incorporate the needs and preferences of low-resource language communities into their development and deployment, and what are the potential benefits and challenges of using human-in-the-loop approaches in low-resource machine translation systems?"
https://aclanthology.org/2023.ranlp-1.87/,"Does the use of sub-domains in low-resource machine translation systems improve their quality and relevance to the target community, and how can these sub-domains be identified and utilized to create more effective and culturally sensitive MT systems?"
https://aclanthology.org/2023.ranlp-1.88/,"Can a multimodal model trained on question descriptions and source codes in multiple programming languages achieve high accuracy in duplicate detection using the proposed learning objectives, and what is the average processing time of the Multimodal Question Duplicity Detection (MQDD) model on a large dataset?"
https://aclanthology.org/2023.ranlp-1.89/,What are the key factors that contribute to the poor compositional generalization of current Transformer models when dealing with hierarchical structures in human language?
https://aclanthology.org/2023.ranlp-1.89/,Do the incorporation of composition operators and pooling functions in the proposed Treeformer architecture improve the performance of Transformer models on downstream tasks such as machine translation and natural language understanding?
https://aclanthology.org/2023.ranlp-1.90/,How can hierarchical topic models be designed to produce more accurate topic trees with a smaller number of labels while maintaining a high overall accuracy of over 70% when using a large number of labels in the dataset?
https://aclanthology.org/2023.ranlp-1.90/,Can a subset of labels covering only 1% of the data be sufficient to achieve high accuracy in evaluating the quality of hierarchical topic models and their ability to produce coherent taxonomies?
https://aclanthology.org/2023.ranlp-1.91/,How can the incorporation of temporal aspects in topic modeling improve the extraction of meaningful topics in time-sensitive applications such as news article analysis?
https://aclanthology.org/2023.ranlp-1.91/,"Can a hierarchical topic modeling approach be used to extract subtopics within a given time period, and if so, how can the temporal dimension be incorporated into the model?"
https://aclanthology.org/2023.ranlp-1.92/,"What is the impact of task-agnostic continual learning methods on the performance of multilingual models in a real-world deployment scenario, measured by the consistency of their language-specific accuracy across multiple datasets and languages?"
https://aclanthology.org/2023.ranlp-1.92/,"How do the effectiveness of different continual learning strategies, such as incremental learning and transfer learning, compare in terms of processing time and syntactic correctness when applied to multilingual models in a dynamic language environment?"
https://aclanthology.org/2023.ranlp-1.93/,"Can transformer-based models be improved for long document classification by employing model fusion techniques, and how do BERT and Longformer architectures perform in comparison to each other in this context?"
https://aclanthology.org/2023.ranlp-1.93/,"Can model fusion techniques enhance the performance of transformer models in handling long documents, and what are the specific benefits and limitations of using BERT and Longformer for long document classification?"
https://aclanthology.org/2023.ranlp-1.94/,"Can transformer-based discriminative models achieve higher accuracy than generative pre-trained models in detecting multiword terms in English and Spanish flower and plant names, and what is the key factor contributing to the better performance of these models?"
https://aclanthology.org/2023.ranlp-1.94/,Can the evaluation of transformer-based discriminative models on multiword terms identification be improved by using different pre-training datasets or fine-tuning the models on specialized domain data?
https://aclanthology.org/2023.ranlp-1.95/,"Can the proposed end-to-end Semantic Role Labeling model improve the performance of Aspect-Based Sentiment Analysis in English and Czech languages when utilizing extracted semantic information from SRL models, as measured by accuracy and F1-score?"
https://aclanthology.org/2023.ranlp-1.95/,"Can the incorporation of semantic information from SRL models into ABSA models lead to improved performance, specifically in terms of processing time and user satisfaction, when compared to traditional approaches using only contextual information?"
https://aclanthology.org/2023.ranlp-1.96/,"Can huPWKP corpus improve the performance of text simplification models for Hungarian language compared to English language, measured by automatic metrics such as BLEU score?"
https://aclanthology.org/2023.ranlp-1.96/,"Can huPWKP corpus attain a high SARI score comparable to state-of-the-art models on the official PWKP set, and how does it relate to human evaluation scores in terms of information retention and grammaticality?"
https://aclanthology.org/2023.ranlp-1.97/,Can the proposed approach effectively identify overlapping topics in a text corpus when the distribution of words among the underlying topics is uneven?
https://aclanthology.org/2023.ranlp-1.97/,"Can the proposed approach estimate the number of topics in a text corpus when the topic count is unknown, without requiring user input?"
https://aclanthology.org/2023.ranlp-1.98/,"Can we develop an effective approach to automatically detect non-inclusive language in English sentences using machine learning techniques, and what is the optimal way to evaluate the performance of such a model in terms of accuracy? Can we design a phrase dictionary that accurately identifies and excludes non-inclusive keywords/phrases from a business context, and how can we incorporate this dictionary into a text analysis pipeline to improve the detection of non-inclusive language?"
https://aclanthology.org/2023.ranlp-1.99/,"Can large language models like BERT and GPT-3 improve their performance in answering yes/no questions on figurative text by automatically simplifying the contexts into non-figurative ones, and what is the optimal approach for achieving this improvement?"
https://aclanthology.org/2023.ranlp-1.99/,"Can ChatGPT's chain-of-thought prompting strategy effectively improve the overall performance of QA models on figurative language, and what are the key factors contributing to its success?"
https://aclanthology.org/2023.ranlp-1.100/,"How does the proposed complexity measure LRC impact the learning performance of BERT and RoBERTa when used in Curriculum Learning CL-LRC, and what are the key factors that influence its effectiveness in improving learning outcomes for downstream tasks?"
https://aclanthology.org/2023.ranlp-1.100/,"Can the proposed CL-LRC approach be generalized to other deep learning models beyond BERT and RoBERTa, and what are the potential limitations of using LRC as a complexity measure for other models?"
https://aclanthology.org/2023.ranlp-1.101/,"How do pre-trained Transformers and syntactic/lexical neural networks perform on unseen sentences in classification tasks, and what is the effect of fine-tuning on their performance after extreme domain adaptation?"
https://aclanthology.org/2023.ranlp-1.101/,"Can pre-trained Transformers benefit from large pre-training corpora through exposure to a wide range of sentences, and do they require a large corpus to achieve optimal results?"
https://aclanthology.org/2023.ranlp-1.102/,"How does the memorization ability of BERT impact its performance in downstream tasks, and what specific metrics can be used to measure memorization in LLMs?"
https://aclanthology.org/2023.ranlp-1.102/,Can PreCog effectively evaluate memorization in BERT and what implications does its correlation with performance have for downstream applications?
https://aclanthology.org/2023.ranlp-1.103/,"Is it possible to develop machine learning models that can accurately moderate Luxembourgish news article comments using transformer-based architectures, and what is the impact of training models on old data on their performance on recent data?"
https://aclanthology.org/2023.ranlp-1.103/,"Can the language of Luxembourgish news article comments change over time, and how do these changes affect the performance of comment moderation systems?"
https://aclanthology.org/2023.ranlp-1.104/,Can the use of MFCC features in the LSTM-DNN model improve the performance of speaker identification on Indian languages compared to other features?
https://aclanthology.org/2023.ranlp-1.104/,"Can a deep learning approach, such as the LSTM-DNN model, outperform traditional baseline models in speaker identification tasks, particularly when using mel-spectrogram images as input?"
https://aclanthology.org/2023.ranlp-1.105/,"Is the proposed NCRF approach effective in identifying chemical compounds with high accuracy in patent documents, measured by precision and recall of compound names extracted, and can it improve the extraction of chemical events and their relations between compounds in a chemical reaction? Can the NCRF model improve the extraction of specific roles of chemical compounds in a chemical reaction, measured by the accuracy of assigned labels?"
https://aclanthology.org/2023.ranlp-1.106/,"Can active learning with uncertainty-based and diversity-based query strategies improve the performance of text classification models in handling imbalanced datasets by achieving better class coverage and identifying rare cases, measured by F1 score and precision?"
https://aclanthology.org/2023.ranlp-1.106/,"Does the use of uncertainty-based sampling outperform diversity-based sampling in selecting minority classes, and what are the implications for developing effective text classification models that meet the demands of users in terms of class coverage and efficiency, measured by F1 score and processing time?"
https://aclanthology.org/2023.ranlp-1.107/,Can a deep learning-based approach utilizing a transformer architecture be used to improve the accuracy of event detection in code-mixed text data?
https://aclanthology.org/2023.ranlp-1.107/,Can the proposed guidelines for annotating events in Kannada-English code-mixed data lead to a significant reduction in the processing time for event detection tasks in social media platforms?
https://aclanthology.org/2023.ranlp-1.108/,"Can a supervised machine learning approach using a Named Entity Recogniser for Slovenian language be applied to classify client emails in other languages based on topics and priorities, and what are the challenges that may arise from language differences?"
https://aclanthology.org/2023.ranlp-1.108/,"Can the accuracy of the proposed approach be evaluated using a metric such as F1-score, precision, or recall, and how would this evaluation impact the applicability of the approach to other languages?"
https://aclanthology.org/2023.ranlp-1.109/,Can abstractive summarisation models achieve high-quality summaries of podcast episodes with high ROUGE-1 and ROUGE-L scores using a dataset of 100K podcast episodes?
https://aclanthology.org/2023.ranlp-1.109/,Can pre-trained models such as BART and T5 be fine-tuned to produce summaries that capture semantic meaning in podcast content?
https://aclanthology.org/2023.ranlp-1.110/,Can machine learning models be effectively applied to improve the accuracy of named entity recognition in low-resource languages using a transformer-based architecture and a hybrid approach combining rule-based and machine learning techniques? Can the proposed taxonomy of NLP fields be used to identify areas of research that have the potential to drive breakthroughs in natural language understanding and generation tasks?
https://aclanthology.org/2023.ranlp-1.111/,How do lightweight adapters affect the accuracy of sentence embeddings when compared to fine-tuning the entire sentence embedding model?
https://aclanthology.org/2023.ranlp-1.111/,Can domain-specific adapters trained on a fixed underlying sentence embedding model achieve competitive performance with fine-tuning the entire model?
https://aclanthology.org/2023.ranlp-1.112/,Can AspectCSE improve the accuracy of aspect-based sentence embeddings compared to generic sentence embeddings on information retrieval tasks across multiple aspects?
https://aclanthology.org/2023.ranlp-1.112/,Does the use of Wikidata knowledge graph properties enhance the performance of multi-aspect sentence embeddings compared to single-aspect embeddings on aspect-specific information retrieval tasks?
https://aclanthology.org/2023.ranlp-1.113/,"Can the use of natural language processing techniques on metadata associated with YouTube comment threads and user channels improve the accuracy of collusion scam detection, and can these methods be replicated with existing tools and datasets? Can modern language models, such as chatGPT, be trained to detect collusion scams without relying on labeled training data?"
https://aclanthology.org/2023.ranlp-1.114/,"What is the feasibility of applying a generic deception detection model trained on one domain to detect deception in another domain, and how can we improve the performance of such models?"
https://aclanthology.org/2023.ranlp-1.114/,Can a multi-task learning approach using domain-specific and domain-independent training strategies improve the generalization of deception detection models across different mediums?
https://aclanthology.org/2023.ranlp-1.115/,"Can the proposed method for extracting parties from legal contract documents achieve a higher exact match score than the current state-of-the-art model by increasing the number of encoder layers and adding normalization and dropout layers? Can the incorporation of contextual span representations in the method improve the accuracy of party extraction from legal documents, particularly in handling the complex structure of the legal text?"
https://aclanthology.org/2023.ranlp-1.116/,"Can unsupervised domain adaptation techniques improve the performance of fake news detection models without requiring labeled data for the target task, and do the use of clustering and topic modeling algorithms enhance the results of UDA in this context?"
https://aclanthology.org/2023.ranlp-1.116/,"Do the different UDA methods, such as cluster alignment with a teacher and cross-domain contrastive learning, provide comparable performance gains in text classification tasks like fake and hyperpartisan news detection?"
https://aclanthology.org/2023.ranlp-1.117/,"What are the effects of using sequence-to-sequence models for aspect-based sentiment analysis in Czech, and how does the prompt-based approach compare to traditional fine-tuning in terms of accuracy and processing time? Can pre-training on target domain data improve the performance of zero-shot sentiment classification in Czech?"
https://aclanthology.org/2023.ranlp-1.118/,Can machine learning models accurately predict hate speech with gender-neutral data and how does this approach compare to binary gender-based models in reducing bias in hate speech prediction? Does the inclusion of gender-neutral data improve the overall performance and fairness of hate speech classification models?
https://aclanthology.org/2023.ranlp-1.119/,Can LeSS outperform the state-of-the-art lexical simplification system for Spanish in terms of accuracy and loading time on a dataset of 1000 texts?
https://aclanthology.org/2023.ranlp-1.119/,"Can LeSS's computational requirements, including disk space, CPU, and GPU usage, be reduced to 50% of those of transformer-based lexical simplification models?"
https://aclanthology.org/2023.ranlp-1.120/,"Can morphologically inspired segmentation methods outperform Byte Pair Encoding in building NMT systems for low-resource languages, specifically Hindi to Malayalam and Hindi to Tamil?"
https://aclanthology.org/2023.ranlp-1.120/,Can the performance of NMT systems for morphologically rich languages such as Malayalam and Tamil be improved by using morphological segmentation instead of Byte Pair Encoding?
https://aclanthology.org/2023.ranlp-1.121/,"Can a machine translation approach be used to effectively detect Bulgarian textual deepfakes with high accuracy, and what are the limitations of this approach in comparison to other methods? Can a supervised classifier trained on a Bulgarian-language dataset achieve high accuracy in detecting Bulgarian textual deepfakes?"
https://aclanthology.org/2023.ranlp-1.122/,Can machine learning algorithms be used to accurately identify pro-Russian propaganda in Telegram posts with an overall accuracy of over 96% for confirmed sources and 92% for unconfirmed sources?
https://aclanthology.org/2023.ranlp-1.122/,Can the development of a dataset for text classification in Telegram posts containing pro-Russian propaganda and benign political texts contribute to a better understanding of political communications and propaganda on social media?
https://aclanthology.org/2023.ranlp-1.123/,Can a dense information retrieval model pre-trained using a conditional language model that maximizes the question's likelihood by marginalizing over retrieved documents outperform the current state-of-the-art in zero-shot dense information retrieval on a low-resource setting?
https://aclanthology.org/2023.ranlp-1.123/,Can a synthetic corpus created by zero-shot question generation improve the performance of a dense information retrieval model pre-trained using a dense IR model for encoding questions and retrieving documents during training?
https://aclanthology.org/2023.ranlp-1.124/,"Can NoHateBrazil's system accurately classify implicit offensiveness in Brazilian Portuguese comments, and how does its performance compare to other similar systems?"
https://aclanthology.org/2023.ranlp-1.124/,Does the implementation of NoHateBrazil's friendly web application effectively mitigate the risk of reinforcing social stereotypes in online comments?
https://aclanthology.org/2023.ranlp-1.125/,"Can hate speech classifiers accurately detect and mitigate the propagation of social stereotypes, and how do they reflect and reinforce existing stereotypical beliefs in marginalized groups?"
https://aclanthology.org/2023.ranlp-1.125/,Can the integration of expert and context information from offensiveness markers improve the accuracy and fairness of hate speech detection models in reducing social stereotype bias?
https://aclanthology.org/2023.ranlp-1.126/,"Can a machine learning model trained on the FactNews dataset be able to accurately predict the factuality of news reporting with a high degree of precision, measured by the F1-score, and how does the model's performance compare to a baseline approach in detecting biased sentences in Brazilian Portuguese news articles?"
https://aclanthology.org/2023.ranlp-1.127/,"Can BERT-based models be improved for long document classification by incorporating additional training data or using pre-training objectives that specifically target long-form text, and what is the impact of these modifications on their performance on US supreme court decisions or SCDB?"
https://aclanthology.org/2023.ranlp-1.127/,"Can a fine-grained classification of US supreme court decisions using BERT-based models achieve higher accuracy than previous SOTA results, and what features or techniques are most critical for achieving such results in this domain?"
https://aclanthology.org/2023.ranlp-1.128/,Can kāraka-based approach outperform traditional methods in retrieving answers for Hindi and Marathi question-answering systems in terms of accuracy and processing time?
https://aclanthology.org/2023.ranlp-1.128/,How do different methods of kāraka extraction impact the overall performance of kāraka-based question-answering systems in low-resource languages like Hindi and Marathi?
https://aclanthology.org/2023.ranlp-1.129/,"Can Large Language Models be trained to improve Named Entity Recognition in fantasy literature, and if so, what specific domain-specific features and annotations can be used to enhance their performance?"
https://aclanthology.org/2023.ranlp-1.129/,Can the use of open-source Large Language Models for annotating and evaluating Named Entity Recognition in fantasy literature lead to more accurate results and better model performance in this domain?
https://aclanthology.org/2023.ranlp-1.130/,Can a supervised approach using a multilingual SBERT-based model be more effective in detecting text anomalies than unsupervised methods in a dataset with limited positive examples?
https://aclanthology.org/2023.ranlp-1.130/,Can semi-supervised methods utilizing weak labels be more accurate in identifying text anomalies than semi-supervised methods using only negative samples for training in a hate speech detection context?
https://aclanthology.org/2023.ranlp-1.131/,"How can the proposed graph neural network poetry theme representation model improve the topic consistency of ancient Chinese poetry generation by leveraging label embedding and word granularity, and what is the evaluation metric used to measure the improvement in topic consistency?"
https://aclanthology.org/2023.ranlp-1.131/,"Can the proposed theme-oriented ancient Chinese poetry generation model TLPG achieve better fluency and format accuracy in poetry generation compared to existing work, and what are the specific features of the model that contribute to its improved performance?"
https://aclanthology.org/2023.ranlp-1.132/,What is the impact of using generative models versus finetuned LLM models on the performance of graph-to-text generation tasks in terms of BLEU scores and semantic relation understanding?
https://aclanthology.org/2023.ranlp-1.132/,Can generative models achieve comparable or superior results to finetuned LLM models in terms of detecting machine-generated text using BERT?
https://aclanthology.org/2023.ranlp-1.133/,"Can Word Embedding Models trained on Slavic languages effectively capture the nuances of syntactic non-compositionality, and how do they compare to syntax-based models in this task? Do the cross-linguistic properties of microsyntactic units in six Slavic languages have a significant impact on the performance of Word Embedding Models?"
https://aclanthology.org/2023.ranlp-1.134/,Does the incorporation of domain-specific knowledge in TextRank algorithm improve its performance in extractive summarization tasks compared to traditional approaches? Can fine-tuning the TextRank parameters with data-driven techniques lead to better summarization quality and faster processing times?
https://aclanthology.org/2023.ranlp-stud.0/,"Can generative language models such as ChatGPT be effectively differentiated from human-generated text based on stylistic and linguistic characteristics, and what metrics can be used to evaluate the accuracy of such differentiation methods?"
https://aclanthology.org/2023.ranlp-stud.0/,"Can ChatGPT-generated text be reliably identified through machine learning-based approaches using features such as syntax, semantics, and pragmatics, and what are the limitations of these methods in detecting deception?"
https://aclanthology.org/2023.ranlp-stud.1/,"Can large-scale language models be adapted to perform text classification tasks using only a few in-domain sample queries and no labelled samples, and if so, what is the optimal number of queries required to achieve the best performance?"
https://aclanthology.org/2023.ranlp-stud.1/,"Does the calibration of LLM posteriors to the task improve the model's performance for text classification tasks, and what is the relationship between the number of training shots in the prompt and the model's performance after calibration?"
https://aclanthology.org/2023.ranlp-stud.2/,"Can the proposed control tokens improve the controllable active-passive voice generation task in the WebNLG dataset, as measured by AP accuracy?"
https://aclanthology.org/2023.ranlp-stud.2/,"Can the contrastive learning approach outperform other methods, such as prefix tuning, in achieving high AP accuracy while maintaining performance on the original WebNLG task?"
https://aclanthology.org/2023.ranlp-stud.3/,What linguistic features of social media text can be used to identify depression in adolescents compared to adults on Reddit?
https://aclanthology.org/2023.ranlp-stud.3/,Can the use of topic modeling and data visualization techniques improve the accuracy of depression classification based on age-specific language patterns on social media?
https://aclanthology.org/2023.ranlp-stud.4/,"Can machine learning algorithms effectively detect and predict the emotional responses of social media users to trigger warnings, and what is the relationship between the content of trigger warnings and user engagement?"
https://aclanthology.org/2023.ranlp-stud.4/,"How do trigger warnings impact the diversity and content of responses from online communities, and what are the implications for developing domain-specific datasets?"
https://aclanthology.org/2023.ranlp-stud.5/,Can large language models accurately predict hallucinations for Bulgarian language tasks without relying on large amounts of reference data?
https://aclanthology.org/2023.ranlp-stud.5/,How does the performance of large language models on Bulgarian language tasks compare to their performance on other languages in terms of hallucination detection?
https://aclanthology.org/2023.ranlp-stud.6/,Can probabilistic graph models such as conditional random fields and hidden Markov models be used to improve the accuracy of nested named entity recognition for the Polish language?
https://aclanthology.org/2023.ranlp-stud.6/,Can the use of Word2Vec and HerBERT embeddings in conjunction with the BiLSTM-CRF model enhance the performance of nested named entity recognition in Polish?
https://aclanthology.org/2023.ranlp-stud.7/,"Can the proposed model improve the accuracy of veridicality annotations in Spanish texts by reducing the effect of annotator disagreement and increasing the inter-annotator agreement, measured by the Cohen's kappa coefficient?"
https://aclanthology.org/2023.ranlp-stud.7/,"Can the entropy distribution of mood alternation and specificity in Spanish texts be used as a more robust and reliable feature for veridicality analysis, as suggested by Pavlick and Kwiatkowski (2019), and how does it compare to the current annotations?"
https://aclanthology.org/2023.ranlp-stud.8/,Can a model utilizing seed words for aspect and sentiment classification achieve significant improvements over existing baselines in Urdu aspect-based sentiment analysis tasks with minimal user guidance and unlabeled data?
https://aclanthology.org/2023.ranlp-stud.8/,"Can the use of word embedding space regularization and BiLSTM classifier for sentence-level sentiment and aspect classification improve the performance of ABSA models for Urdu language, particularly for resource-poor languages like Urdu?"
https://aclanthology.org/2023.ranlp-stud.9/,"What are the key factors that contribute to the improved performance of Transformer-based models in low-resource language pairs, and how can they be optimized through data augmentation and hyper-parameter tuning?"
https://aclanthology.org/2023.ranlp-stud.9/,"Can the use of back-translated data in training Neural Machine Translation models lead to significant performance gains in low-resource language pairs, and what are the limitations of this approach in comparison to other synthetic data generation methods?"
https://aclanthology.org/2023.ranlp-stud.10/,"Can prompt engineering techniques be used to improve the performance of Large Language Models in re-training by incorporating contextual information such as keywords, and how effective are these techniques in enhancing the plausibility and human-likeness of definitions?"
https://aclanthology.org/2023.ranlp-stud.10/,"Can the optimal prompting strategy for asking a Large Language Model to define new words based on morphological connections involve a persona-type prompt, and what role do keywords such as 'new' and'morpheme' play in achieving this goal?"
https://aclanthology.org/R17-1000/,Can D-Bees be used as a reliable method for word sense disambiguation with consistent results across different domains and languages?
https://aclanthology.org/R17-1000/,Does the parameter tuning of D-Bees improve its performance in word sense disambiguation compared to simulated annealing?
https://aclanthology.org/R17-1001/,"Can an approach based on named entity recognition and dependency parsing be used to identify the specific part of a reference paper being cited in a citation sentence, and what are the performance metrics for evaluating the accuracy of this approach, such as precision, recall, and F1 score? Can a machine learning model using a combination of natural language processing techniques, such as topic modeling and sentiment analysis, be used to predict the specific reason why a citation sentence has been cited, and what is the optimal feature set for this task?"
https://aclanthology.org/R17-1002/,"Does a character-based neural model with a CRF layer outperform a rule-based system in scansion of poetry in English and Spanish, measured by accuracy, and does it provide more informative representations than hand-crafted features? Can the use of whole word structure information improve the accuracy of scansion in both languages, compared to analyzing individual syllables?"
https://aclanthology.org/R17-1003/,"Can a bridging language like English improve the quality of Statistical Machine Translation from Persian to Spanish by serving as a pivot between the two languages, and does the approach of translating phrases rather than sentences lead to better results in the Persian-Spanish language pair?"
https://aclanthology.org/R17-1004/,"Can a simple approach leveraging novel, automatically identifiable features significantly improve the accuracy of stance classification models on Twitter, and how can these features be extracted efficiently? Can the use of simple stance classification models be justified without prior feature extraction, and what are the implications for the development of effective stance classification systems?"
https://aclanthology.org/R17-1005/,Can GATE DictLemmatizer outperform TreeTagger in lemmatization accuracy for languages supported by the Helsinki Finite-State Transducer Technology (HFST)?
https://aclanthology.org/R17-1005/,Does the inclusion of HFST support in GATE DictLemmatizer improve lemmatization performance for languages without HFST support?
https://aclanthology.org/R17-1006/,Can a machine learning model trained on the Arabic tweets dependency treebank (ATDT) to the Universal Dependency (UD) scheme be able to achieve high accuracy in detecting linguistic universals across languages?
https://aclanthology.org/R17-1006/,Can the mapping of ATDT to UD scheme enable the development of a cross-lingual dependency parsing model that can effectively compare and contrast linguistic structures across different languages?
https://aclanthology.org/R17-1007/,Can a word embedding-based approach using Continuous Bag of Words and Skip-gram be effective in building a machine translation model for translating the Egyptian dialect (EGY) to Modern Standard Arabic (MSA) without the need for large parallel datasets?
https://aclanthology.org/R17-1007/,Can the proposed method's performance be evaluated using a four-fold cross-validation approach on the validation datasets to assess its accuracy and generalizability to other language pairs and dialects?
https://aclanthology.org/R17-1008/,What is the most accurate method for extracting inference rules from English dictionaries to generate common sense knowledge using a dictionary like WordNet?
https://aclanthology.org/R17-1008/,How does the precision and recall of inference rules differ between the MacMillan Dictionary and WordNet definitions?
https://aclanthology.org/R17-1009/,Can a shallow approach combined with a theorem prover for handling multi-step inference tasks using dependency trees and syllogistic rules outperform a traditional shallow approach in terms of accuracy for multi-step inference tasks?
https://aclanthology.org/R17-1009/,"Can the use of continuation programming improve the efficiency of combining non-deterministic algorithms in a natural language inference engine, as demonstrated by the achievement of 92.8% accuracy for single-premise cases?"
https://aclanthology.org/R17-1010/,"Can ensemble methods improve the performance of individual classifiers in spotting false translations in translation memories and parallel web corpora, and do these methods perform differently on the two data types?"
https://aclanthology.org/R17-1010/,"Do Majority Voting, Bagging, Stacking and Ada Boost ensemble techniques achieve better accuracy, processing time or user satisfaction than individual classifiers for spotting false translation units in translation memories and parallel web corpora?"
https://aclanthology.org/R17-1011/,What are the effects of training a multilanguage keyphrase extraction pipeline on a machine learning model trained on a well-known English language corpus versus a language-specific corpus on its performance on Arabic and non-English languages?
https://aclanthology.org/R17-1011/,Can supervised keyphrase extraction pipelines trained on a machine learning model trained on a well-known English language corpus outperform unsupervised keyphrase extraction pipelines on languages which lack a gold standard?
https://aclanthology.org/R17-1012/,"Can a combination of multi-lingual SMT models trained on pooled data of MSA and dialectal Arabic improve translation accuracy for both forms of Arabic, or does the bias towards MSA data still affect the outcome?"
https://aclanthology.org/R17-1012/,"Does the use of an Arabic form classifier improve the performance of a multi-lingual SMT system, or does it only mask the underlying bias towards MSA data?"
https://aclanthology.org/R17-1013/,"Can the use of sub-sentential levels for paraphrasing improve the efficiency of machine translation compared to traditional sentential level methods, measured by processing time and accuracy? Can the application of sub-sentential levels for paraphrasing enable more effective understanding of human language, as indicated by user satisfaction and comprehension metrics?"
https://aclanthology.org/R17-1014/,"Can machine learning algorithms be used to improve the inter-annotator agreement in multi-class, multi-label sentiment annotation of messages by analyzing the correlations between annotators' ratings and identifying inconsistent labels? Can the use of active learning techniques in sentiment annotation reduce the number of labels that need to be annotated by human annotators and increase inter-annotator agreement?"
https://aclanthology.org/R17-1015/,Can the proposed optimized tree-computation algorithm improve the accuracy of part-of-speech tagging tasks compared to the original ID3 algorithm?
https://aclanthology.org/R17-1015/,Does the use of results caching in the proposed algorithm significantly reduce the processing time of the morphological-attribute resolution task?
https://aclanthology.org/R17-1016/,Can the proposed evolutionary algorithm improve the summarization accuracy of existing methods that use integer linear programming for sentence extraction?
https://aclanthology.org/R17-1016/,Does the approach of treating a summary as a whole text improve the efficiency of the evaluation metric used for unsupervised summarization evaluation?
https://aclanthology.org/R17-1017/,"Can chat-bots trained using question answering data from Web forums outperform traditional dialog data in terms of accuracy on a given task, and how does the choice of evaluation metric impact the performance of the chat-bots?"
https://aclanthology.org/R17-1017/,Can a model trained using a new model selection strategy based on QA measures achieve better performance on extrinsic evaluation compared to traditional methods in chat-bot systems?
https://aclanthology.org/R17-1018/,"Can a machine learning approach using context-aware frequent pattern mining be used to improve the accuracy of extracting medical terminology from informal texts, and what is the effect of using a small terminological lexicon on the precision of extracted patterns in text mining?"
https://aclanthology.org/R17-1019/,"Can multilingual embeddings improve the performance of image–sentence ranking (ISR) tasks when compared to monolingual embeddings, and what is the effect of combining multilingual signals with other modalities on ISR evaluation metrics such as precision and recall?"
https://aclanthology.org/R17-1019/,"Can multilingual embeddings enhance the accuracy of neural machine translation (NMT) systems by improving the re-ranking of n-best lists, and what is the optimal combination of multilingual signals and NMT models for achieving the best results?"
https://aclanthology.org/R17-1020/,How does the proposed NER model perform in terms of precision when identifying therapeutic indications versus adverse reactions in the Spanish Summary of Product Characteristics?
https://aclanthology.org/R17-1020/,Can a NER model be trained to discard entities out of scope while maintaining high precision in the identification of specific roles in documents such as the Spanish Summary of Product Characteristics?
https://aclanthology.org/R17-1021/,"Can the proposed semi-automatic methodology for pre-annotating unlabelled sentences with reduced emotional categories improve the efficiency of the manual refinement process by reducing the number of conflicting annotations, and how does the inclusion of polarity and subjective information affect the overall accuracy of the pre-annotation process?"
https://aclanthology.org/R17-1022/,"Can chatbots with robust NLU be designed to handle a wide range of conversational scenarios, and if so, how can their performance be measured in terms of user satisfaction and dialogue completion rates? Can the use of underspecification in NLU affect the accuracy of chatbot responses and what are the implications for user experience in chat-based dialog systems?"
https://aclanthology.org/R17-1023/,How does the proposed application utilize machine learning algorithms to analyze the frequency and distribution of concepts in students' collaborative chats?
https://aclanthology.org/R17-1023/,Can the proposed application effectively identify intensively debated concepts based on the chat tempo and utterances' timestamps using a supervised learning approach?
https://aclanthology.org/R17-1024/,"Can machine learning algorithms be trained to accurately extract anatomical entities and findings from radiology reports written in Spanish, using a dataset annotated by human annotators?"
https://aclanthology.org/R17-1024/,"Can supervised machine learning models achieve high accuracy in extracting information from radiology reports, using a dataset that is annotated by human annotators, to evaluate the effectiveness of information extraction algorithms?"
https://aclanthology.org/R17-1025/,Can the choice of grammatical functions used in parsing models have a significant impact on parsing accuracy across different languages and treebanks?
https://aclanthology.org/R17-1025/,Can the rarity threshold used in parsing evaluation scripts affect the overall parsing accuracy of machine learning models?
https://aclanthology.org/R17-1026/,Can the proposed method improve the accuracy of discourse relation identification by leveraging parallel corpora and lexical resources to detect AltLexes beyond the scope of a closed inventory of discourse connectives?
https://aclanthology.org/R17-1026/,Can the use of parallel corpora in text simplification and lexical resources enable the discovery of AltLexes that are not yet included in the current discourse relation identification systems?
https://aclanthology.org/R17-1027/,"What stylistic changes in Solomon Marcus' writing style occurred when transitioning from a communist regime to democracy, and how do these changes affect the distribution of words and phrases in his texts? Can machine learning algorithms be used to identify the specific characteristics of writing styles in different historical periods?"
https://aclanthology.org/R17-1028/,How does the proposed system improve the accuracy of action detection from tweets in soccer games by leveraging external knowledge bases and graph theory?
https://aclanthology.org/R17-1028/,Can the proposed system's real-time visualization capabilities be scaled to handle large volumes of tweets from multiple soccer games simultaneously?
https://aclanthology.org/R17-1029/,"Is it possible to improve the accuracy of action detection in sports games by incorporating external knowledge bases into a graph-based model, and how does this approach affect the processing time of the system? Can the proposed approach effectively evaluate the quality of live sports summaries against the proposed timeline with actions?"
https://aclanthology.org/R17-1030/,"Can a supervised learning approach using named entity recognition and graph-based clustering be effective in detecting clusters of tweets describing the same events, and how does the entity context impact the accuracy of this approach?"
https://aclanthology.org/R17-1030/,"Does the use of temporal event graphs and graph-based algorithms improve the detection of clusters of tweets related to specific events, and how do the results compare to existing keyword-based approaches?"
https://aclanthology.org/R17-1031/,Can automatic tools using social networks improve the accuracy of election predictions in comparison to traditional poll models in a real-world scenario?
https://aclanthology.org/R17-1031/,Can the use of social networks and machine learning algorithms enhance the processing time and outcome of election predictions in comparison to traditional methods?
https://aclanthology.org/R17-1032/,Can a machine translation system between Spanish and Shipibo-konibo be developed using a statistical machine translation model trained on a bilingual and monolingual corpus created using existing linguistic resources and data?
https://aclanthology.org/R17-1032/,Can the addition of linguistic rules and automatic language processing functions improve the performance of the machine translation system in translating Shipibo-konibo texts from Spanish?
https://aclanthology.org/R17-1033/,"Can machine learning algorithms be applied to improve the accuracy of translating concept names and their text entries from Russian to Tatar, and how can the specificity of the Tatar lexical-semantic system be better represented in the translation process?"
https://aclanthology.org/R17-1033/,Can the use of corpus-based approaches to generate Tatar text entries for the Russian-Tatar Socio-Political Thesaurus improve its overall coverage and maintainability of the bilingual lexical resource?
https://aclanthology.org/R17-1034/,"Does the chatbot's ability to learn discourse trees for complex questions and answers improve its rhetorical agreement, measured by the percentage of questions for which the answer's style, argumentation patterns, and communication means match the question's attributes, and is it comparable to a baseline model that only checks for relevance but not rhetorical agreement? Does the extension of discourse trees with communicative action labels improve the chatbot's ability to recognize valid rhetorical agreements, as measured by the accuracy of its algorithm for finding the best DT for an answer given a question?"
https://aclanthology.org/R17-1035/,"Can the addition of contextual information improve the accuracy of hate speech detection models by 3% to 4% in F1 score compared to baseline models, and can combining the two proposed models further increase the F1 score by 7% compared to the baseline models? Does the incorporation of context features in logistic regression models lead to improved hate speech detection compared to traditional models?"
https://aclanthology.org/R17-1036/,"Can machine learning models be trained to accurately predict the most worthy claims for fact-checking in a political debate, using a contextual representation of the debate, opponent interaction, and public reaction? Can the use of contextual information improve the performance of fact-checking models in a ranking task compared to models that only consider individual sentences?"
https://aclanthology.org/R17-1037/,Can the use of hashtag segmentation improve the clustering of tweets by reducing semantic ambiguity and increasing topic coverage?
https://aclanthology.org/R17-1037/,Can segmented and harmonized hashtags enhance the accuracy of named entity recognition in tweets by reducing the impact of word-level analysis on compositional meaning?
https://aclanthology.org/R17-1038/,How can Natural Language Processing (NLP) technologies be utilized to improve the accuracy of document metadata extraction and representation for search engines?
https://aclanthology.org/R17-1038/,What are the essential NLP techniques required to create a document profile that can effectively support semantic search functionality?
https://aclanthology.org/R17-1039/,Can MappSent improve the performance of textual similarity tasks by using a bilingual word mapping technique in conjunction with linear sentence embedding representations compared to state-of-the-art methods?
https://aclanthology.org/R17-1039/,"Does MappSent's ability to map sentences to a joint-subspace improve the accuracy of textual similarity tasks, particularly in cases where RNNs and LSTMs are outperformed by weighted average sum of word embedding vectors?"
https://aclanthology.org/R17-1040/,"Does the inclusion of figurative language indicators improve the accuracy of sentiment analysis models in detecting irony, sarcasm, and metaphor, as measured by mean squared error, and does the use of convolutional neural networks with additional training data lead to better results than traditional approaches?"
https://aclanthology.org/R17-1040/,"Can the integration of figurative language indicators into sentiment analysis pipelines effectively capture the nuances of figurative language, as evaluated through cosine similarity on the SemEval-2015 Task 11 dataset?"
https://aclanthology.org/R17-1041/,"How does the performance of a Long Short Term Memory (LSTM) based model compare to the state of the art RNN approach in argument labeling tasks, and what are the implications of this difference for the application of such models to multiple textual genres and languages?"
https://aclanthology.org/R17-1041/,"Can a feature engineering approach improve the performance of LSTM-based models in argument labeling tasks, and what are the key differences between the proposed LSTM-based model and the state of the art feature-based systems?"
https://aclanthology.org/R17-1042/,Can a lexicon-based approach to word segmentation outperform a CRF-based approach in parsing Chinese text when using a highly probable word list?
https://aclanthology.org/R17-1042/,"Can a lattice parser be used to select the optimal word segmentation from thousands of options, and what is the impact on parsing performance?"
https://aclanthology.org/R17-1043/,"What are the most significant factors influencing the differences in sentiment between writers and readers of news text, and how can they be effectively addressed in sentiment analysis of news articles? Can machine learning models using transformer-based architectures be trained to accurately identify and classify news articles as positive, negative, or neutral with high inter-annotator agreement?"
https://aclanthology.org/R17-1044/,"Can neural networks with attention mechanisms effectively identify and mitigate the spread of fake news and clickbait in the Bulgarian cyberspace, measured by the accuracy of sentiment analysis and author profiling?"
https://aclanthology.org/R17-1044/,"Can the use of sentiment lexicons and lexical features in conjunction with attention mechanisms improve the detection of clickbait content in online publications, evaluated by the reduction in clickbait click-through rates?"
https://aclanthology.org/R17-1045/,"Can deep neural networks with LSTM text encoding and semantic kernels improve the accuracy of fact-checking by incorporating external sources, and how do different source reliability metrics impact the performance of the proposed framework on rumor detection and fact checking tasks?"
https://aclanthology.org/R17-1045/,"Can the proposed framework be effectively evaluated and compared with existing fact-checking methods using publicly available datasets and metrics such as accuracy, precision, and recall for rumor detection and fact checking of community question answering forums?"
https://aclanthology.org/R17-1046/,"Can an HMM-based named entity recognizer accurately extract relevant entities from machine-generated travel itinerary emails, improving user journey tracking and time management, as measured by the F1-score of extracted entities? Can the proposed set of domain-specific features enhance the performance of the NER model in extracting relevant information from travel itineraries, as evaluated by the precision and recall of extracted entities?"
https://aclanthology.org/R17-1047/,"Can a supervised approach using graph-based representation and Logistic Model Tree for recognizing CST relations achieve higher accuracy than traditional methods in recognizing CST relations in Polish texts, measured by the accuracy of correctly classified CST relations? Can the use of different graph similarity methods and configurations improve the performance of the CST relation recognition task, as evaluated by the similarity between sentences and the classifier's accuracy?"
https://aclanthology.org/R17-1048/,"Can domain control improve the performance of neural machine translation models when translating out-of-domain text, and what is the average improvement in accuracy when using this technique compared to traditional domain adaptation methods?"
https://aclanthology.org/R17-1048/,"Can domain control reduce the need for re-estimation of model parameters for each domain, and what is the average processing time saved when using this technique compared to traditional domain adaptation methods?"
https://aclanthology.org/R17-1049/,"Can the use of sentence pairing orderings that prioritize homogeneity in minibatches improve the accuracy of neural machine translation models in Czech? Can incorporating curriculum learning, where sentence types are gradually introduced during training, yield better results in NMT compared to the baseline method?"
https://aclanthology.org/R17-1050/,Is the proposed Cascade of Partial Rules method effective in improving the accuracy of temporal expression normalisation for Polish temporal expressions compared to the updated Liner2 machine learning system? Does the use of Cascade of Partial Rules lead to a significant reduction in processing time for temporal expression normalisation tasks?
https://aclanthology.org/R17-1051/,Can WoRel's jointly learned word embeddings and semantic representation of word relations improve the performance of word similarity and syntactical word analogy tasks compared to existing word embedding models such as Skip-Gram and GloVe?
https://aclanthology.org/R17-1051/,Can the use of semantic representation of word relations in WoRel enable more accurate expression of phrase meaning and improve semantics at the sentence level?
https://aclanthology.org/R17-1052/,Can a machine learning model achieve a Spearman correlation coefficient of 0.9 or higher on the proposed dataset for semantic similarity and semantic relatedness using only supervised learning methods?
https://aclanthology.org/R17-1052/,Can a deep learning model trained on the proposed dataset for semantic similarity and semantic relatedness be able to distinguish between words with high semantic relatedness and words with low semantic relatedness with an accuracy of 90% or higher?
https://aclanthology.org/R17-1053/,Can a statistical word-alignment model be used to identify unsupported discourse annotations in discourse annotation projection from one language to another and how effective is it in improving the accuracy of discourse annotation classification in the target language? Can the use of a filtered corpus for training a classifier improve the F1-score of discourse annotation classification in the target language compared to using non-filtered annotations?
https://aclanthology.org/R17-1054/,What is the effectiveness of combining rule-based approaches with deep learning techniques in extracting lexical-semantic relations from texts?
https://aclanthology.org/R17-1054/,Can a hybrid approach that leverages both symbolic and connectionist AI methods improve the accuracy of semantic relation extraction from unstructured text data?
https://aclanthology.org/R17-1055/,"Can an automatic algorithm be developed to detect potential secondary errors in a data set with high accuracy, measured by the number of false positives and false negatives, and how would this impact the overall quality of the JeuxDeMots network?"
https://aclanthology.org/R17-1055/,"Can crowdsourcing methods be designed to automatically detect initial errors in a data set with high precision, measured by the percentage of correctly identified errors, and what would be the optimal parameters for this method?"
https://aclanthology.org/R17-1056/,"Does the use of trainable word embeddings outperform static word embeddings in the classification of longer texts in the multi-label scenario, and what are the implications for the design of convolutional neural networks? Can the initialization of word vectors affect the performance of convolutional neural networks in the multi-label classification of longer texts?"
https://aclanthology.org/R17-1057/,Can character and word n-grams improve the accuracy of gender prediction models for Weibo users compared to traditional methods using word embeddings?
https://aclanthology.org/R17-1057/,Can the use of character and word embeddings on a per-post basis enhance the classification of Weibo users' gender with improved results compared to the traditional approach?
https://aclanthology.org/R17-1058/,Can the proposed model outperform state-of-the-art models on the standard datasets with simple features by utilizing a forest-to-tree algorithm for sentence-to-lambda-logical expression conversion?
https://aclanthology.org/R17-1058/,Can the proposed model's performance on standard datasets be improved by transforming lambda-logical expression structure into a form suitable for statistical machine translation mechanics?
https://aclanthology.org/R17-1059/,Can a word graph-based approach effectively identify keyphrases in multilingual microblog text streams to generate accurate summaries?
https://aclanthology.org/R17-1059/,Can the proposed method outperform existing summary generation techniques in terms of precision and overall summary quality?
https://aclanthology.org/R17-1060/,Can a phrase be considered conventionalized if its component words have high frequency of association with each other among native speakers?
https://aclanthology.org/R17-1060/,What is the relationship between the entropy of phrase associations and the intersection of component word and phrase associations in determining conventionalized phrases?
https://aclanthology.org/R17-1061/,"Can a supervised classification model using character n-grams, word n-grams, and word skip-grams achieve high accuracy in distinguishing hate speech from profanity on social media?"
https://aclanthology.org/R17-1061/,Can a classification system be designed to differentiate between hate speech and profanity with higher accuracy than 78% on a dataset annotated for this purpose?
https://aclanthology.org/R17-1062/,"Can Inforex's new graphical interface improve the usability of the system for non-expert users in the humanities and social sciences fields, and how does it affect the annotation quality of collaborative text corpora?"
https://aclanthology.org/R17-1062/,Can the implementation of private annotations and annotation agreement by a super-annotator in Inforex increase the reliability of gold standard annotations in the CLARIN infrastructure?
https://aclanthology.org/R17-1063/,"Can the use of a machine learning approach improve the accuracy of the lemmatization tool for multi-word common noun phrases and named entities in Polish, and how does it compare to the current rule-based approach?"
https://aclanthology.org/R17-1063/,"Can the inclusion of a larger and more comprehensive dictionary improve the accuracy of the lemmatization tool for named entities in Polish, and what are the potential limitations of using such an approach?"
https://aclanthology.org/R17-1064/,Can a hybrid approach combining bilingual and monolingual corpus optimization improve the morphological segmentation accuracy of Uyghur spoken translation models beyond that of traditional CRF feature-based methods?
https://aclanthology.org/R17-1064/,Does the incorporation of monolingual suffixword co-occurrence feature enhance the BLEU score of Uyghur spoken translation models compared to the baseline model relying solely on bilingual and monolingual corpus optimization?
https://aclanthology.org/R17-1065/,Can an existing machine learning model trained on the Romanian language be effectively adapted for biomedical domain Named Entity Recognition by utilizing the newly developed Romanian sub-corpus for medical-domain NER?
https://aclanthology.org/R17-1065/,Can the proposed Romanian sub-corpus for medical-domain NER improve the performance of automatic NER tools in the biomedical domain by providing a more comprehensive and accurate representation of medical terminology?
https://aclanthology.org/R17-1066/,"What is the impact of using local entity information and profiles as a feature set on the performance of a Named Entity Classification system, measured by overall F1 score?"
https://aclanthology.org/R17-1066/,"How does the performance of a language and domain independent Named Entity Classification system compare to one that requires external knowledge or complex linguistic analysis, as demonstrated by the difference in overall F1 scores between two datasets?"
https://aclanthology.org/R17-1067/,"What are the effects of using different similarity metrics on the performance of genre-based POS tagging and dependency parsing, and can they achieve comparable accuracy to joint topic modeling approaches?"
https://aclanthology.org/R17-1067/,"How do topic modeling-based methods for genre assignment impact the performance of POS tagging and dependency parsing on heterogeneous datasets, and what are the benefits of using genre experts in these tasks?"
https://aclanthology.org/R17-1068/,"Can a supervised learning model be trained to detect reputation defence strategies in parliamentary questions and answers with high accuracy, and what is the optimal feature set for this task?"
https://aclanthology.org/R17-1068/,Can the proposed model be generalized to handle unlabelled datasets and evaluate its performance using metrics such as F1 score and precision?
https://aclanthology.org/R17-1069/,"Can deep neural networks with distributional representations improve the accuracy of frame classification at the sentence level compared to document-level approaches, and how does the choice of LSTM or GRU architecture affect the results? Can a more advanced neural network architecture improve the performance of frame classification at the sentence level compared to the current state-of-the-art results of at least 14-point improvement?"
https://aclanthology.org/R17-1070/,"Does the use of a subset of the development set, selected based on sentence length, alleviate the learning problem in pairwise ranking optimization (PRO) for Statistical Machine Translation (SMT)?"
https://aclanthology.org/R17-1070/,"Can the incorporation of a more diverse subset of sentence pairs, tailored to specific combinations of optimizers, objective functions, and evaluation measures, improve the robustness of hyper-parameters in SMT systems?"
https://aclanthology.org/R17-1071/,"Can a machine learning model utilizing a supervised learning approach with a ranking SVM to predict the credibility of answers posted in community forums be improved by incorporating additional features that model the similarity between the question and the answer, and the interaction between the user and the thread? Can the performance of a credibility model trained on a large annotated corpus of crowdsourced data be significantly improved by incorporating features that model the user's profile, particularly trollness, and leveraging the power of deep learning techniques such as transformers?"
https://aclanthology.org/R17-1072/,"Can the proposed hybrid machine translation system achieve higher accuracy in translating Bulgarian to English compared to the Moses system alone, while maintaining its linguistic annotation benefits in the post-processing step? Can the hybrid system's ability to incorporate transferred linguistic annotation improve its performance on translating imperative and interrogative sentences in the Bulgarian language?"
https://aclanthology.org/R17-1073/,"Can phrase level linguistic patterns be used to identify character adjectives in Indian mythological texts with high accuracy using machine learning algorithms, and how do novel features such as multi-word expressions and parse tree nodes contribute to this task?"
https://aclanthology.org/R17-1073/,"Can the use of deep learning models, particularly those based on neural networks, improve the classification of character adjectives in Mahabharata texts by leveraging the extracted features and linguistic patterns?"
https://aclanthology.org/R17-1074/,"Can neural networks be used to improve the accuracy of gender identification in social networks by fusing text, image, and location data, and how does this approach compare to traditional author profiling methods? Does the use of multimodal data improve the performance of gender identification in social networks?"
https://aclanthology.org/R17-1075/,"Can the proposed method of creating class-related sense dictionaries significantly improve the accuracy of distinguishing genuine Polish suicide notes from counterfeited ones? Can the algorithm be further optimized by incorporating additional features or techniques, such as using machine learning models or natural language processing techniques to enhance the performance of SNs classification?"
https://aclanthology.org/R17-1076/,Can the use of Universal Dependencies for cross-lingual Semantic Role Labeling improve the accuracy of SRL systems compared to traditional methods?
https://aclanthology.org/R17-1076/,Can the conversion of monolingual SRL annotations into Universal Dependencies using the proposed methods lead to more reliable and consistent labeling of semantic roles in cross-lingual texts?
https://aclanthology.org/R17-1077/,Can a gaze-based model using both native and non-native gaze data outperform a model relying solely on frequency data in identifying multiword expressions in English?
https://aclanthology.org/R17-1077/,"Can late processing measures using gaze data improve the accuracy of multiword expression identification compared to early processing measures, and do native and non-native gaze data contribute equally to this improvement?"
https://aclanthology.org/R17-1078/,"Does the proposed approach to real-time summarization of news events reduce redundant information effectively, and what is the evaluation metric used to measure this effectiveness?"
https://aclanthology.org/R17-1078/,"Can the proposed approach be adapted to other real-world datasets without requiring significant modifications, and what are the expected benefits of such adaptation?"
https://aclanthology.org/R17-1079/,"Is it possible to develop a machine learning model that can accurately capture the semantic divergence between different expressions of the same sentence across different audiences, modalities, and syntactic variations, and evaluate its performance using a metric such as semantic similarity or coherence score? Can a natural language processing system effectively summarize a large corpus of semantic divergent sentences, such as those from 200 English tweets, without losing the essential meaning and nuance of the original text?"
https://aclanthology.org/R17-1080/,"Can morphological analysis be used to improve the prediction of sentiment polarity for complex German words, and what is the impact of different morphological features on sentiment polarity classification accuracy? Can the use of morphological parses and polarity annotations in supervised classification experiments significantly improve the performance of sentiment analysis models for German words?"
https://aclanthology.org/R17-1081/,"Can EVALD 1.0 effectively assess the coherence of texts written by non-native Czech speakers using the six-step scale of the CEFR, and can it be improved to better align with the European language learning standards? Can the EVALD 1.0 application for native Czech speakers achieve a high accuracy in evaluating texts on a five-step scale commonly used in Czech schools?"
https://aclanthology.org/R17-1082/,"Does a lexical fixedness metric improve the performance of idiom type identification tasks, and how can a machine learning approach be designed to effectively utilize such a metric? Can a machine learning model achieve a high F1-score in idiom type identification using a lexical fixedness metric?"
https://aclanthology.org/R17-1083/,"Can a calibration technique based on precision vs recall curves be applied to optimize the performance of a continuous sentiment analyzer when mapping onto a discrete sentiment classification dataset, and what are the potential benefits of using such a technique in sentiment analysis?"
https://aclanthology.org/R17-1083/,"Can the proposed calibration method be generalized to accommodate different types of sentiment analysis tasks, such as sentiment intensity or sentiment polarity classification?"
https://aclanthology.org/R17-1084/,Can the integration of domain-specific bilingual lexicons of Multiword Expressions improve the translation quality of Example-Based Machine Translation systems for in-domain and out-of-domain texts? Does the use of domain-specific bilingual lexicons of MWEs lead to a significant deterioration in translation quality when translating general-purpose texts?
https://aclanthology.org/R17-1085/,"Can machine learning algorithms accurately classify the national variety of English used by authors on social media platforms with high precision and accuracy, and what are the most effective features that contribute to this classification task?"
https://aclanthology.org/R17-1085/,"How do different feature types, including formal linguistic features, POS features, lexicon-based features, and data-based features, impact the classification performance of machine learning models in identifying authors' national variety of English in social media texts?"
https://aclanthology.org/R17-1086/,Can the use of Lexical Chain based templates over Knowledge Graphs improve the performance of word embeddings on the WordSim353 Similarity and WordSim353 Relatedness test sets?
https://aclanthology.org/R17-1086/,Does the incorporation of many-relation lexical chains have a significant impact on the processing time of word embeddings compared to unrestricted-length chains?
https://aclanthology.org/R17-1087/,"Can distributed representations derived from word embeddings improve the performance of a supervised coreference resolution system in terms of accuracy, and do they offer a cost-effective alternative to using labeled training data? Do word embeddings-based features, such as embedding clusters and cosine similarity, provide a robust representation of entity compatibility that can be leveraged for effective coreference resolution?"
https://aclanthology.org/R17-1088/,"Can Flames Detector accurately measure the sentiment of news commentaries across languages and identify the most flaming topics in real-time, and does the system's aggregated score effectively capture the intensity of online discussions? Can Flames Detector's machine learning approach be improved to increase the precision of flame detection in discussions and reduce false positives for verbal offences?"
https://aclanthology.org/R17-1089/,"How does the proposed metric compare to ROUGE metrics in terms of accuracy in measuring content coverage of automatic summaries, and what specific aspects of the abstract meaning representation do they capture?"
https://aclanthology.org/R17-1090/,Can we design a more efficient algorithm to improve the precision of sentiment analysis for named entities in large volumes of news articles while maintaining a reasonable recall?
https://aclanthology.org/R17-1090/,Can the application of a syntactic parser to identify specific predictive structures in opinion recognition improve the recall of sentiment analysis for named entities in English language news articles?
https://aclanthology.org/R17-1091/,"Can a Support Vector Machine classifier trained on lexical features be used to predict the law area of a case with a high level of accuracy, and can the addition of time period information improve the prediction of the case's textual form? Can the use of masking the judge's motivation in a case description affect the performance of a linear SVM classifier in predicting the time span of a ruling?"
https://aclanthology.org/R17-1092/,"How does the proposed graph-based probabilistic model of morphology perform in reducing the number of rules required to explain the data, and what are the implications for the task of finding pairs of morphologically similar words?"
https://aclanthology.org/R17-1092/,"Can the proposed model outperform a state-of-the-art segmentation-based approach in generating new words, and what are the potential limitations of using the Metropolis-Hastings algorithm in this context?"
https://aclanthology.org/R17-1093/,"Can word embeddings with sentiment lexicon-based techniques be used to improve the accuracy of sentiment analysis for tweets that contain multiple entities, by assigning a total score to indicate the polarity of opinion towards each entity? Can the proposed approach be applied to extract sentiment towards multiple entities simultaneously, and what is the impact on the overall sentiment classification accuracy?"
https://aclanthology.org/R17-1094/,Can automatically induced word senses be used to identify subtle changes in word meanings and how can this method be evaluated to assess its accuracy in detecting such changes?
https://aclanthology.org/R17-1094/,"How can the use of polysemy-based grouping improve the detection of novel and homonymic senses, and what is the estimated time required to identify these changes?"
https://aclanthology.org/R17-1095/,Can the proposed system handle the extraction of event types from a large volume of text data with varying levels of noise and inconsistencies in a distributed Flink environment?
https://aclanthology.org/R17-1095/,Can the system accurately geo-locate and extract mobility- and industry-related events from heterogeneous text sources with high throughput and low latency?
https://aclanthology.org/R17-1096/,What are the specific features of eye-tracking data that can be used to improve the accuracy of named entity recognition systems in natural language processing tasks?
https://aclanthology.org/R17-1096/,How do human annotators' fixation patterns and working time compare to those of current state-of-the-art automatic named entity recognition systems in terms of identifying and categorizing named entities in text?
https://aclanthology.org/R17-1097/,"Does the use of named-entities extracted from texts in the construction of n-gram graphs improve the performance of text similarity measures, and how does it affect the time-performance of clustering algorithms?"
https://aclanthology.org/R17-1097/,Can the extraction of named entities at the first step be a profitable approach for text similarity measures that rely on n-gram graphs without compromising the overall performance of the NLP task?
https://aclanthology.org/R17-1098/,"How can word embeddings be effectively used in conjunction with neural networks to improve the accuracy of metaphor detection in noun phrases with literal and metaphorical sense, and what is the optimal architecture for this task?"
https://aclanthology.org/R17-1098/,"Can a hybrid approach combining rule-based analysis with deep learning techniques improve the performance of metaphor detection in the Polish language, particularly in identifying context-dependent expressions?"
https://aclanthology.org/R17-1099/,Can the proposed rule-based system improve the accuracy of Gleason score extraction to 0.95 or higher by incorporating machine learning techniques for handling ambiguous or uncertain cases?
https://aclanthology.org/R17-1099/,Can the system reduce the time required for manual encoding of pathology reports by 50% through automated extraction of predefined fields with an F-score of 0.90 or higher?
https://aclanthology.org/R17-1100/,"Can we design a neural network architecture that leverages LSTM structures to learn deep representations of sentence patterns in named entity recognition, and evaluate its performance using accuracy metrics?"
https://aclanthology.org/R17-1100/,"Can we improve the NER accuracy of a baseline model by utilizing CNN structures for sentence-level pattern learning, and measure the improvement using a precision metric?"
https://aclanthology.org/R17-1101/,Can the proposed data collection method using social network analysis be effectively scaled up to handle large numbers of online reviews across multiple domains?
https://aclanthology.org/R17-1101/,Can the addition of diverse deceptive reviews to the dataset improve the performance of online deception detection models using generalized features such as advertising speak and writing complexity scores?
https://aclanthology.org/R17-1102/,"Can a weakly supervised approach to learning contextual temporal relation classifiers be used to identify regular event pairs and detect after and before temporal relations with comparable performance to supervised systems, and what evaluation metrics can be used to assess the quality of the acquired regular event pairs? Can contextual temporal relation classifiers trained on regular event pairs with rich commonsense and domain-specific knowledge be used to recognize new temporal relation contexts and identify new regular event pairs with high accuracy?"
https://aclanthology.org/R17-1103/,"Can multilingual and cross-lingual Complex Word Identification (CWI) models trained on a single language achieve comparable performance to monolingual models when applied to other languages, and what are the language-independent features required to improve cross-lingual CWI performance?"
https://aclanthology.org/R17-1103/,"Can the use of multilingual and cross-lingual CWI models trained on one language improve the performance of CWI for languages other than the training language, and what is the impact of native vs non-native annotators on CWI model performance?"
https://aclanthology.org/R17-1104/,"Can an approach that automatically generates a situation model from textual instructions effectively reduce the complexity of planning problems by identifying and representing hierarchical, spatial, directional, and causal relations in a PDDL notation?"
https://aclanthology.org/R17-1104/,"Does the integration of a situation model in planning problems lead to a decrease in the number of operators and branching factor, as indicated by a reduction in planning complexity metrics?"
https://aclanthology.org/R17-1105/,What is the impact of using a rule-based model to correct incorrectly annotated verbs in state-of-the-art parsers on the accuracy of behaviour understanding systems for imperative sentences?
https://aclanthology.org/R17-1105/,Can a simple rule-based model improve the performance of a parser that annotates textual instructions with high accuracy without requiring additional training data?
https://aclanthology.org/R17-1106/,"Can SMILLE effectively increase the intake of grammatical information by drawing user attention to grammar in online documents, as measured by the user's ability to identify and correct grammatical errors? Does the use of input enhancements in SMILLE lead to a higher intake of metalinguistic information compared to a system without such enhancements?"
https://aclanthology.org/R17-2000/,"Can the proposed method accurately detect dietary conflicts by analyzing the semantic associations in dish titles, and what metrics would be most effective to evaluate its performance?"
https://aclanthology.org/R17-2000/,"Can the integration of a common knowledge lexical semantic network improve the processing of domain-specific texts in dish titles, and how would it impact the detection of dietary conflicts?"
https://aclanthology.org/R17-2001/,"What is the potential of sentiment analysis in predicting and mitigating future economic crises, considering the impact of market sentiments on global trade and finance?"
https://aclanthology.org/R17-2001/,How can the integration of diverse data sources and sentiment analysis techniques improve the accuracy of market sentiment analysis and its application in financial risk assessment?
https://aclanthology.org/R17-2002/,"Can a supervised learning approach using Grice's Maxims as a set of constraints improve the accuracy of conversational dialog systems in terms of turn-taking and relevance, as measured by a human evaluation metric of conversational coherence? Can the use of Grice's Maxims as a basis for human evaluation of conversational dialog systems be scaled up to accommodate the vast number of possible conversational scenarios and dialogue flows, and if so, what metrics would be most suitable for this purpose?"
https://aclanthology.org/R17-2003/,"Does the proposed neural network architecture using LSTM cells improve word sense disambiguation accuracy compared to existing supervised systems, and can it be further optimized by incorporating different types of word embeddings as input features?"
https://aclanthology.org/R17-2003/,Can the use of distributed word representations as features in the proposed architecture be combined with artificial corpora generated from knowledge bases to improve the performance of word sense disambiguation systems?
https://aclanthology.org/R17-2004/,Can a paragraph vector-based summarization method for Persian text improve the ROUGE score by 10% compared to existing methods?
https://aclanthology.org/R17-2004/,Does the use of paragraph vectors reduce the number of paragraphs in a summary by 20% compared to traditional summarization techniques?
https://aclanthology.org/R17-2005/,"Can a supervised learning approach using Naïve Bayes Classifier effectively classify sentences into sentiment categories, and how does this approach compare to a lexicon-based approach in terms of accuracy in determining sentiment and arousal values?"
https://aclanthology.org/R17-2005/,"Can the combination of machine learning and lexicon-based techniques improve the accuracy of arousal level detection in sentences, and what are the key factors that affect the performance of the proposed approach in this regard?"
https://aclanthology.org/R17-2006/,Can a deep neural network combined with word2vec and NLP techniques be used to accurately cluster words with relations in legal text to extract relevant civil law articles for bar exams in Japanese Legal Bar exam queries?
https://aclanthology.org/R17-2006/,Can the proposed methodology improve the accuracy of civil law article retrieval in bar exams by leveraging the relationship between words and their context in Japanese Legal Bar exam queries?
https://aclanthology.org/R19-1000/,"Can the proposed deep learning-based method for table structure recognition in PDF documents achieve higher accuracy by incorporating more feature sets, and how does the bottom-up approach compare to traditional machine learning-based top-down approaches in terms of accuracy and F1-score?"
https://aclanthology.org/R19-1000/,Does the proposed methodology using Multilayer Feedforward Neural Network for table structure recognition outperform conventional approaches based on heuristics and machine learning-based top-down approaches in recognizing table cells?
https://aclanthology.org/R19-1001/,"Can machine learning models using natural language processing techniques be developed to accurately filter out bad news from Twitter based on their impact on mental health, and what features would be most effective in distinguishing between good and bad news? Can machine learning models using natural language processing techniques be trained to recognize and distinguish between tweets with positive and negative sentiments and their actual content?"
https://aclanthology.org/R19-1002/,"Can the proposed round-trip training approach improve the quality of bilingual NMT models in low-resource scenarios by leveraging monolingual datasets, and how does it compare to existing baselines in terms of translation accuracy?"
https://aclanthology.org/R19-1002/,"Does the use of monolingual datasets in the proposed round-trip training approach affect the computational resources required for training bilingual NMT models, and what is the trade-off between model performance and training time?"
https://aclanthology.org/R19-1003/,"Can LSTM-based phrase table scoring improve the accuracy of Machine Translation systems by reducing the impact of low-quality phrase pairs in the Phrase-Based Statistical Machine Translation framework, and how does the use of LSTM-based scoring compare to traditional log-linear models in terms of BLEU score improvement? Can the application of LSTM-based phrase table scoring be extended to other NLP tasks, such as Sentiment Analysis or Text Classification, to improve model performance and robustness?"
https://aclanthology.org/R19-1004/,"Can the proposed method improve the accuracy of SRL models in Turkish by leveraging parallel data from the translated English PropBank dataset, as measured by the F1 score of the Turkish PropBank dataset?"
https://aclanthology.org/R19-1004/,"Can the use of parallel data from the translated English PropBank improve the coverage of predicate-argument structures in Turkish SRL models, as measured by the percentage of annotated sentences with complete predicate-argument structures?"
https://aclanthology.org/R19-1005/,"What are the methods used to identify biased sentences in Wikipedia revisions, and how do they assess the level of noise in the extracted data?"
https://aclanthology.org/R19-1005/,"Can well-known machine learning models be used to classify biased sentences in multilingual corpora with varying levels of noise, and what are the implications for the development of a comprehensive model for detecting biased language?"
https://aclanthology.org/R19-1006/,"Can a larger training dataset improve the accuracy of morphological segmentation models for Persian language, as evaluated by the F1-score metric, and how do the performance differences between the models vary across different hyperparameter settings?"
https://aclanthology.org/R19-1006/,"Does the use of a hand-annotated lexicon significantly impact the performance of RNN-based models in morphological segmentation, particularly for the Persian language, compared to pre-trained models without such annotations?"
https://aclanthology.org/R19-1007/,Can the proposed method improve the accuracy of Word Sense Induction by leveraging contextual information from both the left and right context of an ambiguous word? Does the combination of left and right context and similarity to the ambiguous word yield more accurate substitutes than the original approach on WSI datasets for two languages?
https://aclanthology.org/R19-1008/,"Can a deep learning model trained with a synthetic dataset achieve high accuracy in detecting and correcting ""de/da"" clitic errors in Turkish text, and how do different word embedding configurations impact its performance?"
https://aclanthology.org/R19-1008/,"Can the proposed model outperform existing spelling correctors, such as Google Docs, in detecting and correcting challenging ""de/da"" clitic errors in Turkish text?"
https://aclanthology.org/R19-1009/,"Can the proposed dataset be used to develop a machine learning model that can accurately classify news articles as containing manipulative techniques or not, with an accuracy of at least 90% and a processing time of less than 5 minutes?"
https://aclanthology.org/R19-1009/,"Can the bag-of-words classification algorithms be improved upon by incorporating natural language processing techniques, such as named entity recognition or part-of-speech tagging, to increase the accuracy of the classification results by at least 15%?"
https://aclanthology.org/R19-1010/,"Can a supervised learning approach using a transformer-based architecture be used to analyze the changes in named entity relations over time in Wikipedia page revisions, and how does the accuracy of this approach compare to traditional methods? Can the proposed resource be used to study the impact of societal and cultural trends on changes in word meanings and their relations to entities over time?"
https://aclanthology.org/R19-1011/,Can an ontology model built using this approach improve the accuracy of lexical semantic knowledge mining from a multilingual lexical semantic resource by leveraging structured semantic relationships?
https://aclanthology.org/R19-1011/,Can the proposed approach reduce the time complexity of ontology building and enhancement by utilizing structured lexical semantic knowledge in a more efficient manner?
https://aclanthology.org/R19-1012/,"Can the use of sentence length regularization improve the translation quality of neural machine translation models in low-resource languages, and by how much?"
https://aclanthology.org/R19-1012/,"Can the application of word frequency regularization improve the translation quality of neural machine translation models in low-resource languages, and what is the average increase in BLEU score that can be achieved?"
https://aclanthology.org/R19-1013/,Can the Combinatory Categorial Grammar approach to semantic parsing achieve comparable performance to state-of-the-art methods using Expectation Maximization algorithm for filtering a compact CCG lexicon in the domain of natural language processing?
https://aclanthology.org/R19-1013/,Does the use of graph algebra in defining semantic construction operators in CCG enable more efficient and accurate lexical template induction compared to traditional methods of lexicon construction?
https://aclanthology.org/R19-1014/,"What are the implications of using a co-attentive layer in a Transformer-based architecture for contextualized embeddings in Word Sense Disambiguation tasks, and how does this approach compare to existing state-of-the-art models in terms of accuracy and performance? Can the proposed QBERT model be adapted for other NLP tasks that benefit from deeply bidirectional representations?"
https://aclanthology.org/R19-1015/,Can a pre-trained semantic model trained on a homogeneous dataset of philosophical texts be able to learn consistent embeddings in a background space that generalize to in-domain texts?
https://aclanthology.org/R19-1015/,Can the proposed consistency measure effectively evaluate the performance of a semantic model when no in-domain gold-standard data is available?
https://aclanthology.org/R19-1016/,"Can the use of transfer learning and warm-starting techniques improve the performance of goal-oriented chatbots in customer support, as demonstrated by a relative success rate improvement of more than 5% in majority of cases, and convergence speed of up to 10x faster than training from scratch?"
https://aclanthology.org/R19-1016/,"Does the application of transfer learning to goal-oriented chatbots in customer support result in improved performance in terms of accuracy and convergence speed, and what are the optimal transfer learning methods and warm-starting techniques that can be used to achieve these improvements?"
https://aclanthology.org/R19-1017/,"What is the potential of sentence embeddings learned through self-supervision in improving text coherence tasks and providing deeper insights into the data, and how do they compare to existing approaches in terms of performance and applicability? Can the use of these embeddings facilitate better understanding of the data through simple visual heuristics and improve writing quality and document structuring for writers and readers?"
https://aclanthology.org/R19-1018/,"Can the use of Linked Open Data in clinical text analysis improve the accuracy of disease risk factor prediction models, and what are the specific LOD resources that yield the best results? Can the integration of clinical text and LOD lead to a more comprehensive understanding of patient risk factors for specific diseases?"
https://aclanthology.org/R19-1019/,"Can a supervised learning approach using a deep neural network architecture be used to automatically detect and align parallel sentences with register variation in biomedical texts with high accuracy, measured by inter-annotator agreement? Can the proposed method be applied to generate a large corpus of parallel sentences with high precision, evaluated by the number of correctly aligned pairs?"
https://aclanthology.org/R19-1020/,"Can a supervised classifier trained on a corpus of Related Work sections with novel features related to citation types and co-reference improve the accuracy of identifying the relevance and quality of academic writing, as measured by the syntactic correctness of the paper?"
https://aclanthology.org/R19-1020/,"Can a machine learning model that considers patterns found in Related Works be able to distinguish between high-quality and low-quality academic papers in the Related Work section, as evaluated by the processing time of the classifier?"
https://aclanthology.org/R19-1021/,"How do the sparse vectorizers compare to neural word embeddings in terms of classification metrics like precision, recall, and accuracy across different dataset sizes?"
https://aclanthology.org/R19-1021/,Can the use of character embeddings like ELMo and Flair improve the performance of text vectorization on imbalanced datasets compared to traditional sparse vectorizers?
https://aclanthology.org/R19-1022/,"What are the effectiveness and limitations of using machine learning algorithms in annotating dialectal Arabic tweets with high accuracy, given the large volume of data and varying dialects and age groups?"
https://aclanthology.org/R19-1022/,Can the incorporation of inter-annotator agreement measures and quality control processes improve the annotation quality of the ARAP-Tweet 2.0 corpus in terms of syntactic correctness and user satisfaction?
https://aclanthology.org/R19-1023/,"Does the use of Big Five personality information improve the accuracy of abstractive text summaries generated by neural sequence-to-sequence models, and if so, what specific aspects of the personality traits contribute to these improvements?"
https://aclanthology.org/R19-1023/,Can neural sequence-to-sequence models leveraging Big Five personality information outperform non-personalized models in terms of human-like text summary quality and syntactic correctness?
https://aclanthology.org/R19-1024/,"Can the proposed method effectively improve the performance of a classifier when adapting to a new domain with limited labelled data, measured by accuracy, and compared to self-training and tri-training methods? Can the use of projection and self-training in the proposed method enhance the generalization ability of the classifier to unseen target domain data, and evaluated by the F1-score of the target class?"
https://aclanthology.org/2020.wmt-1.0/,Can the proposed machine translation systems for the news task achieve high accuracy on test sets consisting mainly of news stories for all 11 language pairs?
https://aclanthology.org/2020.wmt-1.0/,Can the similar language translation task help identify the most suitable machine translation systems for closely related language pairs in terms of syntactic correctness and processing time?
https://aclanthology.org/2020.wmt-1.1/,"Can a neural machine translation model be designed to adapt to new languages without sacrificing its understanding of previously acquired knowledge, and what evaluation metric would be most suitable to measure its performance? Can a lifelong learning machine translation system be trained on a large dataset of English and adapt to new languages such as German or French, and what are the implications for the model's performance and maintenance?"
https://aclanthology.org/2020.wmt-1.2/,"Can machine learning models achieve high accuracy in translating customer support chats between English and German, as measured by BLEU score, and what are the key factors contributing to this accuracy?"
https://aclanthology.org/2020.wmt-1.2/,"Does the use of direct assessments by human evaluators improve the overall quality of machine translations in chat translation tasks, and how does it compare to automated metrics like BLEU and TER?"
https://aclanthology.org/2020.wmt-1.3/,"Can machine translation models handle domain diversity and non-standard texts effectively in social media, as evaluated by human raters, in the English-German and English-Japanese language pairs? Can the few-shot variants of the task provide a more realistic assessment of the robustness of machine translation systems in real-world scenarios?"
https://aclanthology.org/2020.wmt-1.4/,"How can the use of pretraining, multilingual systems, and iterative backtranslation improve the translation quality of low-resource language pairs, specifically English-Tamil, and what are the advantages of using this approach compared to other methods such as language model objectives and unrelated high-resource language pairs?"
https://aclanthology.org/2020.wmt-1.4/,"Can the neural machine translation transformer architecture be adapted to leverage the strengths of multilingual systems to improve translation performance on mid-resource language pairs, such as English-Inuktitut?"
https://aclanthology.org/2020.wmt-1.5/,How do the use of mBART and RoBERTa models impact the performance of unconstrained translation systems in the WMT20 shared news translation task?
https://aclanthology.org/2020.wmt-1.5/,Can the application of back-translation and forward-translation techniques in conjunction with rules and language models improve the BLEU scores for Khmer to English and Pashto to English translations?
https://aclanthology.org/2020.wmt-1.6/,What is the effect of using data filtering on the BLEU score of the Transformer-based model in Chinese->English news translation?
https://aclanthology.org/2020.wmt-1.6/,Does the fine-tuning of the Transformer model with re-ranking improve the BLEU score beyond that of the baseline model?
https://aclanthology.org/2020.wmt-1.7/,"What are the performance metrics used in the paper to evaluate the translation systems, and how do they vary across the different language pairs and techniques employed?"
https://aclanthology.org/2020.wmt-1.7/,"How do the techniques of self-supervised model pretraining, multilingual models, data augmentation, and reranking contribute to the improvement of the translation system in the low resource setting?"
https://aclanthology.org/2020.wmt-1.8/,"Can the proposed back-translation technique improve the accuracy of Tamil-English news translation tasks when combined with word dropout, and how does the choice of subword segmentation technique (Ataman et al., 2017 or SentencePiece, Kudo and Richardson, 2018) impact the overall performance of the NMT model?"
https://aclanthology.org/2020.wmt-1.9/,Can multilingual translation systems leverage the benefits of high-resource languages for low-resource languages like Tamil-English through iterative backtranslation and bilingual baselines?
https://aclanthology.org/2020.wmt-1.9/,"Can iterative backtranslation improve the effectiveness of multilingual translation systems in low-resource languages, as measured by translation accuracy and processing time?"
https://aclanthology.org/2020.wmt-1.10/,Can we develop a more efficient unsupervised pre-training method for encoder-decoder models in machine translation tasks that leverages large amounts of monolingual data and achieves comparable performance to our approach?
https://aclanthology.org/2020.wmt-1.10/,"Can we design a method to evaluate the effectiveness of iterative back-translation in fine-tuning encoder-decoder models for machine translation tasks, using metrics such as BLEU score and human evaluation?"
https://aclanthology.org/2020.wmt-1.11/,"Can a machine learning model utilizing techniques such as back-translation and fine-tuning be able to improve translation accuracy for English-German and English-Japanese pairs, and if so, what specific methods can be used to enhance the model's performance? Can novel approaches to synthetic data filtering and reranking be developed to significantly improve the translation results in the WMT'20 news translation task?"
https://aclanthology.org/2020.wmt-1.12/,"Can the use of transformer models for Inuktitut-English news translation outperform non-transformer models in terms of accuracy on the 2020 WMT shared task, and what are the implications of domain-specific finetuning on the overall performance of the models?"
https://aclanthology.org/2020.wmt-1.12/,Can the development of a morphological model for Inuktitut language improve the translation quality and reduce the need for backtranslation in Inuktitut-English news translation tasks?
https://aclanthology.org/2020.wmt-1.13/,Can the Transformer model achieve better performance on Inuktitut-English translation tasks with the inclusion of a diverse set of training data sources to mitigate the effects of narrow domain bias?
https://aclanthology.org/2020.wmt-1.13/,Can the effectiveness of transfer learning from a high-resource language pair be improved when combined with backtranslation and synthetic data for low-resource language pairs like Inuktitut-English?
https://aclanthology.org/2020.wmt-1.14/,Can the proposed morphologically motivated sub-word unit-based Transformer models outperform the baseline systems in terms of accuracy when trained using sampled back-translation and different parallel and monolingual data selection schemes for both English-Polish news translation pairs in the unconstrained track?
https://aclanthology.org/2020.wmt-1.14/,Can the use of right-to-left re-ranking improve the performance of the ensemble models in terms of processing time for both English-Polish news translation pairs in the constrained track?
https://aclanthology.org/2020.wmt-1.15/,Can a single-directional machine translation model trained on a common multilingual base and fine-tuned on each direction can achieve comparable results to a model trained on a language-specific corpus for the English to Czech and Czech to English translation tasks?
https://aclanthology.org/2020.wmt-1.15/,"Can a re-ranking approach that incorporates document-level information improve the accuracy of machine translation for the English to Inuktitut direction, compared to the base model without this feature?"
https://aclanthology.org/2020.wmt-1.16/,"Can the proposed student models be improved to achieve higher translation accuracy while maintaining their inference efficiency on a single CPU thread, and can the training data be utilized more effectively to fine-tune the models for specific domains within the Czech and English news translations?"
https://aclanthology.org/2020.wmt-1.17/,"Can a supervised learning approach using a pre-trained transformer model be more accurate than a rule-based approach for translating German news articles into English, as measured by BLEU score?"
https://aclanthology.org/2020.wmt-1.17/,"Can the use of active learning techniques improve the performance of a neural machine translation system on news articles, as evaluated by the number of training data samples required to achieve a 5% reduction in BLEU score?"
https://aclanthology.org/2020.wmt-1.18/,Can multilingual Neural Machine Translation models trained on a high-resource language (Hindi) significantly improve the translation quality of low-resource languages (Tamil) when utilizing contact relatedness?
https://aclanthology.org/2020.wmt-1.18/,Does the incorporation of contact relatedness in multilingual Neural Machine Translation models lead to improved performance on the English-Tamil translation task?
https://aclanthology.org/2020.wmt-1.19/,Does the use of precomputed word alignments improve the translation quality of machine translation systems for news articles? Can the incorporation of larger datasets lead to significant improvements in translation accuracy for the news-translation task?
https://aclanthology.org/2020.wmt-1.20/,Can a multilingual Transformer model trained on agglutinative languages achieve better results on the English-Inuktitut translation task by incorporating Inuktitut-specific linguistic features into the model's architecture?
https://aclanthology.org/2020.wmt-1.20/,Can the quality evaluation of machine translation systems for low-resource languages like Inuktitut be improved by using a combination of human evaluation and automated metrics such as BLEU and ROUGE?
https://aclanthology.org/2020.wmt-1.21/,Can neural machine translation techniques with pre-trained language models and collaborative filtering achieve better results on low-resource language pairs like German-Upper Sorbian?
https://aclanthology.org/2020.wmt-1.21/,Can the use of document-enhanced NMT and data-dependent gaussian prior objective improve the performance of machine translation systems on supervised translation tasks?
https://aclanthology.org/2020.wmt-1.22/,Can combining multiple neural machine translation systems through n-best list reranking improve translation quality when using a Transformer Big architecture and additional training data synthesized from monolingual data? Does the presence of translationese texts in the training data negatively impact the performance of neural machine translation systems on test data?
https://aclanthology.org/2020.wmt-1.23/,"Does the use of self-bleu based model ensemble improve the accuracy of the Transformer-based system in the Chinese→English newstranslation task, and can the benefits of this approach be generalized to other machine translation tasks? Can the Transformer-based system with self-bleu based model ensemble outperform the state-of-the-art system in terms of BLEU score on the WMT 2020 shared newstranslation task?"
https://aclanthology.org/2020.wmt-1.24/,Can the MarianNMT-based neural systems used in the submissions achieve higher BLEU scores by incorporating additional training data and improved back-translation models?
https://aclanthology.org/2020.wmt-1.24/,How do the different language pairs and directions impact the overall performance of MarianNMT-based neural systems in news translation tasks?
https://aclanthology.org/2020.wmt-1.25/,Can deep and complex architectures improve translation model performance in low-resource language pairs compared to baseline architectures?
https://aclanthology.org/2020.wmt-1.25/,Does the increased resource allocation to training data result in more competitive systems in the WMT 2020 news translation shared task?
https://aclanthology.org/2020.wmt-1.26/,Can the application of on-lineual sentence selection for creating synthetic training data improve the performance of the Transformer-based machine translation model in low-resource languages such as Tamil?
https://aclanthology.org/2020.wmt-1.26/,Can the use of hyperparameter tuning for the Transformer model enhance the accuracy of machine translation systems in adapting to the complexities of low-resource language pairs like English-Tamil?
https://aclanthology.org/2020.wmt-1.27/,"Can the use of multi-sentence sequences in training improve the performance of sentence-level NMT systems for news translation, as measured by BLEU score? Does the use of document-level NMT systems with multi-sentence sequences outperform sentence-level systems in translating news documents, as measured by character-based metrics?"
https://aclanthology.org/2020.wmt-1.28/,"Can machine learning models achieve higher translation accuracy for the English-Inuktitut language pair by incorporating contextual word embeddings, and does this approach improve the model's ability to segment polysynthetic words correctly? Does adding data from a related language, such as Greenlandic, improve the translation results for the English-Inuktitut language pair?"
https://aclanthology.org/2020.wmt-1.29/,Can the proposed machine translation system for the WMT20 Shared Task on News Translation achieve higher accuracy in translating Pashto and Japanese languages compared to the current state-of-the-art systems?
https://aclanthology.org/2020.wmt-1.29/,"Can the data preprocessing techniques used in the OPPO's machine translation systems have a significant impact on the overall performance of the system, as measured by the ranking of the final submissions in the WMT20 Shared Task?"
https://aclanthology.org/2020.wmt-1.30/,Can the Transformer-Big model be improved by incorporating back translation strategies in the pre-processing step for Zh/En news translation tasks?
https://aclanthology.org/2020.wmt-1.30/,Can the parameter size of the Transformer model be scaled up to achieve better performance in Km/En news translation tasks?
https://aclanthology.org/2020.wmt-1.31/,Can the use of multiscale collaborative deep architecture improve the performance of German-to-French news translation systems in the WMT20 shared task?
https://aclanthology.org/2020.wmt-1.31/,"Can the combination of data selection, back translation, knowledge distillation, domain adaptation, and model ensemble techniques enhance the accuracy of French-to-German news translation systems in the WMT20 shared task?"
https://aclanthology.org/2020.wmt-1.32/,Can our new multilingual pre-trained Transformer model outperform the baseline model in terms of accuracy on the VolcTrans shared news translation task?
https://aclanthology.org/2020.wmt-1.32/,Can the application of dynamic convolutional layers in the Transformer architecture improve the processing time of the baseline model for the 8 translation directions in the WMT20 shared news translation task?
https://aclanthology.org/2020.wmt-1.33/,How can the use of data augmentation methods and ensemble learning improve the performance of deep Transformer-based Neural Machine Translation systems for the WMT 2020 news translation tasks?
https://aclanthology.org/2020.wmt-1.33/,Can a boosted in-domain fine-tuning method and an iterative transductive ensemble method be used to further enhance the translation performance of single models in Neural Machine Translation systems?
https://aclanthology.org/2020.wmt-1.34/,"Can a combination of Transformer models and bi-text data filtering schemes improve the accuracy of machine translation results in the WMT20 shared news translation task, measured by the BLEU value?"
https://aclanthology.org/2020.wmt-1.34/,"Can the use of back-translations and reordering methods in the Sockeye sequence modeling toolkit enhance the translation quality from English to Russian, as indicated by the ranking in the WMT20 shared news translation task?"
https://aclanthology.org/2020.wmt-1.35/,Can the noisy channel factorization approach improve the performance of document translation systems on the WMT2020 Shared Task on News Translation when combined with Monte-Carlo Tree Search decoding and improved uncertainty estimation?
https://aclanthology.org/2020.wmt-1.35/,Can the use of length models and sentence segmentation techniques mitigate the issue of premature truncation of long sequences in document translation systems?
https://aclanthology.org/2020.wmt-1.36/,"How can the iterative back-translation strategy improve the performance of NiuTrans neural machine translation systems in adapting to new domains, and what are the key parameters that influence its effectiveness in this context?"
https://aclanthology.org/2020.wmt-1.36/,"Can widening and deepening the model architecture simultaneously lead to significant performance improvements in machine translation tasks, and how do different model architectures affect the outcome in the Japanese<->English and Inuktitut->English translation tasks?"
https://aclanthology.org/2020.wmt-1.37/,"How do the performance metrics of the German-English systems from WMT20 compare to those from WMT19, and what are the specific linguistic phenomena where all systems struggle?"
https://aclanthology.org/2020.wmt-1.37/,"Can the incorporation of additional training data improve the performance of the Tohoku and Huoshan systems, particularly in handling idioms, resultative predicates, and pluperfect constructions?"
https://aclanthology.org/2020.wmt-1.38/,"Is it possible to design a machine translation model that uses meaningful contextual information to avoid spurious gender correlations in translations, and if so, what evaluation metrics can be used to measure its effectiveness? Can the deployment of machine translation models in commercial systems be improved to reduce the occurrence of gender bias in translations?"
https://aclanthology.org/2020.wmt-1.39/,"Can a supervised learning approach using a Transformer-based architecture improve the performance of machine translation systems in handling word sense disambiguation for the English-Czech, English-German, and English-Russian language pairs?"
https://aclanthology.org/2020.wmt-1.39/,"Can automated evaluation methods, such as the one used in the MUCOW test suite, effectively measure the progress of NMT systems in handling ambiguous source words over time?"
https://aclanthology.org/2020.wmt-1.40/,"Does the use of markables in machine translation systems affect the quality of translation in the News, Audit, and Lease domains differently, and can automatic evaluation tools capture these differences?"
https://aclanthology.org/2020.wmt-1.40/,"Can markable error types have a more significant impact on machine translation performance than the quality of translation itself in the News, Audit, and Lease domains?"
https://aclanthology.org/2020.wmt-1.41/,"Can a transformer-based architecture with back-translation improve the performance of bilingual machine translation models on low-resource language pairs, and how does the mutual intelligibility of the languages affect this improvement? Can bilingual machine translation models outperform multi-lingual models on tasks that require high levels of contextual understanding?"
https://aclanthology.org/2020.wmt-1.42/,Can the proposed Attention Transformer model outperform the traditional RNN-based encoder-decoder model in terms of BLEU score for the Indo-Aryan language pair?
https://aclanthology.org/2020.wmt-1.42/,Can the use of Recurrent Attention in the Transformer model improve the processing time for decoding in the target language compared to the traditional RNN-based model?
https://aclanthology.org/2020.wmt-1.43/,"Can the Transformer-based Neural Machine Translation approach be improved for Hindi-Marathi translation, and how does its performance compare to other NMT models in terms of BLEU score?"
https://aclanthology.org/2020.wmt-1.43/,"Can the use of RIBES and TER scores provide a more accurate evaluation metric for assessing the performance of the NMT system, and how do these scores compare to traditional metrics like BLEU for the Hindi-Marathi language pair?"
https://aclanthology.org/2020.wmt-1.44/,Can NMT models learn more accurate bilingual embeddings by utilizing both monolingual data and similarity features between language pairs?
https://aclanthology.org/2020.wmt-1.44/,How can the limitations of available parallel data be overcome using a multi-source bilingual embedding approach in NMT models?
https://aclanthology.org/2020.wmt-1.45/,How does the fine-tuning of the mBART model on parallel data for the Similar Language Translation task impact the translation accuracy for Hindi <-> Marathi and Spanish <-> Portuguese pairs?
https://aclanthology.org/2020.wmt-1.45/,Can the self-supervised pre-training of mBART on a large amount of monolingual data for many languages improve the overall performance of the model for translation tasks such as Similar Language Translation?
https://aclanthology.org/2020.wmt-1.46/,What are the effects of fine-tuning the Transformer architecture for domain adaptation on the performance of Similar Language Translation systems for the Spanish-Portuguese language pair in WMT 2020?
https://aclanthology.org/2020.wmt-1.46/,How does the use of fine-tuning for domain adaptation impact the processing time of Similar Language Translation systems for the Spanish-Portuguese language pair in WMT 2020?
https://aclanthology.org/2020.wmt-1.47/,Can attention-based sequence-to-sequence models with linguistic features such as part-of-speech (POS) and morphology outperform back-translation in Hindi-Marathi machine translation tasks?
https://aclanthology.org/2020.wmt-1.47/,Can the use of linguistic features such as POS and morphology improve the translation accuracy of sequence-to-sequence models in the Marathi-Hindi language pair?
https://aclanthology.org/2020.wmt-1.48/,What are the effectiveness of Byte Pair Encoding (BPE) in improving the performance of Neural Machine Translation (NMT) systems for closely related languages like Hindi and Marathi?
https://aclanthology.org/2020.wmt-1.48/,Can the use of different architectures in NMT systems impact the translation accuracy and processing time for Hindi↔Marathi language pair?
https://aclanthology.org/2020.wmt-1.49/,"Can a machine learning approach using a Transformer-based architecture be applied to improve the translation quality of Hindi to Marathi and Marathi to Hindi translation tasks, and what is the improvement in translation accuracy achieved by the WIPRO-RIT systems in these tasks?"
https://aclanthology.org/2020.wmt-1.50/,What are the effects of using multilingual data in machine translation systems for Croatian-Slovenian and Serbian-Slovenian language pairs compared to bilingual systems?
https://aclanthology.org/2020.wmt-1.50/,Does the use of character-based cleaning and synthetic parallel data improve the performance of NMT systems in terms of accuracy and processing time?
https://aclanthology.org/2020.wmt-1.51/,"Is the use of a byte-pair encoding based transformer model sufficient for achieving high-quality translations in low-resource language pairs, and can an ensemble approach combining multiple transformer models improve fluency?"
https://aclanthology.org/2020.wmt-1.51/,"Can the proportion of back-translated data in the training data impact the fluency of translations in low-resource language pairs, and does it outperform the baseline system in terms of evaluation metrics?"
https://aclanthology.org/2020.wmt-1.52/,Can document-level neural machine translation with hierarchical attention networks improve the translation quality of low-resource languages like Marathi-Hindi using monolingual data with back translation?
https://aclanthology.org/2020.wmt-1.52/,Does the use of back translation with monolingual data enhance the effectiveness of document-level neural machine translation in improving translation quality for low-resource language pairs?
https://aclanthology.org/2020.wmt-1.53/,Can the use of a multilingual shared encoder/decoder improve translation accuracy for similar language pairs such as Catalan and Spanish?
https://aclanthology.org/2020.wmt-1.53/,"Can the application of back-translation and fine-tuning techniques to the multilingual shared encoder/decoder enhance translation performance for all three language pairs, including Portuguese?"
https://aclanthology.org/2020.wmt-1.54/,How do different tokenization schemes affect the performance of statistical models in Hindi⇐⇒Marathi language pair translation tasks?
https://aclanthology.org/2020.wmt-1.54/,Can synthetic data generated using optimal tokenization scheme and back translation outperform traditional training data in building translation models for the Hindi⇐⇒Marathi language pair?
https://aclanthology.org/2020.wmt-1.55/,Can a BPE-based standard transformer model outperform a baseline system by more than 13 BLEU points in translating agent-side utterances from English to German?
https://aclanthology.org/2020.wmt-1.55/,"Can a multi-encoder Transformer architecture improve the coherence of translations in chat translation tasks, as measured by evaluation on a set of carefully-designed examples?"
https://aclanthology.org/2020.wmt-1.56/,"How can the application of ensemble methods improve the robustness to noise in multilingual document translation tasks, and what specific language model pre-training techniques are most effective in enhancing robustness to out-of-domain translation for German-English bilingual dialogues?"
https://aclanthology.org/2020.wmt-1.57/,Can the use of domain tags improve the performance of machine translation models trained on pseudo-in-domain web crawled data and in-domain task data for English-German translation tasks?
https://aclanthology.org/2020.wmt-1.57/,"Can the inclusion of preceding context in machine translation systems negatively impact their performance, and if so, what are the underlying reasons for this phenomenon?"
https://aclanthology.org/2020.wmt-1.58/,Can the proposed BERT embedding combined with a bidirectional recurrent neural network improve the accuracy of machine translation from English to German compared to a non-ensemble approach?
https://aclanthology.org/2020.wmt-1.58/,Can the hyperparameter tuning of the three ensemble models contribute to the significant improvement in machine translation results despite the limited training corpus size?
https://aclanthology.org/2020.wmt-1.59/,What is the effect of using a hybrid data selection method on the BLEU scores of non-autoregressive neural machine translation systems in English-German chat translation?
https://aclanthology.org/2020.wmt-1.59/,How does the addition of evolved cross-attention to non-autoregressive models impact the accuracy of downstream translation tasks in the context of out-of-domain data?
https://aclanthology.org/2020.wmt-1.60/,Can the application of sequence distillation and transfer learning in low-resource settings improve the efficiency and accuracy of neural machine translation models? How does the stage-wise application of sequence distillation and transfer learning affect the decoding time and translation quality of neural machine translation models in low-resource settings?
https://aclanthology.org/2020.wmt-1.61/,"Can the proposed interleaved bidirectional decoder (IBDecoder) improve the quality of machine translation tasks when compared to semi-autoregressive decoding (SA) in terms of fluency and accuracy, and can the hybrid models achieve significant speedups without compromising the quality of the generated text?"
https://aclanthology.org/2020.wmt-1.61/,"Can the IBDecoder be adapted to perform multi-directional decoding by partitioning the target sequence to achieve even higher speedups, and what are the trade-offs in terms of BLEU and ROUGE scores when using this approach?"
https://aclanthology.org/2020.wmt-1.62/,"Can the use of similar translations as priming cues in the NMT decoder improve the translation accuracy in a multi-domain setting, and how does this approach compare to other mechanisms of micro-adaptation during inference? Can the proposed framework effectively gather valuable information for an NMT network from monolingual resources?"
https://aclanthology.org/2020.wmt-1.63/,"Can zero-shot neural machine translation models trained on multilingual data achieve consistent and accurate results across multiple language pairs, and how does the choice of subword segmentation affect the performance of these models in zero-shot translation?"
https://aclanthology.org/2020.wmt-1.63/,"Does the use of a bridge language in multilingual models hinder or help zero-shot translation, and can a small amount of parallel data in non-bridge language pairs mitigate the negative effects of this approach?"
https://aclanthology.org/2020.wmt-1.64/,What is the impact of incorporating bilingual dictionaries on the performance of neural machine translation systems in terms of BLEU score improvement?
https://aclanthology.org/2020.wmt-1.64/,"Can dictionaries be effectively integrated into neural machine translation models to improve the handling of rare words, and if so, what are the optimal dictionary types for achieving this goal?"
https://aclanthology.org/2020.wmt-1.65/,"Can MNMT models be improved by incorporating multi-way aligned data into English-centric parallel corpora, and how does this affect their performance on non-English language pairs?"
https://aclanthology.org/2020.wmt-1.65/,"Can cMNMT with novel target language conditioned training data sampling strategy be scaled up to accommodate a large number of language pairs, and what is the impact on translation quality?"
https://aclanthology.org/2020.wmt-1.66/,"Can a multilingual neural machine translation model be adapted to generate paraphrases of high grammatical correctness while controlling lexical diversity, and what is the optimal approach for achieving this goal in terms of processing time?"
https://aclanthology.org/2020.wmt-1.66/,"Can the proposed paraphrase generation algorithm be generalized to improve the semantic preservation of paraphrases in low-resource languages, and how can it be evaluated in terms of accuracy and user satisfaction?"
https://aclanthology.org/2020.wmt-1.67/,"Can unsupervised machine translation systems accurately translate low-resource language pairs using scripts with different writing systems, and if so, how can stochasticity in embedding training impact these translations? Can unsupervised machine translation systems perform reliably across domains, particularly when source and target corpora are from different linguistic or cultural backgrounds?"
https://aclanthology.org/2020.wmt-1.68/,Can efficient approximations be developed to make inference with noisy channel modeling comparable to strong ensembles in terms of processing time without compromising on accuracy in neural machine translation tasks?
https://aclanthology.org/2020.wmt-1.68/,Can noisy channel modeling achieve state-of-the-art results in machine translation while outperforming strong pre-training methods on specific translation tasks such as Romanian-English translation?
https://aclanthology.org/2020.wmt-1.69/,"Can MSNMT achieve better translation accuracy when visual information is used to decode the target language, and what is the effect of varying the word order between the source and target languages on the performance of MSNMT?"
https://aclanthology.org/2020.wmt-1.70/,Does the use of document-level bilingual data improve the performance of context-aware neural machine translation models for pronoun resolution tasks?
https://aclanthology.org/2020.wmt-1.70/,Can document-level back-translation be a valuable technique for compensating for the lack of document-level bilingual data in context-aware neural machine translation systems?
https://aclanthology.org/2020.wmt-1.71/,"Can the use of residual adapters in machine translation improve the robustness of baseline models to domain errors, and what are the computational costs associated with this approach compared to fine-tuning the entire model?"
https://aclanthology.org/2020.wmt-1.71/,Can residual adapters with different architectures be more effective than their original implementation in adapting machine translation systems to multiple domains?
https://aclanthology.org/2020.wmt-1.72/,"Can machine translation systems be trained to accurately determine the grammatical gender of words and subjects, and how does this impact the overall translation accuracy in languages with gendered grammatical systems?"
https://aclanthology.org/2020.wmt-1.72/,"Can the use of word-level annotations containing grammatical gender information improve the translation accuracy of machine translation systems, particularly in cases where the gender of the subject is ambiguous or unknown?"
https://aclanthology.org/2020.wmt-1.73/,"Can document-level machine translation be improved by incorporating contextual information from high-quality business conversation data, and how can this be measured through the evaluation of automatic MT systems?"
https://aclanthology.org/2020.wmt-1.73/,Can the manual annotation of contextually relevant phenomena in document-level machine translation be used to alleviate the lack of context in existing evaluation methods?
https://aclanthology.org/2020.wmt-1.74/,"Can a supervised learning approach using a Transformer-based architecture be applied to improve the accuracy of machine translation systems for the English-Chinese language pair, and what are the key factors that affect its performance in this context?"
https://aclanthology.org/2020.wmt-1.74/,"Can a domain-adaptation strategy be designed to enhance the quality of automatic post-editing corrections for English-German and English-Chinese machine translation systems, and how can it be measured in terms of evaluation metrics such as BLEU points and TER?"
https://aclanthology.org/2020.wmt-1.75/,"Can machine translation models achieve high accuracy in translating scientific abstracts and terminologies across multiple language pairs, including English/Russian, English/Italian, and English/Basque, as measured by automated evaluation metrics?"
https://aclanthology.org/2020.wmt-1.75/,"Can the introduction of new language pairs, such as English/Russian and English/Basque, improve the overall performance of machine translation systems in the biomedical domain, compared to previous years?"
https://aclanthology.org/2020.wmt-1.76/,"Can automatic metrics accurately predict human scores on translation systems at the system-level, and what are the implications of using these metrics for evaluating machine translation systems?"
https://aclanthology.org/2020.wmt-1.76/,Do reference-less metrics perform comparably to their reference-based counterparts in evaluating machine translation systems at the document-level?
https://aclanthology.org/2020.wmt-1.77/,"Can machine learning-based methods, specifically deep learning models with word embeddings and attention mechanisms, be used to improve the accuracy of sentence-level quality scoring for noisy corpora of sentence pairs in low-resource languages such as Pashto and Khmer?"
https://aclanthology.org/2020.wmt-1.77/,Can a multi-task learning approach be employed to simultaneously improve sentence alignment from document pairs and sentence-level quality scoring for noisy corpora of sentence pairs in low-resource languages?
https://aclanthology.org/2020.wmt-1.78/,"Can a deep learning model using a transformer-based architecture be trained to predict the quality of machine translation output with high accuracy, measured by BLEU score, and what are the optimal hyperparameters for this task in the English-German language pair?"
https://aclanthology.org/2020.wmt-1.78/,"Can a supervised classification model using a rule-based approach be developed to predict the quality of machine translation output at the document level, measured by F1 score, and what are the best features to use for this task in the English-French language pair?"
https://aclanthology.org/2020.wmt-1.79/,Can unsupervised machine translation systems be improved by using additional data from minority language sources in both directions for German to Upper Sorbian and Upper Sorbian to German translation?
https://aclanthology.org/2020.wmt-1.79/,"Can the performance of machine translation systems be evaluated using a variety of metrics beyond accuracy, including processing time and user satisfaction, for the task of translating German to Upper Sorbian and Upper Sorbian to German?"
https://aclanthology.org/2020.wmt-1.80/,How does the use of cross-lingual Transformer architecture improve the post-editing output in terms of TER and BLEU scores?
https://aclanthology.org/2020.wmt-1.80/,Can a fine-tuned XLM-RoBERTa model be used to predict the actual word for each mask in the post-edited output based on word-level quality estimation?
https://aclanthology.org/2020.wmt-1.81/,"Can a cross-lingual language model trained with translation and masked language modeling objectives achieve better automatic post-editing results than a model trained with a single objective, and how does the addition of new synthetic data impact the performance of the ensemble model?"
https://aclanthology.org/2020.wmt-1.81/,Can the use of jointly learned language representations between the source and target languages improve the accuracy of automatic post-editing systems in terms of TER and BLEU scores for the En-De and En-Zh language pairs?
https://aclanthology.org/2020.wmt-1.82/,"Can a Transformer-based multi-source model with a noising module be used to effectively generate synthetic post-editing data for training machine translation models, and how does this approach impact the quality of the model in terms of TER and BLEU scores?"
https://aclanthology.org/2020.wmt-1.82/,"Can the use of synthetic data generated by a noising module in a Transformer-based APE model improve the overall performance of machine translation models in terms of TER and BLEU scores, compared to traditional training methods using human-crafted data?"
https://aclanthology.org/2020.wmt-1.83/,Can a two-stage training pipeline combining pre-training of a BERT-like cross-lingual language model and fine-tuning with an additional neural decoder improve the performance of Automatic Post-Editing tasks?
https://aclanthology.org/2020.wmt-1.83/,Does the application of imitation learning to augment pseudo training data with APE data enhance the model's performance on held-out data?
https://aclanthology.org/2020.wmt-1.84/,How does the use of Bottleneck Adapter Layers in the Transformer model impact its performance in the English-German and English-Chinese translation tasks?
https://aclanthology.org/2020.wmt-1.84/,Can external MT augmentation using collected translations as additional candidates improve the fine-tuned NMT model's performance in the APE corpus?
https://aclanthology.org/2020.wmt-1.85/,Can LIMSI's biomedical translation system achieve high accuracy in translating medical abstracts from English into French using a combination of back-translated texts and terminological resources within a reasonable processing time?
https://aclanthology.org/2020.wmt-1.85/,"Can the proposed multi-domain, noise-robust translation systems for English into German handle the zero-shot and few-shot domain adaptation tasks with high robustness and syntactic correctness?"
https://aclanthology.org/2020.wmt-1.86/,Can a Transformer-based approach be used to effectively integrate open-domain and biomedical domain data to improve the accuracy of terminology translation for the English-Basque language pair?
https://aclanthology.org/2020.wmt-1.86/,Can a combination of open-domain and biomedical domain data lead to improved performance in abstract translation for the English-Basque and English-Spanish language pairs?
https://aclanthology.org/2020.wmt-1.87/,"Does YerevaNN's data preprocessing pipeline for English-Russian machine translation significantly improve BLEU scores, and if so, what specific techniques are used to fix poorly aligned sentences?"
https://aclanthology.org/2020.wmt-1.87/,Can YerevaNN's neural machine translation systems for English-Russian and English-German language pairs outperform existing systems in terms of processing time and accuracy?
https://aclanthology.org/2020.wmt-1.88/,"Can pretraining a BERT-fused NMT model improve translation accuracy in low-resource languages, and how does backtranslating monolingual data affect the performance of NMT models in biomedical translation tasks?"
https://aclanthology.org/2020.wmt-1.89/,"Can low-cost hardware and pre-trained models such as T5 improve the performance of machine translation tasks, particularly for languages with non-English characters?"
https://aclanthology.org/2020.wmt-1.89/,"Can the adaptation of the English tokenizer to represent Portuguese characters, such as diaeresis, acute and grave accents, improve the translation accuracy of low-cost models for Portuguese-English and English-Portuguese tasks?"
https://aclanthology.org/2020.wmt-1.90/,Can the use of pseudo parallel data selection and hyperparameter tuning improve the performance of Transformer-based neural machine translation systems for translating biomedical terminology from English to Basque? Can the incorporation of monolingual data into synthetic corpora for training NMT models enhance their accuracy on low-resource language pairs like English-Basque?
https://aclanthology.org/2020.wmt-1.91/,Can BERT-based models achieve better performance on French to English translation tasks when fine-tuned with in-domain corpora extracted from out-of-domain sources?
https://aclanthology.org/2020.wmt-1.91/,Can the use of domain adaptive subword units in BERT-based models improve the accuracy of French to English translations when training with in-domain corpora from various out-of-domain sources?
https://aclanthology.org/2020.wmt-1.92/,Can the use of in-domain dictionaries improve the performance of cross-domain neural machine translation models when fine-tuned on pre-trained models?
https://aclanthology.org/2020.wmt-1.92/,"Does the application of transfer learning through pre-trained machine translation models enhance the translation directions from English to French, German, and Italian?"
https://aclanthology.org/2020.wmt-1.93/,Can a Minimum Risk Training approach using robust fine-tuning on imperfect training pairs outperform data-filtering in reducing exposure bias effects in small-domain biomedical translation tasks?
https://aclanthology.org/2020.wmt-1.93/,Can a single model with MRT fine-tuning achieve state-of-the-art results in English-Spanish biomedical translation without ensembling?
https://aclanthology.org/2020.wmt-1.94/,Can the proposed Transformer-based machine translation system achieve higher accuracy on the English/Spanish language pair using a combination of in-domain and out-of-domain training data?
https://aclanthology.org/2020.wmt-1.94/,Can the use of TensorFlow Model Garden toolkit enable faster processing times for translating English/Russian language pairs compared to other machine translation systems?
https://aclanthology.org/2020.wmt-1.95/,"Can the use of clinical terminology in machine translation systems improve the accuracy of biomedical translation tasks, as measured by BLEU scores, and what are the implications of this improvement on the average sentence length of the generated outputs?"
https://aclanthology.org/2020.wmt-1.95/,"Does the inclusion of clinical terminology in machine translation systems result in increased CO2 emissions, and can this be mitigated by optimizing the training process to reduce power consumption?"
https://aclanthology.org/2020.wmt-1.96/,How does the use of back-translation to enlarge the in-domain bilingual corpus impact the BLEU scores of the German->English and English->German translation systems?
https://aclanthology.org/2020.wmt-1.96/,Can the combination of different transformer architectures in the model ensemble technique improve the translation performance of the Chinese->English and English->Chinese systems?
https://aclanthology.org/2020.wmt-1.97/,"Can the use of PRISM-generated paraphrases in multilingual machine translation systems improve the segment-level correlations of base metrics such as BLEU, CHRF, and ESIM?"
https://aclanthology.org/2020.wmt-1.97/,"Does the number of additional synthetic references generated by PRISM have a systematic impact on the gains achieved by parBLEU, parCHRF++, and parESIM in improving the performance of machine translation systems?"
https://aclanthology.org/2020.wmt-1.98/,Can pretrained language models with different architectures enhance the correlation between YiSi-1 and human translation quality judgment on machine translation tasks?
https://aclanthology.org/2020.wmt-1.98/,Does the use of pretrained language models' intermediate layers impact the correlation between YiSi-1 and human translation quality judgment on machine translation tasks?
https://aclanthology.org/2020.wmt-1.99/,"Can YiSi-2 improve the semantic representation of machine translation evaluation by using a cross-lingual linear projection (CLP) matrix learned from a small development set, and how does this approach compare to using multilingual BERT embeddings versus XLM-RoBERTa embeddings?"
https://aclanthology.org/2020.wmt-1.99/,Can the use of contextual embeddings from different layers of multilingual BERT and XLM-RoBERTa pretrained models improve the accuracy of semantic similarity representations for machine translation evaluation using YiSi-2?
https://aclanthology.org/2020.wmt-1.100/,Can the COMET framework be used to improve the accuracy of machine translation models for low-resource languages by fine-tuning the regression models on human-generated quality scores?
https://aclanthology.org/2020.wmt-1.100/,Can a novel ranking model trained on relative ranks from Direct Assessments outperform the current state-of-the-art in the system-level track of the WMT 2020 Shared Task on all language pairs?
https://aclanthology.org/2020.wmt-1.101/,Can the BLEURT metric achieve state-of-the-art results on the WMT 2020 Metrics Shared Task when fine-tuned on 14 language pairs with available labeled data?
https://aclanthology.org/2020.wmt-1.101/,Can BLEURT's predictions be combined with those of YiSi to improve performance on English-German translations using alternative reference translations?
https://aclanthology.org/2020.wmt-1.102/,"Can machine learning algorithms be used to automatically acquire human scores for evaluating the effectiveness of machine translation metrics at both system- and segment-level, and if so, what are the optimal methods for doing so?"
https://aclanthology.org/2020.wmt-1.102/,Do metrics such as BLEU and METEOR score correlate with human judgement in a way that can be consistently measured across different human evaluators and translation tasks?
https://aclanthology.org/2020.wmt-1.103/,How can the proposed SWSS approach be adapted to incorporate domain-specific dictionaries to improve the accuracy of identifying semantic core words in machine translation tasks?
https://aclanthology.org/2020.wmt-1.103/,Can the use of semantic core words in machine translation evaluation metrics lead to more consistent and informative results compared to traditional lexical similarity metrics?
https://aclanthology.org/2020.wmt-1.104/,"Can a transformer-based multilingual pre-trained language model be effectively fine-tuned for low-resource parallel corpus filtering tasks using a proxy task learner, and what are the implications of this approach for improving filtering performance?"
https://aclanthology.org/2020.wmt-1.104/,Can the proposed proxy task learner improve the filtering accuracy of noisy parallel corpora by leveraging the capabilities of a transformer-based multilingual pre-trained language model?
https://aclanthology.org/2020.wmt-1.105/,Can LASER models achieve better performance when combined with a custom classifier compared to the baseline in the WMT20 sentence filtering task?
https://aclanthology.org/2020.wmt-1.105/,Can the mBART setup provide a more stable improvement in sacreBLEU score with the addition of a custom classifier for Pashto and Khmer languages?
https://aclanthology.org/2020.wmt-1.106/,"Can the Extremely Randomised Trees feature extraction method improve the accuracy of the Bicleaner tool in identifying parallel sentences, and can the use of lexical similarity features that account for word frequency improve the overall performance of the classifier?"
https://aclanthology.org/2020.wmt-1.106/,Does the incorporation of character-level language models and n-gram saturation in re-scoring the output of Bicleaner contribute to a more accurate identification of parallel sentences?
https://aclanthology.org/2020.wmt-1.107/,"Can the use of multilingual word embeddings improve the performance of corpus filtering tasks in low-resource languages, measured by perplexity of language models? Can the combination of multilingual word embeddings, language models, and pre/post filtering rules achieve better performance than the LASER baseline on the dev set for language pairs with limited training data?"
https://aclanthology.org/2020.wmt-1.108/,How can the combination of LASER similarity scores and perplexity scores from language models improve the filtering accuracy of Pashto-English alignments?
https://aclanthology.org/2020.wmt-1.108/,Can a supervised machine learning model using a Transformer-based architecture be trained to achieve higher accuracy in Pashto-English alignment by incorporating a duplication penalty into the cross entropy loss function?
https://aclanthology.org/2020.wmt-1.109/,What is the impact of the XLM-RoBERTa model on the translation quality of neural machine translation systems when fine-tuned on parallel data extracted by the statistical sentence alignment method?
https://aclanthology.org/2020.wmt-1.109/,How does the statistical sentence alignment approach compare to the LASER-based sentence-embedding method in terms of re-aligning sentences in document pairs in low-resource contexts?
https://aclanthology.org/2020.wmt-1.110/,What is the impact of using a positive-unlabeled learning model in combination with brute-force search on the performance of the Dual Bilingual GPT-2 model in the filtering task of the WMT 2020 Shared Task on Parallel Corpus Filtering and Alignment?
https://aclanthology.org/2020.wmt-1.110/,How does the bilingual lexicon mining step in the extraction pipeline of the alignment-filtering task affect the overall performance of the IBM word alignment model in the alignment-filtering task of the WMT 2020 Shared Task on Parallel Corpus Filtering and Alignment?
https://aclanthology.org/2020.wmt-1.111/,What is the effectiveness of the iterative mining strategy used in the Volctrans system for extracting latent parallel sentences in low-resource conditions?
https://aclanthology.org/2020.wmt-1.111/,How does the ensemble-based reranking mechanism improve the accuracy of parallel sentence scoring in the Volctrans system?
https://aclanthology.org/2020.wmt-1.112/,"How can task-specific pretraining schemes be designed to improve the generalization capability of machine translation models, and what are the key factors that influence the effectiveness of such schemes?"
https://aclanthology.org/2020.wmt-1.112/,What is the impact of task-specific data augmentation on the performance of machine translation models in terms of accuracy and processing time?
https://aclanthology.org/2020.wmt-1.113/,"Can RTMs with stacked predictions outperform baseline models on Task 1 subtasks in terms of accuracy, and what is the impact of stacking on test set results?"
https://aclanthology.org/2020.wmt-1.113/,"Can RTMs achieve comparable or better performance compared to other models in multilingual track of sentence-level Task 1, as measured by MAE?"
https://aclanthology.org/2020.wmt-1.114/,"Can our proposed method of injecting noise at the target side of the QE Brain improve its performance on sentence-level quality estimation tasks, measured by accuracy, compared to the original QE Brain model?"
https://aclanthology.org/2020.wmt-1.114/,Can the integration of masked language models at the target side and ensemble of features from different models enhance the overall performance of the QE system in terms of user satisfaction on EN-ZH and EN-DE language pairs?
https://aclanthology.org/2020.wmt-1.115/,"What is the feasibility of using pre-trained representations for black-box quality estimation in machine translation, and how does it compare to feature-based regression models in terms of accuracy and processing time?"
https://aclanthology.org/2020.wmt-1.115/,"Can a set of glass-box quality indicators extracted from neural machine translation systems be used to predict MT quality directly without supervision, and what is the generalization performance across languages?"
https://aclanthology.org/2020.wmt-1.116/,What is the impact of deep transformer machine translation models on the performance of quality estimation in machine translation tasks
https://aclanthology.org/2020.wmt-1.116/,Can the combination of transfer learning and multilingual pretraining improve the accuracy of translation quality estimation for all language pairs in the WMT 2020 shared task
https://aclanthology.org/2020.wmt-1.117/,Can fine-tuning the XLM-RoBERTa model on a human-labeled dataset improve its performance on the WMT 2020 English-German QE test set for word-level translation quality estimation?
https://aclanthology.org/2020.wmt-1.117/,"Does the use of a pre-trained cross-lingual language model like XLM-RoBERTa, fine-tuned on an artificially generated QE dataset, achieve better results on the WMT 2020 English-German QE test set for word-level and sentence-level translation quality estimation?"
https://aclanthology.org/2020.wmt-1.118/,"Can transformer-based predictor-estimator architectures improve the accuracy of quality estimation for machine translation systems, and what specific features can be extracted from neural machine translation systems to incorporate into the quality estimation framework?"
https://aclanthology.org/2020.wmt-1.118/,Can the OpenKiwi framework be effectively extended to handle uncertainty-based features and improve the performance of quality estimation for machine translation systems?
https://aclanthology.org/2020.wmt-1.119/,"Can the proposed ensemble model of XLM-RoBERTa with language tags achieve higher Pearson scores than 80% on a multilingual track, and what is the impact of incorporating different language tags on the model's performance in terms of RMSE?"
https://aclanthology.org/2020.wmt-1.120/,Does the proposed approach of using a self-supervised learning task to model errors in machine translation outputs improve the domain adaptation of multi-task fine-tuned cross-lingual language models in the context of Word and Sentence-level Post-editing Effort task?
https://aclanthology.org/2020.wmt-1.120/,Can the proposed method achieve better results on the English-to-German and English-to-Chinese translation directions using a combination of multi-task fine-tuning and the proposed intermediate training method?
https://aclanthology.org/2020.wmt-1.121/,"Can cross-lingual transformers be used to improve the performance of QE frameworks in direct assessment tasks, and how can data augmentation techniques be used to further enhance the results of these frameworks?"
https://aclanthology.org/2020.wmt-1.121/,"Can the combination of ensemble methods and cross-lingual transformers lead to improved accuracy in direct assessment tasks, and what are the optimal data augmentation techniques to achieve this improvement?"
https://aclanthology.org/2020.wmt-1.122/,What is the impact of integrating Bottleneck Adapter Layers in the Predictor on the transfer learning efficiency of the Transformer model in post-editing quality estimation tasks?
https://aclanthology.org/2020.wmt-1.122/,Can the use of multitask learning for jointly training word- and sentence-level tasks with a unified model improve the overall performance of post-editing quality estimation systems?
https://aclanthology.org/2020.wmt-1.123/,What is the effectiveness of using XLM-based predictor in conjunction with LSTM-estimator in improving the sentence-level post-editing effort for English-Chinese translation tasks?
https://aclanthology.org/2020.wmt-1.123/,How does the incorporation of multi-decoding in machine translation module improve the performance of the Transformer-based Predictor-Estimator architecture in the WMT20 QE Shared Task?
https://aclanthology.org/2020.wmt-1.124/,Can a zero-shot QE model using explicit cross-lingual patterns achieve comparable performance to a supervised QE method on the WMT 2020 Shared Task?
https://aclanthology.org/2020.wmt-1.124/,Can explicit word alignments and generation scores improve the performance of a zero-shot QE model on sentence-level direct assessment tasks?
https://aclanthology.org/2020.wmt-1.125/,"Can the proposed BPE-based approach effectively address the Out of Vocabulary (OOV) word problem in machine translation, as measured by BLEU score, for low-resource languages such as HSB to GER? Can the use of a base vocabulary of size 256 improve the performance of BPE-based models in translation tasks across different languages?"
https://aclanthology.org/2020.wmt-1.126/,"Can the decoder-only transformer architecture achieve state-of-the-art results on the low-resource supervised machine translation task at WMT20, as evaluated by metrics such as BLEU score and ROUGE score?"
https://aclanthology.org/2020.wmt-1.126/,"Can the pretraining of the transformer model on a similar language parallel corpus improve the performance of the decoder-only transformer on the low-resource supervised machine translation task at WMT20, as measured by the accuracy of the model on the test set?"
https://aclanthology.org/2020.wmt-1.127/,What is the effect of fine-tuning a monolingual pretrained language generation model on both source and target languages on the performance of unsupervised neural machine translation systems?
https://aclanthology.org/2020.wmt-1.127/,How does the use of residual adapters in the direction of Upper Sorbian→German impact the overall performance of the unsupervised neural machine translation system?
https://aclanthology.org/2020.wmt-1.128/,"Can the proposed factored machine translation approach on a small BPE vocabulary improve the performance of unsupervised machine translation systems for German-Upper Sorbian, and can it be adapted for very low-resource supervised machine translation tasks?"
https://aclanthology.org/2020.wmt-1.128/,Does the use of iterative back-translation in conjunction with a factored machine translation approach on a small BPE vocabulary enhance the accuracy of supervised machine translation systems for German-Upper Sorbian?
https://aclanthology.org/2020.wmt-1.129/,"Can the use of a pre-trained model for data selection improve the performance of an unsupervised machine translation system for German–Upper Sorbian, and what is the optimal data size for achieving high-quality translations?"
https://aclanthology.org/2020.wmt-1.129/,Is document-level data selection superior to sentence-level data selection for training XLM models in the context of unsupervised machine translation for German–Upper Sorbian?
https://aclanthology.org/2020.wmt-1.130/,Can the use of synthetic data and transfer learning improve the accuracy of machine translation models for low-resource languages like Upper Sorbian?
https://aclanthology.org/2020.wmt-1.130/,Does the incorporation of orthographically similar word pairs and transliterations of out-of-vocabulary words into the training data enhance the performance of statistical machine translation systems for minority languages?
https://aclanthology.org/2020.wmt-1.131/,"Is the combination of BPE-dropout, lexical modifications, and backtranslation in the NRC's Transformer models effective in improving the performance of unsupervised and low-resource supervised machine translation tasks? Can the NRC's approach be generalized to other languages and domains?"
https://aclanthology.org/2020.wmt-1.132/,Can the use of pre-training on a related language pair improve the performance of low-resource supervised machine translation systems for translating from and into Upper Sorbian? Can the addition of synthetic data to the training data improve the unsupervised machine translation performance for translating from and into Upper Sorbian?
https://aclanthology.org/2020.wmt-1.133/,Can the use of scheduled multi-task learning and optimized subword segmentation improve the performance of low-resource language pairs in machine translation tasks?
https://aclanthology.org/2020.wmt-1.133/,Does the joint participation in WMT 2020 tasks with a focus on monolingual and related bilingual corpora enhance the translation accuracy of low-resource language pairs?
https://aclanthology.org/2020.wmt-1.134/,"Can the proposed approach of jointly pre-training the encoder and decoder using monolingual data from both languages improve the performance of the pseudo-supervised system on the target language, and does the use of backtranslation loss contribute to the overall quality of the translation model in the constrained setting of the WMT 2020 unsupervised machine translation shared task?"
https://aclanthology.org/2020.wmt-1.135/,Can a subword-level Transformer-based neural machine translation model trained on original training bitext achieve better performance on the Upper Sorbian-German language pair compared to a backtranslation approach using limited monolingual data?
https://aclanthology.org/2020.wmt-1.135/,"Can pretraining on a synthetic, backtranslated corpus followed by fine-tuning on the original parallel training data improve the performance of a subword-level Transformer-based neural machine translation model on the Upper Sorbian-German language pair?"
https://aclanthology.org/2020.wmt-1.136/,"Does the use of document-level evaluation metrics in machine translation affect the inter-annotator agreement between professional translators compared to sentence-level evaluation, and does this impact the accuracy of fluency and adequacy assessments? Does the effort required to annotate documents influence the agreement between annotators for error annotation and pairwise ranking?"
https://aclanthology.org/2020.wmt-1.137/,"Can MT models learn to accurately place markup tags using data augmentation, and how does the size of the augmented data affect the accuracy of tag placement?"
https://aclanthology.org/2020.wmt-1.137/,"Does the complexity of markup tags impact the performance of MT models trained with data augmentation, and what is the optimal level of tag complexity for language pairs of varying difficulty?"
https://aclanthology.org/2020.wmt-1.138/,Can a new benchmark for machine translation that covers thousands of language pairs and tools for creating state-of-the-art translation models improve the development of open translation tools and models for the world's languages?
https://aclanthology.org/2020.wmt-1.138/,Can the use of a comprehensive collection of diverse data sets in hundreds of languages with systematic language and script annotation enable the creation of realistic low-resource scenarios for training machine translation models?
https://aclanthology.org/2020.wmt-1.139/,"What is the impact of using paraphrased references on the performance of end-to-end system development for machine translation, as measured by human judgment and automatic metrics such as BLEU?"
https://aclanthology.org/2020.wmt-1.139/,How does the use of paraphrased references affect the trade-off between human judgment and automatic metrics in end-to-end system development for machine translation?
https://aclanthology.org/2020.wmt-1.140/,"Can an autoregressive model for lexically constrained APE be used to preserve 95% of the terminologies in the final translation, and how does it compare to non-autoregressive models in this aspect? Does a simple data augmentation technique improve the robustness of lexically constrained MT output?"
https://aclanthology.org/2021.wmt-1.0/,"Can machine learning models achieve high accuracy in translating news articles between Indo-European languages with limited training data, and how does the performance of these models compare to human editors in terms of post-editing accuracy?"
https://aclanthology.org/2021.wmt-1.0/,"Can machine translation systems be designed to adapt to specific news story structures and nuances, and how do different machine translation architectures impact the quality of the output for this task?"
https://aclanthology.org/2021.wmt-1.1/,"Can the proposed model achieve a BLEU score of at least 20 for the SMALL-TASK2 evaluation, and what are the computational resources required to train a model that achieves this score on the FLORES-101 dataset?"
https://aclanthology.org/2021.wmt-1.1/,"Can the proposed model improve the performance of the FLORES-101 dataset in the FULL-TASK setting, measured by a BLEU score of at least 25, and what are the implications of this improvement on the overall efficiency of the Dynabench environment?"
https://aclanthology.org/2021.wmt-1.2/,What are the most effective methods for improving the accuracy of multilingual translation models when translating from less-resourced languages such as Hausa and Zulu to more-resourced languages like English and Bengali?
https://aclanthology.org/2021.wmt-1.2/,Can the application of backtranslation and forward-translation techniques in conjunction with rules and language models enhance the overall quality of unconstrained multilingual translation systems?
https://aclanthology.org/2021.wmt-1.3/,"Can the proposed corpus filtering method significantly improve the performance of the English-Hausa translation system, as measured by the BLEU score?"
https://aclanthology.org/2021.wmt-1.3/,"Can the use of pre-trained English-German models for back-translation in the English-Hausa system enhance the quality of the translated Hausa news articles, as evaluated by human raters?"
https://aclanthology.org/2021.wmt-1.4/,How do the adaptations made to the baseline models from WMT20 improve the performance of the Russian–English machine translation system in the WMT21 evaluation campaign?
https://aclanthology.org/2021.wmt-1.4/,Can the use of different adaptation methods affect the accuracy of machine translation systems for the Russian–English language pair?
https://aclanthology.org/2021.wmt-1.5/,"Can the use of pre-trained models, specifically mBART50, improve the translation accuracy of German to French and French to German models, and how does fine-tuning versus training from scratch affect the final BLEU score of these models?"
https://aclanthology.org/2021.wmt-1.5/,Can the ensemble of fine-tuned and scratch-trained models improve the overall performance of German to French and French to German translations in terms of BLEU score?
https://aclanthology.org/2021.wmt-1.6/,Can the CUNI-DocTransformer NMT system be improved by incorporating better sentence-segmentation pre-processing and post-processing for error correction in numbers and units?
https://aclanthology.org/2021.wmt-1.6/,Can the CUNI-Marian-Baseline NMT system be evaluated using various backtranslation techniques to improve its performance in news translation tasks?
https://aclanthology.org/2021.wmt-1.7/,"Can the proposed multitask model achieve a BLEU score of 70% or higher for the Bengali ↔ Hindi translation task with a given amount of training data, and how does the knowledge distillation technique improve the performance of the bilingual model for the Hausa ↔ Zulu translation task?"
https://aclanthology.org/2021.wmt-1.8/,"Can a transformer-based model adapted from pre-trained mBART-25 be effectively used for backtranslation in the Icelandic→English subset of the 2021 WMT news translation task, and what is the impact of the number of backtranslation iterations on the model's performance?"
https://aclanthology.org/2021.wmt-1.8/,"Can the use of a pre-trained model in the English→Icelandic subset of the 2021 WMT news translation task, combined with iterative backtranslation, improve the model's translation accuracy compared to the baseline model?"
https://aclanthology.org/2021.wmt-1.9/,"Can the transformer-big architecture be effectively adapted for uni-directional translation tasks such as Icelandic→English, and can it improve the accuracy of news translation systems in both directions? Can the use of corpora filtering and back-translation improve the overall performance of the news translation system in Icelandic→English direction?"
https://aclanthology.org/2021.wmt-1.10/,"Can a politeness-and-formality-aware model improve the accuracy of Japanese to English news translation by incorporating a tagger to capture nuances of Japanese language, and how does this approach compare to using a standard Transformer model without such a tagger?"
https://aclanthology.org/2021.wmt-1.10/,"Can the use of language-independent BPE tokenization and n-best reranking improve the efficiency and fluency of Japanese to English news translation, compared to using language-dependent tokenization and standard reranking?"
https://aclanthology.org/2021.wmt-1.11/,"Can a deeper and wider network with relative positional encoding improve the translation performance of the MiSS system in the English-Chinese translation task, and how does the contrastive learning-reinforced domain adaptation method compare to self-supervised training and optimization objective switching in terms of model convergence and optimal performance? Can the proposed objective function used during the finetune phase with relatively small domain-related data improve the stability of the model's convergence and achieve better optimal performance in the Japanese-English translation task?"
https://aclanthology.org/2021.wmt-1.12/,"Can a simple system combining BPE dropout, sub-subword features and back-translation with a Transformer model achieve good results on low-resource language pairs in news translation tasks, and can it improve upon existing state-of-the-art results in biomedical translation tasks? Can the proposed system be adapted to achieve high accuracy in abstract and terminology translation subtasks for low-resource language pairs in news translation and biomedical translation tasks?"
https://aclanthology.org/2021.wmt-1.13/,"Can the proposed approach improve the accuracy of Hausa-English translation tasks by leveraging monolingual data via back-translation, and what is the performance metric for evaluating the effectiveness of the proposed approach?"
https://aclanthology.org/2021.wmt-1.13/,"Can the use of PB-SMT systems as baseline solutions impact the overall performance of the NMT models in the Hausa-English translation task, and how does the base Transformer architecture influence the results?"
https://aclanthology.org/2021.wmt-1.14/,What is the impact of data selection and filtering on the performance of deep neural machine translation models in the context of the European Commission's eTranslation service?
https://aclanthology.org/2021.wmt-1.14/,How can data-driven approaches to improving baseline systems contribute to the development of competitive NMT models in constrained language pairs like French-German?
https://aclanthology.org/2021.wmt-1.15/,Can the use of large-scale back-translation and fine-tuning on domain-specific subsets of training data improve the performance of Bengali↔Hindi news translation models?
https://aclanthology.org/2021.wmt-1.15/,Does the incorporation of Transformer-based architectures in news translation tasks lead to significant improvements in accuracy and efficiency compared to traditional machine translation methods?
https://aclanthology.org/2021.wmt-1.16/,Can the Volctrans system utilizing the Glancing Transformer achieve similar or better performance on the German-English translation task compared to the strong autoregressive models in future WMT competitions?
https://aclanthology.org/2021.wmt-1.16/,Can the Volctrans system with the Glancing Transformer be scaled to translate large volumes of text with high accuracy and fast processing time in a competitive scenario?
https://aclanthology.org/2021.wmt-1.17/,Can a combination of checkpoint averaging and model scaling improve the performance of a transformer-based sequence-to-sequence model on the WMT21 News and Biomedical Translation Tasks?
https://aclanthology.org/2021.wmt-1.17/,Does the use of a biomedically biased vocabulary and training on both news task data and biomedical data improve the performance of a neural machine translation system on the WMT’20 Biomedical Task?
https://aclanthology.org/2021.wmt-1.18/,"Can multilingual models be scaled to achieve high-quality representations of all languages without compromising translation accuracy, and how can the optimal model size be determined for each language direction?"
https://aclanthology.org/2021.wmt-1.18/,"What is the effect of ensemble methods on multilingual translation models in terms of BLEU score improvement, particularly in the context of the WMT2021 shared task?"
https://aclanthology.org/2021.wmt-1.19/,"Can the proposed ""one model one domain"" approach improve the performance of news translation systems by modeling news genre characteristics at both fine-tuning and decoding stages, and what is the BLEU score achieved by the constrained Chinese-English system in this task?"
https://aclanthology.org/2021.wmt-1.20/,"Can a Transformer-based approach improve the performance of Huawei's translation models on the WMT 2021 News Translation Shared Task, and how does the choice of pre-processing strategies affect the overall quality of the translated text?"
https://aclanthology.org/2021.wmt-1.21/,Can the hierarchical sentence-level tagging approach improve the performance of biomedical translation systems in handling texts with standardized structure?
https://aclanthology.org/2021.wmt-1.21/,Can unsupervised adaptation of retrieval-based strategies enhance the quality of financial news translation systems for the French-German language pair?
https://aclanthology.org/2021.wmt-1.22/,"Can the proposed Transformer-based architecture with novel variants achieve state-of-the-art results on the English->Chinese, English->Japanese, and Japanese->English translation tasks when using advanced finetuning approaches and boosted Self-BLEU based model ensemble?"
https://aclanthology.org/2021.wmt-1.22/,Can the proposed system's performance on the English->German translation task be improved by incorporating additional data filtering and large-scale synthetic data generation techniques?
https://aclanthology.org/2021.wmt-1.23/,"Can the proposed data filtering and selection techniques using rules, language models, and word alignment significantly improve the translation performance of ZengHuiMT on the English to Chinese direction, as measured by BLEU score, and how do the results compare to the baseline model without these techniques?"
https://aclanthology.org/2021.wmt-1.23/,"Can the use of monolingual data obtained through language models to facilitate back translation improve the translation performance of ZengHuiMT on the Chinese to English direction, as measured by BLEU score, and what are the key factors contributing to the improvement?"
https://aclanthology.org/2021.wmt-1.24/,"Can a Transformer-based architecture with knowledge distillation and ensemble methods outperform a single model in news translation tasks, as evidenced by the improvement in accuracy or processing time?"
https://aclanthology.org/2021.wmt-1.24/,"Can the use of back-translation in news translation tasks lead to better results, as indicated by the ranking of the final submission for the English-to-Hausa task?"
https://aclanthology.org/2021.wmt-1.25/,"How can the Transformer-DLCL architecture be improved upon in terms of fluency and coherence, and what role does back-translation play in enhancing model performance in NiuTrans neural machine translation systems?"
https://aclanthology.org/2021.wmt-1.25/,"Can the use of knowledge distillation and post-ensemble techniques improve the accuracy of NiuTrans systems in translating languages with limited training data, such as English2Hausa?"
https://aclanthology.org/2021.wmt-1.26/,"Can pre-trained neural machine translation models achieve state-of-the-art results on low-resource language pairs, and what are the key factors contributing to their success in such tasks?"
https://aclanthology.org/2021.wmt-1.26/,"Can the use of transfer learning improve the performance of low-resource language pairs by leveraging the knowledge from high-resource languages, and how can the performance be evaluated and measured in terms of BLEU score?"
https://aclanthology.org/2021.wmt-1.27/,"Can OpenNMT's default transformer model effectively handle corpus cleaning and preparation tasks such as replacing numbers for variables, solving upper/lower case issues, and providing good segmentation for most of the punctuation when using a custom python tokenizer?"
https://aclanthology.org/2021.wmt-1.27/,Does the use of BPE SentencePiece for subword units improve the performance of OpenNMT in handling syllabical word segmentation in a corpus?
https://aclanthology.org/2021.wmt-1.28/,"Can a transformer-based neural machine translation model utilizing pre-trained word embeddings improve the bilingual evaluation understudy (BLEU) score for Tamil-Telugu translations, and how does the model's performance compare to the state-of-the-art results achieved in the WMT21 shared task?"
https://aclanthology.org/2021.wmt-1.28/,"Can the use of monolingual data in pre-training the transformer model affect the translation edit rate (TER) score for Telugu-Tamil translations, and what are the implications for the overall performance of the model?"
https://aclanthology.org/2021.wmt-1.29/,"Can transformer-based Neural Machine Translation improve translation accuracy when using language similarity as a feature for Tamil-Telugu and Telugu-Tamil pairs, and how does script conversion affect the results?"
https://aclanthology.org/2021.wmt-1.29/,Can the use of different subword configurations impact the performance of single model training for both directions in Neural Machine Translation for Tamil-Telugu and Telugu-Tamil language pairs?
https://aclanthology.org/2021.wmt-1.30/,Can the Marian neural machine translation toolkit be improved upon by using different byte pair encoding strategies in the training of Catalan-Spanish and Portuguese-Spanish translation systems?
https://aclanthology.org/2021.wmt-1.30/,Can the BLEU scores of the SEBAMAT system be increased by incorporating comparable corpora into the training data of the translation systems?
https://aclanthology.org/2021.wmt-1.31/,Can the addition of Byte Pair Encoding (BPE) improve the performance of a Transformer-based Neural Machine Translation system when used in conjunction with a pre-trained MultiBPEmb model for subword tokenization?
https://aclanthology.org/2021.wmt-1.31/,Does the use of a 6-layer encoder-decoder model in a Neural Machine Translation system lead to better translation outcomes compared to using a model with fewer layers?
https://aclanthology.org/2021.wmt-1.32/,What are the optimal tokenization schemes for training statistical models in the Tamil ⇐⇒ Telugu language pair for the highest accuracy in machine translation tasks?
https://aclanthology.org/2021.wmt-1.32/,Can the proposed tokenization schemes improve the processing time and user satisfaction of the submitted systems for the Tamil ⇐⇒ Telugu language pair in the Similar Language Translation Shared Task 2021?
https://aclanthology.org/2021.wmt-1.33/,What is the impact of incorporating curriculum learning in training stages on the performance of a neural machine translation model for the English-German language pair in terms of TER and BLEU scores?
https://aclanthology.org/2021.wmt-1.33/,How does the application of Multi-Task Learning Strategy with Dynamic Weight Average during fine-tuning affect the performance of the APE system in terms of translation quality and processing time?
https://aclanthology.org/2021.wmt-1.34/,Can APE models improve the accuracy of machine translation systems when fine-tuned on a diverse set of APE samples from previous editions of the WMT shared task?
https://aclanthology.org/2021.wmt-1.34/,Can the use of WikiMatrix for adapting MT models to the task domain improve the overall performance of APE systems on the WMT'21 test set?
https://aclanthology.org/2021.wmt-1.35/,Can the use of a Transformer-based architecture and corpus filtering improve the accuracy of Russian-to-Chinese machine translation?
https://aclanthology.org/2021.wmt-1.35/,Can the combination of system pipelines and model ensembles enhance the processing time and translation quality of the Russian-to-Chinese translator in the Triangular Machine Translation Task?
https://aclanthology.org/2021.wmt-1.36/,"Can a Transformer-based architecture with larger parameter sizes outperform the baseline results on the Russian-to-Chinese task at WMT 2021, and what are the optimal training strategies that lead to the highest BLEU score?"
https://aclanthology.org/2021.wmt-1.36/,Can the use of pre-processing and filtering techniques on the provided bilingual data improve the performance of the Multilingual Translation and Back Translation strategies on the Russian-to-Chinese task at WMT 2021?
https://aclanthology.org/2021.wmt-1.37/,Can the proposed multilingual neural machine translation approach improve the performance of the baseline model in the Russian-to-Chinese task by leveraging English resources such as parallel data?
https://aclanthology.org/2021.wmt-1.37/,"Can the use of data filtering, data selection, fine-tuning, and post-editing techniques enhance the BLEU score of the baseline model in the Russian-to-Chinese task?"
https://aclanthology.org/2021.wmt-1.38/,What is the effectiveness of using pivot language-based transfer learning in improving the translation quality of non-English language pairs compared to baseline transformer-based neural machine translation systems in terms of BLEU score?
https://aclanthology.org/2021.wmt-1.38/,"Can the development of neural machine translation systems for non-English language pairs be significantly improved using transfer learning techniques leveraging the resources of a closely related language, such as English?"
https://aclanthology.org/2021.wmt-1.39/,Can the use of averaging checkpoints and model ensemble techniques improve the performance of the Transformer-based translation model for Russian-to-Chinese machine translation tasks?
https://aclanthology.org/2021.wmt-1.39/,Does the transformation of indirect parallel data into direct data improve the performance of bilingual machine translation systems compared to multi-lingual machine translation systems?
https://aclanthology.org/2021.wmt-1.40/,Can pre-trained models fine-tuned on Germanic languages improve translation performance for Romance languages?
https://aclanthology.org/2021.wmt-1.40/,Can transfer learning from an unrelated language pair improve the performance of low-resource language translation systems?
https://aclanthology.org/2021.wmt-1.41/,"Can a machine learning model be trained to accurately translate specialized terms with varying surface forms while preserving overall translation quality, and what is the impact of lemmatization on the performance of such a model in the English-French language pair?"
https://aclanthology.org/2021.wmt-1.42/,Can the proposed multilingual semi-supervised machine translation model based on XLM-RoBERTa achieve better performance on the Wikipedia cultural heritage articles for the four Romance languages by incorporating additional shallow decoder initialization techniques?
https://aclanthology.org/2021.wmt-1.42/,Can the use of a pre-trained language model like XLM-RoBERTa as a starting point for multilingual machine translation lead to improved results on the Subtask 2 of the WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task?
https://aclanthology.org/2021.wmt-1.43/,"How do multilingual pre-training and fine-tuning approaches impact the performance of low-resource language translation models for North Germanic languages, and what are the key factors that contribute to their success?"
https://aclanthology.org/2021.wmt-1.43/,"Can multilingual models trained on a single source language outperform ensembled models trained on multiple source languages for translating to/from Icelandic, Norwegian-Bokmal, and Swedish?"
https://aclanthology.org/2021.wmt-1.44/,Can the proposed TenTrans system improve the translation quality from Catalan to Occitan using pivot-based methods and multilingual models?
https://aclanthology.org/2021.wmt-1.44/,Can the pre-trained model fine-tuning process improve the BLEU scores of low-resource language pairs like Catalan to Romanian and Italian?
https://aclanthology.org/2021.wmt-1.45/,"Can the FLORES101_MM100 model be improved to achieve higher BLEU scores through selective fine-tuning on specific language pairs, and what are the key factors that contribute to the model's performance in the WMT 2021 task?"
https://aclanthology.org/2021.wmt-1.46/,"Can TelU-KU models achieve significant improvements in BLEU scores when using a smaller training dataset for multilingual machine translation, specifically for the Indonesian-Tagalog and Malay-Tagalog language pairs?"
https://aclanthology.org/2021.wmt-1.46/,Can the flores101_mm100_175M model be further optimized using hyperparameter tuning to achieve BLEU scores above 15 for the TelU-KU models on the five Southeast Asian languages?
https://aclanthology.org/2021.wmt-1.47/,"Can MMTAfrica outperform state-of-the-art systems in terms of BLEU score when translating from English to African languages, and what specific improvements can be made to the BT&REC objective to further boost translation quality for non-African languages?"
https://aclanthology.org/2021.wmt-1.48/,Can bilingual translation systems improve multilingual translation systems using data augmentation techniques such as back-translation and knowledge distillation?
https://aclanthology.org/2021.wmt-1.48/,Can bilingual translation systems influence the performance of multilingual translation systems in terms of BLEU scores?
https://aclanthology.org/2021.wmt-1.49/,"Can the constrained sampling method improve multilingual translation performance compared to other back-translation methods, and how does the size of the vocabulary affect the translation accuracy?"
https://aclanthology.org/2021.wmt-1.49/,Does the use of extensive monolingual English data provide a significant improvement in multilingual translation performance compared to smaller vocabularies?
https://aclanthology.org/2021.wmt-1.50/,"Can the proposed multilingual machine translation system be improved further by incorporating domain-specific knowledge into the model's architecture, and how does the incorporation of synthetic data affect the overall translation performance on the target subset of languages?"
https://aclanthology.org/2021.wmt-1.50/,"Does the use of similarity regularizer in zero-shot multilingual machine translation have a significant impact on the final translation accuracy, and how does it compare to other techniques used in the proposed system?"
https://aclanthology.org/2021.wmt-1.51/,"How does the use of data preprocessing techniques impact the performance of a standard Seq2Seq Transformer model in the Large Scale Multilingual Translation Task, and what specific data preprocessing methods were used to achieve the highest ranking in the Indonesian to Javanese translation task?"
https://aclanthology.org/2021.wmt-1.51/,Can a standard Seq2Seq Transformer model achieve comparable performance to top-performing models in other language pairs if it relies solely on data preprocessing techniques and no advanced model architectures or training methods?
https://aclanthology.org/2021.wmt-1.52/,"Can the use of forward/back-translation improve the translation results for multilingual machine translation systems, and how does it compare to other methods such as model averaging?"
https://aclanthology.org/2021.wmt-1.52/,Does the application of knowledge distillation in conjunction with other techniques like in-domain data selection and gradual fine-tuning enhance the performance of multilingual machine translation systems in specific domains?
https://aclanthology.org/2021.wmt-1.53/,Can a fine-tuned DeltaLM model with progressive learning and iterative back-translation approaches achieve better results in unconstrained large-scale multilingual machine translation compared to its pre-trained counterparts?
https://aclanthology.org/2021.wmt-1.53/,Can the use of parallel data sources and progressive learning in multilingual machine translation improve the performance of the model on constrained tracks such as the small tracks in WMT21 shared task?
https://aclanthology.org/2021.wmt-1.54/,"Can a transformer-based architecture with pre-processing and filtering be used to improve the performance of multilingual machine translation on large-scale datasets, and how does it compare to ensemble methods such as back translation and adapter fine-tuning?"
https://aclanthology.org/2021.wmt-1.54/,"Can the use of a single multilingual model trained on a large-scale dataset with various strategies improve the translation quality and efficiency in constrained conditions, and what are the key factors that affect its performance?"
https://aclanthology.org/2021.wmt-1.55/,"Can machine translation systems be robustly ranked based on human judgments of quality using a segment rating protocol that accounts for document context and outliers, and how does this impact the validity of WMT news task system rankings?"
https://aclanthology.org/2021.wmt-1.55/,"Does the ease or difficulty of translating different documents affect the system rankings in the news translation task, and what implications does this have for annotation task composition?"
https://aclanthology.org/2021.wmt-1.56/,"How can the performance of automatic metrics in predicting translation quality rankings be evaluated against human judgements on pairwise systems, and what are the most accurate metrics for this task?"
https://aclanthology.org/2021.wmt-1.56/,"What are the effects of using a single metric, such as BLEU, on the development of machine translation models and their deployment?"
https://aclanthology.org/2021.wmt-1.57/,Can a supervised machine learning model using a transformer-based architecture be trained to predict the quality of automatically-generated questions and answers for evaluating the quality of Machine Translation systems?
https://aclanthology.org/2021.wmt-1.57/,Can the proposed metric for system-level MT evaluation outperform or be comparable to existing metrics such as BLEU and METEOR in terms of accuracy and robustness?
https://aclanthology.org/2021.wmt-1.58/,"What are the strengths and weaknesses of BERTScore in detecting content word differences between candidate and reference translations, and do they relate to known weaknesses of BERT?"
https://aclanthology.org/2021.wmt-1.58/,"Does BERTScore perform better than other automatic metrics in detecting semantic and syntactic errors in machine translation, particularly in cases where the candidate and reference sentences are lexically or stylistically similar?"
https://aclanthology.org/2021.wmt-1.59/,"What are the key factors that influence the performance of multilingual machine translation models in the Turkic language family, and how can they be improved to better serve the needs of speakers of these languages?"
https://aclanthology.org/2021.wmt-1.59/,How can the development of high-quality parallel corpora for the Turkic language family be facilitated to support the evaluation and improvement of machine translation systems in these languages?
https://aclanthology.org/2021.wmt-1.60/,"Can machine translation systems be trained to reduce gender bias in occupation translation, as measured by the accuracy of translations of neutral occupation names, using a dataset that includes both masculine and feminine versions of the occupations? Can machine translation systems be trained to reduce gender bias in occupation translation, using a dataset that includes sentences with gender-biased verbs, as measured by the accuracy of translations of sentences with gender-biased verbs?"
https://aclanthology.org/2021.wmt-1.61/,Does the proposed method for adding a new language to an existing multilingual NMT model result in a significant improvement in translation accuracy for the new language when compared to the initial languages? Can the proposed method be applied to large-scale datasets like ParaCrawl to achieve comparable performance with the more costly alternatives?
https://aclanthology.org/2021.wmt-1.62/,Can a machine translation system be able to accurately capture the nuances of context-aware ellipsis in document-level translations from English into Brazilian Portuguese?
https://aclanthology.org/2021.wmt-1.62/,Can the proposed corpus be used to effectively evaluate the performance of MT systems on addressing context-aware issues such as lexical ambiguity and reference in document-level translations?
https://aclanthology.org/2021.wmt-1.63/,What is the impact of combining multiple language adapters on the performance of cross-lingual transfer in machine translation when domain-specific adapters are not available for certain languages?
https://aclanthology.org/2021.wmt-1.63/,How does the use of back-translation with domain adapters improve the BLEU score for target languages without in-domain data in machine translation?
https://aclanthology.org/2021.wmt-1.64/,"Can NMT models learn and utilize domain information effectively to improve clustering performance, and what is the comparison of clustering results between NMT and pre-trained language models in document-level clustering?"
https://aclanthology.org/2021.wmt-1.64/,"Can NMT models be used as a source of unsupervised clusters for domain adaptation, and what is the performance of this approach compared to using external language models for text clustering?"
https://aclanthology.org/2021.wmt-1.65/,Can CmBT improve the translation of multi-sense words using cross-lingual contextual word representations for unseen word senses?
https://aclanthology.org/2021.wmt-1.65/,Does the application of bilingual lexicon induction on cross-lingual contextual word representations enhance the quality of word sense disambiguation in machine translation systems?
https://aclanthology.org/2021.wmt-1.66/,"Can a deep learning-based approach to quality estimation for machine translation be able to detect meaning-altering perturbations with high accuracy, and what is the relationship between the model's ability to do so and its overall performance?"
https://aclanthology.org/2021.wmt-1.66/,"Does the correlation between human judgements and QE systems' performance improve when QE systems are evaluated on their ability to detect meaning-altering perturbations, rather than relying on manual quality annotation?"
https://aclanthology.org/2021.wmt-1.67/,Can machine learning models using GPU hardware achieve faster translation speeds with minimal impact on quality compared to single-core CPU hardware for translating large volumes of text?
https://aclanthology.org/2021.wmt-1.67/,Can a batched throughput approach improve the efficiency of machine translation models by reducing latency and increasing translation capacity for applications requiring high-speed processing?
https://aclanthology.org/2021.wmt-1.68/,"Can machine learning models achieve high accuracy in translating medical terminology with high precision and consistency across different language pairs, particularly for COVID-19 specific terms? Can a benchmarking framework be effectively established to evaluate the quality of terminology translation systems in the medical domain?"
https://aclanthology.org/2021.wmt-1.69/,"Can machine learning models be trained to improve the accuracy of summarization models for biomedical texts, specifically for animal experiment summaries, using a combination of rule-based and deep learning approaches?"
https://aclanthology.org/2021.wmt-1.69/,Can the development of a multilingual summarization model for the English/Basque language pair be improved through the use of pre-trained multilingual models and fine-tuning techniques?
https://aclanthology.org/2021.wmt-1.70/,What is the performance of state-of-the-art neural machine translation systems in predicting the quality of output for unseen languages in zero-shot settings?
https://aclanthology.org/2021.wmt-1.70/,How does the addition of post-edited data improve the accuracy of quality estimation models in predicting sentences with catastrophic errors?
https://aclanthology.org/2021.wmt-1.71/,"Can machine learning models be trained to improve the translation accuracy for minority languages like German and Upper Sorbian, and how do the results compare to those for more widely spoken languages?"
https://aclanthology.org/2021.wmt-1.71/,"Can the use of digital data from minority language communities effectively support the development of low-resource supervised machine translation systems, such as those for Russian and Chuvash?"
https://aclanthology.org/2021.wmt-1.72/,"How do the automatic metrics perform in correlating with human ratings on the news and TED talks domains, and what is the impact of using expert-based MQM annotation versus DA scores on the evaluation of automatic metrics in translation systems?"
https://aclanthology.org/2021.wmt-1.72/,"Can the automatic metrics evaluate the robustness of translations across different domains, specifically English to German, English to Russian, and Chinese to English, and how do the results vary when using reference translations?"
https://aclanthology.org/2021.wmt-1.73/,Can the use of knowledge distillation in machine translation models improve efficiency on multi-core CPU hardware compared to using a simpler decoder architecture like the simple recurrent unit (SSRU)?
https://aclanthology.org/2021.wmt-1.73/,Can the application of 4-bit log quantization and pruning techniques on GPU hardware with tensorcores improve the processing speed of machine translation models?
https://aclanthology.org/2021.wmt-1.74/,"Can the proposed sentence-level teacher-student distillation technique improve the efficiency of translation models using Huawei Noah's Bolt library while maintaining high translation quality, as measured by BLEU score? Can the use of INT8 quantization, self-defined GEMM operator, and caching techniques in conjunction with the proposed technique further enhance the efficiency of the translation models on a single CPU core?"
https://aclanthology.org/2021.wmt-1.75/,What is the impact of combining lightweight Transformer architectures with knowledge distillation strategies on the efficiency of the NiuTrans system?
https://aclanthology.org/2021.wmt-1.75/,Can knowledge distillation and graph optimization improve the translation efficiency of the NiuTrans system while maintaining its quality?
https://aclanthology.org/2021.wmt-1.76/,Can the TenTrans's self-developed open-source multilingual training platform improve the efficiency of transformer models when compared to existing state-of-the-art methods?
https://aclanthology.org/2021.wmt-1.76/,Can the optimized inference toolkit for transformer models using techniques such as attention caching and kernel fusion achieve higher translation speeds without compromising on accuracy?
https://aclanthology.org/2021.wmt-1.77/,"Does the proposed method of augmenting training data to encourage copy behavior when encountering terminology constraints improve the model's ability to satisfy most terminology constraints, and does constraint token masking improve model generalization, measured by the percentage of satisfied terminology constraints and translation quality? Does the use of a Transformer-based architecture with the proposed modifications improve translation quality for English to French, Russian, and Chinese machine translation tasks, as measured by BLEU score?"
https://aclanthology.org/2021.wmt-1.78/,"Can the proposed approach of pre-training with target lemma annotations and fine-tuning with exact target annotations improve the term consistency of the generated translations in the En→Fr language direction, as measured by the BLEU score?"
https://aclanthology.org/2021.wmt-1.78/,"Can the incorporation of in-domain data and back-translation methods into the proposed approach enhance its translation quality in terms of syntactic correctness and fluency, as evaluated by the human evaluation metric?"
https://aclanthology.org/2021.wmt-1.79/,"Can OpenNMT and JoeyNMT toolkits achieve comparable results in translating English to French terminology with the WMT 2021 dataset, and how does the choice of toolkit affect the linguistic properties of the translated output?"
https://aclanthology.org/2021.wmt-1.79/,"Does the inclusion of text genres in the evaluation script improve the accuracy of the terminology translation, and how does it impact the overall quality of the translated output?"
https://aclanthology.org/2021.wmt-1.80/,"Can Tilde MT systems effectively leverage external terminologies for less-resourced languages and emerging domains with limited in-domain data, and what are the key challenges in achieving high accuracy in terminology use for these languages and domains? Can Tilde MT systems dynamically integrate terminology at the time of translation, and how does the use of external terminologies impact the overall performance of the translation systems?"
https://aclanthology.org/2021.wmt-1.81/,"Can a machine learning model be trained to accurately translate specialized terms while preserving the overall translation quality in a given language pair, and what is the most effective way to incorporate lemmatization in the training process to improve the model's performance in producing correct surface forms of the words?"
https://aclanthology.org/2021.wmt-1.82/,"Can a modified Dinu et al. (2019) soft-constrained approach to terminology translation be improved upon using deep learning techniques, specifically neural networks, to enhance its accuracy and efficiency?"
https://aclanthology.org/2021.wmt-1.82/,Can PROMT Smart Neural Dictionary (SmartND) achieve state-of-the-art results in English to Russian terminology translation using a combination of machine learning algorithms and large-scale bilingual dictionaries?
https://aclanthology.org/2021.wmt-1.83/,Can the use of morphosyntactic annotation with placeholders improve the accuracy of terminology insertion in machine translation networks?
https://aclanthology.org/2021.wmt-1.83/,Does the injection of target constraints in the source stream improve the overall performance of terminology insertion in machine translation networks?
https://aclanthology.org/2021.wmt-1.84/,"Can a terminology data augmentation strategy based on Transformer model improve the performance of machine translation systems when using term translations in training data, and what is the optimal approach to incorporate phrase tables extracted from bilingual corpus into the training data?"
https://aclanthology.org/2021.wmt-1.85/,Can the proposed multilingual NMT systems with Transformer architecture achieve better performance on out-of-domain tasks compared to in-domain tasks when trained on IR and domain adaptation techniques?
https://aclanthology.org/2021.wmt-1.85/,"Can the combination of in-domain and out-domain parallel corpora improve the accuracy of multilingual NMT systems for translating German, Spanish, and French to English?"
https://aclanthology.org/2021.wmt-1.86/,Can using out-of-domain data improve the performance of biomedical translation tasks when combined with in-domain data in the context of transformer-based architectures like the one used in this study?
https://aclanthology.org/2021.wmt-1.86/,Can the addition of in-domain sub-words generated through a simple bpe optimization method enhance the accuracy of biomedical translation tasks when training a transformer model on a mixed dataset of in-domain and out-of-domain data?
https://aclanthology.org/2021.wmt-1.87/,"Can a combination of finetuning order and terminology dictionaries improve the performance of neural machine translation systems on the WMT21 biomedical translation task, and what is the impact on overfitting and under-translation? Can the use of ensemble decoding methods alleviate the issues of overfitting and under-translation in neural machine translation systems for biomedical translation?"
https://aclanthology.org/2021.wmt-1.88/,"Can the pretraining strategy using mBART improve the translation quality of machine translation models in low-resource language pairs, and how does it compare to other pretraining strategies in terms of BLEU scores?"
https://aclanthology.org/2021.wmt-1.88/,Does the use of back-translation in conjunction with pretraining improve the fluency and accuracy of machine translation models in the German-French-Spanish⇒English language direction?
https://aclanthology.org/2021.wmt-1.89/,"Can HuaweiTSC's English→Chinese and English→German translation models outperform the baseline in terms of BLEU scores, and what are the key factors that contribute to this performance?"
https://aclanthology.org/2021.wmt-1.89/,How do the pre-processing and model enhancement strategies employed by HuaweiTSC improve the overall translation performance on the WMT21 biomedical test set?
https://aclanthology.org/2021.wmt-1.91/,Can a multitask learning approach using a pre-trained XLM-Roberta as predictor and task-specific classifier or regressor as estimator improve the performance of the systems in the Word and Sentence-Level Post-editing Effort task and Critical Error Detection task in the WMT 2021 QE Shared Task?
https://aclanthology.org/2021.wmt-1.91/,Does incorporating post-edit sentence or additional high-quality translation sentence into the Predictor-Estimator framework using multitask learning or encoding it directly with predictors improve the results of the systems in the Sentence-Level Direct Assessment task in the WMT 2021 QE Shared Task?
https://aclanthology.org/2021.wmt-1.92/,Can the proposed mBERT-based regression models achieve comparable Pearson's correlation with the baseline system for the zero-shot setting?
https://aclanthology.org/2021.wmt-1.92/,Can the proposed ensemble system outperform the baseline system in terms of MAE/RMSE for several language pairs in the zero-shot setting?
https://aclanthology.org/2021.wmt-1.93/,"Can the proposed Levenshtein Transformer approach improve the accuracy of post-editing effort estimation for machine translation output compared to the OpenKiwi-XLM baseline, and how does data augmentation with pseudo post-editing affect the performance of the system?"
https://aclanthology.org/2021.wmt-1.94/,"Can a massively multilingual Transformer-based language model trained on a subset of target languages achieve comparable performance to models pre-trained on all target languages, and can adapter-based methods effectively extend these models to new languages and unseen scripts?"
https://aclanthology.org/2021.wmt-1.94/,"Can adapter-based methods improve the performance of massively multilingual language models when extended to unseen scripts, and do these models achieve comparable performance to pre-trained models on the respective languages?"
https://aclanthology.org/2021.wmt-1.95/,What is the feasibility of using two pre-trained monolingual encoders to improve the stability of single encoder-based quality estimation models for machine translation tasks?
https://aclanthology.org/2021.wmt-1.95/,Can the incorporation of cross-attention networks in the exchange of information between two pre-trained monolingual encoders enhance the performance of word-level and sentence-level quality estimation systems?
https://aclanthology.org/2021.wmt-1.96/,"Can the proposed sequence classification model achieve higher accuracy in critical error detection by incorporating features related to toxicity, named-entities, and sentiment, compared to the base classifier alone?"
https://aclanthology.org/2021.wmt-1.96/,"Can the use of a weighted sampler improve the performance of the model on the development set for critical error detection, particularly in cases with unbalanced data?"
https://aclanthology.org/2021.wmt-1.97/,Can a multilingual pre-trained language model achieve better performance in the WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment when fine-tuned with in-domain synthetic data and gold labeled data through an iterative training pipeline?
https://aclanthology.org/2021.wmt-1.97/,Can the knowledge distillation process improve the efficiency of the multilingual system while maintaining its competitive performance in multilingual and individual language pair settings?
https://aclanthology.org/2021.wmt-1.98/,Can the use of token-oriented metrics improve the performance of QE models in translation quality estimation?
https://aclanthology.org/2021.wmt-1.98/,Will the combination of self-supervised and QE pretraining lead to better results for downstream tasks in machine translation?
https://aclanthology.org/2021.wmt-1.99/,What is the effect of incorporating uncertainty features into machine translation models on the performance of quality estimation systems?
https://aclanthology.org/2021.wmt-1.99/,How does the use of pre-trained language models like XLM-Roberta impact the accuracy of quality estimation systems in machine translation tasks?
https://aclanthology.org/2021.wmt-1.100/,"Can attention weight matrices be effectively used to estimate post-editing effort in machine translation, and how does this approach compare to traditional methods using general metrics? Can a glass-box approach based on attention weights be trained with a small amount of high-cost labelled data, and what is its performance in the absence of such data?"
https://aclanthology.org/2021.wmt-1.101/,Can multilingual models trained on OpenKiwi predictor-estimator architecture with pre-trained multilingual encoders and adapters achieve higher accuracy in direct assessment tasks compared to models without these enhancements?
https://aclanthology.org/2021.wmt-1.101/,Can the use of uncertainty-related objectives and features improve the performance of multilingual models on post-editing effort tasks in the WMT 2021 Shared Task on Quality Estimation?
https://aclanthology.org/2021.wmt-1.102/,"Can a back-translation approach improve the performance of a baseline system in low-resource supervised machine translation tasks, and to what extent can the initialization from a parent model further enhance the results? Can multi-task training with varying schedules improve the performance of unsupervised machine translation systems for low-resource languages such as Upper Sorbian and Lower Sorbian?"
https://aclanthology.org/2021.wmt-1.103/,"Can a multilingual transformer-based architecture be trained to improve the performance of an unsupervised machine translation system from a high-resource language to a low-resource one, and what is the effect of the order in which offline and online back-translation are used during training on this performance?"
https://aclanthology.org/2021.wmt-1.103/,"How effective is a novel method for initializing the vocabulary of an unseen language on the performance of an unsupervised machine translation system, and what are the improvements in BLEU scores achieved through this method?"
https://aclanthology.org/2021.wmt-1.104/,What is the impact of pre-training on low-resource machine translation systems for German↔Upper Sorbian and Russian↔Chuvash languages?
https://aclanthology.org/2021.wmt-1.104/,How effective is iterated back-translation with monolingual data in improving the performance of the unsupervised German↔Lower Sorbian system?
https://aclanthology.org/2021.wmt-1.105/,Can a pre-trained MASS model fine-tuned using iterative back-translation achieve comparable performance on the German-Lower Sorbian language pair as the pre-trained model fine-tuned using parallel data?
https://aclanthology.org/2021.wmt-1.105/,Can iterative back-translation improve the performance of the German-Lower Sorbian model when initialized with a pre-trained German-Upper Sorbian model?
https://aclanthology.org/2021.wmt-1.106/,"Can neural machine translation systems improve their performance on low-resource languages by utilizing transfer learning from high-resource languages, and can data filtering and backtranslation enhance the robustness of unsupervised machine translation systems? Can the application of ensemble methods and BPE-dropout techniques increase the accuracy of machine translation systems when translating between low-resource languages?"
https://aclanthology.org/2021.wmt-1.107/,Can a Transformer-based model with dual transfer and iterative back-translation be able to improve the accuracy of Very Low Resource Supervised Machine Translation by utilizing selected finetuning techniques? Can the combination of dual transfer and ensemble methods lead to significant improvements in BLEU scores for neural machine translation systems in low-resource languages?
https://aclanthology.org/2021.wmt-1.108/,"What is the effect of using pre-trained language models on the automatic tuning of hLEPOR metric's weighting parameters, and how does it impact the agreement between human evaluations and the proposed customised hLEPOR metric?"
https://aclanthology.org/2021.wmt-1.108/,How does cushLEPOR perform in terms of agreement with pre-trained language models and human evaluations using MQM and pSQM framework on English-German and Chinese-English language pairs?
https://aclanthology.org/2021.wmt-1.109/,"Does the MTEQA metric effectively evaluate the quality of Machine Translation systems at the system-level, and can it be improved by incorporating more information from the whole translation?"
https://aclanthology.org/2021.wmt-1.109/,Can the MTEQA framework achieve comparable performance with other state-of-the-art solutions when using the entire translation information?
https://aclanthology.org/2021.wmt-1.110/,Can a pre-trained model fine-tuned on z-normalized Multidimensional Quality Metric (MQM) scores achieve higher correlations with MQM than a model fine-tuned on Direct Assessments?
https://aclanthology.org/2021.wmt-1.110/,"Can a reference-free COMET model outperform a reference-based model on MQM correlation, and how does its performance compare to the best COMET model from 2020?"
https://aclanthology.org/2021.wmt-1.111/,Can ensemble-based approaches improve the accuracy of machine translation quality evaluation using a combination of established metrics in monolingual and cross-lingual settings?
https://aclanthology.org/2021.wmt-1.111/,Does a reference-free baseline significantly outperform the commonly-used BLEU and METEOR measures in evaluating machine translation quality?
https://aclanthology.org/2021.wmt-1.112/,Can a multilingual model fine-tuned on past years' metric task outperform its non-fine-tuned counterpart on a synthetic negative example-based approach using Pearson's correlation score as the evaluation metric?
https://aclanthology.org/2021.wmt-1.112/,Does fine-tuning a model on pseudo-negative examples derived from a multilingual model fine-tuned on a corpus of past years' metric task improve its performance on system-level translations compared to the non-fine-tuned model?
https://aclanthology.org/2021.wmt-1.113/,Can we develop a model that jointly leverages the strengths of source-included and reference-only models to improve the performance of trainable metrics?
https://aclanthology.org/2021.wmt-1.113/,"Can we design a data denoising strategy to enhance the fine-tuning process of the model on the BLEURT task, leading to improved correlations with human annotations?"
https://aclanthology.org/2021.wmt-1.114/,"Can the proposed semi-automated test suite be refined to better evaluate the accuracy of idioms in machine translation systems, and do the top-performing systems (Online-W and Facebook-AI) utilize any specific linguistic features to improve their test suite accuracy for German to English translation?"
https://aclanthology.org/2021.wmt-1.115/,"Can neural networks be pruned to achieve significant speed-up without compromising on quality, specifically by removing entire rows, columns, or blocks of parameters during training?"
https://aclanthology.org/2021.wmt-1.115/,"How do the sparsity patterns of pruned feedforward and attention layers in encoder and decoder models vary across different language pairs, and can these patterns be leveraged to optimize model efficiency?"
https://aclanthology.org/2021.wmt-1.116/,"What are the most informative full sentences and phrases in the new domain that can be selected from unlabelled data to improve the performance of an out-of-domain NMT model in active learning settings, and how can they be effectively incorporated into the NMT system to leverage their structural properties and improve translation accuracy? Can the proposed active learning approach be generalized to other NMT systems and translation tasks to address domain shift and improve overall performance?"
https://aclanthology.org/2021.wmt-1.117/,Can a machine learning approach that learns weights for multiple sentence-level features improve the performance of Neural Machine Translation systems on noisy corpora by effectively filtering out low-quality data?
https://aclanthology.org/2021.wmt-1.117/,Does the proposed method generalize to other language pairs and maintain its performance when applied to different types of noise in the data?
https://aclanthology.org/2021.wmt-1.118/,"Can a non-autoregressive neural machine translation model achieve better monotonicity in translations by reordering and refining a full sentence translation corpus using word alignment, and does this approach improve BLEU scores? Does training a wait-k simultaneous translation model on a reordered-and-refined corpus lead to more monotonically aligned translations than traditional training methods?"
https://aclanthology.org/2021.wmt-1.119/,Does the proposed method improve the quality of simultaneous translation by reducing the latency in the English-to-Japanese translation process?
https://aclanthology.org/2021.wmt-1.119/,Can the proposed method's quality-latency trade-off be further improved by adjusting the threshold for determining when to start translating in English-to-Japanese simultaneous translation?
https://aclanthology.org/2021.wmt-1.120/,"Can CorefCL improve the translation quality of context-aware NMT models by incorporating coreference information and corrupting detected coreference mentions in the contextual sentence, and how does it compare to existing methods in terms of BLEU score on document-level translation tasks?"
https://aclanthology.org/2021.wmt-1.120/,Does CorefCL's data augmentation and contrastive learning scheme effectively improve coreference resolution in the English-German contrastive test suite and what are the implications of this improvement for downstream NMT applications?
https://aclanthology.org/2022.wmt-1.0/,What is the impact of using reference-based direct assessment versus a combination of direct assessment and scalar quality metric on the evaluation of machine translation systems in the General Machine Translation Task at WMT 2022?
https://aclanthology.org/2022.wmt-1.0/,Can machine translation systems trained on different language pairs and domains achieve comparable performance when evaluated using reference-based direct assessment versus a combination of direct assessment and scalar quality metric?
https://aclanthology.org/2022.wmt-1.1/,"What is the performance of neural-based learned metrics on the WMT22 News Translation Task in terms of correlation with human ratings, and how do they compare to overlap metrics like Bleu, spBleu, and chrf?"
https://aclanthology.org/2022.wmt-1.1/,Can the use of expert-based human evaluation via Multidimensional Quality Metrics (MQM) improve the reliability and accuracy of automatic MT evaluation metrics in the context of the WMT22 News Translation Task?
https://aclanthology.org/2022.wmt-1.2/,"Can neural machine translation systems achieve high accuracy in predicting sentence-level quality using the Multidimensional Quality Metrics, and how can this metric be improved to better capture the nuances of human quality evaluation for under-resourced languages such as English-Marathi?"
https://aclanthology.org/2022.wmt-1.2/,"Can the Direct Assessments and post-edit data (MLQE-PE) approach be applied to other language pairs beyond English, and what are the implications for the development of explainable quality estimation models in low-resource languages?"
https://aclanthology.org/2022.wmt-1.3/,How can transformer-based machine translation models be optimized for improved latency without compromising translation accuracy on GPU and single-core CPU hardware?
https://aclanthology.org/2022.wmt-1.3/,What is the optimal trade-off between model size and translation efficiency in terms of MB and words translated per dollar for multi-core CPU hardware?
https://aclanthology.org/2022.wmt-1.4/,"Can a machine learning model be trained to improve the accuracy of post-editing for the English→Marathi language pair by 10% using data from multiple domains, and what features of the model's architecture would be most beneficial in achieving this goal?"
https://aclanthology.org/2022.wmt-1.4/,"Can the performance of a post-editing model be evaluated using a combination of automatic metrics such as TER and human evaluation, and what are the implications for model selection and optimization?"
https://aclanthology.org/2022.wmt-1.5/,"What is the impact of incorporating document-level context on the performance of pre-trained machine translation metrics, and how does this extension compare to the reference-free metric COMET-QE in resolving ambiguities in the reference sentence? Does the document-level extension of COMET-QE significantly improve accuracy on discourse phenomena tasks?"
https://aclanthology.org/2022.wmt-1.6/,"Can machine learning models using transformer-based architectures be able to achieve statistical significance with a significantly reduced budget by utilizing interim testing to focus on borderline significant pairs, and what are the power and efficiency gains achievable with this approach?"
https://aclanthology.org/2022.wmt-1.6/,"How can interim testing improve the evaluation of machine translation systems by increasing the power and reducing the number of judgments required for pairwise comparisons, and what are the implications for the evaluation of the budget required for these comparisons?"
https://aclanthology.org/2022.wmt-1.7/,"Can character-level metrics effectively evaluate the translation quality of automatic systems for Inuktitut language, considering its polysynthetic nature?"
https://aclanthology.org/2022.wmt-1.7/,Do the human annotations of the WMT20 English-Inuktitut machine translation dataset improve the accuracy of automatic evaluation metrics for this language?
https://aclanthology.org/2022.wmt-1.8/,"Can Continuous Rating be reliably used as a quality assessment tool for simultaneous speech translation, and does its reliability improve with increasing levels of source language knowledge?"
https://aclanthology.org/2022.wmt-1.8/,"Does Continuous Rating provide a more accurate assessment of comprehension of foreign language documents than factual questionnaires, and do users' preferences for subtitle layout and presentation style impact their evaluation of SST quality?"
https://aclanthology.org/2022.wmt-1.9/,"What are the effects of explicit gender tags on sentence-level gender agreement in NMT systems for translating from genderless languages to languages with grammatical gender, specifically in the Basque to Spanish translation direction?"
https://aclanthology.org/2022.wmt-1.9/,"Can a template-based fine-tuning strategy with explicit gender tags improve the gender bias mitigation of NMT systems for translating occupations in Basque to Spanish, and what is the optimal set of templates for achieving this?"
https://aclanthology.org/2022.wmt-1.10/,"Can multilingual Non-autoregressive (NAR) machine translation models achieve comparable performance to autoregressive (AR) models on related languages, and what are the implications for multilingual machine translation?"
https://aclanthology.org/2022.wmt-1.10/,Does the use of bilingual versus multilingual teachers affect the performance of multilingual Non-autoregressive (NAR) machine translation models under capacity constraints?
https://aclanthology.org/2022.wmt-1.11/,"Can multilingual neural translation models learn common representations across languages by discretizing their encoder output latent space and assigning states to entries in a codebook, thereby increasing robustness in unseen testing conditions?"
https://aclanthology.org/2022.wmt-1.11/,"Does the use of an artificial language, derived from the encoder output latent space, facilitate knowledge-sharing among languages and improve model performance in zero-shot conditions?"
https://aclanthology.org/2022.wmt-1.12/,Can speech segmentation methods improve the performance of online spoken language translation models on continuous audio without human-supplied segmentation?
https://aclanthology.org/2022.wmt-1.12/,Can a fixed-window audio segmentation approach achieve comparable or better translation quality and reduced flicker and delay in online spoken language translation compared to other segmentation strategies?
https://aclanthology.org/2022.wmt-1.13/,"Can additive interventions improve the robustness of neural machine translation systems to label uncertainty in multi-domain settings, and how does their performance compare to tag-based approaches?"
https://aclanthology.org/2022.wmt-1.13/,"Can the use of additive interventions in large-scale multi-domain machine translation settings be effective when training data is scaled, and what are the implications for fine-tuning strategies?"
https://aclanthology.org/2022.wmt-1.14/,"Can the proposed Latin-script transcription convention improve the character-level correspondence between Slavic languages and English, and what are the effects on machine translation results in the cs→en and cs↔uk language directions? Can the use of multilingual, transcribed models outperform bilingual baselines in terms of accuracy and processing time for the cs→en and cs↔uk translation tasks?"
https://aclanthology.org/2022.wmt-1.15/,"Can the use of k-nearest-neighbor machine translation (kNN-MT) in combination with Transformer-based models improve the accuracy of machine translation for the English-Japanese language pair, and how does the integration of kNN-MT with reranking affect the overall performance of the translation system?"
https://aclanthology.org/2022.wmt-1.15/,"Does the use of a context-aware model in the translation system contribute to the document-level consistency of the translations, and what is the impact of this model on the overall quality of the machine translation output?"
https://aclanthology.org/2022.wmt-1.16/,"Can the proposed approach of combining iterative noised/tagged back-translation and iterative distillation improve the quality of machine translations for medium and low resource languages, as measured by BLEU score?"
https://aclanthology.org/2022.wmt-1.16/,"Can the use of BERT-liked models for text classification and domain extraction affect the final quality of ensemble NMT models, as evaluated by fluency and accuracy of the generated translations?"
https://aclanthology.org/2022.wmt-1.17/,"Can the proposed cross-model word embedding alignment technique improve the performance of M2M100 on low-resource languages like Livonian, and how does it compare to other methods of word embedding alignment?"
https://aclanthology.org/2022.wmt-1.17/,Can the combination of data augmentation with pseudo-parallel data and fine-tuning with online back-translation techniques enhance the performance of the M2M100 model on the English-Livonian translation task?
https://aclanthology.org/2022.wmt-1.18/,"How can the use of sparse expert models with adapters improve the performance of multilingual translation systems in the WMT 2022 General Translation shared task, specifically in the direction from English to Czech?"
https://aclanthology.org/2022.wmt-1.18/,"Can the combination of large-scale backtranslation and language model reranking techniques enhance the overall ranking performance of multilingual translation systems in the WMT 2022 General Translation shared task, particularly in the direction from Ukrainian to Russian?"
https://aclanthology.org/2022.wmt-1.19/,How does the addition of more encoder layers in the DeepBig model compared to the DeepLarger model affect its performance in terms of processing time?
https://aclanthology.org/2022.wmt-1.19/,Can the application of the talking-heads trick in the DeepBig-TalkingHeads model improve its performance in translating English to Chinese compared to the original DeepBig model using the same pre-trained model?
https://aclanthology.org/2022.wmt-1.20/,"Can a combination of block backtranslation techniques and MBR decoding improve translation accuracy in English-Czech direction as measured by COMET score, and can the results be replicated using a traditional mixed backtranslation training approach? Does the use of block backtranslation techniques lead to improved named entities translation accuracy compared to traditional mixed backtranslation training in English-Czech direction?"
https://aclanthology.org/2022.wmt-1.21/,Can the proposed neural machine translation system with fine-tuning and ensembling achieve better translations in the English-to-Japanese direction using a smaller model and filtered JParaCrawl data set compared to other online translation services? Can the use of N-best ranking with 10 different checkpoints improve the overall translation quality of the English-to-Japanese model?
https://aclanthology.org/2022.wmt-1.22/,"Can influence functions be used to identify and remove erroneous training instances in neural machine translation systems, improving the overall accuracy of the model? Can influence functions be used to develop more efficient methods for finding relevant training examples for neural machine translation systems, specifically for the sub-problem of copied training examples?"
https://aclanthology.org/2022.wmt-1.23/,Can the proposed Transformer architecture with novel variants achieve state-of-the-art results in the English-Japanese translation direction using data filtering and large-scale back-translation techniques? Does the use of knowledge distillation and forward-translation strategies improve the performance of the model in terms of BLEU scores for the Chinese-English translation direction?
https://aclanthology.org/2022.wmt-1.24/,"Can the use of ensemble methods with pre-trained Transformer models improve the accuracy of English-to-Japanese translation tasks, as measured by BLEU score?"
https://aclanthology.org/2022.wmt-1.24/,"Can the application of data augmentation and selection techniques enhance the performance of individual Transformer models in the pre-training and fine-tuning scheme for Japanese-to-English translation tasks, as evaluated by ROUGE score?"
https://aclanthology.org/2022.wmt-1.25/,"Can the use of a noisy back-translation technique in conjunction with the Transformer (big) architecture improve the performance of the ensemble-based approach in Ukrainian ↔ Czech machine translation, as measured by the COMET evaluation metric? Does the incorporation of source factors in the models enhance the translation accuracy of the ensemble, and if so, to what extent, as evaluated by the automatic metrics?"
https://aclanthology.org/2022.wmt-1.26/,"Can the transformer-based neural machine translation models achieve better accuracy when trained on cleaned parallel corpora versus raw parallel corpora for the german-to-english and german-to-french language pairs, as compared to the base models trained on raw data?"
https://aclanthology.org/2022.wmt-1.26/,"Does the use of probabilistic dictionaries in Bicleaner lead to more accurate translations compared to the base models trained on raw parallel corpora, specifically in terms of syntactic correctness?"
https://aclanthology.org/2022.wmt-1.27/,Can the transformer-big configuration of the MarianNMT toolkit achieve improved translation accuracy for English-Russian and English-German language pairs when using a vocabulary size of 32k compared to 24k?
https://aclanthology.org/2022.wmt-1.27/,Can the use of publicly and privately sourced data in the training of the PROMT systems using the MarianNMT toolkit and transformer-big configuration impact the performance of the systems in the English-Ukrainian direction?
https://aclanthology.org/2022.wmt-1.28/,Can NMT models using data selection and filtering techniques outperform multilingual systems in the WMT news task for medium resource language pairs?
https://aclanthology.org/2022.wmt-1.28/,Can the eTranslation system's limited resources be effectively utilized to improve the performance of NMT models for less domain-specific text in the European Commission's task?
https://aclanthology.org/2022.wmt-1.29/,What is the impact of rule-based romanization on machine translation quality in Czech-Ukrainian and Ukrainian-Czech translation systems?
https://aclanthology.org/2022.wmt-1.29/,"Can the proposed Charles Translator system, which did not use romanization, achieve comparable translation quality to the constrained systems that incorporate romanization?"
https://aclanthology.org/2022.wmt-1.30/,"Can the proposed ensemble decoding approach improve the performance of the Transformer-based machine translation systems for English-Ukrainian and Ukrainian-English translation directions, measured by the BLEU score? Does the fine-tuning of Transformer models with a subset of the training data and data augmentation with back-translated monolingual data enhance the quality of the machine translation outputs, as evaluated by the automatic evaluation metric of METEOR?"
https://aclanthology.org/2022.wmt-1.31/,Can the proposed multi-domain model structure improve the performance of the NiuTrans neural machine translation systems in the Chinese→English and English→Croatian directions compared to the single-domain models?
https://aclanthology.org/2022.wmt-1.31/,"Can the use of pre-trained mBERT to initialize the translation model enhance the performance of the NiuTrans systems in low-resource scenarios, particularly in the Livonian↔English direction?"
https://aclanthology.org/2022.wmt-1.32/,"Can a pre-trained M2M-100 model be fine-tuned for the English-Livonian language pair to achieve state-of-the-art results in the WMT22 General Machine Translation task, and what are the effects of using transfer learning and back-translation on the training time and accuracy of the model?"
https://aclanthology.org/2022.wmt-1.33/,"Can multi-domain multilingual neural machine translation (MDML-NMT) improve zero-shot translation performance when one of the source languages is from a different domain, and what is the effect of adding target-language tags to the encoder in MDML-NMT?"
https://aclanthology.org/2022.wmt-1.34/,Can the use of wider FFN layers in Transformer-based architectures improve the performance of machine translation models on the WMT22 General MT Task for English-to-Chinese and English-to-Japanese translation tasks?
https://aclanthology.org/2022.wmt-1.34/,Does the combination of data augmentation methods and post-editing techniques enhance the overall BLEU scores of constrained machine translation systems on the WMT22 General MT Task for English-to-Chinese and English-to-Japanese translation tasks?
https://aclanthology.org/2022.wmt-1.35/,"Can Transformer architecture be used to achieve better performance on low-resource languages with the addition of data augmentation methods such as Back Translation, Self Training, and Ensemble Knowledge Distillation?"
https://aclanthology.org/2022.wmt-1.35/,Can the effectiveness of fine-grained pre-processing and filtering on large-scale datasets improve the overall performance of machine translation models for medium and high-resource languages?
https://aclanthology.org/2022.wmt-1.36/,Can the proposed Vega-MT system effectively leverage the benefits of multidirectional training for all language pairs in the WMT 2022 shared general translation task?
https://aclanthology.org/2022.wmt-1.36/,"Can the extremely large Transformer-Big model achieve state-of-the-art results in the WMT 2022 shared general translation task, particularly for low-resource language pairs like Czech-English and Russian-English?"
https://aclanthology.org/2022.wmt-1.37/,How does the use of rules and multilingual language models impact the performance of data filtering and data selection in the English to Chinese machine translation task?
https://aclanthology.org/2022.wmt-1.37/,Can a data cleaning approach that incorporates TM-augmented NMT improve the BLEU and COMET scores of the Japanese to English machine translation task?
https://aclanthology.org/2022.wmt-1.38/,"Does a multilingual translation model focusing on translating from English to Ukrainian be able to improve the overall performance of a backtranslation system, and can this improvement be measured by comparing the syntactic correctness of the translated sentences?"
https://aclanthology.org/2022.wmt-1.38/,"Can the application of rules and language models to filter monolingual, parallel sentences and synthetic sentences enhance the quality of the backtranslation system, and is this improvement reflected in the processing time of the system?"
https://aclanthology.org/2022.wmt-1.39/,"Can machine translation systems achieve high accuracy when translating idioms, tenses of modal verbs, and resultative predicates in the German–English direction, and how do these challenges impact overall system performance?"
https://aclanthology.org/2022.wmt-1.39/,"Can machine translation systems improve their performance on translating idioms, transitive-past progressive, and middle voice in the English–German direction, and what techniques can be used to address these challenges?"
https://aclanthology.org/2022.wmt-1.40/,What is the feasibility of applying the proposed term consistency evaluation metric to professional domains like legal texts and how does it compare to widely used sentence-level metrics?
https://aclanthology.org/2022.wmt-1.40/,"Can the proposed metric accurately capture the consistency of term translations throughout a text, and how does it correlate with human assessment of translation quality?"
https://aclanthology.org/2022.wmt-1.41/,Can machine translation systems accurately translate morphologically complex words from English to German and preserve grammatical features such as gender in pronouns and number in morphologically complex structures?
https://aclanthology.org/2022.wmt-1.41/,Can the translation of English noun phrases as compounds or phrases into German be effectively evaluated using morphological analysis and rule-based approaches?
https://aclanthology.org/2022.wmt-1.42/,"Can Machine Translation metrics effectively distinguish between translations with and without critical errors, particularly in cases where errors affect named entities and numbers, and what are the key factors contributing to the variance in robustness among current methods?"
https://aclanthology.org/2022.wmt-1.42/,"Can the development of more robust MT metrics that can accurately penalize translations with critical errors be improved through the use of novel augmentation approaches like SMAUG, and what are the potential benefits of such an improvement in terms of reliability and safety of MT systems?"
https://aclanthology.org/2022.wmt-1.43/,What is the impact of incorporating discourse-level perturbations on the performance of machine translation metrics that rely on surface-level overlap with the reference?
https://aclanthology.org/2022.wmt-1.43/,How do combining multiple metrics with different strengths affect the accuracy of machine translation in the context of the ACES challenge set?
https://aclanthology.org/2022.wmt-1.44/,"Can machine translation metrics perform adequately on detecting named entities and terminology, particularly in cases involving units, punctuation, polar questions, relative clauses, dates, and idioms?"
https://aclanthology.org/2022.wmt-1.44/,"Can machine translation metrics accurately measure the nuances of present progressive of transitive verbs, future II progressive of intransitive verbs, simple present perfect of ditransitive verbs, and focus particles in both German-English and English-German translation directions?"
https://aclanthology.org/2022.wmt-1.45/,What is the effect of using contextual word embeddings versus surface-form matching metrics on the correlation with human ratings in machine translation automatic evaluations?
https://aclanthology.org/2022.wmt-1.45/,How robust are reference-based and reference-free metrics in discerning catastrophic errors at both word and sentence levels in different areas of text?
https://aclanthology.org/2022.wmt-1.46/,Can the proposed metrics improve the accuracy of automatic metrics in filtering out problematic human judgements compared to the current COMET architecture?
https://aclanthology.org/2022.wmt-1.46/,Does averaging scores of all equal segments evaluated multiple times improve the overall performance of automatic metrics on system-level pair-wise system ranking?
https://aclanthology.org/2022.wmt-1.47/,What is the effectiveness of HWTSC-EE-BERTScore* in evaluating machine translation systems at the segment level compared to other unsupervised metrics in terms of accuracy?
https://aclanthology.org/2022.wmt-1.47/,How do the supervised metrics HWTSC-Teacher-Sim and CROSS-QE perform in the system-level track compared to unsupervised metrics in terms of processing time?
https://aclanthology.org/2022.wmt-1.48/,Can the proposed metric effectively capture the fluency and context of machine translation outputs by considering both syntactic and contextual similarities?
https://aclanthology.org/2022.wmt-1.48/,"Does the use of weighted combination of syntactic, lexical, morphological, and semantic similarities in the final sentence translation score improve the accuracy of machine translation outputs compared to traditional metrics?"
https://aclanthology.org/2022.wmt-1.49/,Can the proposed unsupervised metric effectively estimate translation quality at the chunk level for the en-de language pair using BERT contextual word embeddings?
https://aclanthology.org/2022.wmt-1.49/,"Can the proposed method achieve high correlation with human judgements for the WMT17, WMT18 and WMT19 test sets using Language-Agnostic BERT models for sentence-level similarity computation?"
https://aclanthology.org/2022.wmt-1.50/,"Can the MaTESe metrics effectively capture the nuances of machine translation errors, particularly in terms of error spans and severity, through sequence tagging, and what are the implications for automatic evaluation of machine translation systems?"
https://aclanthology.org/2022.wmt-1.50/,Can a reference-free metric such as MaTESe-QE provide a viable alternative for evaluating machine translation systems in scenarios where reference translations are scarce or impractical to obtain?
https://aclanthology.org/2022.wmt-1.51/,Can the COMET estimator model and the multitask model be improved by incorporating multimodal features from human evaluations and automatic metrics in the hyper-parameter search for the ensemble?
https://aclanthology.org/2022.wmt-1.51/,Does the proposed CometKiwi model outperform traditional predictor-estimator models in terms of correlation and robustness to critical errors?
https://aclanthology.org/2022.wmt-1.52/,Can the proposed UNITE model achieve state-of-the-art results in the WMT 2022 Metrics Shared Task using data cropping and ranking-based score normalization strategies during the pre-training phase?
https://aclanthology.org/2022.wmt-1.52/,Does the use of Direct Assessment and Multidimensional Quality Metrics from past years' WMT competitions during the fine-tuning phase improve the overall performance of the UNITE model?
https://aclanthology.org/2022.wmt-1.53/,Can a multilingual MT system be used to accurately estimate the quality of machine translation hypotheses by back-translating them into the source language?
https://aclanthology.org/2022.wmt-1.53/,Can combining backtranslation-based metrics with off-the-shelf QE scorers improve the correlation with human judgments in sentence-level quality prediction?
https://aclanthology.org/2022.wmt-1.54/,How do the pseudo-labeled data examples and data cropping affect the performance of the UniTE model in achieving high-quality translations?
https://aclanthology.org/2022.wmt-1.54/,Can the use of Direct Assessment and Multidimensional Quality Metrics data from past years' WMT competitions improve the fine-tuning phase of the UniTE model in terms of overall ranking?
https://aclanthology.org/2022.wmt-1.55/,Can the proposed prompt-based fine-tuning approach for the quality estimation task improve the performance of the XLM-RoBERTa model for critical error detection in unconstrained settings?
https://aclanthology.org/2022.wmt-1.55/,Can the reformulation of the CED task to resemble the masked language model objective lead to better performance in both English-German and Portuguese-English language pairs?
https://aclanthology.org/2022.wmt-1.56/,"Can the proposed pseudo data generation methods improve the performance of the XLMR-large model on the quality estimation task, as measured by the average sentence-level score and the accuracy of word-level tags?"
https://aclanthology.org/2022.wmt-1.56/,Can the use of multi-task learning with pseudo data and real data on the XLMR-large model improve the overall performance on the English-German language pair in terms of processing time and user satisfaction?
https://aclanthology.org/2022.wmt-1.57/,"How does the integration of monolingual language models with pre-finetuning improve the quality estimation of MQM in the given task, and what is the key difference between the two pre-finetuning styles used?"
https://aclanthology.org/2022.wmt-1.57/,What is the performance of the proposed system compared to the XLM-RoBERTa baseline on the English-German language pairs in terms of accuracy and processing time?
https://aclanthology.org/2022.wmt-1.58/,Can a multilingual and multi-task model with a Pretrained Language Model (PLM) and task layers be used to improve performance in both sentence and word-level quality prediction tasks on multiple language pairs?
https://aclanthology.org/2022.wmt-1.58/,Does the use of auxiliary tasks and diverse sources of additional data improve the performance of the proposed system in the WMT 2022 Quality Estimation shared task?
https://aclanthology.org/2022.wmt-1.59/,What is the impact of incorporating references during pretraining on the performance of sentence-level quality estimation models for multiple language pairs?
https://aclanthology.org/2022.wmt-1.59/,Can a combination of attention and gradient information improve the extraction of good explanations for sentence-level quality estimation models in the context of the COMET framework?
https://aclanthology.org/2022.wmt-1.60/,Can CrossQE's sentence-level quality prediction model achieve higher accuracy with the addition of a pre-trained large language model as a predictor and a task-specific classifier or regressor as estimator compared to the original predictor-only model?
https://aclanthology.org/2022.wmt-1.60/,"Can the use of masked language modeling task loss and MC dropout methods in CrossQE improve the performance of the word-level quality prediction task, as measured by the inverse of maximum similarity between each word in the target and source languages?"
https://aclanthology.org/2022.wmt-1.61/,Can the use of XLM-RoBERTa as a feature extractor improve the accuracy of quality estimation in the DA subtask of WMT 2022 compared to other feature extractors?
https://aclanthology.org/2022.wmt-1.61/,Can incorporating pretrained models as additional external features improve the correlation between the estimated quality scores and human judgments in the DA subtask of WMT 2022?
https://aclanthology.org/2022.wmt-1.62/,Can the use of knowledge distillation with a deep encoder and a shallow decoder improve the efficiency of machine translation models on CPU and GPU hardware compared to using simpler recurrent units and shortlisting alone?
https://aclanthology.org/2022.wmt-1.62/,"Can the use of 8-bit quantization on CPU and FP16 quantization on GPU significantly impact the accuracy and processing time of machine translation models, and how do these quantization methods interact with other efficiency strategies such as pruning and bidirectional decoders?"
https://aclanthology.org/2022.wmt-1.63/,"Can a 12-layer Transformer model with connectionist temporal classification outperform an autoregressive model in decoding speed on the given dataset, and how does the knowledge-distilled dataset impact the performance of the non-autoregressive model?"
https://aclanthology.org/2022.wmt-1.63/,"Can the proposed non-autoregressive system be improved by using a more efficient decoding method, such as beam search or length normalization, to reduce decoding time and increase translation efficiency?"
https://aclanthology.org/2022.wmt-1.64/,Can the Hybrid Regression Translation (HRT) paradigm outperform the autoregressive translation system in terms of inference speed while maintaining equivalent translation performance?
https://aclanthology.org/2022.wmt-1.64/,Can the integration of sequence-level knowledge distillation and deep-encoder-shallow-decoder layer allocation strategy improve the inference speed of the HRT system by at least 2x?
https://aclanthology.org/2022.wmt-1.65/,Can the application of sentence-level distillation strategy to train small models with different configurations improve the efficiency of lightweight RNN models for Huawei Noah's Bolt-based inference?
https://aclanthology.org/2022.wmt-1.65/,Does the integration of the average attention mechanism into the lightweight RNN model enhance the decoding efficiency of Huawei Noah's Bolt for 8-bit and 4-bit models?
https://aclanthology.org/2022.wmt-1.66/,Can the curriculum training strategy improve the performance of an APE system in terms of TER and BLEU scores?
https://aclanthology.org/2022.wmt-1.66/,Does the use of LaBSE technique and phrase-level APE triplets contribute to the improvement of the APE system's quality and performance in the WMT22 Automatic Post-Editing task?
https://aclanthology.org/2022.wmt-1.67/,"How does the use of mixture of experts (MoE) algorithm improve the performance of the automatic post-editing (APE) model in terms of BLEU score, and what is the average improvement in BLEU score on the test set?"
https://aclanthology.org/2022.wmt-1.67/,"Can the APE model achieve similar or better results on the test set using different GMM clustering methods, such as k-means or hierarchical clustering?"
https://aclanthology.org/2022.wmt-1.68/,"Can machine learning models be trained to accurately translate clinical case descriptions from English to Italian, with a precision of at least 90% in terms of syntactic correctness? Can the use of transformer-based architectures improve the translation of clinical case descriptions from English to Italian, as measured by a reduction in processing time of at least 20% compared to baseline models?"
https://aclanthology.org/2022.wmt-1.69/,Can machine learning models trained on genuine bilingual conversations outperform those trained on synthetic data in translating customer support conversational text?
https://aclanthology.org/2022.wmt-1.69/,Does the use of automatic metrics versus human judgments provide a more accurate evaluation of translation quality in conversational text translation tasks?
https://aclanthology.org/2022.wmt-1.70/,Can the proposed methods for DSGS-to-German sign language translation improve the accuracy of sign language recognition systems using deep learning architectures compared to traditional hand-tracking-based approaches?
https://aclanthology.org/2022.wmt-1.70/,Can the development of a reproducible baseline system for DSGS-to-German translation provide a foundation for further research on the application of multimodal fusion techniques in sign language translation?
https://aclanthology.org/2022.wmt-1.71/,"Can machine learning algorithms be trained to improve the translation quality of African languages by leveraging human-annotated data, and if so, what are the key factors influencing the effectiveness of such training?"
https://aclanthology.org/2022.wmt-1.71/,"Can the use of advanced NLP models, such as Transformer-based architectures, contribute to significant improvements in BLEU scores for African language translations, and if so, what are the optimal hyperparameters for achieving these improvements?"
https://aclanthology.org/2022.wmt-1.72/,"Can unsupervised machine translation models achieve comparable accuracy to supervised models for minority language pairs, and what are the key factors influencing the performance of unsupervised models in these language pairs?"
https://aclanthology.org/2022.wmt-1.72/,"Can supervised machine translation models improve the preservation of minority languages by leveraging the available resources and community engagement, and what are the most effective ways to incorporate community feedback into the model development process?"
https://aclanthology.org/2022.wmt-1.73/,"Can machine learning models be trained to improve the accuracy of monolingual to code-mixed machine translation, specifically for low-resource languages, and if so, what features of the code-mixed text are most critical for achieving this improvement?"
https://aclanthology.org/2022.wmt-1.73/,"Can code-mixed language models be adapted to handle the nuances of monolingual to code-mixed translation, and what are the performance gains that can be achieved by incorporating domain-specific knowledge into the model?"
https://aclanthology.org/2022.wmt-1.74/,What are the factors that contribute to the development of high-quality Computer-Aided Translation (CAT) systems in rigorous translation scenarios?
https://aclanthology.org/2022.wmt-1.74/,How can the use of human evaluations and CAT system data improve the performance of Word-level AutoCompletion (WLAC) models in machine translation?
https://aclanthology.org/2022.wmt-1.75/,Can a machine learning model trained on the English-German corpus outperform the model trained on the English-Chinese corpus in terms of automatic metric BLEU score for the naive translation suggestion task?
https://aclanthology.org/2022.wmt-1.75/,Can a supervised learning approach using a Transformer-based architecture achieve higher translation suggestion accuracy with hints compared to the naive translation suggestion task?
https://aclanthology.org/2022.wmt-1.76/,Can a context-aware neural machine translation model be improved by discounting the impact of target context on the translation of the current sentence using a novel concatenation approach?
https://aclanthology.org/2022.wmt-1.76/,Does the incorporation of relative sentence distance and clear sentence boundaries in a context-aware neural machine translation model enhance its ability to capture inter-sentential discourse phenomena?
https://aclanthology.org/2022.wmt-1.77/,"Does the choice of sentence segmenter impact the accuracy of machine translation tasks when applied to a black-box system, and what are the potential harms of over- or under-segmentation in such systems?"
https://aclanthology.org/2022.wmt-1.77/,"Does the incorporation of segmentation into the training process of machine translation models lead to improved performance, and what are the optimal segmentation strategies for achieving this improvement?"
https://aclanthology.org/2022.wmt-1.78/,"How can we design an efficient locality sensitive hashing algorithm to reduce the number of vocabulary items that must be evaluated during neural machine translation, without compromising translation quality measured by BLEU score?"
https://aclanthology.org/2022.wmt-1.78/,"Can LSH-based models achieve comparable or better performance compared to full softmax models when minimizing search errors, and what is the optimal trade-off between translation speed and quality in LSH-based neural machine translation?"
https://aclanthology.org/2022.wmt-1.79/,"What is the impact of knowledge distillation on the performance of machine translation models when using different amounts of synthetic data for distillation, and how does this compare to post-training quantization for language pairs with limited training data?"
https://aclanthology.org/2022.wmt-1.79/,"Can post-training quantization outperform knowledge distillation in achieving consistent performance across low-resource languages, and what are the key factors that influence the effectiveness of these compression techniques?"
https://aclanthology.org/2022.wmt-1.80/,"Can an end-to-end model trained on a parallel corpus of text with inline tags be able to translate a sentence with inline formatted tags into a tagged sentence with high accuracy, and what is the optimal placement of tags in the output sentence to improve the translation quality?"
https://aclanthology.org/2022.wmt-1.80/,"Can a word alignment-based detag-and-project approach with tag reinsertion be able to outperform an end-to-end model in translating a sentence with inline formatted tags, and how can tag injection be improved to reduce computational costs while maintaining translation quality?"
https://aclanthology.org/2022.wmt-1.81/,"Can the JoeyNMT toolkit achieve higher accuracy in translating English to French compared to the SYSTRAN Pure Neural Server toolkit when fine-tuned with a selection of texts from WMT, Khresmoi, and UFAL data sets?"
https://aclanthology.org/2022.wmt-1.81/,Can the use of fine-tuning with diverse data sets improve the performance of the JoeyNMT toolkit in translating French to English compared to the SYSTRAN Pure Neural Server toolkit?
https://aclanthology.org/2022.wmt-1.82/,"Can the deep transformer architecture improve the translation of domain-specific terminologies in biomedical text, and how can the back-translation strategy be applied to enhance the quality of the translation system?"
https://aclanthology.org/2022.wmt-1.82/,Can the soft-constrained terminology translation approach using biomedical terminology dictionaries improve the overall performance of the translation system compared to the best model in WMT20 and WMT21?
https://aclanthology.org/2022.wmt-1.83/,Can xLPLMs consistently outperform smaller-sized PLMs in fine-tuning for domain-specific machine translation tasks across different dataset sizes?
https://aclanthology.org/2022.wmt-1.83/,Do the performance differences between xLPLMs and smaller-sized PLMs diminish when using specific evaluation metrics in clinical translation tasks?
https://aclanthology.org/2022.wmt-1.84/,What is the impact of using different Transformer structures on the quality of Chinese→English translation in the context of the WMT 2022 shared biomedical translation task?
https://aclanthology.org/2022.wmt-1.84/,"How does the use of data filtering and model ensemble techniques affect the BLEU score of the Chinese→English translation system, Summer, compared to other approaches?"
https://aclanthology.org/2022.wmt-1.85/,Can a transformer-based approach to fine-tuning a pre-trained model with in-house clinical domain data and biomedical data improve translation accuracy in the ClinSpEn-CC subtask compared to the pre-trained model?
https://aclanthology.org/2022.wmt-1.85/,Can the use of a fine-tuned transformer model with in-house clinical domain data and biomedical data lead to a measurable improvement in BLEU score in the ClinSpEn-OC subtask?
https://aclanthology.org/2022.wmt-1.86/,Can BabelTar achieve a higher accuracy in translating biomedical texts from English to other languages by incorporating homograph disambiguation techniques and pre-trained multilingual NMT models into its existing framework?
https://aclanthology.org/2022.wmt-1.86/,Can the use of ensemble learning methods improve the processing time and overall performance of the BabelTar system in translating biomedical texts from English to other languages?
https://aclanthology.org/2022.wmt-1.87/,"Can the proposed deep Transformer architecture with R-Drop and data diversification techniques significantly improve the accuracy of biomedical translation systems compared to those without these techniques, as measured by BLEU score?"
https://aclanthology.org/2022.wmt-1.87/,"Can the use of forward and back translation, data selection, and finetuning in conjunction with the Transformer architecture enhance the overall performance of biomedical translation systems, particularly in terms of fluency and accuracy, as evaluated by the CodaLab results?"
https://aclanthology.org/2022.wmt-1.88/,How does the use of kNN-MT at decoding time improve the performance of pre-trained models like mBART50 on the WMT 2022 Chat Translation Shared Task for specific language directions?
https://aclanthology.org/2022.wmt-1.88/,Can the two-step fine-tuning process of mBART50 on publicly available data and validation set improve the model's performance in translating domain-specific content?
https://aclanthology.org/2022.wmt-1.89/,Can multilingual transformer-based models with separate encoders for context and source utterance achieve better results when using context in the English-to-German direction compared to the German-to-English direction?
https://aclanthology.org/2022.wmt-1.89/,Can the removal of the context encoder during testing affect the performance of a multilingual transformer-based model in terms of COMET scores and other metrics such as chrF and BLEU scores?
https://aclanthology.org/2022.wmt-1.90/,"Can the proposed pre-training-then-fine-tuning paradigm improve the performance of Transformer-based chat translation models for English-German and German-English tasks, and what are the key factors that contribute to the highest COMET scores achieved by the proposed system?"
https://aclanthology.org/2022.wmt-1.90/,"Can the incorporation of speaker-aware in-domain data generation, speaker adaptation, prompt-based context modeling, and boosted self-COMET-based model ensemble in the fine-tuning stage enhance the translation quality and efficiency of the Transformer-based chat translation model?"
https://aclanthology.org/2022.wmt-1.91/,Can the proposed deep transformer architecture with a larger parameter size outperform existing sentence-level translation models on chat translation tasks in the WMT22 en-de bidirectional shared task?
https://aclanthology.org/2022.wmt-1.91/,"Can the strategies adopted by HW-TSC, such as back translation, forward translation, domain transfer, data selection, and noisy forward translation, improve the results on the development set of the WMT22 en-de bidirectional shared task for chat translation?"
https://aclanthology.org/2022.wmt-1.92/,"Can the proposed approach to extract full body information using a pre-trained I3D model improve the accuracy of Swiss German sign language translation, and what is the effect of lip reading features on the BLEU score of the system?"
https://aclanthology.org/2022.wmt-1.93/,"Can the proposed spatio-temporal feature representations improve the generalization of sign language translation systems to new datasets, as measured by BLEU score?"
https://aclanthology.org/2022.wmt-1.93/,Does the use of a single model for learning spatio-temporal features and translation in sign language translation outperform the traditional approach of using separate models for feature extraction and translation?
https://aclanthology.org/2022.wmt-1.94/,"Can the proposed deep-learning sequence-to-sequence model achieve a significant improvement in sign language translation accuracy when using geometric data augmentation with 3D body keypoints, compared to the baseline model without augmentation?"
https://aclanthology.org/2022.wmt-1.94/,Can the use of 3D-transformation with artificial rotation in the training process of the deep-learning model improve the robustness of the sign language translation system to variations in sign language usage?
https://aclanthology.org/2022.wmt-1.95/,Can the use of an I3D backbone with a pre-trained model on isolated sign recognition improve the performance of a Transformer-based encoder-decoder model for sign language translation in DSGS - German?
https://aclanthology.org/2022.wmt-1.95/,Can the use of RGB images alone in a sign language translation model without relying on pre-extracted human pose improve the accuracy and efficiency of the model?
https://aclanthology.org/2022.wmt-1.96/,"Can the Transformer-based model improve the accuracy of sign-to-text translation using data augmentation techniques and pretraining with the PHOENIX-14T dataset, and what is the optimal vocabulary size for this task? Can the use of a Transformer model with Fairseq toolkit improve the BLEU score for the test set in the sign language translation task?"
https://aclanthology.org/2022.wmt-1.97/,Does the use of a sentence-pair classifier for filtering noisy data improve the accuracy of machine translation models in low-resource languages?
https://aclanthology.org/2022.wmt-1.97/,Can the proposed approach of fine-tuning a pre-trained language model for sentence-pair classification be used to improve the quality of machine translation systems using automatically aligned parallel data?
https://aclanthology.org/2022.wmt-1.98/,How does the use of DeltaLM model impact the performance of machine translation systems on African languages in the WMT22 shared task?
https://aclanthology.org/2022.wmt-1.98/,Can fine-tuning DeltaLM with language family and language-specific adapter units improve the ranking of machine translation systems in the constrained track of WMT22?
https://aclanthology.org/2022.wmt-1.99/,"Can adapter fusion with multiple task adapters trained on different translation pairs improve the performance of low-resource multilingual translation models, and what are the key factors that affect the success of adapter fusion in this context?"
https://aclanthology.org/2022.wmt-1.99/,Can the use of adapter fusion with multiple task adapters trained on different translation pairs achieve better performance in specific translation directions compared to a single model trained on all directions at once?
https://aclanthology.org/2022.wmt-1.100/,How effective are the overlap BPE and back-translation techniques in improving the translation accuracy of a multilingual model for low-resource African languages?
https://aclanthology.org/2022.wmt-1.100/,Can the addition of synthetic training data generation and multiple translation directions during training significantly improve the performance of a multilingual model for machine translation tasks in African languages?
https://aclanthology.org/2022.wmt-1.101/,Can the proposed data augmentation technique improve the translation accuracy for African languages in the WMT22 shared task compared to the baseline models?
https://aclanthology.org/2022.wmt-1.101/,Does the use of distributionally robust optimization enhance the performance of multilingual neural machine translation models in handling data imbalance issues in the WMT22 shared task?
https://aclanthology.org/2022.wmt-1.102/,Can DENTRA outperform the strong baseline M2M-100 in terms of accuracy on monolingual and multilingual machine translation tasks in African languages?
https://aclanthology.org/2022.wmt-1.102/,Can DENTRA improve the processing time of multilingual machine translation models in the context of constrained translation tasks?
https://aclanthology.org/2022.wmt-1.103/,Can the VolcTrans system be improved upon by incorporating additional self-collected parallel corpora and NLLB data to enhance its multilingual model's performance in terms of BLEU score and inference speed?
https://aclanthology.org/2022.wmt-1.103/,"Can the use of heuristic rules for cleaning bilingual and monolingual texts affect the accuracy of the VolcTrans system's performance on the official test set, particularly in terms of spBLEU and chrF2++ metrics?"
https://aclanthology.org/2022.wmt-1.104/,"What are the effects of incorporating WebCrawl African corpora on the performance of machine translation models for low-resource and extremely low-resource languages, measured by BLEU score improvement, for African languages translated into English?"
https://aclanthology.org/2022.wmt-1.104/,"Can the use of WebCrawl African corpora improve the translation of African languages that are not covered by the existing corpora, measured by BLEU score improvement?"
https://aclanthology.org/2022.wmt-1.105/,Can multilingual training with deep transformer improve the performance of African language machine translation systems in terms of BLEU score compared to base transformer on the whole corpora?
https://aclanthology.org/2022.wmt-1.105/,Can using joint vocabulary selection strategy improve the performance of low resource languages in multilingual machine translation systems compared to language-wise vocabulary selection strategy?
https://aclanthology.org/2022.wmt-1.106/,Can a deep Transformer-based architecture with a large filter size achieve the highest BLEU scores in the WMT22 Very Low Resource Supervised MT task when combined with multilingual transfer and ensemble methods?
https://aclanthology.org/2022.wmt-1.106/,"Does the use of regularized dropout, back translation, and fine-tuning improve the performance of deep Transformer-based systems in translating Upper/Lower Sorbian to German?"
https://aclanthology.org/2022.wmt-1.107/,Can transformer-based models trained on low-resource languages improve performance when used for unsupervised masked language modeling on related high-resource languages?
https://aclanthology.org/2022.wmt-1.107/,Can the use of pre-trained language models like XLM for unsupervised machine translation improve the performance of low-resource language pairs compared to the baseline approach of using only the pre-trained model for decoding?
https://aclanthology.org/2022.wmt-1.108/,"Can the proposed novel tokenization algorithm improve the performance of neural machine translation systems on low-resource languages like Lower Sorbian, and does it require significant modifications to existing tokenization techniques?"
https://aclanthology.org/2022.wmt-1.108/,Can supervised NMT systems achieve state-of-the-art results on unsupervised MT and very low resource supervised MT tasks with data augmentation techniques like Data Diversification?
https://aclanthology.org/2022.wmt-1.109/,Can a supervised machine translation system using a pre-trained De-Salvic mBART model achieve better performance on the German ↔ Upper Sorbian language pair compared to the unsupervised phrase-based statistical machine translation system?
https://aclanthology.org/2022.wmt-1.109/,Can the fine-tuning of the mBART model on synthetic and authentic parallel data improve the overall performance of the low-resource supervised machine translation system for the German ↔ Lower Sorbian language pair?
https://aclanthology.org/2022.wmt-1.110/,Can a multi-way fine-tuning approach improve the automatic evaluation score of code-mixed language models for Hinglish to English translation?
https://aclanthology.org/2022.wmt-1.110/,Can the use of code-mixed pre-training enhance the performance of Hinglish to English translation systems in terms of automatic evaluation score?
https://aclanthology.org/2022.wmt-1.111/,"Can a machine translation model using mBART with pre-processing and post-processing techniques achieve high ROUGE-L and WER scores for translating Hinglish text from Devanagari script to English, and what are the effects of transliteration on the translation accuracy of code-mixed data?"
https://aclanthology.org/2022.wmt-1.112/,Can the proposed models effectively transliterate Hinglish text from the Latin script to the Devanagari script with high accuracy? Can the proposed models generate efficient and fluent target text in English from pseudo-translated Hinglish text with high Recall-Oriented Under-study for Gisting Evaluation (ROUGE) scores?
https://aclanthology.org/2022.wmt-1.113/,What is the impact of using large pre-trained multilingual NMT models on the performance of the MixMT system in terms of accuracy and translation fluency?
https://aclanthology.org/2022.wmt-1.113/,Can ensemble techniques improve the translation quality of the MixMT system in the context of subtask 1 Hindi/English to Hinglish translation?
https://aclanthology.org/2022.wmt-1.114/,Can the use of backtranslation from monolingual resources improve the quality of code-mixed Hindi/English text generated by machine translation models?
https://aclanthology.org/2022.wmt-1.114/,Can the pretraining of machine translation models with simple initialization versus aligned augmentation techniques significantly affect the performance of Hinglish to English translation systems?
https://aclanthology.org/2022.wmt-1.115/,"Can transformer-based neural machine translation models achieve higher ROUGE-L scores and lower WER scores for code-mixed text when trained on a larger, more diverse synthetic corpus including named-entity annotated data?"
https://aclanthology.org/2022.wmt-1.115/,"Can the use of named-entity annotated data improve the accuracy of machine translation models for code-mixed languages, particularly in capturing the nuances of proper nouns and their transliteration?"
https://aclanthology.org/2022.wmt-1.116/,"Can a pre-trained model fine-tuned on a diverse set of code-mixed data sources exhibit improved performance in monolingual machine translation subtasks, and how does the performance vary across different data schedules? Can the use of a sentence alignment objective improve the performance of a mixed-domain model in code-mixed machine translation tasks?"
https://aclanthology.org/2022.wmt-1.117/,What is the impact of incorporating human-typed constraints on the performance of word-level auto-completion systems in the German-English and English-German directions of the WLAC task?
https://aclanthology.org/2022.wmt-1.117/,How does the use of a joint optimization strategy accounting for various types of translation context affect the accuracy of word-level auto-completion systems in the WLAC task?
https://aclanthology.org/2022.wmt-1.118/,"Can pre-trained models improve the efficiency of sentence-level translation auto-suggestion systems for low-resource languages, and how do these systems compare to word-level auto-completion in terms of accuracy and user satisfaction?"
https://aclanthology.org/2022.wmt-1.118/,"Can the use of open-source APIs for auto-suggestion and auto-completion in machine translation improve the productivity of translators, and what are the optimal features required for these APIs to achieve significant gains in productivity?"
https://aclanthology.org/2022.wmt-1.119/,Can the proposed segment-based interactive machine translation approach be improved by incorporating a word-level language model for better autocompletion accuracy in the English-German and German-English categories?
https://aclanthology.org/2022.wmt-1.119/,Does the decoding step of the proposed approach allow for the effective use of pre-trained MT models in the autocompletion task without requiring significant modifications?
https://aclanthology.org/2022.wmt-1.120/,Can a Generate-then-Rerank framework improve the performance of Word-Level AutoCompletion in language directions such as English to Chinese and Chinese to English?
https://aclanthology.org/2022.wmt-1.120/,Can the use of span-level mask prediction task facilitate the training of the generator in a Word-Level AutoCompletion system?
https://aclanthology.org/2022.wmt-1.121/,What is the impact of using a bi-context based Transformer model with a mixture of subword and character encoding units on the performance of the end-to-end auto-completion task in the WMT 2022 Word-Level AutoCompletion Task?
https://aclanthology.org/2022.wmt-1.121/,How does the fine-tuning of a pre-trained machine translation model with BERT-style MLM data improve the performance of the auto-completion model on the zh→en and en→de tracks in the WMT 2022 task?
https://aclanthology.org/2022.wmt-1.122/,"Can fine-tuning pre-trained models such as FAIR's WMT19 and MBART50 improve the performance of Translation Suggestion systems, and what specific data augmentation strategies can be used to enhance model performance in this context?"
https://aclanthology.org/2022.wmt-1.122/,What is the effect of incorporating dual conditional cross-entropy models and GPT-2 language models on the performance of Translation Suggestion systems in the WMT22 Translation Suggestion task?
https://aclanthology.org/2022.wmt-1.123/,Can the use of DeltaLM for fine-tuning improve the performance of TranslationSuggestion tasks in terms of BLEU scores compared to traditional methods?
https://aclanthology.org/2022.wmt-1.123/,Can a two-stage training strategy on DeltaLM outperform the official results in the WMT2022 shared task for TranslationSuggestion with Hints in both Zh→En and En→Zh language directions?
https://aclanthology.org/2022.wmt-1.124/,"Can the proposed ensemble approach of using different translation architectures (Transformer, SA-Transformer, and DynamicConv) lead to improved translation suggestion performance in the absence of large amounts of supervised data?"
https://aclanthology.org/2022.wmt-1.124/,Can the introduction of a multi-phase pre-training strategy with in-domain data enhance the system's performance on the English-German and English-Chinese bidirectional tasks?
https://aclanthology.org/2023.wmt-1.0/,"Can machine translation systems achieve human-competitive performance on all 14 translation directions, and what are the key factors that contribute to the discrepancy between human and machine translation outputs in these directions?"
https://aclanthology.org/2023.wmt-1.0/,Can the use of domain-specific training data improve the accuracy of machine translation systems on test sets consisting of up to four different domains?
https://aclanthology.org/2023.wmt-1.1/,Can the proposed approach of using ChatGPT 3.5 as a comparison system be improved by incorporating additional machine learning algorithms to enhance its performance in translating biomedical abstracts from non-English languages into English?
https://aclanthology.org/2023.wmt-1.1/,"Can the evaluation metrics used in the Biomedical Translation Task, such as accuracy and processing time, provide a comprehensive measure of the overall quality of the translations generated by the participating systems?"
https://aclanthology.org/2023.wmt-1.2/,"What are the most effective machine learning algorithms for discourse-aware translation of literary texts, and how do they compare to traditional statistical machine translation models in terms of accuracy and fluency?"
https://aclanthology.org/2023.wmt-1.2/,"Can the incorporation of literary and discourse features into neural machine translation systems improve the overall performance of machine translation, as measured by human evaluation metrics such as coherence and semantic accuracy?"
https://aclanthology.org/2023.wmt-1.3/,"Can a machine learning model achieve high accuracy in translating Swiss German Sign Language to German, and how does the use of visual information in the form of video frames affect the model's performance?"
https://aclanthology.org/2023.wmt-1.3/,"Can the proposed baseline system for DSGS-to-German translation using a Transformer-based architecture improve the translation quality of sign language translation systems in general, and what are the key factors contributing to its success?"
https://aclanthology.org/2023.wmt-1.4/,Can the use of a rule-based approach versus a machine learning-based approach to document alignment in Estonian-Lithuanian web data improve downstream machine translation quality?
https://aclanthology.org/2023.wmt-1.4/,Can a filtering approach that focuses on high-quality sentence pairs improve the overall accuracy of machine translation models trained on the aligned data?
https://aclanthology.org/2023.wmt-1.5/,Can the use of synthetic backtranslated data and noisy channel reranking in Transformer-based sequence-to-sequence models improve their performance on low-resource languages compared to unconstrained baseline models on the FLORES-200 benchmark? Can the addition of synthetic backtranslated data and noisy channel reranking during online decoding increase the translation accuracy of Transformer-based sequence-to-sequence models on the NTREX-128 benchmark?
https://aclanthology.org/2023.wmt-1.6/,What is the effect of incorporating multiple decoding algorithms in a two-stage reranking system on the overall quality of machine translation outputs in the English ↔ Japanese general machine translation task?
https://aclanthology.org/2023.wmt-1.6/,Can diverse translation candidates generated from various techniques improve the performance of a machine translation system when reranked using a well-designed reranker model?
https://aclanthology.org/2023.wmt-1.7/,"Does the use of a genetic algorithm in the CUNI-GA method improve the overall performance of the system in terms of ChrF, BLEU, COMET22-DA, and COMET22-QE-DA scores, and can the method be applied to other translation tasks beyond the WMT23 General translation task? Can the CUNI-GA method achieve better results than the top-tier unconstrained systems in the constrained track?"
https://aclanthology.org/2023.wmt-1.8/,Can ensemble Transformer models with large parameters and cross-self-attention mechanisms achieve better performance when trained with back-translation and data augmentation techniques?
https://aclanthology.org/2023.wmt-1.8/,Does the use of MBR reranking methods with COMET and COMET-QE improve the quality of the selected candidate translations from a large pool of generated translations?
https://aclanthology.org/2023.wmt-1.9/,"Can a fine-tuning approach utilizing a larger dataset improve the accuracy of the Transformer-based model in machine translation, and what are the optimal pre-processing techniques for enhancing translation quality?"
https://aclanthology.org/2023.wmt-1.9/,"Can the deployment of ensembling methods, such as N-best ranking, yield a significant improvement in translation accuracy for both English-Japanese and Japanese-English pairs?"
https://aclanthology.org/2023.wmt-1.10/,Can the use of bilingual models with sparse expert models and large-scale back-translation improve the effectiveness of the Chinese-to-English translation system?
https://aclanthology.org/2023.wmt-1.10/,Can the application of model size scaling and language model reordering techniques enhance the performance of the English-to-Chinese translation system?
https://aclanthology.org/2023.wmt-1.11/,Can the MarianNMT toolkit with transformer-big configuration and BPE encoding be used to achieve competitive results in English to Russian and Russian to English translation tasks?
https://aclanthology.org/2023.wmt-1.11/,Can the automatic metrics for evaluating translation models be used as a reliable measure of success for the MarianNMT toolkit in both directions of the Shared Translation Task?
https://aclanthology.org/2023.wmt-1.12/,"Can the performance of NMT systems be improved by incorporating parallel data distillation and iterative back-translation in the training process for translation between English, German, and Japanese?"
https://aclanthology.org/2023.wmt-1.12/,Can the use of multilingual BERT base for initialising encoder and decoder weights in non-autoregressive sequence-to-sequence models affect the overall accuracy of NMT systems?
https://aclanthology.org/2023.wmt-1.13/,What is the impact of using DeepNorm modification of the transformer architecture on the performance of the system compared to other architectures in terms of accuracy?
https://aclanthology.org/2023.wmt-1.13/,Does the use of custom tokenizer derived from HFT have a significant effect on the system's processing time compared to the HFT tokenizer used in the initial system?
https://aclanthology.org/2023.wmt-1.14/,"Can the proposed Lan-Bridge Translation system achieve state-of-the-art results in the WMT 2023 General Translation shared task for document-level machine translation from English to Chinese, as measured by BLEU score? Can the proposed Lan-Bridge Translation system outperform the current state-of-the-art models such as GPT-3.5 and GPT-4 in terms of fluency and accuracy, as evaluated by human evaluators?"
https://aclanthology.org/2023.wmt-1.15/,Can the proposed Transformer-based architecture with larger parameters improve translation accuracy when combined with data diversification and forward translation strategies in the Chinese↔English language pair at WMT23?
https://aclanthology.org/2023.wmt-1.15/,Can the addition of model enhancement strategies such as Regularized Dropout and Bidirectional Training improve the processing time and user satisfaction of the proposed system in the Chinese↔English language pair at WMT23?
https://aclanthology.org/2023.wmt-1.16/,Can UvA-MT's use of a single model to handle bidirectional tasks in MMT achieve comparable results to traditional bilingual translation for both English → Hebrew and Hebrew → English directions? Can the use of effective strategies such as back-translation and task-oriented fine-tuning improve the automatic evaluation results for both English → Hebrew and Hebrew → English directions?
https://aclanthology.org/2023.wmt-1.17/,"Can a decoder-only architecture fine-tuned on a multilingual model with partially sampled data from diverse datasets outperform the baseline system in translation tasks, and how does this approach compare to the state-of-the-art model GPT-4 in terms of bleu scores?"
https://aclanthology.org/2023.wmt-1.17/,"Does the use of carefully curated high-quality parallel corpora across multiple translation directions improve the performance of the multilingual model, and what specific translation directions show the most significant improvement over GPT-4?"
https://aclanthology.org/2023.wmt-1.18/,Can a Transformer-based translation system using pre-norm or deep-norm architecture with back-translation and data diversification achieve better results than a baseline system in English-to-Chinese translation tasks?
https://aclanthology.org/2023.wmt-1.18/,Can a data augmentation strategy utilizing substantial amounts of monolingual data improve the BLEU score of a Transformer-based translation system compared to a system without such augmentation?
https://aclanthology.org/2023.wmt-1.19/,"Can a machine translation system utilizing backtranslation and multilingual models achieve higher accuracy in translating Ukrainian-English, Czech-English, and Hebrew-English language pairs compared to state-of-the-art systems?"
https://aclanthology.org/2023.wmt-1.19/,Does the integration of human-generated and machine-generated data in fine-tuning machine translation models improve BLEU scores in English-Hebrew and German-English language pairs?
https://aclanthology.org/2023.wmt-1.20/,"Can machine translation models generalise well to non-standard user-generated content when trained on a diverse dataset of professionally translated texts, and can they handle a wide range of linguistic phenomena, such as phonetically inspired spellings, contraction, and truncations?"
https://aclanthology.org/2023.wmt-1.20/,"Can automatic quality estimation metrics accurately capture the nuances of human evaluation in machine translation for non-standard user-generated content, and do these metrics hold up to the diversity of RoCS-MT datasets?"
https://aclanthology.org/2023.wmt-1.21/,"Can the proposed Multifaceted Challenge Sets effectively measure the impact of source sentence difficulty on the performance of machine translation models, as measured by evaluation metrics such as BLEU score or ROUGE score?"
https://aclanthology.org/2023.wmt-1.21/,"Can the proposed approach of construing challenge sets from four aspects (word difficulty, length difficulty, grammar difficulty, and model learning difficulty) improve the fairness and efficiency of machine translation evaluation, as reflected in the results of participants in the WMT23 MT Test Suites?"
https://aclanthology.org/2023.wmt-1.22/,Does the GPT-4 model perform comparably to the best systems in the German-English direction in terms of idioms and resultative predicates accuracy?
https://aclanthology.org/2023.wmt-1.22/,Can the GPT-4 model improve its performance in the English-Russian direction by addressing the challenges posed by idioms and semantic roles?
https://aclanthology.org/2023.wmt-1.23/,"Can the proposed machine translation systems achieve a significant improvement in domain-specific evaluation metrics, such as accuracy or fluency, for the entertainment domain, and how do these improvements relate to the writing style-specific evaluations?"
https://aclanthology.org/2023.wmt-1.23/,"Can the use of a hybrid approach combining different machine translation models and writing style-specific evaluation metrics improve the overall performance of the translation systems, as measured by the reduction in processing time or user satisfaction?"
https://aclanthology.org/2023.wmt-1.24/,Can machine translation models effectively and accurately translate feminine and masculine gender forms in naturalistic contexts without explicit instruction?
https://aclanthology.org/2023.wmt-1.24/,"How can language models be improved to generate more inclusive translations, particularly for gender-inclusive forms, in machine translation systems?"
https://aclanthology.org/2023.wmt-1.25/,Can Large Language Models improve sentence filtering performance by more than 2.3 BLEU points when combined with domain-centric filtering using in-domain corpora?
https://aclanthology.org/2023.wmt-1.25/,How does the inclusion of domain knowledge in sentence selection methodologies impact the performance of Large Language Models in parallel sentence filtering from in-domain corpora?
https://aclanthology.org/2023.wmt-1.26/,"Can deep learning-based NMT systems with larger parameter sizes outperform traditional machine translation methods in the biomedical domain for the en↔de language pair, and what are the key factors that contribute to the improvement in performance when using Curriculum Learning and Data Diversification techniques in NMT systems?"
https://aclanthology.org/2023.wmt-1.27/,Can we develop a more accurate fine-tuning strategy for training biomedical in-domain fr<>en models using textometric analysis to detect repetitive segments within the test set?
https://aclanthology.org/2023.wmt-1.27/,Can we define a set of criteria for filtering in-domain training data based on the detection of repetitive segments in the test set to improve the performance of mBart-50 baseline model?
https://aclanthology.org/2023.wmt-1.28/,"Can a Transformer model effectively utilize paragraph-level context to improve its translation performance, as measured by sentence-level metrics such as BLEU and d-BLEU? Does the MEGA model outperform the Transformer model in modeling long-range sequences and improving document-level translation accuracy, as evaluated by BlonDe?"
https://aclanthology.org/2023.wmt-1.29/,"Does the use of fine-tuning with Chinese-English data improve the performance of the mBART50 model for literary translation, as measured by the accuracy of the translation outputs? Does the approach of training a sentence-level transformer model for a shorter duration and using a lower batch size compared to the document-level transformer model improve the processing time for large-scale literary translation tasks?"
https://aclanthology.org/2023.wmt-1.30/,Can large language models achieve comparable or better performance to fine-tuned models in discourse-level neural machine translation when using appropriate prompt strategies?
https://aclanthology.org/2023.wmt-1.30/,Does the use of large language models with different training strategies outperform traditional model training methods in discourse-level machine translation?
https://aclanthology.org/2023.wmt-1.31/,"Is it possible to improve the performance of standard sentence-level transformer models through domain adaptation using Back-Translation, Forward-Translation, and Data Diversification? Can multi-resolutional document-to-document translation techniques be effectively used to enhance discourse-level capabilities in machine translation?"
https://aclanthology.org/2023.wmt-1.32/,"How does the use of data augmentation technique for alignment in the Transformer-based MOE model improve neural machine translation performance in terms of accuracy and processing time, and what are the key factors that influence this improvement?"
https://aclanthology.org/2023.wmt-1.32/,Can the application of MOE-based architecture in machine translation improve the model's ability to handle out-of-vocabulary words and unseen language patterns in the translation task?
https://aclanthology.org/2023.wmt-1.33/,"Is the use of Fria∥el for parallel text curation of Nko language effective in improving machine translation accuracy, measured by a reduction in chrF++ score of 20% or more? Can the Expansion of the FLoRes-200 and NLLB-Seed corpora with Nko translations lead to significant improvements in bilingual machine translation performance on Fria∥el, evaluated using a bilingual evaluation metric such as BLEU score?"
https://aclanthology.org/2023.wmt-1.34/,Can the use of large-scale self-supervised pre-training improve the performance of sign language translation models compared to traditional supervised approaches in the Swiss-German Sign Language (DSGS) to German task?
https://aclanthology.org/2023.wmt-1.34/,"Does the integration of a VideoSwin transformer with a T5 model improve the accuracy and efficiency of sign language translation tasks, as evidenced by the significant increase in BLEU and chrF scores achieved in the WMT-SLT 22 development and test sets?"
https://aclanthology.org/2023.wmt-1.35/,"Can a gloss-free framework for Sign Language Translation using visual embeddings and a generator improve the translation accuracy of existing models, and what specific metrics would be used to evaluate its performance? Can the use of an embedding alignment block improve the diversity of visual embeddings in a Sign Language Translation system, and what are the potential benefits of this approach?"
https://aclanthology.org/2023.wmt-1.36/,Can a dictionary-based approach improve the accuracy of machine translation models when combined with rule-based methods for data curation in high-quality parallel corpora?
https://aclanthology.org/2023.wmt-1.36/,Can the BLEU score serve as a reliable evaluation metric for assessing the effectiveness of parallel data curation methods in machine translation systems?
https://aclanthology.org/2023.wmt-1.37/,How does the use of multilingual sentence embedding models impact the accuracy of cosine distance calculations for filtering parallel data pairs?
https://aclanthology.org/2023.wmt-1.37/,Can the application of Bicleaner AI in filtering parallel data pairs improve the overall quality of the curated data based on language detection and fluency classification metrics?
https://aclanthology.org/2023.wmt-1.38/,Can a context-aware translation system utilizing document-level monolingual data outperform sentence-level translation systems in terms of accuracy on diverse translation tasks?
https://aclanthology.org/2023.wmt-1.38/,Can the integration of large language models via model combination improve the performance of document-targeted translation systems in terms of processing time and computational overhead?
https://aclanthology.org/2023.wmt-1.39/,"Can large language models outperform traditional machine translation models for low-resource languages, and if not, what specific factors contribute to this disparity?"
https://aclanthology.org/2023.wmt-1.39/,"Does the performance of large language models in machine translation improve as the resource level of the language increases, and if so, what are the key characteristics of high-resource languages that enable this improvement?"
https://aclanthology.org/2023.wmt-1.40/,"Can large language models achieve more accurate and fluent translations when translating entire paragraphs rather than individual sentences, and how do the quality of these translations compare to human translations in terms of discourse-level coherence and stylistic consistency?"
https://aclanthology.org/2023.wmt-1.40/,"Do the benefits of translating entire paragraphs outweigh the increased computational cost and time required for annotation and analysis in evaluating large language models for literary translation tasks, and what evaluation metrics can be used to assess the quality of these translations?"
https://aclanthology.org/2023.wmt-1.41/,"What is the effectiveness of the MultiPro pipeline in identifying contextual sentences for translation, specifically for the phenomenon of verb phrase ellipsis, and how does it compare to previous annotation pipelines in terms of accuracy and scalability for languages such as English, Spanish, French, Italian, Polish, Portuguese, and Russian?"
https://aclanthology.org/2023.wmt-1.41/,"How does the use of coreference, part-of-speech, and morphological features in the MultiPro pipeline improve the identification of contextual sentences for pronouns, and what is the overlap with previous annotation pipelines in terms of annotation coverage and dataset scale for the five phenomena it targets?"
https://aclanthology.org/2023.wmt-1.42/,"What is the impact of using QLoRA fine-tuning on the BLEU score of machine translation models, and how does it compare to few-shot learning and models trained from scratch?"
https://aclanthology.org/2023.wmt-1.42/,Can QLoRA fine-tuning improve the performance of machine translation models on both sentence-level and document-level translations?
https://aclanthology.org/2023.wmt-1.43/,"Can Large Language Models effectively handle highly polysemous words in Machine Translation, and what are the performance gains from fine-tuning on curated ambiguous datasets?"
https://aclanthology.org/2023.wmt-1.43/,"Can LLMs outperform traditional Neural Machine Translation systems in translating sentences with rare word senses, and how do in-context learning methods impact disambiguation capabilities?"
https://aclanthology.org/2023.wmt-1.44/,Can a multilingual Transformer model's self-attention and cross-attention mechanisms be optimized for improved translation accuracy by pruning noisy heads and analyzing the remaining heads' functions and behaviors for different language pairs?
https://aclanthology.org/2023.wmt-1.44/,Can the cross-attention mechanism in multilingual Transformer models learn to identify and exploit the cooperative relationships between deep-layer heads to improve word reordering capabilities in translation tasks?
https://aclanthology.org/2023.wmt-1.45/,Can position-based attention with relative position representations and gating mechanism improve the efficiency of Transformer models on consumer GPUs while maintaining translation quality?
https://aclanthology.org/2023.wmt-1.45/,Can position-based attention with minimal degradation in attention weights improve the efficiency of Transformer models by utilizing memristive crossbar arrays for in-memory computation?
https://aclanthology.org/2023.wmt-1.46/,Can multimodal machine translation models be trained to generalize to unseen text-only language pairs without requiring additional human annotations?
https://aclanthology.org/2023.wmt-1.46/,Can the use of visual features learned from multimodal parallel data improve the performance of text-only machine translation models?
https://aclanthology.org/2023.wmt-1.47/,Can the proposed Gender-Gap Pipeline be applied to datasets outside of the News task to assess gender representation in other languages and domains?
https://aclanthology.org/2023.wmt-1.47/,How can the use of gender quantification in large-scale datasets be used to mitigate gender biases in language generation systems through data augmentation and other methods?
https://aclanthology.org/2023.wmt-1.48/,"Can a Transformer-based approach be used to classify Japanese text into formal, polite, and informal categories with high accuracy, and what are the implications of this approach for controlling the formality level of machine translation using Large Language Models?"
https://aclanthology.org/2023.wmt-1.48/,"Can prompting Large Language Models with specific formal or informal prompts improve the accuracy and effectiveness of machine translation in terms of formality, and how does the proposed approach compare to existing methods?"
https://aclanthology.org/2023.wmt-1.49/,"Can neural QE models be used to identify the most accurate sentence pairs in large-scale NMT training datasets, and what are the implications of using QE for filtering out low-quality examples?"
https://aclanthology.org/2023.wmt-1.49/,"Can the application of QE metrics to NMT training data lead to a reduction in training size without compromising translation quality, and what are the resulting improvements in model performance?"
https://aclanthology.org/2023.wmt-1.50/,Can neural-based metrics outperform non-neural metrics in correlating with human judgments on the sentence-level translation of Chinese-English and Hebrew-English language pairs?
https://aclanthology.org/2023.wmt-1.50/,Can the proposed method of generating synthetic reference translations based on MT system outputs and MQM ratings improve the correlation of metrics with human judgments for language pairs with poor reference translations?
https://aclanthology.org/2023.wmt-1.51/,Can machine learning models predict the quality of neural machine translation systems at the word and sentence levels with high accuracy using the updated quality annotation scheme and Multidimensional Quality Metrics?
https://aclanthology.org/2023.wmt-1.51/,"Can fine-grained error prediction models be developed to motivate research towards more detailed quality predictions using zero-shot testing on low-resource language pairs such as English-Hindi, English-Tamil, English-Telegu and English-Gujarati?"
https://aclanthology.org/2023.wmt-1.52/,"Can the proposed WLAC model outperform state-of-the-art models in completing target words given a translation context, as measured by the accuracy of the completed words?"
https://aclanthology.org/2023.wmt-1.52/,"Can the inclusion of semantic analysis in the WLAC model improve its performance in reducing semantic errors, as indicated by a decrease in the semantic error rate in the experimental results?"
https://aclanthology.org/2023.wmt-1.53/,"Can machine learning models effectively incorporate specialized terminology dictionaries to improve translation quality, as evaluated by BLEU score, and how does this approach compare to weakly supervised training that utilizes terminology access? Does the use of terminology dictionaries lead to a significant improvement in translation accuracy compared to a baseline model without terminology support?"
https://aclanthology.org/2023.wmt-1.54/,"Can machine learning algorithms be trained to improve the accuracy of post-editing of machine translation systems by leveraging human corrections, and how can their performance be evaluated using metrics such as automatic evaluation scores and human evaluation?"
https://aclanthology.org/2023.wmt-1.54/,"Can the use of diverse data sources from multiple domains, such as healthcare, tourism, and general news, affect the performance of machine translation post-editing systems in improving the quality of initial translations?"
https://aclanthology.org/2023.wmt-1.55/,"Can machine learning models achieve high accuracy in translating northeastern Indic languages such as Assamese, Mizo, Khasi, and Manipuri using the IndicNE-Corp1.0 dataset, as measured by BLEU score? Can the use of transformer-based architectures improve the translation quality of Indic language pairs compared to traditional machine translation systems evaluated using automatic metrics such as TER and RIBES?"
https://aclanthology.org/2023.wmt-1.56/,How do ensemble approaches combining different design families of metrics affect their overall performance in evaluating machine translation systems?
https://aclanthology.org/2023.wmt-1.56/,"Can multilingual embeddings significantly impact the accuracy of segment-level metrics in machine translation evaluation, and if so, how can their influence be better accounted for in evaluation frameworks?"
https://aclanthology.org/2023.wmt-1.57/,What are the effects of using Cometoid22-wmt23 and MetricX-23-c on the performance of machine translation systems for passive voice detection in German-English and focus particle recognition in English-Russian translation pairs?
https://aclanthology.org/2023.wmt-1.57/,Can a fine-tuned mT5 encoder-decoder language model improve the accuracy of terminology detection and measurement unit recognition in English-German translation pairs?
https://aclanthology.org/2023.wmt-1.58/,How can the use of tokenization algorithms improve the accuracy of the Tokengram_F metric in evaluating machine translation systems?
https://aclanthology.org/2023.wmt-1.58/,"Can Tokengram_F provide a more accurate evaluation of machine translation systems than the F-score-based metric, chrF++?"
https://aclanthology.org/2023.wmt-1.59/,"Can Embed_llama improve the semantic similarity detection between sentences by leveraging the embedding layer of the Llama 2 Large Language Model, and how does this improvement affect the overall accuracy of the metric in capturing geometric and semantic proximities?"
https://aclanthology.org/2023.wmt-1.59/,"Can the Embed_llama metric be optimized to reduce the processing time required for vector space transformation while maintaining its semantic similarity detection capabilities, and what is the impact on the model's ability to establish connections between geometric and semantic proximities?"
https://aclanthology.org/2023.wmt-1.60/,What is the effect of using fastText word embeddings on the performance of eBLEU compared to BLEU and ChrF metrics in machine translation tasks on the WMT23 dataset?
https://aclanthology.org/2023.wmt-1.60/,Does eBLEU surpass traditional metrics such as f101spBLEU and ChrF in metrics like MQM in machine translation tasks on the WMT22 dataset?
https://aclanthology.org/2023.wmt-1.61/,Can knowledge distillation be applied to machine translation evaluation metrics to create more efficient and accurate reference-free metrics?
https://aclanthology.org/2023.wmt-1.61/,Can reference-based teacher metrics be effectively distilled into neural QE metrics to improve their performance on machine translation tasks?
https://aclanthology.org/2023.wmt-1.62/,"Can learned regression-based metrics be improved by using different training data sources, and how do the performance results compare to the baseline models that use DA and MQM ratings?"
https://aclanthology.org/2023.wmt-1.62/,"Does the relationship between metric performance and model size have a significant impact on the overall quality estimation, and what is the optimal model size for this task?"
https://aclanthology.org/2023.wmt-1.63/,Can GEMBA-MQM accurately detect translation quality errors using only a fixed three-shot prompting technique without relying on human reference translations?
https://aclanthology.org/2023.wmt-1.63/,Does GEMBA-MQM's language-agnostic prompts allow for more efficient and flexible use across different languages without requiring manual prompt preparation?
https://aclanthology.org/2023.wmt-1.64/,"Can the proposed Metric Score Landscape Challenge (MSLC23) dataset improve the understanding of metric scores in machine translation by providing a more comprehensive view of the quality spectrum, and can it help to establish a more accurate benchmark for evaluating machine translation systems? Does the MSLC23 dataset enable the analysis of metric characteristics that are currently not fully captured by existing metrics, such as the impact of quality on the performance of machine translation systems?"
https://aclanthology.org/2023.wmt-1.65/,"Can the unsupervised metric MEE4 achieve comparable results to the supervised metric XLSim in evaluating machine translation systems, measured by their ability to predict human scores from reference translations? Can the performance of MEE4 be improved by incorporating contextual information from pre-trained language models such as XLM-RoBERTa?"
https://aclanthology.org/2023.wmt-1.66/,"How does the use of MBR decoding with BLEURT affect the quality of machine translation outputs, measured by BLEURT's utility metric?"
https://aclanthology.org/2023.wmt-1.66/,Can an MBR-based reference-free quality estimation metric be developed that achieves comparable results to a reference-based metric like BLEURT?
https://aclanthology.org/2023.wmt-1.67/,Can SLIDE outperform its context-less counterpart in terms of accuracy on the WMT22 MQM evaluation campaign?
https://aclanthology.org/2023.wmt-1.67/,Can SLIDE achieve better performance than COMET in scoring a single unit of concatenated chunks from a fixed sentence-length window on the WMT22 evaluation campaign?
https://aclanthology.org/2023.wmt-1.68/,"Can a regression encoder be used to predict the semantic meaning of machine translation outputs with high accuracy, and if so, how can it be improved to reduce the time consumption in human evaluation? Can the contrastive pretraining of regression encoder lead to more accurate machine translation results compared to traditional evaluation methods?"
https://aclanthology.org/2023.wmt-1.69/,Can KG-BERTScore be improved by incorporating more domain-specific knowledge into its scoring mechanism for better handling of domain-specific language pairs?
https://aclanthology.org/2023.wmt-1.69/,Can HWTSC-EE-Metric be adapted to evaluate the performance of machine translation systems on low-resource languages with limited training data?
https://aclanthology.org/2023.wmt-1.70/,Can the pseudo data methods proposed in this study improve the performance of quality estimation models when pre-trained on pseudo data and fine-tuned on real data in the English-German language pair?
https://aclanthology.org/2023.wmt-1.70/,Can a simple method to convert word-level outputs to fine-grained error span results using pseudo data methods for quality estimation improve the overall performance of the XLMR large model?
https://aclanthology.org/2023.wmt-1.71/,"Can the proposed CrossQE model with finetuned and ensembled multiple base models (XLM-R, InfoXLM, RemBERT, and CometKiwi) achieve better performance on sentence-level QE tasks compared to its previous version?"
https://aclanthology.org/2023.wmt-1.71/,Can the proposed corruption-based data augmentation method improve the performance of the CrossQE model in sentence-level QE tasks on various language pairs?
https://aclanthology.org/2023.wmt-1.72/,What are the key differences in performance between the proposed multilingual approaches and the previous state-of-the-art CometKiwi model in the WMT 2023 Shared Task on Quality Estimation?
https://aclanthology.org/2023.wmt-1.72/,What are the specific improvements in correlation with human judgements that the proposed multilingual approaches achieve compared to the previous state-of-the-art model?
https://aclanthology.org/2023.wmt-1.73/,"Can MonoTransQuest with InfoXLM-large outperform other models in quality estimation tasks for low-resource languages, and what is the optimal ensemble size for achieving the best results in MonoTransQuest for quality estimation tasks?"
https://aclanthology.org/2023.wmt-1.74/,"Can the proposed data augmentation approach using synonym replacement via the Paraphrase Database (PPDB) improve the correlation between QE model predictions and human quality assessments for all language pairs, and how does the performance of the model change when trained on a more diverse and larger set of samples?"
https://aclanthology.org/2023.wmt-1.74/,"Can the use of contextual word embeddings-based words insertion, back translation, and direct paraphrasing methods outperform synonym replacement via the Paraphrase Database (PPDB) for language pairs where these methods are found to be more effective?"
https://aclanthology.org/2023.wmt-1.75/,Can the proposed cross-lingual and multitask model for sentence and word level quality estimation achieve higher accuracy on unseen data using pre-trained multilingual models compared to state-of-the-art methods?
https://aclanthology.org/2023.wmt-1.75/,Can the proposed method of combining predictions from multiple models and automatically optimizing their weights for better performance on the development set improve the overall quality estimation results in the test set?
https://aclanthology.org/2023.wmt-1.76/,Can machine learning-based word-level auto-completion methods outperform traditional statistical models in terms of accuracy when applied to various encoder-based architectures in Computer-Assisted Translation?
https://aclanthology.org/2023.wmt-1.76/,Can the incorporation of machine translation tasks into word-level auto-completion systems using joint methods lead to significant improvements in model size and performance in the context of WMT23 WLAC task?
https://aclanthology.org/2023.wmt-1.77/,"What are the effectiveness and computational efficiency of the proposed segment-based interactive machine translation approach when no context is available for the English-German and German-English categories, and how does fine-tuning the pre-trained mT5 large language model for autocompletion impact its performance?"
https://aclanthology.org/2023.wmt-1.78/,"Can LLMs achieve high accuracy in word-level auto-completion tasks in multilingual contexts, and how do they perform in zero-shot and few-shot settings?"
https://aclanthology.org/2023.wmt-1.78/,Can the incorporation of exemplars in the training set improve the performance of LLMs in word-level auto-completion tasks in multilingual contexts?
https://aclanthology.org/2023.wmt-1.79/,"How can a translate-then-refine approach using pseudo-terminology translations effectively incorporate domain-specific terminologies into a machine translation system, and what are the key factors that influence its performance in terms of accuracy and recall?"
https://aclanthology.org/2023.wmt-1.79/,Can the use of large language models in post-processing to refine terminology-aware models lead to improved terminology recall and how does it compare to the alignment-based approach in terms of effectiveness and computational resources?
https://aclanthology.org/2023.wmt-1.80/,"Can a non-supervised approach to creating a synthetic dictionary from parallel corpora effectively improves the translation of technical terms in machine translation systems, as measured by accuracy and syntactic correctness? Does the proposed method of re-sampling annotated data improve the model's ability to recognize and translate terminology in different language directions, such as Chinese to English, English to Czech, and German to English?"
https://aclanthology.org/2023.wmt-1.81/,"Can large language models be used to generate high-quality synthetic bilingual terminology-based data for machine translation systems, and can fine-tuning these models with pre-approved terms improve translation accuracy in specialized domains?"
https://aclanthology.org/2023.wmt-1.81/,"Can the post-editing of machine translation outputs using large language models improve the incorporation of specialized terms into translations, and what are the key factors that influence this process?"
https://aclanthology.org/2023.wmt-1.82/,Can the OPUS-CAT project's terminology-based machine translation systems achieve a higher accuracy for the target language terms than those without terminology support for the language pairs included in the WMT 2023 task?
https://aclanthology.org/2023.wmt-1.82/,Can the use of terminology support in the training pipeline for the OPUS-CAT project improve the processing time for the translation of source language terms to target language terms in the WMT 2023 task?
https://aclanthology.org/2023.wmt-1.83/,"Can a machine learning framework be designed to automatically extract and incorporate domain-specific terminology into neural machine translation models, improving consistency in translation outcomes, and how can this framework be evaluated using metrics such as precision and recall in low-supervision settings?"
https://aclanthology.org/2023.wmt-1.83/,"Can the use of terminology-aware model architectures with constraints improve the accuracy and consistency of machine translation, especially in narrow domains like literature and medicine, and what are the potential benefits of incorporating domain-specific terminology in machine translation systems?"
https://aclanthology.org/2023.wmt-1.84/,"Can pre-trained APE models be improved by fine-tuning with a limited APE corpus and external MT augmentation, and what is the impact on TER and BLEU scores?"
https://aclanthology.org/2023.wmt-1.84/,How does the incorporation of R-Drop and sentence-level QE in APE systems affect the over-correction issue and overall performance?
https://aclanthology.org/2023.wmt-1.85/,"Can NMT models be improved for low-resource languages such as Assamese and Manipuri to achieve higher BLEU scores, and if so, what specific transformer architecture modifications are required for this task?"
https://aclanthology.org/2023.wmt-1.85/,"What is the impact of using pre-trained multilingual models on the performance of NMT systems for low-resource language pairs, and how can these models be fine-tuned for better results?"
https://aclanthology.org/2023.wmt-1.86/,"Can Neural Machine Translation models achieve significant improvements in performance on low-resource languages when utilizing back-translation and fine-tuning techniques, and what specific subword tokenization approaches yield the best results for these models?"
https://aclanthology.org/2023.wmt-1.86/,"Can the integration of monolingual data into the bilingual dataset through iterative back-translation significantly enhance the performance of NMT models on low-resource language pairs, and what is the impact on BLEU scores?"
https://aclanthology.org/2023.wmt-1.87/,"Can the backtranslation process improve translation quality by up to 4 BLEU points in the Indic MT task in WMT 2023, and how does the combination of primary and contrastive systems impact overall translation quality? Can fine-tuning IndicTrans2 DA models on official parallel corpora and seed data improve the performance of low-resource North-East Indian languages?"
https://aclanthology.org/2023.wmt-1.88/,Can the pre-trained multilingual NMT model improve the performance of low-resource MT systems for North-East Indian languages in terms of accuracy and processing time when fine-tuned on a small parallel corpus?
https://aclanthology.org/2023.wmt-1.88/,"Does the transfer learning approach using a large pre-trained multilingual NMT system outperform traditional approaches in terms of system development speed and quality for low-resource languages like Assamese, Khasi, Manipuri, and Mizo?"
https://aclanthology.org/2023.wmt-1.89/,"Can the use of multilingual masked language modeling and denoising auto-encoding for pretraining improve the translation performance into English for Assamese, Khasi, Mizo, and Manipuri languages without using multilingual MT pretraining step?"
https://aclanthology.org/2023.wmt-1.89/,Can the effectiveness of online back-translation for data augmentation in multilingual machine translation systems be compared to that of pseudo-parallel data mined from monolingual corpora for pretraining?
https://aclanthology.org/2023.wmt-1.90/,Can the use of word embeddings initialization methods impact the performance of supervised neural machine translation systems for low-resource languages?
https://aclanthology.org/2023.wmt-1.90/,Does the relationship between dataset size and model size influence the effectiveness of training frameworks for neural machine translation systems on low-resource languages?
https://aclanthology.org/2023.wmt-1.91/,"Can the transformer-based NMT system be improved upon to achieve higher BLEU scores for the English-Manipuri language pair, and what are the key factors that contribute to the differences in translation quality between the English to Manipuri and Manipuri to English models?"
https://aclanthology.org/2023.wmt-1.92/,Can machine learning models achieve state-of-the-art performance on the Manipuri-to-English translation task with limited parallel training data available for this language pair?
https://aclanthology.org/2023.wmt-1.92/,"Can the incorporation of multimodal learning approaches improve the translation quality of Indic languages with limited parallel data, as evidenced by the proposed approach's best scoring system for Manipuri-to-English translation?"
https://aclanthology.org/2023.wmt-1.93/,"Can transformer-based neural networks improve the quality of low-resource language translation by utilizing monolingual data through pre-training and data augmentation, as demonstrated by the experimental results of the WMT23 shared task?"
https://aclanthology.org/2023.wmt-1.93/,"Can the combination of denoising language models and multilingual machine translation models improve the accuracy of English-Indic language pairs, as indicated by the BLEU scores achieved in the WMT23 shared task?"
https://aclanthology.org/2023.wmt-1.94/,"Can a metric trained on human evaluations be improved by fine-tuning its parameters using a supervised learning approach, and does this improvement generalize to more robustness to machine-translated references?"
https://aclanthology.org/2023.wmt-1.94/,"Can a baseline metric, such as Prism, be made more robust to machine-translated references through fine-tuning, and what is the impact on its overall correlation with human judgments?"
https://aclanthology.org/2023.wmt-1.95/,"Can we develop a more accurate paragraph-level evaluation metric that captures the nuances of paragraph-level translations, and how does this approach compare to existing sentence-level metrics in terms of precision and recall on longer translations?"
https://aclanthology.org/2023.wmt-1.95/,"Can sentence-level metrics be effectively adapted to assess the quality of paragraph-level translations, and what are the limitations of using these metrics for this task?"
https://aclanthology.org/2023.wmt-1.96/,"Can Large Language Models be used to generate diverse and effective source sentences for behavioral testing of Machine Translation systems, and how do these generated sentences impact the accuracy of the evaluation framework?"
https://aclanthology.org/2023.wmt-1.96/,Can Behavioral testing of Machine Translation systems using Large Language Models be able to uncover potential bugs and differences in MT systems that are not apparent through traditional accuracy-based metrics?
https://aclanthology.org/2023.wmt-1.97/,"Is it possible to achieve comparable or improved accuracy using a single FFN across both the encoder and decoder layers, and what are the potential benefits of sharing FFN in terms of latency? Can removing or reducing the number of FFN layers in the Transformer model lead to significant improvements in model size and computational efficiency?"
https://aclanthology.org/2023.wmt-1.98/,How do dialect-specific evaluation metrics perform on non-standardized dialects compared to standardized dialects in natural language processing tasks?
https://aclanthology.org/2023.wmt-1.98/,Can dialect-robust metrics improve the accuracy of Swiss German text generation models when exposed to segment-level variation in language varieties?
https://aclanthology.org/2023.wmt-1.99/,"Can AutoMQM improve the accuracy of machine translation systems compared to traditional metrics, and how does the performance of AutoMQM change with the size of the model used?"
https://aclanthology.org/2023.wmt-1.99/,Does the use of in-context learning and finetuning in AutoMQM lead to more accurate error annotations than simple score prediction prompting?
https://aclanthology.org/2024.wmt-1.0/,"Can a transformer-based machine translation system achieve higher accuracy in translating medical texts compared to LLMs, measured by the F1-score on the ESA-annotated test sets? Can the use of online translation providers result in lower error rates compared to participating systems, measured by the percentage of sentence-level corrections required by professional human annotators?"
https://aclanthology.org/2024.wmt-1.1/,"Can LLM-based machine translation systems be accurately evaluated using existing metrics, and if so, what specific types of translation errors do these metrics effectively identify and penalize?"
https://aclanthology.org/2024.wmt-1.1/,Can pairwise accuracy of MT metrics improve when evaluating systems at both the system-level and segment-level in real-world usage scenarios?
https://aclanthology.org/2024.wmt-1.2/,"Can we design an automated post-editing system that achieves high accuracy in correcting translated outputs using Multidimensional Quality Metrics (MQM) annotations for the languages of English, Spanish, and Hindi?"
https://aclanthology.org/2024.wmt-1.2/,"Can large language models (LLMs) be trained to reduce gender bias and improve performance in translation from English into Hindi, Gujarati, Tamil, and Telugu?"
https://aclanthology.org/2024.wmt-1.3/,Can a more diverse range of languages be effectively integrated into the FLORES+ and MT Seed datasets to improve the robustness of multilingual language models?
https://aclanthology.org/2024.wmt-1.3/,Can the use of transfer learning techniques improve the accuracy of multilingual machine translation models on the expanded FLORES+ and MT Seed datasets?
https://aclanthology.org/2024.wmt-1.4/,"How can large language model-based systems be improved to achieve higher accuracy in patent translation tasks, particularly in handling domain-specific terminology and technical jargon?"
https://aclanthology.org/2024.wmt-1.4/,"Can large language model-based systems be evaluated and compared effectively using a combination of automatic and manual evaluation metrics, and what are the implications for the development of more accurate patent translation systems?"
https://aclanthology.org/2024.wmt-1.5/,"Can the proposed baseline system using Llama 3.1 achieve a higher BLEU score on the biomedical translation task compared to previous years, and how does the lack of sentence splitting affect the performance of the system?"
https://aclanthology.org/2024.wmt-1.5/,"Does the use of Llama 3.1 as a baseline system have a significant impact on the translation quality of biomedical abstracts from and into languages such as French, German, Italian, Portuguese, Russian, and Spanish?"
https://aclanthology.org/2024.wmt-1.6/,"Can a Transformer-based system be trained to achieve state-of-the-art performance on the English-German, English-Spanish, and Japanese-Chinese MSLC metrics using a simple modification to the standard translation training pipeline?"
https://aclanthology.org/2024.wmt-1.6/,Can the use of constrained data and minimal model modifications significantly impact the accuracy of the MSLC metrics for Transformer-based translation systems?
https://aclanthology.org/2024.wmt-1.7/,Can a combination of pretraining with tens of billions of parameters and fine-tuning with hundreds of billions of parameters using open-source large language models improve the performance of machine translation systems?
https://aclanthology.org/2024.wmt-1.7/,Can the use of ensemble learning in conjunction with open-source data and LLMs enhance the accuracy of machine translation systems in various translation directions?
https://aclanthology.org/2024.wmt-1.8/,"Can the use of continue pre-training and contrastive preference optimization improve the performance of neural machine translation models, as measured by the accuracy of the final translation output? Does the combination of Minimum Bayesian risk decoding and supervised fine-tuning enhance the effectiveness of large language models in machine translation tasks?"
https://aclanthology.org/2024.wmt-1.9/,Can CycleGN with MLM pre-training be used to improve the accuracy of translation tasks on permuted non-parallel datasets and how does its performance compare to the traditional Cycle Consistency Loss approach? Can CycleGN with MLM pre-training be used to improve the accuracy of translation tasks on non-intersecting non-parallel datasets and how does its performance compare to the traditional Cycle Consistency Loss approach?
https://aclanthology.org/2024.wmt-1.10/,Can FT-LLMs achieve state-of-the-art performance on the WMT24 general MT shared task for English to Chinese using high-quality but small bitext datasets?
https://aclanthology.org/2024.wmt-1.10/,"Can the use of Quality Estimation data filtering improve the performance of encoder-decoder NMT systems when combined with LLMs, and does it have a limited impact on the performance of FT-LLMs?"
https://aclanthology.org/2024.wmt-1.11/,Can Tower v2's expanded language coverage and improved data quality lead to better performance in low-resource language pairs compared to its 7B parameter predecessor? Does the increased model capacity of Tower v2 enable more accurate quality-aware decoding and improved overall translation quality?
https://aclanthology.org/2024.wmt-1.12/,"Can discrete diffusion models be used to improve the length prediction of machine translation outputs for all four language pairs (English-Russian, English-German, English-Czech, English-Spanish) with high accuracy?"
https://aclanthology.org/2024.wmt-1.12/,"How does the use of a separate length regression model affect the performance of discrete diffusion models for English-to-{Russian, German, Czech, Spanish} translation tasks in the constrained track of WMT'24?"
https://aclanthology.org/2020.lrec-1.0/,Can a neural network-based approach using the mention detection part of a state-of-the-art coreference resolution system achieve high recall in a HIGH RECALL coreference annotation setting?
https://aclanthology.org/2020.lrec-1.0/,Can a neural network-based approach using BERT embeddings and a biaffine classifier outperform state-of-the-art mention detection models on the CONLL and CRAC coreference data sets in a HIGH F1 annotation setting?
https://aclanthology.org/2020.lrec-1.1/,"Can an attention-based approach improve the performance of anaphora resolution systems in identifying singletons and non-referring expressions, and how does the inclusion of these elements affect the overall performance on non-singleton clusters?"
https://aclanthology.org/2020.lrec-1.1/,"Can the use of additional classifiers for singleton and non-referring markables enhance the effectiveness of cluster-ranking systems in identifying and resolving anaphora, and what are the implications for the overall system design?"
https://aclanthology.org/2020.lrec-1.2/,"Can Mandarinograd effectively reduce biases in natural language understanding models by providing a dataset of Winograd Schemas in Mandarin Chinese, and does the dataset's use of ENTAILMENT or NO ENTAILMENT pairs improve the accuracy of anaphora resolution models?"
https://aclanthology.org/2020.lrec-1.2/,Can the use of natural language inference instances in Mandarinograd improve the robustness of anaphora resolution models to syntactic or semantic anomalies in existing datasets?
https://aclanthology.org/2020.lrec-1.3/,"Can transformer-based end-to-end approaches to coreference resolution improve the performance of downstream tasks using six different word embedding methods, particularly in lexical-semantic evaluation tasks such as instantiation/hypernymy detection?"
https://aclanthology.org/2020.lrec-1.3/,"Do the improvements in F1-scores from CR with transformer networks remain significant when pronouns are substituted in the text, and how does this impact the performance of word embeddings in downstream tasks?"
https://aclanthology.org/2020.lrec-1.4/,"Is the use of standoff annotation scheme in noun ellipsis annotation effective in capturing the nuances of ellipsis resolution in a large corpus, and can it improve the accuracy of downstream NLP tasks such as information retrieval and event extraction? Can machine learning classifiers trained on annotated noun ellipsis data achieve high accuracy in detecting and resolving noun ellipsis in real-world text data?"
https://aclanthology.org/2020.lrec-1.5/,"What are the characteristics of long-distance coreference resolution in literary works compared to other domains, measured by the accuracy of coreference annotations?"
https://aclanthology.org/2020.lrec-1.5/,"Can this new dataset be used to train and evaluate the performance of deep learning models for coreference resolution in longer documents, and how do they compare to existing models on shorter texts?"
https://aclanthology.org/2020.lrec-1.6/,"What is the effect of integrating dramatis personae information into a coreference resolution system, and how does this integration impact the performance of the system in terms of accuracy?"
https://aclanthology.org/2020.lrec-1.6/,"How do the structural properties of dramatic texts differ from those of news texts and dialogical text types such as interviews, and what implications does this have for the design of coreference resolution systems?"
https://aclanthology.org/2020.lrec-1.7/,"Can deep learning models achieve high accuracy in identifying entity coreference chains in email conversations, and what are the characteristics of email threads that significantly affect their performance?"
https://aclanthology.org/2020.lrec-1.7/,"What are the key steps and challenges in creating and annotating a seed corpus for entity resolution in email conversations, and how do these impact the performance of deep learning models?"
https://aclanthology.org/2020.lrec-1.8/,Can a knowledge-based approach to annotating pronouns in text improve the efficiency and accuracy of coreference resolution tasks compared to traditional annotation methods?
https://aclanthology.org/2020.lrec-1.8/,Can a model-based annotation scheme that links entities to a knowledge base enhance the inter-annotator agreement and overall performance of coreference resolvers in handling pronouns?
https://aclanthology.org/2020.lrec-1.9/,"What is the impact of using different training configurations on the performance of coreference resolution systems for French, specifically the effect of including singletons in the model?"
https://aclanthology.org/2020.lrec-1.9/,"Does the focus on boundary identification improve mention detection, and how does this improvement affect the overall coreference resolution performance of the model?"
https://aclanthology.org/2020.lrec-1.10/,Can a BERT-based cross-lingual model be effectively trained to resolve zero-pronouns in Arabic and Chinese languages without relying on explicit lexical relationships?
https://aclanthology.org/2020.lrec-1.10/,Can the performance of BERT feature extraction and fine-tuning for zero-pronoun resolution be compared to a proposed neural model that leverages semantic coherence and layer-specific representations?
https://aclanthology.org/2020.lrec-1.11/,"Can a machine learning model trained on multilingual corpora be able to accurately classify non-nominal co-reference of the pronoun 'it' across different languages, and if so, how does the type of construction used in the translation affect the classification accuracy? Can the model generalize to other types of non-nominal reference, such as pronouns and proper nouns, using parallel multilingual corpora as cheap supervision?"
https://aclanthology.org/2020.lrec-1.12/,"Can a deep learning model using a transformer-based architecture achieve high accuracy in coreference resolution for the MuDoCo dataset, and can it be improved by incorporating additional linguistic annotations? Can a deep learning model using a transformer-based architecture generate accurate and coherent referring expressions for the MuDoCo dataset, and can it be improved by using a combination of language models and coreference resolution models?"
https://aclanthology.org/2020.lrec-1.13/,What is the impact of incorporating affective knowledge from Affect Control Theory (ACT) into Long Short-term Memory (LSTM) models on sentiment analysis accuracy?
https://aclanthology.org/2020.lrec-1.13/,How does the use of EPA vectors in LSTM models enhance the identification of affective terms and improve model performance compared to conventional LSTM models?
https://aclanthology.org/2020.lrec-1.14/,Can linguistic features derived from the Alice Datasets be used to improve the accuracy of deep learning-based models for natural language processing tasks?
https://aclanthology.org/2020.lrec-1.14/,Can the use of hierarchical syntactic predictors in the Alice Datasets lead to more accurate predictions of prosodic cues in speech processing?
https://aclanthology.org/2020.lrec-1.15/,"Can text world annotation schemes based on the Text World Theory be used to improve the accuracy of machine learning models for sentiment analysis in literary texts, measured by F1-score, and what are the challenges and limitations of applying such schemes to annotating narratives in criminal evidence?"
https://aclanthology.org/2020.lrec-1.15/,"Can the proposed annotation scheme for text worlds and their elements be generalized to annotating narratives in other domains, such as teaching materials and quests, and what is the impact of using this scheme on the processing time of text preprocessing tasks?"
https://aclanthology.org/2020.lrec-1.16/,Can the proposed neural code hypothesis of articulatory code (AC) be verified through the analysis of synchronized cortical recordings with speech signals in a controlled environment? Can the use of Ɵ/γ-oscillations as a mechanism for transporting and segmenting the AC be validated through machine learning-based classification models?
https://aclanthology.org/2020.lrec-1.17/,"Can the gaze patterns of participants in the task-specific paradigm differ significantly from those in the natural reading paradigm, and how do these differences relate to the cognitive processing of semantic relations in written text?"
https://aclanthology.org/2020.lrec-1.17/,"Can the use of electroencephalography data in conjunction with eye-tracking data improve the accuracy of semantic relation detection in natural reading and annotation tasks, and what are the implications for the development of more accurate cognitive models of human language processing?"
https://aclanthology.org/2020.lrec-1.18/,"Can linguistic and kinematic features of utterances referring to concrete actions be used to predict the stability of a participant's gaze on an area, and what is the accuracy of such predictions using a supervised classification model based on a Transformer architecture? Can the use of gaze behavior and kinematic information in task descriptions be used to improve the performance of language models by enhancing their ability to understand the context of concrete actions?"
https://aclanthology.org/2020.lrec-1.19/,What methods can be used to efficiently mine the ACQDIV corpus database to identify universal patterns in child language acquisition across 14 typologically diverse languages?
https://aclanthology.org/2020.lrec-1.19/,Can the extensible software package developed for the ACQDIV corpus database be used to analyze child language acquisition patterns in smaller corpora with fewer linguistic features?
https://aclanthology.org/2020.lrec-1.20/,"Can we develop a more efficient method to link pictograms to their corresponding WordNet synsets, and how does this impact the accuracy of text-to-picto applications in the French language?"
https://aclanthology.org/2020.lrec-1.20/,"Can we design a more scalable and user-friendly interface to access and utilize the Arasaac-WN database, and how does this affect the overall user experience of people with cognitive disabilities?"
https://aclanthology.org/2020.lrec-1.21/,Can a supervised learning approach using a Transformer-based architecture improve the accuracy of reading times in relation to orthographic similarity between words for alphabetic languages?
https://aclanthology.org/2020.lrec-1.21/,"Can the use of inverse feature weighting, such as the inverse of mutual information, affect the neighborhood effect in a non-alphabetic writing system like Korean Hangul?"
https://aclanthology.org/2020.lrec-1.22/,"Can keystroke logging data from Etherpad accurately predict the syntactic complexity of the texts produced by upper-intermediate to advanced L2 learners of English, and how does this prediction relate to their writing performance?"
https://aclanthology.org/2020.lrec-1.22/,"Can the behavioral data from keystroke logging be used to identify lexical complexity in texts produced by L2 learners, and how does this relate to their writing accuracy?"
https://aclanthology.org/2020.lrec-1.23/,Can a deep learning model trained on the BCCWJ-EEG corpus achieve higher accuracy in sentiment analysis tasks compared to a model trained on existing language resources with human annotated data?
https://aclanthology.org/2020.lrec-1.23/,"Can the use of EEG signals in conjunction with deep learning models improve the performance of NLP tasks, specifically in the analysis of written Japanese text, as compared to traditional NLP approaches?"
https://aclanthology.org/2020.lrec-1.24/,Is the perception of speech disfluencies in the brain associated with increased activity in the anterior cingulate cortex and the prefrontal cortex?
https://aclanthology.org/2020.lrec-1.24/,Can the use of annotated multichannel corpora like RUPEX improve the accuracy of fMRI-based studies on speech disfluencies perception?
https://aclanthology.org/2020.lrec-1.25/,"Can machine translation techniques improve the accuracy of grammatical error correction systems for Japanese as a Second Language learners, and what is the performance difference between NMT and SMT systems in this context?"
https://aclanthology.org/2020.lrec-1.25/,"Can the use of a noise-reduced corpus, such as the one created for JSL learners, improve the evaluation of grammatical error correction systems and what metrics can be used to measure this improvement?"
https://aclanthology.org/2020.lrec-1.26/,"Can a crowdsourced dataset for Korean information extraction tasks achieve higher accuracy and precision than traditional methods when using a single, comprehensive dataset for all tasks?"
https://aclanthology.org/2020.lrec-1.26/,Will the sequential evaluation of a state-of-the-art model on multiple information extraction tasks using the same dataset reveal a significant improvement in performance when training and evaluating the model on each task consecutively?
https://aclanthology.org/2020.lrec-1.27/,"Can an AI system accurately interpret indirect speech acts in context-dependent scenarios, as measured by its ability to correctly classify 90% of ISAs with a precision of 80% and a recall of 90%?"
https://aclanthology.org/2020.lrec-1.27/,"Can a crowdsourced corpus of indirect speech acts be effectively developed using corpus analysis and a schema authoring approach that maximizes realism while minimizing expert authoring effort, and what are the characteristics of the collected data?"
https://aclanthology.org/2020.lrec-1.28/,Can the proposed probabilistic model effectively estimate the quality of speech artifacts by considering both the qualities of the artifacts and the biases of the creators and reviewers as latent variables?
https://aclanthology.org/2020.lrec-1.28/,"Can the proposed model outperform the majority voting method in estimating the quality of speech artifacts in partially subjective tasks, particularly in tasks with high levels of disagreement among reviewers?"
https://aclanthology.org/2020.lrec-1.29/,"Can crowdsourcing approaches using translated definitions in FrameNet be effective in capturing cross-linguistically the meaning of frames, and what are the implications for the construction of multilingual resources in FrameNet?"
https://aclanthology.org/2020.lrec-1.29/,"How do different crowdsourcing settings, including the provision of English definitions, impact the accuracy of cross-culturally capturing the meaning of frames in multilingual FrameNets?"
https://aclanthology.org/2020.lrec-1.30/,"Can crowdsourcing be used to evaluate the intrinsic and extrinsic quality of query-based extractive text summaries with high accuracy and reliability, measured by the mean opinion score and correlation coefficients?"
https://aclanthology.org/2020.lrec-1.30/,Does the number of repetitions in crowdsourcing setups affect the robustness of mean opinion score and correlation coefficients between crowd and laboratory ratings for evaluating the quality of text summaries?
https://aclanthology.org/2020.lrec-1.31/,"Can a machine learning model trained on a dataset of Wikipedia articles about Hindu temples achieve high accuracy in extracting accurate facts about temples, and how can the performance of such a model be evaluated?"
https://aclanthology.org/2020.lrec-1.31/,"Can the proposed platform for creating temple corpora be adapted to extract information from other types of cultural or historical sites in India, such as museums or monuments?"
https://aclanthology.org/2020.lrec-1.32/,Does modality markers with high certainty trigger Chinese readers' confidence in believing events have occurred?
https://aclanthology.org/2020.lrec-1.32/,Can event-selecting predicates from authoritative sources affect Chinese readers' veridicality judgments of news events?
https://aclanthology.org/2020.lrec-1.33/,"Can crowdsourced language exercises be designed to improve the accuracy of language learning resources (LRs) in a way that is comparable to human-annotated datasets, and if so, what specific annotation techniques can be used to achieve this goal? Can the proposed approach be applied to produce a comprehensive and consistent set of LRs for low-resource languages using crowdsourcing and machine learning techniques?"
https://aclanthology.org/2020.lrec-1.34/,"Can crowdsourced annotation of idioms with a fixed list and clear instructions be scaled up to accommodate a corpus of over 50,000 instances, and what are the implications for the analysis of idiom distribution across different genres?"
https://aclanthology.org/2020.lrec-1.34/,"Does the use of crowdsourcing in creating a large idiom corpus impact the quality of the annotations, and can the metadata of the corpus be used to investigate the relationship between idiom usage and genre?"
https://aclanthology.org/2020.lrec-1.35/,How can CRWIZ's semi-guided dialogue approach improve the accuracy of crowd-sourced data for emergency response tasks compared to traditional task-based dialogues that rely on expert domain knowledge?
https://aclanthology.org/2020.lrec-1.35/,"Can CRWIZ's ability to capture a wide variety of interactions be measured through the use of machine learning algorithms that analyze the collected data for patterns and trends in collaborative, complex tasks?"
https://aclanthology.org/2020.lrec-1.36/,"Can machine learning models predict the effort required to complete named entity annotation tasks with high accuracy and precision, and if so, what are the key factors that influence the time spent on such tasks, such as cognitive load and input length?"
https://aclanthology.org/2020.lrec-1.36/,"Can crowdsourcing platforms effectively use the predicted effort times to compute fair pricing for human annotators, and how can these platforms optimize their payment structures to incentivize workers to complete tasks efficiently?"
https://aclanthology.org/2020.lrec-1.37/,"Can the V-TREL vocabulary trainer, accessed through a Telegram chatbot interface, effectively improve vocabulary skills among university students learning English at the C1 level, as measured by their ability to provide accurate answers to word relation questions over a period of 16 days?"
https://aclanthology.org/2020.lrec-1.37/,"Does the implicit crowdsourcing paradigm used in V-TREL enable the collection of a large quantity of high-quality data on word relations suitable for expanding ConceptNet, as evidenced by the collection of over 12,000 learner responses?"
https://aclanthology.org/2020.lrec-1.38/,"Can the proposed framework accurately estimate expressivity in young readers using phonetic features and linguistic features, and how does its performance compare to a baseline model using only linguistic features?"
https://aclanthology.org/2020.lrec-1.38/,"Can the proposed framework effectively utilize multiple adult references to estimate multidimensional subjective ratings of reading performance in young readers, and what is the average processing time required for this estimation?"
https://aclanthology.org/2020.lrec-1.39/,"Can LARA's semi-automated text annotation process improve the accuracy of machine learning models for language learning tasks by reducing the time required to produce substantial annotated texts in multiple languages, as measured by the average processing time per sentence?"
https://aclanthology.org/2020.lrec-1.39/,"Does the use of crowdsourcing techniques for creating LARA resources affect the quality of the annotated texts, as evaluated by the user satisfaction rate of language learners, compared to traditional annotation methods?"
https://aclanthology.org/2020.lrec-1.40/,How do open-ended comments and mitigating expressions in teacher feedback affect the revision outcome of student-written sentences?
https://aclanthology.org/2020.lrec-1.40/,What is the impact of directness in teacher feedback on the revision outcome of student-written sentences with linking adverbial errors?
https://aclanthology.org/2020.lrec-1.41/,Can a supervised learning approach using a transformer-based architecture be used to generate accurate and informative feedback comments that can effectively guide students in improving their writing skills?
https://aclanthology.org/2020.lrec-1.41/,"Can the use of preposition use feedback comments be correlated with improved student performance in writing tasks, as measured by a significant increase in syntactic correctness and overall writing quality?"
https://aclanthology.org/2020.lrec-1.42/,"What is the feasibility of using CEFRLex resources to build language learning applications, considering the potential for vocabulary items to be used on lower-level materials?"
https://aclanthology.org/2020.lrec-1.42/,Can the CEFRLex resource be adjusted to better align with the CEFR levels by incorporating values from monolingual and parallel corpora?
https://aclanthology.org/2020.lrec-1.43/,"Can a Convolutional Neural Network based approach be used to recognize objects in a user's environment and provide interactive 3D information in multiple languages, and if so, how can the accuracy of this approach be evaluated?"
https://aclanthology.org/2020.lrec-1.43/,Can the use of Augmented Reality to enhance language learning in teaching contexts be improved by using an Open Source mobile application that can superimpose 3D information on real-world objects in multiple languages?
https://aclanthology.org/2020.lrec-1.44/,Can the proposed dataset of revisions be used to train a machine learning model to predict the likelihood of a revision being a major revision versus a minor revision based on the 31 automatically extracted features?
https://aclanthology.org/2020.lrec-1.44/,Can the product-oriented analysis of the revisions in the provided dataset be used to develop a linguistic model that can identify the most common revision patterns for argumentative texts and academic abstracts?
https://aclanthology.org/2020.lrec-1.45/,"Does the proposed system effectively identify specific classes of grammatical errors commonly found in engineering students' assignments, and can it improve the quality of student assignments when providing constructive feedback? Can the system's performance be measured using traditional metrics such as accuracy or F1-score to evaluate its effectiveness in English Scientific Writing?"
https://aclanthology.org/2020.lrec-1.46/,Can TLT-school corpus be used to evaluate the performance of automatic speech recognition systems in assessing non-native English and German proficiency among students of different age groups and educational levels?
https://aclanthology.org/2020.lrec-1.46/,Can the manual transcription guidelines and procedures used in the TLT-school corpus be improved to increase the accuracy of automatic speech recognition systems for second language learners?
https://aclanthology.org/2020.lrec-1.47/,"Can a supervised machine learning approach using a deep learning model be used to identify and correct linguistic errors in the ReLCo corpus with high accuracy, as measured by the F1-score, and how does it compare to rule-based approaches?"
https://aclanthology.org/2020.lrec-1.47/,"Can the longitudinal growth of the ReLCo corpus, which reflects the dynamic nature of language learning, be used to develop and evaluate the effectiveness of language learning models that incorporate learning patterns and error types over time?"
https://aclanthology.org/2020.lrec-1.48/,Can the proposed methodology for annotating and correcting learner corpus be improved by incorporating machine learning algorithms to reduce the manual review of annotations and increase accuracy?
https://aclanthology.org/2020.lrec-1.48/,"Can the use of automated morphological analysis in the annotation process affect the overall quality of the Latvian Language Learner corpus, and how can this impact the learning outcomes of language learners?"
https://aclanthology.org/2020.lrec-1.49/,What is the impact of incorporating linguistic features on the performance of a machine learning model for predicting the grades of précis texts in English?
https://aclanthology.org/2020.lrec-1.49/,Can a model trained on a large corpus of annotated précis texts using a combination of automatic summarization and AWE features achieve a high accuracy in predicting the grades of précis texts?
https://aclanthology.org/2020.lrec-1.50/,"Can a low-level, task-oriented dialogue system improve the usability of Natural Language Image Editing for novices by reducing the complexity of instructions through explicit edit operations, as indicated by a 25% increase in user satisfaction?"
https://aclanthology.org/2020.lrec-1.50/,"Does object segmentation play a crucial role in the adoption of low-level language interfaces for image editing, and can it be used as a key factor to evaluate the effectiveness of such systems?"
https://aclanthology.org/2020.lrec-1.51/,Can an annotation methodology that associates clinical note sentences with sets of dialogue sentences improve the effectiveness of automated clinical note generation in clinical settings?
https://aclanthology.org/2020.lrec-1.51/,"Can the proposed annotation methodology support the development of multiple modeling methods, including information extraction and sequence-to-sequence modeling, for clinical note generation from clinic visit conversations?"
https://aclanthology.org/2020.lrec-1.52/,Can state-tracking models accurately predict the dialogue state from the corrected MultiWOZ 2.1 dataset using canonicalized slot values and user dialogue acts?
https://aclanthology.org/2020.lrec-1.52/,How do crowdsourced re-annotation of dialogue state and utterances affect the performance of state-of-the-art dialogue state tracking models on the MultiWOZ 2.1 dataset?
https://aclanthology.org/2020.lrec-1.53/,How can proactive dialogue strategies in recommendation systems affect user perception and satisfaction?
https://aclanthology.org/2020.lrec-1.53/,Can proactive dialogue systems with autonomous information gathering improve the user experience compared to reactive systems?
https://aclanthology.org/2020.lrec-1.54/,Can conversational question answering systems be developed to effectively handle low-resource languages like Basque with high accuracy using cross-lingual transfer techniques?
https://aclanthology.org/2020.lrec-1.54/,"Can the use of dialogue history models be transferred to other languages without significant loss of performance, and what are the implications for CQA systems in low-resource languages?"
https://aclanthology.org/2020.lrec-1.55/,"Can the use of dialog act tags to measure the closeness level between speakers in a multimodal dialog system improve the establishment of rapport with users, as indicated by a significant decrease in user disengagement and increase in user satisfaction? Does the annotation of dialog act tags by multiple annotators affect the accuracy of the closeness level assessment, and can this impact the effectiveness of the system in establishing a relationship with the user?"
https://aclanthology.org/2020.lrec-1.56/,Can a machine learning model utilizing a transformer-based architecture be trained to predict user satisfaction with a given questionnaire based on the responses provided by the BLISS agent?
https://aclanthology.org/2020.lrec-1.56/,Can the use of a happiness model in a personalized spoken dialogue system like BLISS improve the accuracy of extracting information about people's well-being compared to traditional questionnaires?
https://aclanthology.org/2020.lrec-1.57/,"Can a large-scale real scenario Chinese E-commerce conversation corpus such as JDDC be used to train a deep learning model to improve the accuracy of task-oriented dialogue systems, and what are the key challenges and evaluation metrics that need to be considered when developing such a system?"
https://aclanthology.org/2020.lrec-1.57/,"Can the use of multi-turn dialogues and long-term dependency among the context in the JDDC corpus affect the performance of generative models in question-answering tasks, and what are the optimal features or architectures that can be used to leverage this characteristic?"
https://aclanthology.org/2020.lrec-1.58/,Does smile frame humor in French conversations?
https://aclanthology.org/2020.lrec-1.58/,Does the use of smiling in French conversations influence the success or failure of attempts at humor?
https://aclanthology.org/2020.lrec-1.59/,"Can a two-step strategy for creating a knowledge base for a Time-Offset Interaction Application be effective in collecting useful data for training a dialogue system to retrieve the best answer to a user's question, and how can the methodology be improved to increase the quality and diversity of the collected data?"
https://aclanthology.org/2020.lrec-1.59/,"Can the development of a dialogue corpus for a Time-Offset Interaction Application using a combination of human-generated dialogues and pre-existing knowledge bases be a viable approach for improving the accuracy of single-turn answer retrieval, and what are the potential challenges and limitations of this approach?"
https://aclanthology.org/2020.lrec-1.60/,"Is the proactive voice output in a driving simulator significantly associated with reduced cognitive load for car drivers, as measured by response times to PA actions?"
https://aclanthology.org/2020.lrec-1.60/,"Does the proactive assistant behavior in driving-relevant use cases receive the highest level of user satisfaction and acceptance, measured by questionnaires and ratings?"
https://aclanthology.org/2020.lrec-1.61/,"Can emotional speech be used to express a speaker's emotions more effectively than text-based emotional expressions in a persuasive dialogue, and what are the implications for the development of a more persuasive dialogue system? Does the use of emotional speech in a persuasive dialogue system improve its emotional expressiveness, as indicated by experimental results?"
https://aclanthology.org/2020.lrec-1.62/,Does the occurrence of laughter and interruptions in group interactions have a significant positive correlation with the perceived level of group cohesion?
https://aclanthology.org/2020.lrec-1.62/,"Can combining non-verbal social cues, dialogue acts, and interruptions improve the accuracy of analyzing group cohesion in multi-party interactions?"
https://aclanthology.org/2020.lrec-1.63/,"Can dialogue evaluation be effectively assessed using anomaly detection methods, and how do the objective functions of four different dialogue modeling approaches relate to human annotation scores? Does anomaly detection improve the accuracy of dialogue evaluation in comparison to traditional human evaluation methods?"
https://aclanthology.org/2020.lrec-1.64/,"Can the proposed dialogue system improve the evaluation of argument quality by providing a more nuanced rating system than the traditional four categories, and what are the specific aspects of the retrieved arguments that are most indicative of the quality ratings provided by the users in the user study?"
https://aclanthology.org/2020.lrec-1.65/,"Can an AI voice assistant accurately recognize and annotate temporal expressions in natural language voice commands using a crowdsourcing method involving pictures and scenario descriptions, and how does this method compare to existing annotation methods from other domains?"
https://aclanthology.org/2020.lrec-1.65/,"What is the effectiveness of the proposed crowdsourcing method in collecting temporal expressions for an AI voice assistant, measured by the accuracy of the annotated commands in the Snips dataset?"
https://aclanthology.org/2020.lrec-1.66/,"Can the use of ISO 24617-2 standard for dialog act annotation improve the performance of automatic communicative function recognition approaches, and what is the effect of including the mapped dialogs in the training phase on the recognition accuracy in the Task dimension?"
https://aclanthology.org/2020.lrec-1.67/,"What features, including dialogue act features, grammatical features, and linguistic features, are necessary for a neural network to effectively classify the elaborateness and directness of spoken interaction with high accuracy?"
https://aclanthology.org/2020.lrec-1.67/,"Can a recurrent neural network classifier outperform a support vector machine in estimating the directness of spoken interaction, and how do word embeddings influence the classification results?"
https://aclanthology.org/2020.lrec-1.68/,"Can the proposed ISO 24617-2 dialogue act annotation standard be improved to better capture the nuances of dependence and rhetorical relations in dialogue systems, and if so, what specific modifications are needed to achieve this improvement?"
https://aclanthology.org/2020.lrec-1.68/,"Can the proposed ISO 24617-2 dialogue act annotation standard be adapted to incorporate a plug-in mechanism that enables the annotation of emotions and application-specific dialogue act types, and what are the potential benefits and challenges of this adaptation?"
https://aclanthology.org/2020.lrec-1.69/,Can the use of eye-gaze data collected from human-robot interactions with a humanoid robot like Nao be used as a reliable metric to study differences in attention and engagement patterns between humans and robots?
https://aclanthology.org/2020.lrec-1.69/,Can the multimodal analysis of human participants' eye-gaze and gesturing behaviors in human-robot interactions provide insights into the limitations of conversational capabilities of humanoid robots like Nao?
https://aclanthology.org/2020.lrec-1.70/,Can a self-attention decoder model trained on a labeled dataset with pre-specified facts and opinions be able to generate consistent and knowledgeable responses in non-goal oriented dialogues?
https://aclanthology.org/2020.lrec-1.70/,Can the introduction of a labeled dialogue dataset with fact and opinion profiles improve the accuracy and attentiveness of end-to-end trained self-attention decoder models in generating natural and opinionated responses?
https://aclanthology.org/2020.lrec-1.71/,"Can the proposed dialogue corpus be used to improve the performance of machine learning models for medical dialogue systems in French, measured by the accuracy of their ability to recognize and respond to patient concerns?"
https://aclanthology.org/2020.lrec-1.71/,Can the annotation guidelines for the proposed corpus be validated through a human evaluation study to assess their effectiveness in capturing the nuances of medical consultation interactions between doctor and patient in French?
https://aclanthology.org/2020.lrec-1.72/,"Can a deep learning-based approach leveraging distant supervision from conversational dialogue data outperform existing attribute extraction methods in terms of accuracy and precision, and can it be applied to real-world scenarios such as personalized recommendation systems?"
https://aclanthology.org/2020.lrec-1.72/,"Can the proposed two-stage attribute extractor be adapted to handle noisy and sparse data in dialogue systems, and what are the implications for the overall performance and user experience of such systems?"
https://aclanthology.org/2020.lrec-1.73/,"Can we design a more efficient dialogue act classification system that incorporates contextualized dialogue acts and improves upon the results of the proposed Balanced Bagging Classifier, Condiontal Random Field, and Long Short Term Memory networks?"
https://aclanthology.org/2020.lrec-1.73/,"Can CRFs be used to develop a more interpretable and computationally efficient model that achieves similar or better performance than deep learning models, particularly in scenarios where resource constraints are a concern?"
https://aclanthology.org/2020.lrec-1.74/,"How can the annotation scheme developed for the pedagogical reference resolution game be applied to other multimodal dialogue corpora, and what are the potential benefits and challenges of extending the annotation scheme to include additional modalities such as gesture or text data?"
https://aclanthology.org/2020.lrec-1.74/,"Can the RDG-Map be used as a benchmark for evaluating the effectiveness of different dialogue strategies in achieving the goal of rapid country identification on a world map, and how can the performance of different strategies be compared and contrasted using the corpus?"
https://aclanthology.org/2020.lrec-1.75/,"Can a supervised learning approach using a Transformer-based architecture be used to accurately classify emotions and interpersonal relationships in Chinese dialogue, and what is the relationship between the type of emotion and the type of interpersonal relationship in emotion and relation classification tasks?"
https://aclanthology.org/2020.lrec-1.76/,"Can the performance of a voice assistant be evaluated based on its ability to detect and respond to natural language queries in unconstrained conversations, and what metrics can be used to measure its effectiveness in such scenarios? Can the use of machine learning algorithms for topic modeling and sentiment analysis be applied to the VACW dataset to gain insights into human-machine interactions and improve voice assistant design?"
https://aclanthology.org/2020.lrec-1.77/,"Can recurrent neural models with and without context be used to effectively annotate emotion corpora with dialogue act labels, and what is the impact on the annotation accuracy when using an ensemble annotator?"
https://aclanthology.org/2020.lrec-1.77/,"Can the co-occurrence of emotion and dialogue act labels reveal specific relations between emotions and dialogue acts in conversational data, and what are the most common emotional states associated with certain dialogue acts?"
https://aclanthology.org/2020.lrec-1.78/,Is the impact of lack of common ground on participants' smiles during topic transitions measurable using PACO corpus and can it be reliably quantified? Does the use of semi-automatic smile annotation protocol in PACO corpus reduce annotation time compared to manual annotation?
https://aclanthology.org/2020.lrec-1.79/,Can the proposed annotation method for dialogue acts in first encounter dialogues be evaluated using a supervised learning approach with a multilayer perceptron architecture to improve accuracy?
https://aclanthology.org/2020.lrec-1.79/,"Do feedback dialogue acts with co-occurring gestural behavior in the corpus exhibit a higher frequency of overlap with specific dialogue acts, such as acknowledgement or request for clarification?"
https://aclanthology.org/2020.lrec-1.80/,What is the effect of the four-way distinction in turn-taking behavior on the distribution of syntactic features in Japanese multi-party conversations?
https://aclanthology.org/2020.lrec-1.80/,How does the prosodic characteristics of utterances vary when a speaker switches speakership versus continuing their own turn in a multi-party conversation?
https://aclanthology.org/2020.lrec-1.81/,"Can the proposed BERT-based approach achieve higher precision for the entailment recognizer when fine-tuned with a larger dataset, and can the precision of the yes/no response classifier be improved by incorporating domain-specific knowledge into the model architecture?"
https://aclanthology.org/2020.lrec-1.82/,Can the proposed framework improve the multilingual support of interactive agents in specialized domains with limited language resources by leveraging external language services?
https://aclanthology.org/2020.lrec-1.82/,Can the developed gradual design process for acquiring dialogue corpora and improving interactive agents effectively address the challenges of context-aware dialogue generation in small corpora?
https://aclanthology.org/2020.lrec-1.83/,Can a machine learning model trained on multimodal data from human-robot conversations using a Transformer-based architecture be able to accurately classify the emotional tone of human conversations with a high level of syntactic correctness?
https://aclanthology.org/2020.lrec-1.83/,Can the use of fMRI and physiological data in a multimodal corpus improve the accuracy of human conversation analysis models by reducing the impact of individual variability in neural responses?
https://aclanthology.org/2020.lrec-1.84/,"What are the effects of incongruent feedback on the brain activity of participants in a human-machine interaction, measured by EEG signals, and how does it compare to human-human interactions?"
https://aclanthology.org/2020.lrec-1.84/,How can the multimodal annotations on the verbal and non-verbal levels in the Brain-IHM dataset be used to improve the evaluation of human feedback in human-machine interactions?
https://aclanthology.org/2020.lrec-1.85/,"Does the use of Dialogue-AMR improve the accuracy of natural language understanding in human-robot interaction compared to standard AMR, as measured by the F1 score of the annotators?"
https://aclanthology.org/2020.lrec-1.85/,"Can the automated methods for constructing the DialAMR corpus effectively capture the illocutionary force, tense, and aspect of human-robot dialogue, as evaluated by human annotators using the inter-annotator reliability test?"
https://aclanthology.org/2020.lrec-1.86/,"Can a supervised learning approach using a Transformer-based architecture be used to classify responsive utterances into five levels of empathy, and how does the performance of the model change when using different evaluation metrics such as accuracy, precision, and recall?"
https://aclanthology.org/2020.lrec-1.86/,"Can the proposed classification system be applied to improve the motivation of human speakers when interacting with communication robots and smart speakers, and what are the potential limitations and challenges in using this approach in real-world scenarios?"
https://aclanthology.org/2020.lrec-1.87/,"What is the potential of using deep learning methods to recognize intent in doctor-patient interactions in medical training, with a focus on improving the efficiency and effectiveness of this process?"
https://aclanthology.org/2020.lrec-1.87/,How can the development of language-based virtual patient interfaces for medical training be enhanced using information retrieval and machine learning techniques to address the limitations of current methods?
https://aclanthology.org/2020.lrec-1.88/,Can this tool accurately predict individual brain activity in real-time based on behavioral features extracted from human-human and human-robot conversations?
https://aclanthology.org/2020.lrec-1.88/,Can the visualization module effectively display the dynamics of brain active areas synchronized with behavioral raw data in real-time?
https://aclanthology.org/2020.lrec-1.89/,"Can a BERT-based model like MTSI-BERT be fine-tuned for multi-turn conversation analysis and intent classification, and what are the key metrics to evaluate its performance in this task?"
https://aclanthology.org/2020.lrec-1.89/,"Can a BERT-based model like MTSI-BERT be used to develop a chatbot that can effectively monitor and support users with asthma, and what is the impact of this on user satisfaction and health outcomes?"
https://aclanthology.org/2020.lrec-1.90/,"Can the use of simulated dialogues generated using dialogue policies be sufficient to predict human ratings of system quality and user experience in the Wizard of Oz setting for conversational aspects such as intelligence, naturalness, and overall quality?"
https://aclanthology.org/2020.lrec-1.90/,Can the training of dialogue evaluation functions on simulated data improve the predictive power of human ratings of system quality and user experience for conversational aspects such as friendliness and enjoyment in the Wizard of Oz setting?
https://aclanthology.org/2020.lrec-1.91/,"Does the cross-language LSTM model outperform the cross-language relevance model in a small corpus setting, and what are the key factors that contribute to this difference in performance? Can a more efficient approach be developed to improve the performance of the cross-language LSTM model on smaller corpora?"
https://aclanthology.org/2020.lrec-1.92/,"How do multimodal signals such as speech, eye-gaze, pointing gestures, and object movements relate to the process of language grounding in situated dialogue?"
https://aclanthology.org/2020.lrec-1.92/,Can the proposed method of using the 'Chinese Whispers' concept to avoid experimenter biases effectively reduce implicit biases in assembling IKEA furniture instructions?
https://aclanthology.org/2020.lrec-1.93/,"Can a deep learning architecture that incorporates Graph Convolution Networks and memory networks to learn unified embeddings for query-response pairs improve the performance of conversational systems in terms of syntactic accuracy and contextual relevance, and can it be benchmarked against existing techniques using the next sentence prediction task?"
https://aclanthology.org/2020.lrec-1.93/,"Can a retrieval-based conversational agent that utilizes AMUSED to represent query, response, and context improve human engagement and user satisfaction in chit-chat systems, and can it be validated using expert linguists' feedback on comprehensiveness of engagement?"
https://aclanthology.org/2020.lrec-1.94/,"Can a machine learning model be trained to accurately recognize and interpret the social and referential functions of human eye gaze in multi-modal human-human dialogue, with a focus on improving the performance of conversational agents in understanding and responding to human cues?"
https://aclanthology.org/2020.lrec-1.94/,"Can a proposed annotation scheme for eye-gaze in human-human dyadic interactions be evaluated for its effectiveness in facilitating the learning of eye-gaze patterns in multi-modal natural dialogue, using metrics such as accuracy, latency, and user satisfaction?"
https://aclanthology.org/2020.lrec-1.95/,What are the syntactic features of Middle Low German that necessitate the adaptation of the Penn annotation scheme for corpus annotation and how do these features differ from the original Penn scheme?
https://aclanthology.org/2020.lrec-1.95/,How can the uncertainty in attestation data be effectively captured and represented in the annotation of a syntactically annotated corpus for Middle Low German?
https://aclanthology.org/2020.lrec-1.96/,"What are the most effective methods for improving the legibility of handwritten text in Book of Hours manuscripts, considering the challenges posed by lavish ornamentation and abbreviations, and how can these methods be integrated with Handwritten Text Recognition (HTR) techniques for accurate transcription?"
https://aclanthology.org/2020.lrec-1.96/,"Can the hierarchical structure of the Book of Hours be effectively segmented using existing text segmentation approaches, and what are the key factors that influence the accuracy of these segmentations?"
https://aclanthology.org/2020.lrec-1.97/,How can the use of machine learning algorithms improve the accuracy of keyword analysis for studying the historical linguistic use of gender-specific terms in Classical Chinese?
https://aclanthology.org/2020.lrec-1.97/,Can the application of corpus-based methods to analyze the semantic representations of Classical Chinese terms aid in understanding the stability and evolution of gender-specific language use across different dynastic histories?
https://aclanthology.org/2020.lrec-1.98/,Can the use of the extended Royal Society Corpus facilitate the development of more accurate language models in historical scientific texts by leveraging its vast 300+ year dataset?
https://aclanthology.org/2020.lrec-1.98/,"Does the corpus's unique combination of linguistic and historical data align with the requirements of a corpus for linguistic and humanistic study, and how might this impact the analysis of scientific language evolution?"
https://aclanthology.org/2020.lrec-1.99/,"Can machine learning models be trained on the REDEWIEDERGABE corpus to improve their performance on German language text classification tasks, with a focus on evaluating the impact of ST&WR annotations on model accuracy? Can the ST&WR annotations in REDEWIEDERGABE be used to develop a novel method for representing complex linguistic phenomena in machine learning models, and what are the implications for the development of more sophisticated language models?"
https://aclanthology.org/2020.lrec-1.100/,"Can a user-friendly web interface such as WeDH effectively increase the accessibility of textual resources on the web by providing a clear and concise way to retrieve and combine metadata from sources like DBpedia, wikidata and VIAF?"
https://aclanthology.org/2020.lrec-1.100/,"Can the integration of metadata from DBpedia, wikidata and VIAF with textual corpora using WeDH improve the usability and discoverability of literary works in digital humanities research?"
https://aclanthology.org/2020.lrec-1.101/,"Can a deep learning approach using a convolutional neural network outperform traditional machine learning methods in segmenting obituaries into predefined sections, and what is the precision of this approach when evaluated on a dataset of 20058 obituaries?"
https://aclanthology.org/2020.lrec-1.101/,"Does the proposed annotation guidelines for obituary sections achieve high inter-annotator agreement, and how does it compare to other annotation methods in terms of accuracy and Fleiss' κ coefficient?"
https://aclanthology.org/2020.lrec-1.102/,Can a supervised machine learning model trained on the SLäNDa corpus be able to achieve high accuracy in annotating dialogue segments with high inter-annotator agreement?
https://aclanthology.org/2020.lrec-1.102/,"Can the use of named entity recognition in the SLäNDa corpus help in identifying linguistic changes in Swedish language, specifically the shift from old to modern function words in speech and narrative?"
https://aclanthology.org/2020.lrec-1.103/,"Can the RiQuA corpus effectively capture the nuances of interpersonal dialogue structures in 19th-century literature through its detailed annotations of speaker, addressee, and cue information?"
https://aclanthology.org/2020.lrec-1.103/,Can RiQuA's annotated corpus be used to train a supervised classification model to predict the likelihood of direct versus indirect quotations in literary text with high accuracy?
https://aclanthology.org/2020.lrec-1.104/,"Can machine learning algorithms be used to identify and analyze the linguistic features of song lyrics that are indicative of specific genres or moods, and if so, what are the most accurate features to use for such analysis?"
https://aclanthology.org/2020.lrec-1.104/,"Can the extralinguistic metadata of a song, such as its release date and artist, influence the linguistic features of the lyrics, and if so, how can these influences be measured and accounted for in a statistical analysis?"
https://aclanthology.org/2020.lrec-1.105/,"Can the BDCamões Collection be used to develop a supervised learning model for authorship detection in Portuguese texts with high accuracy, measured by the F1-score, and how does the quality of the automatically parsed Treebank subcorpus impact this task? Can the BDCamões Collection be used to study the evolution of linguistic features across genres and time periods, measured by the frequency of specific linguistic features, and how do the different orthographic conventions affect the results?"
https://aclanthology.org/2020.lrec-1.106/,"What are the factors that influence the frequency changes of cognates in English and French across different time periods, and how do these changes compare to one another?"
https://aclanthology.org/2020.lrec-1.106/,How can the proposed dataset be used to evaluate the effectiveness of machine learning models in identifying linguistic patterns and correlations between cognates in different languages over time?
https://aclanthology.org/2020.lrec-1.107/,Can a machine learning-based approach be used to improve the lemmatization of medieval Nordic personal names and enhance the accuracy of their contextualization? Can the NordiCon database be effectively integrated with Språkbanken Text to provide a comprehensive repository of historical written data?
https://aclanthology.org/2020.lrec-1.108/,"What is the impact of the number of papers published on NLP research on its overall productivity and focus, measured by the average citation count per paper?"
https://aclanthology.org/2020.lrec-1.108/,"Can citation counts in the NLP Scholar Dataset be correlated with the authors' productivity, as indicated by the number of papers they published in the dataset?"
https://aclanthology.org/2020.lrec-1.109/,"Can a deep learning-based approach be used to develop a high-performance, multilingual text processing system that can accurately classify and annotate a large corpus of digitized documents?"
https://aclanthology.org/2020.lrec-1.109/,"Can the proposed corpus infrastructure be used to investigate the effectiveness of various text analysis techniques, such as named entity recognition and sentiment analysis, on a large-scale multilingual dataset?"
https://aclanthology.org/2020.lrec-1.110/,"Can a supervised learning approach using a Convolutional Neural Network (CNN) improve the accuracy of handwritten document transcription compared to a rule-based approach, and can LiViTo's features be effectively used to identify scribes in historical Czech manuscripts?"
https://aclanthology.org/2020.lrec-1.111/,Can TextAnnotator's ability to annotate complex textual structures be effectively evaluated using a combination of inter-annotator agreement and processing time metrics? Can TextAnnotator's flexibility in supporting multiple annotation tools and platforms be assessed using a comparative study of annotation quality and user satisfaction?
https://aclanthology.org/2020.lrec-1.112/,Can a hybrid model combining locality sensitive hashing and word embeddings outperform existing deduplication methods in detecting exact and near duplicates in scholarly documents?
https://aclanthology.org/2020.lrec-1.112/,"Does the use of a ground truth dataset of 100K scholarly documents enable the establishment of optimal parameters for a deduplication method, leading to improved accuracy and efficiency in real-time application?"
https://aclanthology.org/2020.lrec-1.113/,"Can the proposed corpus of historical Italian texts effectively capture the nuances of regional dialects and diatopic variations in linguistic expression, as demonstrated by the inclusion of part-of-speech and lemmas annotations?"
https://aclanthology.org/2020.lrec-1.113/,"Can the corpus's annotation of historical texts improve the performance of a supervised classification model in predicting author type based on linguistic features, using a dataset representative of different genres and language varieties?"
https://aclanthology.org/2020.lrec-1.114/,"Can the proposed discourse network analysis framework be applied to analyze the sentiment and topic modeling of debates on immigration in the context of German politics, measuring the effectiveness of the framework using accuracy metrics such as precision and recall? Can the annotation of claims in newspaper articles using the proposed annotation scheme be automated using natural language processing techniques, and what are the challenges and limitations of such automation?"
https://aclanthology.org/2020.lrec-1.115/,Can the proposed Python interface for querying and analyzing the corpus using NLTK and spaCy libraries improve the efficiency of text analysis tasks by reducing the time required to access and manipulate the corpus?
https://aclanthology.org/2020.lrec-1.115/,Can the TF-IDF frequencies provided in the HTML visualizations facilitate the identification of trends and patterns in the historical speeches of the head of state of Spain?
https://aclanthology.org/2020.lrec-1.116/,"Can the proposed treebank's unique Late Latin Charter Treebank 2 (LLCT2) annotations be accurately evaluated using existing syntactic annotation tools and models, and what are the key differences in the treebank's structure compared to other existing Latin treebanks in the Universal Dependencies framework?"
https://aclanthology.org/2020.lrec-1.116/,How can the diachronic linguistic phenomena observed in the Late Latin Charter Treebank 2 (LLCT2) be measured and quantified using statistical models and machine learning algorithms to better understand the transition from Latin to Romance languages?
https://aclanthology.org/2020.lrec-1.117/,Can the proposed approach for identifying dialectal variations of words using word embedding models and semantic tools be successfully applied to other language corpora and regions with non-standard language collections?
https://aclanthology.org/2020.lrec-1.117/,"How can the combination of GermaLemma, word embedding models, and Germanet be used to evaluate the semantic similarity between dialectal and standard language words in a meaningful way?"
https://aclanthology.org/2020.lrec-1.118/,"Can machine learning-based transliteration systems be developed for Yiddish using the Sequitur-G2P toolkit, and what are the key factors contributing to error rates in such systems?"
https://aclanthology.org/2020.lrec-1.118/,How can the proposed multi-orthography parallel corpus of Yiddish nouns be used to improve the accuracy of transliteration models for low-resource languages like Yiddish?
https://aclanthology.org/2020.lrec-1.119/,"Can the use of semantic technologies and ontology-based approach improve the interoperability and reusability of the Open Access Database: Adjective-Adverb Interfaces in Romance, as measured by the FAIR Data Principles? Can the annotation model developed for the corpus be adapted to accommodate diverse forms, functions, and meanings of adverbs across languages, with a focus on cross-linguistic categorization?"
https://aclanthology.org/2020.lrec-1.120/,"What is the feasibility of developing a language model that can accurately process and retrieve information from historical newspapers in multiple languages, and how does this compare to current state-of-the-art models in terms of processing time and accuracy?"
https://aclanthology.org/2020.lrec-1.120/,"How can the semantic annotations and language models developed for the 'impresso' resource collection be fine-tuned for use in a real-world setting, and what are the implications for the robustness of historical language processing approaches?"
https://aclanthology.org/2020.lrec-1.121/,"How can the digitization quality and searchability of historical newspapers catering to specialized audiences, such as music criticism or arts publications, be improved through the development of an OCR-based indexing system for post-digitalization challenges?"
https://aclanthology.org/2020.lrec-1.121/,"Can the implementation of an open-source, user-friendly interface enhance the discoverability and accessibility of digitized content from historical newspapers for niche audiences, such as those requiring scholarly or cultural exchange?"
https://aclanthology.org/2020.lrec-1.122/,Can stylometric methods based on the most frequent words be effective in distinguishing between original and translated texts across languages if a shared glossary is used to create pseudolemmas? Can the use of pseudolemmas improve the clustering of bilingual texts by removing language-specific features?
https://aclanthology.org/2020.lrec-1.123/,"Can a character-based method effectively calculate the distance between any two sentence pairs using a small alphabet, and can it be used as a proxy for phonemes?"
https://aclanthology.org/2020.lrec-1.123/,Can dialect clustering using this method accurately reflect the conventional boundaries of dialects and sub-languages?
https://aclanthology.org/2020.lrec-1.124/,Can a machine learning model trained on a large corpus of annotated discourse markers and semantic relations be used to automatically generate a comprehensive taxonomy of discourse relations for English?
https://aclanthology.org/2020.lrec-1.124/,"Can the use of discourse markers as input for a machine learning model improve the accuracy of semantic relation classification, as compared to using only the semantic relations themselves?"
https://aclanthology.org/2020.lrec-1.125/,"Can ThemePro accurately identify the thematic progression of texts with a high degree of precision, measured by the F1-score, and how does it compare to existing NLP tools? Does ThemePro's visualization of syntactic trees and hierarchical thematicity improve the understanding of discourse structure in natural language processing applications?"
https://aclanthology.org/2020.lrec-1.126/,"Can a machine learning model accurately distinguish between normative claims and desires in annotated text data, and what is the impact on the overall understanding of fine-grained proposition types?"
https://aclanthology.org/2020.lrec-1.126/,"Can a hybrid machine learning and human workflow improve the annotation of complex linguistic phenomena in argumentative text data, and what are the implications for quantitative analyses of rhetorical strategies and structure in presidential debates?"
https://aclanthology.org/2020.lrec-1.127/,Can the proposed model using pre-trained transformer and CKY-like algorithm outperform existing systems in Chinese discourse parsing tasks when using different evaluation metrics such as micro and macro F1 scores?
https://aclanthology.org/2020.lrec-1.127/,"Does the use of multiway ground truth improve the performance of the model in Chinese discourse parsing, especially when comparing left-heavy and right-heavy binarization approaches?"
https://aclanthology.org/2020.lrec-1.128/,How do the discourse relations annotated on the TED talks impact the performance of supervised machine translation models for Chinese-English translation tasks?
https://aclanthology.org/2020.lrec-1.128/,"Can the adapted Penn Discourse TreeBank annotation scheme be applied to other types of Chinese text, such as news articles or social media posts?"
https://aclanthology.org/2020.lrec-1.129/,"Can a deep learning model trained on the Discussion Tracker corpus to predict argument moves achieve high accuracy in distinguishing between low, medium, and high specificity of argumentation, and how does this performance compare to the model's performance when trained to predict collaboration dimensions?"
https://aclanthology.org/2020.lrec-1.129/,"Can a multi-task learning approach utilizing the Discussion Tracker corpus improve the performance of argument move prediction and collaboration dimension prediction, and what is the trade-off between the two tasks in terms of overall model performance?"
https://aclanthology.org/2020.lrec-1.130/,"Can machine translation from English to German, combined with annotation projection, provide a feasible and accurate shallow discourse parsing resource for German, and can it outperform the gold standard PDTB corpus in certain sub-tasks of discourse parsing?"
https://aclanthology.org/2020.lrec-1.130/,Can the creation of a German PDTB corpus using machine translation and annotation projection improve the accuracy of discourse parsing models compared to training on the gold standard English PDTB corpus?
https://aclanthology.org/2020.lrec-1.131/,"Can typed lambda calculus translations of Simple English Wikipedia sentences effectively improve the performance of quantifier scope disambiguation systems, and how can they be integrated into existing natural language processing pipelines to enhance overall system reliability? Can the proposed corpus be used to develop and train machine learning models that can accurately identify and resolve quantifier scope ambiguity in a variety of domains?"
https://aclanthology.org/2020.lrec-1.132/,Can the use of the Penn Discourse TreeBank framework for annotating coherence relations improve the usability of the Potsdam Commentary Corpus for shallow discourse parsing tasks in German?
https://aclanthology.org/2020.lrec-1.132/,Can the introduction of additional coherence relation types in the Potsdam Commentary Corpus enhance the accuracy of discourse parsing models when compared to the existing annotation scheme?
https://aclanthology.org/2020.lrec-1.133/,"How can a convolutional neural network be used to effectively distinguish between coherent and incoherent discourse argument pairs, and what are the optimal parameters that would result in the highest accuracy in this task? Can a machine learning model be trained to generate coherent discourse argument pairs using a combination of discourse connectives and discourse arguments from a given corpus, and what are the key factors that affect the coherence of the generated pairs?"
https://aclanthology.org/2020.lrec-1.134/,What is the impact of incorporating syntactic features like part-of-speech tags and dependency relations on the performance of a multi-lingual discourse segmentation model trained with BERT?
https://aclanthology.org/2020.lrec-1.134/,"Can BERT-based models achieve state-of-the-art performance in discourse segmentation across multiple languages, as demonstrated by the model's F-score of 96.7 on the RST-DT corpus?"
https://aclanthology.org/2020.lrec-1.135/,Can gestures and long silent pauses in speech be used to predict audience reaction without relying on other speech information?
https://aclanthology.org/2020.lrec-1.135/,Can head movements and facial expressions be used as independent predictors of audience reaction?
https://aclanthology.org/2020.lrec-1.136/,"Can GeCzLex's ability to annotate and link connectives across languages effectively improve the accuracy of machine translation models, as measured by the F1 score of bilingual machine translation systems? Can the use of GeCzLex facilitate the development of more accurate long-distance discourse coherence models, as evaluated by the precision of discourse coherence detection in bilingual corpora?"
https://aclanthology.org/2020.lrec-1.137/,Can DiMLex-Bangla accurately capture the nuances of Bangla discourse connectives through its compilation of 123 initial entries and its incorporation of additional connectives from the Bangla RST Discourse Treebank?
https://aclanthology.org/2020.lrec-1.137/,"How does the use of the DiMLex XML schema in DiMLex-Bangla impact the computational applications of the lexicon, particularly in terms of processing time and syntactic correctness?"
https://aclanthology.org/2020.lrec-1.138/,"Can a semi-supervised learning approach using neural sequence tagging improve the extraction of explicit discourse arguments in shallow discourse parsing by 2-10% F1 score, and how do the generated discourse annotations compare to the training relations? Does the use of additional unlabeled data for semi-supervised learning improve the performance of models in extracting explicit discourse arguments in shallow discourse parsing?"
https://aclanthology.org/2020.lrec-1.139/,"Is it possible to develop a machine learning model that can accurately extract possessors from unstructured text and assign certainty scores to each possessor based on the strength of textual evidence? Can a Transformer-based architecture be used to effectively anchor possessors to specific times and events, and identify temporal relations between possessors and possession events?"
https://aclanthology.org/2020.lrec-1.140/,"Can the annotators' implicit expectations and question predictability be correlated using a supervised learning approach on the provided dataset, and what are the implications for dialogue systems and conversational question answering?"
https://aclanthology.org/2020.lrec-1.140/,"Can the use of crowdsourced annotations on a large scale affect the semantic meaning and coherence of the evoked questions in the dataset, and how can this be mitigated in future research?"
https://aclanthology.org/2020.lrec-1.141/,Can the CzeDLex 0.6 lexicon be used to develop a more accurate machine learning model for discourse relation classification by analyzing the correlation between connective types and sentiment in text data?
https://aclanthology.org/2020.lrec-1.141/,Can PML Tree Query effectively mine information from CzeDLex 0.6 by leveraging its human-readable format to improve the precision of search results for discourse relation queries?
https://aclanthology.org/2020.lrec-1.142/,"Can persuasive documents in online forums be identified by analyzing the number of claims they contain, and how do the interaction patterns among persuasive and non-persuasive documents differ in online forums?"
https://aclanthology.org/2020.lrec-1.142/,How can an argument mining system be trained to identify and extract argument structures from user-generated inner-post arguments and inter-post relations in online forums?
https://aclanthology.org/2020.lrec-1.143/,"Can the proposed system effectively simplify coreference chains in written texts for dyslexic children by reducing errors by more than 80% through a combination of machine learning-based coreference resolution and rule-based text transformation operations, and can it improve reading comprehension by 20% through a clear and concise text rewriting process? Can the coreference resolution system and text rewriting tool be optimized to minimize the impact of simplification perception errors to below 5% through the use of multilingual coreference patterns and automated text evaluation metrics?"
https://aclanthology.org/2020.lrec-1.144/,"Can BERT be effectively pre-trained on text tailored to discourse classification to improve its performance on implicit discourse relation classification, and what benefits can be gained from adding explicit connective prediction tasks during pre-training versus fine-tuning?"
https://aclanthology.org/2020.lrec-1.145/,"Can a machine learning model achieve high accuracy in detecting explicit and implicit intentions in speaker queries during meals by leveraging linguistic features from annotated data, and can the model's performance be improved by fine-tuning its parameters on a larger dataset?"
https://aclanthology.org/2020.lrec-1.145/,"Can a supervised classification model using a transformer-based architecture be trained to accurately predict the implicit intentions behind speaker queries during meals, and what linguistic features would be most effective in achieving this goal?"
https://aclanthology.org/2020.lrec-1.146/,Can a machine learning model trained on a dialogue act classification model using a labeled corpus specifically designed for automated cognitive health screening be able to achieve high accuracy in identifying patient utterances with high inter-annotator agreement?
https://aclanthology.org/2020.lrec-1.146/,Can a task-specific dialogue agent trained to respond to patient utterances in a manner similar to a human interviewer be able to alleviate some of the economic burdens associated with healthcare by reducing the workload of healthcare professionals?
https://aclanthology.org/2020.lrec-1.147/,"What are the effects of data augmentation on the performance of machine learning models in identifying stigma in social media discourse, and how does it compare to other models such as traditional and deep learning models?"
https://aclanthology.org/2020.lrec-1.147/,"Can the annotation scheme developed for stigma identification be applied to other health-care domains, and what are the potential challenges and limitations of using Amazon MTurk annotators versus experts in the field?"
https://aclanthology.org/2020.lrec-1.148/,Can the use of machine learning algorithms with deep learning architectures improve the accuracy of discourse mode classification in Hindi short stories compared to traditional rule-based approaches?
https://aclanthology.org/2020.lrec-1.148/,Can the part-of-speech tagging of sentences in the corpus be improved by using a combination of rule-based and statistical models?
https://aclanthology.org/2020.lrec-1.149/,How do large-scale multi-lingual datasets like SHINRA-5LDS improve the performance of NLP models in predicting entities in multi-language texts and what are the limitations of current models when trained on fine-grained tag sets?
https://aclanthology.org/2020.lrec-1.149/,Can a multi-lingual dataset like SHINRA-5LDS be effectively used to evaluate the performance of ENE label set classification models and what are the key challenges in structuring and annotating large-scale datasets like SHINRA-5LDS?
https://aclanthology.org/2020.lrec-1.150/,"Can a deep learning approach using the TWIFIL platform be able to accurately classify Algerian dialect tweets as positive, negative, or neutral with a high precision and recall rate?"
https://aclanthology.org/2020.lrec-1.150/,Can the annotated Algerian dialect dataset developed using TWIFIL be used to train a machine learning model that can predict the sentiment of tweets with high accuracy and precision in a subjectivity lexicon?
https://aclanthology.org/2020.lrec-1.151/,"Can large language models based on the Transformer architecture be improved upon by incorporating BERT sentence embeddings as input features for stance detection tasks, and can fine-tuning these models on larger datasets lead to state-of-the-art results on challenging NLP tasks?"
https://aclanthology.org/2020.lrec-1.152/,Can context-aware models improve the performance of a BiLSTM encoder-decoder model on the new classification task by leveraging the symbolic modality of mathematical formulas?
https://aclanthology.org/2020.lrec-1.152/,Can grouping scientific statements into thirteen classes align with known success rates from the state of the art using a machine-readable representation of the arXiv.org collection of preprint articles?
https://aclanthology.org/2020.lrec-1.153/,"Can a machine learning model trained on a single-domain corpus of Brazilian Portuguese text perform well in predicting author demographics when used to classify text from a different domain, and how does the performance change when using a combination of multiple cross-domain sources?"
https://aclanthology.org/2020.lrec-1.153/,"Can a machine learning model that uses word- and psycholinguistics-based features be more accurate in predicting author demographics in cross-domain settings than models that rely solely on linguistic features, and what is the impact of corpus size on the performance of these models?"
https://aclanthology.org/2020.lrec-1.154/,"Can a supervised learning approach using a deep learning model be applied to accurately classify legal provisions in contracts with a high degree of accuracy, measured by the F1-score, using the LEDGAR corpus? Can the performance of the model be improved by using a transfer learning approach that leverages pre-trained language models, such as BERT, on a dataset of contracts outside the LEDGAR corpus?"
https://aclanthology.org/2020.lrec-1.155/,"What is the effectiveness of the proposed online near-duplicate detection system in filtering out near-duplicate documents in real-time with high precision, measured by its F1-scores, and how does it compare to previous offline methods in this regard?"
https://aclanthology.org/2020.lrec-1.155/,"How can the proposed online system be tuned to balance precision and recall in real-time applications, and what are the implications of this tuning for the productivity of human analysts in a situational awareness tool?"
https://aclanthology.org/2020.lrec-1.156/,"What is the effectiveness of a feature-based approach versus a neural-network-based approach in achieving accurate automated essay scoring for non-native Japanese learners, measured by the quadratic weighted kappa score?"
https://aclanthology.org/2020.lrec-1.156/,How does the BERT model perform in terms of root mean squared error and quadratic weighted kappa scores compared to the LSTM model in automated essay scoring for Japanese as a second language learners?
https://aclanthology.org/2020.lrec-1.157/,"Can the proposed corpus effectively evaluate the performance of keyword-based approaches in detecting sensitive information in complex documents, and how do these approaches compare to deep learning models such as LSTM and RecNN?"
https://aclanthology.org/2020.lrec-1.157/,"Does the use of human annotators and automated label inference improve the quality and reliability of the annotations in the corpus, and what are the implications for the evaluation of sensitive information detection models?"
https://aclanthology.org/2020.lrec-1.158/,"Can a neural network automatically identify politically biased news articles with high accuracy using annotated corpora created by domain experts and crowd workers, and how does this approach compare to inferring article labels from a newspaper's ideology? Can a self-supervised training method improve the performance of a neural network in detecting media bias in news articles?"
https://aclanthology.org/2020.lrec-1.159/,Can computational models trained on the proposed corpora of humour and non-humourous text achieve higher accuracy in humour recognition when using linguistic features compared to content features?
https://aclanthology.org/2020.lrec-1.159/,"Can the use of machine learning algorithms on the proposed corpora of humour and non-humourous text improve the recognition of verbal humour in Portuguese, as measured by user satisfaction ratings?"
https://aclanthology.org/2020.lrec-1.160/,"Can fact-checks from a corpus linguistic perspective provide insights into the linguistic features of false scientific claims in the news, and how these features can be used to improve fact-checking algorithms?"
https://aclanthology.org/2020.lrec-1.160/,"How do the rhetorical and content elements of fact-checks relate to the perceived accuracy of false claims in the news, as demonstrated by the keyword analyses of FactCorp?"
https://aclanthology.org/2020.lrec-1.161/,"Can a machine learning model using linguistic features effective for modern language data accurately identify conceptually-oral historical texts, and what are the specific features that contribute to this identification? Can the ratio of verbs to nouns and frequency of pronouns be used to distinguish between conceptually-oral and literate historical texts?"
https://aclanthology.org/2020.lrec-1.162/,Can a deep neural network based classification model with a lightweight context encoder improve the accuracy of suicidal behavior classification in Autism Spectrum Disorder patient records compared to a model that only considers the target sentence? Does the use of contextual information from sentences to the left and right of the target sentence in EHRs significantly improve the classification accuracy of suicidal behavior in Autism Spectrum Disorder patient records?
https://aclanthology.org/2020.lrec-1.163/,"Can gradient boosting machines be improved to achieve a higher accuracy for film age appropriateness classification in the UK market compared to the current state-of-the-art, and can this improvement be achieved through the use of a combination of gradient boosting machines and a transformer-based approach? Can a supervised learning model using a transformer-based architecture be trained to achieve a higher accuracy for film age appropriateness classification in the UK market compared to the current state-of-the-art, and what are the key factors that contribute to the difference in accuracy between the UK and US markets?"
https://aclanthology.org/2020.lrec-1.164/,"Can a deep learning model using word embeddings achieve higher accuracy than a classical machine learning approach for dialect identification in the Habibi corpus, and how do different word embeddings affect the performance of the model in this task? Can the Habibi corpus be used to identify country of origin with higher accuracy than a baseline approach?"
https://aclanthology.org/2020.lrec-1.165/,Can an RNN-based architecture with attention be used to accurately predict MPAA ratings for children's movies by jointly modeling genre and emotional content in scripts?
https://aclanthology.org/2020.lrec-1.165/,Can the proposed architecture improve the accuracy of MPAA rating prediction for children's movies compared to traditional machine learning methods?
https://aclanthology.org/2020.lrec-1.166/,"Is the use of social network information in addition to textual information effective in improving the performance of email classification tasks, and can the thread structure of emails provide further improvement in email classification accuracy? Can incorporating social network information and thread structure into an email classification model based on textual information improve the accuracy of detecting personal emails compared to a baseline model that uses only textual information?"
https://aclanthology.org/2020.lrec-1.167/,"How can the proposed Chinese humor corpus be used to develop more accurate humor-related AI models that can effectively learn to recognize and respond to humor framing, effect, and amusing level in context?"
https://aclanthology.org/2020.lrec-1.167/,"Can machine learning algorithms be used to validate the validity of a manually labeled corpus, and if so, what are the key factors that affect the accuracy of such validation?"
https://aclanthology.org/2020.lrec-1.168/,"Can text simplification tools using machine learning algorithms and lexical analysis effectively reduce reading errors for children with reading difficulties, as measured by the number of errors made in reading simplified texts compared to the original texts, and how do these tools perform on different age groups of children? Can the proposed corpus of simplified texts be used to develop more effective reading tests for assessing reading abilities in children with reading difficulties?"
https://aclanthology.org/2020.lrec-1.169/,"What is the accuracy of a machine learning model trained on the proposed dataset to identify chronic pain as a phenotype from nursing progress notes, using a bag-of-words representation of the text and a support vector machine classifier, compared to a model trained on the same dataset but with a convolutional neural network architecture?"
https://aclanthology.org/2020.lrec-1.169/,Can a deep learning-based approach using a transformer model and BERT embeddings outperform a traditional rule-based approach using a dictionary-based approach to infer patient phenotypes from discharge summaries in a large-scale electronic health record dataset?
https://aclanthology.org/2020.lrec-1.170/,"Does the proposed multilingual stance detection dataset facilitate the development of accurate stance detection models in both Catalan and Spanish, and can it improve the state-of-the-art results on the TW-10 dataset?"
https://aclanthology.org/2020.lrec-1.170/,Can a semi-automatic method for annotating the dataset based on Twitter user categorization lead to better performance in stance detection for multilingual and cross-lingual settings?
https://aclanthology.org/2020.lrec-1.171/,"Can PNNs outperform fine-tuning methods in terms of knowledge retention for sequence labeling tasks, and what are the optimal architecture configurations for this application?"
https://aclanthology.org/2020.lrec-1.171/,"Can PNNs improve the performance of text classification tasks compared to fine-tuning methods, and what are the key factors influencing the effectiveness of PNNs in NLP?"
https://aclanthology.org/2020.lrec-1.172/,Can machine learning models trained on comment-level data achieve higher accuracy in detecting online abuse compared to models trained on isolated message-level data?
https://aclanthology.org/2020.lrec-1.172/,Can a benchmarking platform with comment-level data improve the comparability and reproducibility of results in content abuse detection research?
https://aclanthology.org/2020.lrec-1.173/,"Can Arabic event detection systems using machine learning algorithms be improved by utilizing large-scale datasets such as FloDusTA, which contains tweets written in Modern Standard Arabic and Saudi dialect, to enhance their accuracy in detecting floods, dust storms, traffic accidents, and non-event tweets?"
https://aclanthology.org/2020.lrec-1.173/,"Can the use of deep learning architectures, such as transformer-based models, be effective in improving the performance of Arabic event detection systems in terms of processing time and accuracy, particularly when compared to traditional rule-based approaches?"
https://aclanthology.org/2020.lrec-1.174/,"Can a machine learning model trained on a French corpus of 12,000 tweets be able to accurately detect sexist content in tweets while also distinguishing between sexist content addressed to women and sexist content describing women?"
https://aclanthology.org/2020.lrec-1.174/,"Can the proposed deep learning approach improve the detection of sexist content on social media, specifically in terms of reducing false positives and false negatives, in comparison to traditional methods?"
https://aclanthology.org/2020.lrec-1.175/,Can machine learning algorithms utilizing readability features improve the accuracy of fake news detection for the Brazilian Portuguese language up to 92%?
https://aclanthology.org/2020.lrec-1.175/,"Do readability features have a significant impact on the classification of fake news in the Brazilian Portuguese language, compared to other feature sets?"
https://aclanthology.org/2020.lrec-1.176/,Can the use of textual features and shallow semantic features that only require entity linking lead to improved results in text complexity assessment compared to deep semantic features in the pairwise comparison of two versions of the same text?
https://aclanthology.org/2020.lrec-1.176/,Can shallow features outperform state-of-the-art deep semantic features in the five-level classification of texts?
https://aclanthology.org/2020.lrec-1.177/,Can DecOp improve the performance of deception detection models when using cross-domain and cross-language data compared to existing datasets?
https://aclanthology.org/2020.lrec-1.177/,Can the DecOp corpus serve as a benchmark for evaluating the generalizability of Transformer-based architectures in detecting deception in online sources across different domains and languages?
https://aclanthology.org/2020.lrec-1.178/,"Can a supervised learning approach using a neural network model to predict text age can be effective in achieving high accuracy in determining the suitability of the text for a young audience, and what features from psycholinguistic and NLP tasks are most relevant for this task? Can a hierarchical sentence-based approach to predicting text age outperform a traditional text-based approach in determining the age appropriateness of the text for children?"
https://aclanthology.org/2020.lrec-1.179/,"Can the proposed multilingual Twitter corpus effectively identify biases in hate speech detection models across different languages, and does this impact the accuracy of demographic predictions?"
https://aclanthology.org/2020.lrec-1.179/,Can the empirical analysis of demographic predictability on the English corpus identify the factors that contribute to biases in document classification models?
https://aclanthology.org/2020.lrec-1.180/,Can VICTOR dataset be used to improve the performance of document classification models by leveraging sequential information in legal documents?
https://aclanthology.org/2020.lrec-1.180/,Can the inclusion of domain knowledge in theme classification approach improve its accuracy compared to using all available data in the VICTOR dataset?
https://aclanthology.org/2020.lrec-1.181/,Can dynamic fusion models improve the performance of document classification on specialized collections by combining the strengths of individual models for different document types?
https://aclanthology.org/2020.lrec-1.181/,Can dynamic fusion models outperform individual models and other ensemble methods in terms of accuracy on a variety of document types in web archiving institutions?
https://aclanthology.org/2020.lrec-1.182/,Can a deep learning approach that analyzes aspect flows for text representation be more accurate than traditional methods that rely on summarized features in sentiment analysis tasks?
https://aclanthology.org/2020.lrec-1.182/,Can the proposed Audio-Like Features provide a more detailed understanding of text behavior and sentiment than existing methods that rely on traditional audio analysis features?
https://aclanthology.org/2020.lrec-1.183/,"Can a machine learning model using a supervised approach with a transformer-based architecture be trained to detect subtle bias in news articles with high accuracy on the sentence level, and how does its performance compare to a baseline model using a traditional rule-based approach? Can the proposed dataset be used to develop and evaluate methods for detecting bias in news articles on a fine-grained level, and what are the implications for fake news detection research?"
https://aclanthology.org/2020.lrec-1.184/,"Can Deep Gaussian Process Models Outperform Shallow Gaussian Process Models in Text Classification on the TREC, SST, MR, and R8 Datasets by Achieving Higher Accuracy and Lower Overfitting Rates?"
https://aclanthology.org/2020.lrec-1.184/,"Can Shallow Gaussian Process Models with a Limited Number of Features be Effective for Text Classification Tasks Using the proposed DGP models and traditional machine learning approaches, and what is the optimal number of features for achieving the best results?"
https://aclanthology.org/2020.lrec-1.185/,"Can machine learning models accurately detect emotions in Spanish and English tweets using the proposed dataset, as measured by precision, recall, and F1-score?"
https://aclanthology.org/2020.lrec-1.185/,"Can the proposed machine learning approach distinguish between offensive and non-offensive tweets, and what is its accuracy on both languages?"
https://aclanthology.org/2020.lrec-1.186/,How can the multimodal features of stress and emotional expressions be effectively combined to improve the accuracy of affective state classification in both singular and dyadic settings?
https://aclanthology.org/2020.lrec-1.186/,"Can the presence of stress impact the production and perception of emotional expressions in human-agent interactions, and how can this be quantified and measured in multimodal emotion classification tasks?"
https://aclanthology.org/2020.lrec-1.187/,Can a transfer-learning based approach using pre-trained language models be used to accurately infer the affectual state of individuals from their tweets with minimal fine-tuning of task-specific features?
https://aclanthology.org/2020.lrec-1.187/,"Can the use of pre-learned knowledge in transfer learning models lead to competitive results in affectual content analysis of tweets, compared to traditional machine learning models?"
https://aclanthology.org/2020.lrec-1.188/,"Can a machine learning model be trained to accurately identify emotion carriers in speech transcriptions of personal narratives using the Ulm State-of-Mind in Speech corpus, and what is the average processing time required for this task? Can a deep learning model based on a Transformer architecture be used to predict the emotional state of a narrator from their speech or text segments, and what is the accuracy of this prediction model?"
https://aclanthology.org/2020.lrec-1.189/,"Can speech hesitation be automatically predicted using acoustic features and machine learning algorithms, and what is the relationship between filled pauses and vowel duration in relation to the degree of hesitation in spontaneous speech?"
https://aclanthology.org/2020.lrec-1.189/,"Can regression models be trained to accurately predict the degree of hesitation in speech chunks without manual annotation, and what is the optimal set of acoustic features required for effective automatic prediction?"
https://aclanthology.org/2020.lrec-1.190/,"Can BERT-based contextual word embeddings be used to improve the detection of abusive short texts in the Spanish language, and how do they compare to classical machine learning techniques in terms of accuracy? Can the proposed Spanish Database for cyberbullying prevention be used as a reliable dataset for training classifiers to detect abusive short texts, and what are the key factors that affect its quality?"
https://aclanthology.org/2020.lrec-1.191/,"Can speech patterns of actors and non-actors be distinguished through analysis of emotional speech database collected using designed drama situations, and how does the annotation strategy impact the accuracy of emotion recognition?"
https://aclanthology.org/2020.lrec-1.191/,"Can the use of a large-scale emotional speech database, such as IIIT-H TEMD, improve the performance of emotion recognition models in real-world scenarios?"
https://aclanthology.org/2020.lrec-1.192/,"Can a machine learning model trained on the POTUS Corpus achieve high accuracy in reproducing socio-emotional behavior in ECA, as measured by human annotation of social attitudes, using automatic extraction of social signals from Barack Obama's speeches? Can the use of the POTUS Corpus improve the reproduction of socio-emotional behavior in virtual agents, as measured by human annotation of social attitudes, when compared to a model trained on a corpus of human-generated social signals?"
https://aclanthology.org/2020.lrec-1.193/,"Can an automatic system predict the semantic role structures of news headlines with high accuracy using a deep learning-based approach, and what is the impact of incorporating textual cues on the performance of such a system? Can a machine learning model be trained to detect the emotional causes and targets of news headlines with high precision, and what is the relationship between the annotated causes and targets in the proposed dataset?"
https://aclanthology.org/2020.lrec-1.194/,How do the linguistic features of tweets related to solitude and loneliness differ between men and women in terms of the words co-occurring with them?
https://aclanthology.org/2020.lrec-1.194/,"Do the frequencies of tweets using the words solitude and lonely vary significantly among different age groups, particularly among teenagers compared to other age groups?"
https://aclanthology.org/2020.lrec-1.195/,"What are the factors that impact the emotional expression of children from grades 1 to 12 in their written texts, and how do these factors relate to the development of emotions and emotional regulation in children?"
https://aclanthology.org/2020.lrec-1.195/,"How do age and gender influence the emotional content and development of child-written texts, as measured by valence, arousal, and dominance dimensions?"
https://aclanthology.org/2020.lrec-1.196/,"Can a machine learning model using a deep learning architecture be trained to accurately detect the temporal evolution of emotions in call center conversations using the AlloSat corpus, and what is the precision of the model in detecting frustration and satisfaction levels? Can the proposed corpus be used to develop a real-time emotional intelligence system that can analyze the emotional states of customers during a conversation and provide personalized support?"
https://aclanthology.org/2020.lrec-1.197/,"Can a machine learning model learn to accurately evaluate the quality of generated dialogue by comparing two systems, and what are the key factors that influence its performance in different dialog contexts?"
https://aclanthology.org/2020.lrec-1.197/,"Can a machine learning model trained on human judgments of comparing two dialogue systems achieve consistent evaluation results with high accuracy, and how does its performance compare to human evaluators?"
https://aclanthology.org/2020.lrec-1.198/,"Can the proposed n-gram-based distant supervision method achieve comparable results to the KTEA dataset in detecting emotions from Korean texts, and can the addition of Korean-specific features improve the performance of the emotion classification task? Can the proposed Korean-specific annotation procedure be used to construct a large-scale emotion-labeled dataset, and what is the effect of the sentiment movie review corpus on the quality of the dataset?"
https://aclanthology.org/2020.lrec-1.199/,"What is the impact of using semi-automatically constructed emotion corpus on the accuracy of deep learning-based emotion classification models, and how can errors in emotion labels be automatically corrected to improve classification performance?"
https://aclanthology.org/2020.lrec-1.199/,What is the effect of using emotional seed words on the quality and accuracy of emotion labels in a semi-automatically constructed corpus for deep learning-based emotion classification tasks?
https://aclanthology.org/2020.lrec-1.200/,"Can deep learning models be trained to accurately detect the emotion conveyed in a suicide note with high precision, and what are the performance metrics that would be most effective in evaluating their effectiveness?"
https://aclanthology.org/2020.lrec-1.200/,"Can the use of ensemble architectures improve the detection of subtle emotional cues in suicide notes, and how do different deep learning models (CNN, GRU, and LSTM) contribute to the overall accuracy of emotion detection?"
https://aclanthology.org/2020.lrec-1.201/,What is the impact of using a transformer-based architecture versus a convolutional neural network on the accuracy of a German sentiment classification model?
https://aclanthology.org/2020.lrec-1.201/,How does the size of the sentiment corpus used for training affect the performance of a general-purpose German sentiment classification model in terms of processing time and user satisfaction?
https://aclanthology.org/2020.lrec-1.202/,"Can the proposed annotation scheme for implicit emotions improve the accuracy of emotion classification models in social media text, measured by a 20% increase in F1-score compared to existing models?"
https://aclanthology.org/2020.lrec-1.202/,"Does the use of rhetorical questions and opinion targets in the corpus improve the detection of implicit emotions, as indicated by a 15% increase in precision of implicit emotion detection compared to a baseline model?"
https://aclanthology.org/2020.lrec-1.203/,"Can the use of a bi-representational format for annotating emotions in text improve the accuracy of emotional state classification when compared to a categorical format, as measured by F1-score?"
https://aclanthology.org/2020.lrec-1.203/,"Does the connotation of emotion labels influence the effectiveness of an emotion-annotated corpus in various domains and topics, and if so, how can this impact be mitigated when developing a dataset for emotional state classification?"
https://aclanthology.org/2020.lrec-1.204/,"Is it possible to develop a deep learning model that can accurately classify aesthetic emotions in poetry, as indicated by the reader's emotional response, and if so, what features or techniques would be most effective in improving its performance? Can crowdsourced annotation of mixed emotions in poetry improve the accuracy of aesthetic emotion classification models, such as BERT, in comparison to expert-annotated datasets?"
https://aclanthology.org/2020.lrec-1.205/,"Can deep learning methods effectively learn word ratings for emotions such as empathy from higher-level supervision, and how do these methods compare to traditional approaches?"
https://aclanthology.org/2020.lrec-1.205/,How can Signed Spectral Clustering be used to analyze the properties of words in an automatically created empathy lexicon?
https://aclanthology.org/2020.lrec-1.206/,Can a pre-trained sentence embedding model trained on a low-resource language such as Polish achieve comparable performance to those trained on high-resource languages like English on a specific language-specific task?
https://aclanthology.org/2020.lrec-1.206/,Can the aggregation of word vectors into a single sentence vector using different methods impact the performance of a multilingual sentence encoder on a Polish language task?
https://aclanthology.org/2020.lrec-1.207/,What is the potential of using speech-based features to improve the accuracy of disfluency detection in semi-directed interviews compared to text-based features?
https://aclanthology.org/2020.lrec-1.207/,Can a novel set of audio features inspired by word-based span features lead to better performance in disfluency detection when used in conjunction with acoustic-prosodic information?
https://aclanthology.org/2020.lrec-1.208/,"Can speech disorders be accurately assessed using phonological transcription and cost matrices to evaluate the distance between produced and expected phonemes, and what are the implications for measuring the impact of oral cavity cancer on patient communication?"
https://aclanthology.org/2020.lrec-1.208/,"How can the proposed measurement method be fine-tuned to improve the precision of phonological transcription and reduce the variability in feature differences between phonemes, and what are the expected benefits for the evaluation of speech disorders in patients with oral cavity cancer?"
https://aclanthology.org/2020.lrec-1.209/,"Can the proposed paragraph ordering task effectively capture the coherence of a text by predicting the most suitable order of sentences, and how does this approach compare to existing sentence ordering methods? Can the recurrent graph neural network-based model be robustly evaluated and applied to real-world text coherence modeling tasks using metrics such as WLCS-l and τ?"
https://aclanthology.org/2020.lrec-1.210/,"Can deep learning-based NER systems be improved by incorporating explicit handling of unknown words and label shift in the training process, and how does this approach affect their performance in in-domain and out-of-domain settings? Does the proposed method significantly reduce the number of errors made by NER systems on challenging tokens in both in-domain and out-of-domain settings?"
https://aclanthology.org/2020.lrec-1.211/,"Can recent deep learning models such as BERT be trained to detect communicative functions in sentences with high accuracy, and if so, what features of sentence representations contribute to their effectiveness in this task?"
https://aclanthology.org/2020.lrec-1.211/,"Can the use of high-quality annotated data be improved for the detection of communicative functions in sentences, and if so, what methods can be employed to increase the efficiency of the annotation process?"
https://aclanthology.org/2020.lrec-1.212/,"What are the key factors that affect the accuracy of the automated evaluation system for children's speech and language impairments, considering the weights used in the cost function?"
https://aclanthology.org/2020.lrec-1.212/,How can the proposed system be improved to reduce the time complexity of the transformation process and increase its processing efficiency in evaluating verbal production?
https://aclanthology.org/2020.lrec-1.213/,How do Gumbel Attention for Sense Induction and sense-specific embeddings compare in terms of coherence and accuracy in human-centric tasks versus computer-centric evaluations?
https://aclanthology.org/2020.lrec-1.213/,Can Gumbel Attention for Sense Induction outperform existing sense embeddings in terms of the comprehensiveness of a language's sense inventory?
https://aclanthology.org/2020.lrec-1.214/,"Is there a correlation between the proposed characteristic metrics and the performance of the BERT model on text classification tasks, and can the proposed metrics be used to predict the performance of BERT on unseen text classification tasks?"
https://aclanthology.org/2020.lrec-1.215/,Can a Siamese Network approach be designed to outperform ad-hoc retrieval models in the few-shot Event Mention Retrieval task by leveraging user-supplied query-based event mentions from a large corpus?
https://aclanthology.org/2020.lrec-1.215/,Can a personalized event-centric information retrieval framework be effectively implemented using the ACE dataset to accommodate varied event types and domains of interest in a few-shot EMR setting?
https://aclanthology.org/2020.lrec-1.216/,"Can hierarchical question structures improve the evaluation of reading comprehension questions in the biology domain, and do teacher-generated questions outperform human-generated questions in terms of linguistic and pedagogic quality? Does the use of expert annotators with educational background significantly impact the evaluation of reading comprehension questions in the biology domain?"
https://aclanthology.org/2020.lrec-1.217/,Can event-specific corpora constructed from a large static background corpus using different IR methods improve the performance of timeline summarization algorithms and what is the optimal IR method for this purpose?
https://aclanthology.org/2020.lrec-1.217/,Does the use of sentence filtering techniques affect the performance of timeline summarization systems and can a common static background corpus be used to evaluate the effectiveness of these systems?
https://aclanthology.org/2020.lrec-1.218/,"What are the effects of using natural language interfaces in relational databases on the accuracy of information retrieval, measured by precision and recall rates, in comparison to traditional SQL querying methods?"
https://aclanthology.org/2020.lrec-1.218/,"How do the performance metrics of keyword-enabled relational database systems like SODA compare to information retrieval systems like Terrier, specifically in terms of processing time and user satisfaction?"
https://aclanthology.org/2020.lrec-1.219/,"Can attention layers in neural networks provide robust yet non-causal explanations for text classification tasks, and what implications does this have for the evaluation of explainability in NLP models? Can philosophical theories of explanation provide a framework for developing causal reasoning in NLP applications that can be empirically validated through attention mechanisms?"
https://aclanthology.org/2020.lrec-1.220/,Can a phonetically motivated reduction of linguistic material improve the accuracy of a discrimination classifier in speech disordered populations measured by the area under the receiver operating characteristics curve? Does reducing the linguistic sample to 30% of its original size have a significant impact on the discriminatory performance of the classifier?
https://aclanthology.org/2020.lrec-1.221/,"Can generative language models such as GPT-2 and ULMFiT effectively generate headlines that closely match human judgments, and if so what are the key factors influencing their headline generation capacity?"
https://aclanthology.org/2020.lrec-1.221/,Do Fr ́echet embedding distance and angular embedding similarity metrics better capture the nuances of abstractive summarization than existing metrics such as ROUGE?
https://aclanthology.org/2020.lrec-1.222/,"Can the proposed LinCE benchmark effectively promote generalizability of NLP models to different code-switched languages and tasks, as measured by the accuracy of language identification and named entity recognition tasks? Does the use of multilingual BERT-based models improve performance on sentiment analysis and part-of-speech tagging tasks in the LinCE benchmark compared to the popular LSTM and ELMo models?"
https://aclanthology.org/2020.lrec-1.223/,How does the choice of data selection method for paraphrase generation affect the quality and novelty of generated paraphrases in the colloquial domain
https://aclanthology.org/2020.lrec-1.223/,Can a Transformer-based architecture outperform an RNN-based architecture in generating high-quality paraphrases in the colloquial domain
https://aclanthology.org/2020.lrec-1.223/,What is the correlation between human judgments and automatic evaluation metrics such as BLEU and BERTScore in evaluating paraphrase generation quality in the colloquial domain
https://aclanthology.org/2020.lrec-1.224/,"Can word embeddings trained on different linguistic knowledge sources contribute to improved performance on downstream tasks such as question answering and text classification, as evaluated on the BATS, VecEval, and SentEval datasets?"
https://aclanthology.org/2020.lrec-1.224/,"Does the use of partial least squares path modeling (PLS-PM) with word embeddings allow for a more nuanced understanding of the causal relationships between linguistic knowledge and downstream task performance, as measured by accuracy on VecEval and SentEval?"
https://aclanthology.org/2020.lrec-1.225/,"Can lifelong learning systems be effectively evaluated using existing machine learning metrics, such as accuracy or precision, when incorporating human-assisted learning methods, and what modifications would be needed to these metrics to account for the unique aspects of human-assisted learning? Should a lifelong learning system be evaluated based on its ability to adapt and learn from human feedback, and how would this evaluation differ from traditional machine learning model evaluation?"
https://aclanthology.org/2020.lrec-1.226/,"Can a proposed method for annotating adjectives, adverbs, nouns, and verbs in the Basic Corpus of Polish Metaphors achieve high interannotator agreement statistics, and if so, how does it impact the overall quality of the corpus annotation?"
https://aclanthology.org/2020.lrec-1.226/,"Can the proposed method for annotating abbreviations of words in the corpus improve the accuracy of morphosyntactic annotation, and what are the challenges in annotating pluralia tantum and the się marker?"
https://aclanthology.org/2020.lrec-1.227/,"Can a machine learning model utilizing a pre-trained language model and a rule-based approach achieve high accuracy in detecting and correcting simple typing errors, and how does this compare to a model using only a rule-based approach?"
https://aclanthology.org/2020.lrec-1.227/,"Does the use of a realistic error model in generating the benchmark affect the evaluation of the performance of a deep learning-based spelling correction model, and what are the implications for the choice of evaluation metric?"
https://aclanthology.org/2020.lrec-1.228/,"Can a deep learning model with a cross attention mechanism be used to accurately estimate the quality of human translations, and does this approach improve upon traditional methods that rely on manually engineered features? Can a neural model be designed to predict fine-grained scores for various aspects of translation quality, such as terminological accuracy or idiomatic writing?"
https://aclanthology.org/2020.lrec-1.229/,"What is the performance of UDPipe in named entity recognition for under-resourced languages compared to its reported results in the literature, and how can a universally applicable named entities classification scheme be developed for NERC tasks across different languages?"
https://aclanthology.org/2020.lrec-1.229/,"Can the linguistic processing chains (LPCs) used in the CLEOPATRA action be effectively applied to other EU-official languages with limited resources, and what are the challenges that arise when adapting these chains for such languages?"
https://aclanthology.org/2020.lrec-1.230/,Can FastText word embeddings with 300 dimensions outperform Word2Vec Skipgram and CBOW models in sentiment analysis tasks for Sinhala language?
https://aclanthology.org/2020.lrec-1.230/,Can Glove word embeddings achieve comparable results with FastText word embeddings in part-of-speech (POS) tagging tasks for Sinhala language?
https://aclanthology.org/2020.lrec-1.231/,Can transformer-based models outperform recurrent neural network models in terms of robustness to adversarial examples in Natural Language Inference and Question Answering tasks?
https://aclanthology.org/2020.lrec-1.231/,Do transformer-based models exhibit consistent performance under severe stress conditions compared to their predecessors in NLI and QA tasks?
https://aclanthology.org/2020.lrec-1.232/,"Can neural classification models achieve high accuracy in Brand-Product relation extraction when trained on textual corpora with different underlying text representations, and what are the key properties of Brand-Product relations in textual corpora that influence the performance of these models?"
https://aclanthology.org/2020.lrec-1.233/,"Can a supervised learning approach using a Transformer-based architecture improve the accuracy of meaning representation parsing compared to traditional methods, as measured by the number of correctly identified entities in the parsed graph? Does the use of graph-structured target representations enable the identification of previously unknown properties of the different parsing systems?"
https://aclanthology.org/2020.lrec-1.234/,"Is it possible to design a headword-oriented entity linking model that achieves high accuracy in linking headwords to knowledge bases, and if so, what are the key factors that influence its performance in a cosmetic context? Does a product embedding model with distant supervision and heuristic patterns lead to better performance than traditional supervised learning methods in this specialized entity linking task?"
https://aclanthology.org/2020.lrec-1.235/,Is it possible to improve the performance of image-based table detection models using a combination of weak supervision from Word and Latex documents?
https://aclanthology.org/2020.lrec-1.235/,Can a deep neural network trained on TableBank dataset outperform state-of-the-art models in real-world applications with a limited number of labeled examples?
https://aclanthology.org/2020.lrec-1.236/,"Can deep learning models for ad-hoc information retrieval be improved by using larger datasets created from publicly available sources such as Wikipedia, and how can WIKIR contribute to addressing the lack of publicly available datasets for academic research in this field?"
https://aclanthology.org/2020.lrec-1.236/,Can the use of WIKIR and its generated dataset wikIR59k improve the performance of existing deep learning models for ad-hoc information retrieval on publicly available datasets such as Robust04 and ClueWeb09?
https://aclanthology.org/2020.lrec-1.237/,"Can the proposed method for corpus construction using image processing and OCR improve the accuracy of content search tool for temporal and semantic content analysis, as demonstrated by the 87.8% F-score for corpus construction? Can the proposed method be further optimized to improve the accuracy of content search tool for temporal and semantic content analysis, by analyzing the performance of the content search tool on a larger dataset?"
https://aclanthology.org/2020.lrec-1.238/,Can an automated machine-reading system based on deep learning and heuristic rule-based relation extraction be able to accurately detect entities in synthesis processes of all-solid-state batteries with a macro-averaged F1 score of 0.826? Can a sequence tagger using deep learning achieve high performance in detecting entities in synthesis processes of all-solid-state batteries with a macro-averaged F1 score of 0.887?
https://aclanthology.org/2020.lrec-1.239/,"Can the proposed WEXEA system efficiently annotate all mentions of entities on Wikipedia with links to their corresponding articles, and can the annotated corpus be effectively used for downstream NLP tasks such as relation extraction?"
https://aclanthology.org/2020.lrec-1.239/,"Can the annotation process be optimized to handle large volumes of text and reduce the computational resources required, and what are the implications for the quality of the annotations and the downstream NLP tasks?"
https://aclanthology.org/2020.lrec-1.240/,"Can distributed representations of entity mentions in technical and scientific domains be effectively learned using a corpus selection approach that balances data quantity and quality, and how can this approach be optimized to improve the accuracy of entity normalization tasks in these domains?"
https://aclanthology.org/2020.lrec-1.240/,"Can the parametrization of machine learning-based entity normalization methods be improved by using weak supervision and hyperparameter tuning, and what are the optimal hyperparameters for achieving high-performance results in these domains?"
https://aclanthology.org/2020.lrec-1.241/,"Can machine learning algorithms be used to automatically extract and classify the entities mentioned in behaviour change intervention evaluation reports, specifically population, settings, and results, to aid in synthesizing and summarizing the literature on smoking cessation? Can a named entity recognition model trained on the released annotation dataset improve the accuracy of such extractions, and what is the effect on processing time?"
https://aclanthology.org/2020.lrec-1.242/,Can the proposed share-and-transfer framework improve the performance of event extraction tasks on low-resource languages compared to state-of-the-art supervised models trained from annotated data?
https://aclanthology.org/2020.lrec-1.242/,"Can the use of cross-lingual word embeddings in the framework enhance the representation of graph structures for event extraction across languages, and how does this impact the overall performance of the system?"
https://aclanthology.org/2020.lrec-1.243/,"Can edge detection models be trained to adapt to new domains using transfer learning techniques in biomedical event extraction tasks, and how do these adaptations affect the overall performance of the model?"
https://aclanthology.org/2020.lrec-1.243/,"Can edge detection models be effectively evaluated across different corpora using a standardized benchmark corpus, and what are the key factors that influence the performance of these models in out-of-domain data?"
https://aclanthology.org/2020.lrec-1.244/,"Can the proposed named entity annotation scheme be accurately applied to identify hazards, consequences, and mitigation strategies in a large corpus of construction safety documents, as measured by the F-Score of at least 0.8? Can the use of the proposed annotation scheme improve the processing time of automatic named entity recognition models for construction safety documents, as measured by a 30% reduction in processing time compared to existing methods?"
https://aclanthology.org/2020.lrec-1.245/,"Can a supervised machine learning approach using a transformer-based architecture be used to improve the accuracy of entity-centric sentiment analysis on the Web, by incorporating text analytics and visualization functionalities?"
https://aclanthology.org/2020.lrec-1.245/,"Can the proposed framework be able to accurately cluster texts into events related to entities, while also handling the complexity of real-world events and their dynamics over time?"
https://aclanthology.org/2020.lrec-1.246/,"Can machine learning algorithms be used to accurately extract medication information from unstructured free text in mental health electronic health records, and how does the inclusion of temporal information and attributes affect the extraction accuracy?"
https://aclanthology.org/2020.lrec-1.246/,Can a corpus of annotated medication information in mental health records be developed to support the development and evaluation of applications for medication extraction from EHR text?
https://aclanthology.org/2020.lrec-1.247/,"Can a Conversational Question Answering model's performance on the CoQA task be improved by dynamically sampling between target answers and model predictions during training, and how does this approach affect the model's performance for different question types, conversation lengths, and domains?"
https://aclanthology.org/2020.lrec-1.247/,"Can the severity of compounding errors in CoQA systems be quantitatively analyzed and mitigated through the proposed sampling strategy, and what is the optimal approach to balance the trade-off between accuracy and computational efficiency?"
https://aclanthology.org/2020.lrec-1.248/,"What is the effect of the quality and diversity of annotated datasets on the performance of entity linking models in Chinese text, and how does the proposed difficulty measure influence the evaluation of entity linking tasks on the CLEEK corpus?"
https://aclanthology.org/2020.lrec-1.248/,"Can the use of multi-domain long texts in entity linking improve the generalizability and robustness of Chinese entity linking models, as demonstrated by the results on the proposed CLEEK corpus?"
https://aclanthology.org/2020.lrec-1.249/,"Can a machine learning model using a transformer-based architecture be trained to accurately extract clinical concepts, including medications, symptoms, and conditions, from audio recordings of provider-patient encounters with an F-score of 0.90 or higher for medications and 0.72 or higher for symptoms?"
https://aclanthology.org/2020.lrec-1.249/,"Can a machine learning model be developed to map extracted symptoms to canonical forms as they appear in clinical notes, with a precision of 90% or higher, and minimize errors that do not impact the clinical note, to a level of 90% or higher?"
https://aclanthology.org/2020.lrec-1.250/,"Can a deep learning-based approach using a transformer architecture be used to accurately identify and extract parties' rights and obligations from annotated contract documents, with a precision of at least 90% and a recall of 85%?"
https://aclanthology.org/2020.lrec-1.250/,Can the proposed corpus of annotated contract documents enable the development of a natural language processing system that can recognize and classify the conditions and exceptions under which parties' rights and obligations take effect with an accuracy of at least 95%?
https://aclanthology.org/2020.lrec-1.251/,"What are the effects of using word embeddings and machine learning models in predicting geographic movement in text, on the accuracy of movement detection?"
https://aclanthology.org/2020.lrec-1.251/,Can the proposed corpus of labeled sentences improve the performance of computational processing of geography in text and spatial cognition?
https://aclanthology.org/2020.lrec-1.252/,Can a supervised machine learning approach using a Transformer-based architecture be used to achieve high recall and precision in extracting question and answer pairs from Japanese local assembly minutes?
https://aclanthology.org/2020.lrec-1.252/,Can the use of deep learning-based methods improve the segmentation of question and answer pairs in local assembly minutes and enhance the overall accuracy of the QA task?
https://aclanthology.org/2020.lrec-1.253/,"What is the feasibility of using term extraction to identify key aspects of patient experience in free text questions from the 2017 Irish National Inpatient Survey campaign, and how does it compare to manually annotated results based on the Activity, Resource, Context (ARC) methodology?"
https://aclanthology.org/2020.lrec-1.253/,"Can the proposed approach to patient experience analysis using term extraction effectively map patient feedback to specific healthcare-related categories, such as Activity, Resource, and Context, and what are the implications for healthcare practitioners in terms of identifying potential issues and planning actions?"
https://aclanthology.org/2020.lrec-1.254/,"What is the feasibility of training and evaluating Relation Extraction algorithms on a dataset of 1,500 manually-annotated sentences capturing domain-independent relations in scientific biology texts?"
https://aclanthology.org/2020.lrec-1.254/,How can the proposed dataset improve the coarse-grained typing of scientific biological documents and enable a high-level filter for engineers using Relation Extraction algorithms?
https://aclanthology.org/2020.lrec-1.255/,"Can convolutional neural networks be used to improve the accuracy of definition extraction from mathematical texts by combining them with recurrent neural networks, and what is the effect of syntactic enrichment on the performance of these models? Can the proposed dataset be used to train models that can generalize to other definition extraction tasks in different domains?"
https://aclanthology.org/2020.lrec-1.256/,"Can entity salience be accurately measured using a combination of named entity recognition and part-of-speech tagging, and how does this approach compare to existing methods?"
https://aclanthology.org/2020.lrec-1.256/,Does the use of Wikinews categories as entity annotations affect the performance of entity salience detection models in the WikiNews Salience dataset?
https://aclanthology.org/2020.lrec-1.257/,"Can a hybrid system that combines supervised machine learning and rule-based approaches be used to extract event arguments from unstructured Amharic text with high accuracy, as measured by the number of correctly identified event arguments? Can the proposed hybrid system outperform the standalone rule-based method in event extraction from Amharic text, as measured by the precision of event argument extraction?"
https://aclanthology.org/2020.lrec-1.258/,"Can deep learning approaches outperform traditional machine learning methods for named entities recognition in Italian, and what are the key features that contribute to this superiority?"
https://aclanthology.org/2020.lrec-1.258/,"Do deep learning models outperform traditional machine learning algorithms for sentiment analysis tasks in Italian, and what is the impact of feature engineering on their performance?"
https://aclanthology.org/2020.lrec-1.259/,Can a deep-learning-based sequence labeling model improve the accuracy of information extraction from instructional text in repair manuals by identifying the correct disassembled parts at each step of the repair process?
https://aclanthology.org/2020.lrec-1.259/,"Can an unsupervised method based on a bags-of-n-grams similarity be effective in extracting the required tools in each repair step of repair manuals, and what is the performance metric for evaluating its effectiveness?"
https://aclanthology.org/2020.lrec-1.260/,"Can entity spaces improve the recall of entity linking by capturing the nuances of entity descriptions in text, and what specific characteristics of entity descriptions are most indicative of improved recall?"
https://aclanthology.org/2020.lrec-1.260/,"Can the use of entity spaces in disambiguation pages lead to a more accurate representation of entities in knowledge bases, and how can this be evaluated in terms of precision and F1-score?"
https://aclanthology.org/2020.lrec-1.261/,Can the proposed methods for extracting information from song lyrics improve the accuracy of music search engines in retrieving relevant songs based on user-defined emotions and topics?
https://aclanthology.org/2020.lrec-1.261/,Can the use of the WASABI Song Corpus with its enriched metadata facilitate the development of more effective music recommendation systems that leverage the explicitness and salient passages of song lyrics?
https://aclanthology.org/2020.lrec-1.262/,"Can a temporal dependency tree be effectively used to represent the temporal structure of a text with a high degree of accuracy, and if so, what methods can be employed to quantify the potential loss of temporal information in such representations?"
https://aclanthology.org/2020.lrec-1.262/,"Can the use of temporal dependency trees be justified in tasks that require an accurate global temporal ordering, given the potential for a 109% increase in temporal indeterminacy compared to temporal graphs?"
https://aclanthology.org/2020.lrec-1.263/,How can semi-automated extraction of norms and their elements be achieved to populate legal ontologies using a combination of general-purpose NLP modules and domain-specific rules?
https://aclanthology.org/2020.lrec-1.263/,Can automated information extraction techniques be used to reduce the resource consumption bottleneck in creating specialist knowledge management systems for legal information and compliance?
https://aclanthology.org/2020.lrec-1.264/,"What are the modifications made to the existing spatial expression recognition specifications to adapt them to the Polish language, and how do these modifications affect the annotation process for the PST 2.0 corpus?"
https://aclanthology.org/2020.lrec-1.264/,Can the annotated PST 2.0 corpus be used to train and test spatial expression recognition tools to achieve high accuracy in recognizing spatial expressions in Polish texts?
https://aclanthology.org/2020.lrec-1.265/,"Can a deep learning approach using a transformer-based architecture be used to improve the accuracy of natural premise selection in mathematical text, as measured by the number of correctly identified supporting definitions and propositions? Can the use of a multimodal approach combining natural language processing and symbolic reasoning techniques enhance the effectiveness of natural premise selection in generating informal mathematical proofs?"
https://aclanthology.org/2020.lrec-1.266/,"Can Odinson improve the efficiency of information extraction by reducing the time complexity of pattern matching, and how does indexing with Lucene impact the overall performance of the framework? Can Odinson's query language be adapted to incorporate additional data structures, such as dependency parse trees, to further improve pattern matching accuracy?"
https://aclanthology.org/2020.lrec-1.267/,Can the STEM-ECR v1.0 dataset effectively serve as a benchmark for evaluating the performance of BERT-based neural models in extracting multidisciplinary scientific entities from a domain-independent fashion?
https://aclanthology.org/2020.lrec-1.267/,Can the proposed 3-step entity resolution procedure using encyclopedic entity linking and lexicographic word sense disambiguation improve human annotation accuracy for scientific entities in the STEM-ECR v1.0 dataset?
https://aclanthology.org/2020.lrec-1.268/,"What is the effectiveness of the proposed rule-based approach in extracting LaTeX representations of formula identifiers and linking them to their in-text descriptions, as measured by precision and recall, when applied to the proposed evaluation dataset?"
https://aclanthology.org/2020.lrec-1.268/,Can a rule-based approach using the provided tool be able to accurately segment mathematical formulae into identifiers and link them to their descriptions for a variety of mathematical documents?
https://aclanthology.org/2020.lrec-1.269/,Does the proposed system achieve higher F-score results when using distant supervision for relation extraction compared to a discrete feature based machine learning model? Can the proposed system improve reading comprehension by automatically generating questions based on the extracted relations from pedagogically motivated relation types?
https://aclanthology.org/2020.lrec-1.270/,"Can the proposed THEE-TimeML annotation standard improve the accuracy of event-based surveillance systems in the public health domain by reducing the reliance on coarse document metadata and enabling more precise time extraction? Does the development of TIE systems utilizing THEE-TimeML and TheeBank corpus improve the accuracy of estimated case outbreak times in news articles, as measured by evaluation metrics such as F1-score or mean absolute error?"
https://aclanthology.org/2020.lrec-1.271/,Can a machine learning model using citation type knowledge outperform a model relying solely on author publication history in recommending recently published papers to a specific user?
https://aclanthology.org/2020.lrec-1.271/,"Can the addition of citation positions and contexts enhance the accuracy of paper recommendations based on citation knowledge, and how does this compare to traditional approaches relying solely on citation counts?"
https://aclanthology.org/2020.lrec-1.272/,"Can a deep learning-based model achieve high accuracy in event extraction for Hindi language, using a dataset of over 1700 disaster-related news articles as a benchmark?"
https://aclanthology.org/2020.lrec-1.272/,"Does the proposed event extraction framework for Hindi language enable effective event trigger detection, argument detection, and event-argument linking, as demonstrated by the development of models that surpass existing English benchmarks?"
https://aclanthology.org/2020.lrec-1.273/,"What are the key aspects of the proposed Rad-SpatialNet framework that enable accurate spatial language representation in radiology, and how do these aspects contribute to the overall performance of BERT-based models in extracting spatial trigger terms and frame elements?"
https://aclanthology.org/2020.lrec-1.273/,Can BERT-based models achieve significant improvements in spatial trigger extraction and frame element identification using the proposed Rad-SpatialNet framework and annotated corpus compared to existing NLP methods in radiology text?
https://aclanthology.org/2020.lrec-1.274/,"What are the effectiveness and efficiency of the proposed ""DoRe"" corpus in improving the semantic processing and understanding of French text in finance, regulation, and investment applications, specifically in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.274/,"Can the use of the ""DoRe"" corpus in NLP analytics be adapted to other languages and domains, such as accounting and tax, by leveraging its modular design and scalable structure?"
https://aclanthology.org/2020.lrec-1.275/,Can EEG signal annotations be developed using a self-attention joint-learning approach to predict clinically relevant concepts and their correlations with brain pathologies in EEG reports?
https://aclanthology.org/2020.lrec-1.275/,Can the proposed annotation schema for brain signal attributes be applied to improve the accuracy of EEG report annotations and inform the design of novel knowledge capture techniques?
https://aclanthology.org/2020.lrec-1.276/,"Can AI systems use transformers to improve their performance on tasks requiring complex reasoning and natural language understanding in knowledge bases, and what are the key factors that influence their ability to achieve high scores on such tasks? Can AI systems learn to write essays in a style similar to human writers, and what are the key features of their generated texts that distinguish them from human-written essays?"
https://aclanthology.org/2020.lrec-1.277/,"Can the application of Word2vec filtering in conjunction with Cooc lead to improved ontology creation accuracy compared to OpenIE, and how does the objective F1-score compare to the subjective human assessment of these methods? Can the filtering methods based on keywords and Word2vec improve the extraction of relevant entities and relations from a set of domain documents, and how does this approach compare to the results obtained with Cooc and OpenIE?"
https://aclanthology.org/2020.lrec-1.278/,"Can the proposed ontology improve the accuracy of named entity recognition models in detecting money laundering and financing of terrorism in financial news articles, measured by precision and recall metrics? Can the annotated corpus be used to train a machine learning model that extracts relevant financial relations between entities in French financial news articles, evaluated by F1 score and processing time?"
https://aclanthology.org/2020.lrec-1.279/,Can unsupervised methods be developed to improve the efficiency of lexical semantic resource building by reducing the need for human supervision in the inference process?
https://aclanthology.org/2020.lrec-1.279/,Can the use of hybrid approaches combining multiple inference techniques enhance the accuracy of lexical semantic resources in multilingual settings?
https://aclanthology.org/2020.lrec-1.280/,"Can a machine learning approach using Japanese personality dictionary and driving experience corpus be used to extract meaningful collocations between personality descriptors and driving behavior from a driving behavior and subjectivity corpus, and how can these collocations be evaluated as social knowledge through crowdsourcing tasks?"
https://aclanthology.org/2020.lrec-1.280/,"Can the use of crowdsourcing tasks to validate and refine the extracted social knowledge from the driving behavior and subjectivity corpus lead to more accurate and reliable results, and what are the implications of these findings for implementing social knowledge into driving systems?"
https://aclanthology.org/2020.lrec-1.281/,Can a deep learning model using a transformer-based architecture be trained to accurately identify and extract implied information in argumentative texts by leveraging high-quality human annotations of missing and implied information?
https://aclanthology.org/2020.lrec-1.281/,"Can the characteristics of argumentative texts and the added information, including semantic clause types and commonsense knowledge relations, be effectively used to develop a dataset that reveals interesting patterns and intersections between annotation categories and properties of argumentative texts?"
https://aclanthology.org/2020.lrec-1.282/,"How can MKGDB's large hypernymy graph be effectively utilized to improve the performance of information extraction tasks, such as named entity recognition and part-of-speech tagging, in open-domain natural language processing applications?"
https://aclanthology.org/2020.lrec-1.282/,"Can the integration of multiple taxonomy backbones in MKGDB enhance the accuracy of hypernymy discovery and topic clustering tasks, and if so, what are the key factors contributing to this improvement?"
https://aclanthology.org/2020.lrec-1.283/,"Can a workflow manager utilizing Natural Language Processing and Content Curation services effectively improve the accuracy of legal document analysis and processing, as measured by the reduction in processing time and increase in syntactic correctness? Can a Multilingual Legal Knowledge Graph with semantic information and meaningful references to legal documents improve the efficiency of workflow orchestration and user satisfaction in legal applications?"
https://aclanthology.org/2020.lrec-1.284/,"How can an iterative methodology using an existing state of the art algorithm improve the extraction of application-specific taxonomies from Wikipedia knowledge graphs, specifically in the medical domain?"
https://aclanthology.org/2020.lrec-1.284/,What evaluation metrics can be used to comparatively assess the quality of noisy automatically extracted taxonomies from the proposed gold standard dataset?
https://aclanthology.org/2020.lrec-1.285/,"What is the impact of lexical complexity and grammatical complexity on the overall difficulty of comprehension of audiovisual documents, and how do these factors compare to the impact of speech intelligibility and modality on comprehension difficulty?"
https://aclanthology.org/2020.lrec-1.285/,"How can the use of multimodal documents (text, audio, video) affect the difficulty of comprehension, and what is the relative contribution of each modality to overall comprehensibility?"
https://aclanthology.org/2020.lrec-1.286/,"Can machine learning models be used to improve the detection of multiword term variation in terminological resources, and if so, what features should be considered to develop a robust system for term selection and description in multilingual terminological knowledge bases?"
https://aclanthology.org/2020.lrec-1.286/,"Can the use of deep learning architectures for text representation, such as transformer-based models, enhance the accuracy of term translation and reduction in parallel corpora and terminological resources for environment-related concepts?"
https://aclanthology.org/2020.lrec-1.287/,How can a spatial model leveraging both textual and visual information improve the accuracy of implicit spatial relation prediction in images compared to powerful language models?
https://aclanthology.org/2020.lrec-1.287/,"Can a hybrid model combining object positional and size information with image embeddings enhance the ability to infer spatial relations between entities in images, particularly in cases with unseen subjects, objects, and relations?"
https://aclanthology.org/2020.lrec-1.288/,How do the information coverage and depth of topics in English Wikipedia compare to those in Wikipedias in other widely spoken languages?
https://aclanthology.org/2020.lrec-1.288/,"Can Wikipedias in different languages provide similar depth of coverage of topics as English Wikipedia, or are there significant gaps in information coverage?"
https://aclanthology.org/2020.lrec-1.289/,"Can the digitization of a historical corpus of propaganda texts using natural language processing techniques improve the accuracy of sentiment analysis models, and how can the Pártélet corpus be used to analyze changes in language use over time? Can the text classification algorithms used to categorize the propaganda texts in the Pártélet corpus be compared to those used in modern social media text classification tasks?"
https://aclanthology.org/2020.lrec-1.290/,"Can the use of knowledge graphs improve the performance of named entity recognition and disambiguation systems, as evaluated by the F1-score, and how does this hold for different types of knowledge graphs, such as DBpedia, YAGO, and Wikidata?"
https://aclanthology.org/2020.lrec-1.290/,"Does the use of a unified gold standard dataset, such as KORE 50ˆDYWC, facilitate the evaluation of named entity recognition and disambiguation systems across multiple knowledge graphs, and what are the implications for the field of natural language processing?"
https://aclanthology.org/2020.lrec-1.291/,"Can Eye4Ref's multimodal dataset be used to investigate the relationship between eye movements and the processing of referential expressions in a way that takes into account the complex interplay between linguistic and visual cues? Can the dataset's alignment of eye-tracking data, language, and visual environment be leveraged to improve the accuracy of computer vision-based models for understanding human referential communication?"
https://aclanthology.org/2020.lrec-1.292/,What is the impact of customized self-supervised tasks on the performance of pre-trained Chinese models for Chinese query-passage pairs NLP tasks?
https://aclanthology.org/2020.lrec-1.292/,Can pre-training with Sentence Insertion improve the semantic information capturing ability of Chinese Pre-trained models for tasks like answer span prediction and retrieval question answering?
https://aclanthology.org/2020.lrec-1.293/,"Can the Dakshina dataset be effectively used to improve the performance of machine translation models for South Asian languages by leveraging its native script and romanization data, measured by the accuracy of transliteration tasks? Can the Dakshina dataset be used to develop and evaluate the performance of language models trained on native script data, compared to those trained on romanized text, as measured by the perplexity of language modeling tasks?"
https://aclanthology.org/2020.lrec-1.294/,Can the proposed GM-RKB WikiText Error Correction Task effectively utilize a word-level spell checker to improve the performance of supervised error correction models in detecting and correcting typographical errors in WikiText annotated pages?
https://aclanthology.org/2020.lrec-1.294/,Can the seq2seq neural network architecture significantly outperform a maximum likelihood character-level language model in correcting typographical errors in the GM-RKB domain-specific semantic wiki corpus?
https://aclanthology.org/2020.lrec-1.295/,"Can the CCA measure effectively capture domain similarity in monolingual settings by comparing the dimension-wise correlations between pre-trained word embeddings across different languages, and can it be used to determine the similarity between corpora in a cross-domain sentiment detection task? Can the CCA measure be used to identify a threshold for determining whether two corpora belong to the same domain in a cross-lingual setting by applying permutation tests?"
https://aclanthology.org/2020.lrec-1.296/,"Can the proposed multilingual language model achieve state-of-the-art results on monolingual language modeling for languages with limited training data, and how can the fixed vocabulary size of the multilingual model impact its performance on different languages?"
https://aclanthology.org/2020.lrec-1.297/,What is the effect of corpus composition on the core lexicon estimation in language models pre-trained on different Web-derived corpora?
https://aclanthology.org/2020.lrec-1.297/,How can unsupervised topic models and supervised genre classification be used to evaluate the composition and topicality of Web pages in digital curation of corpora?
https://aclanthology.org/2020.lrec-1.298/,"What is the most effective method for personalizing a language model using a small amount of user-specific text, measured by perplexity and next word prediction performance on smartphone keyboards?"
https://aclanthology.org/2020.lrec-1.298/,"How does the choice of method for personalizing a language model impact its performance when a larger amount of user-specific text is available, compared to when only a small amount of text is available?"
https://aclanthology.org/2020.lrec-1.299/,Can we design a more efficient LSTM model for Russian speech recognition that combines word frequency and linguistic information to improve training time and accuracy without compromising the WER?
https://aclanthology.org/2020.lrec-1.299/,Can the use of class-based LSTM models with linguistic information data outperform word-based models in terms of perplexity and recognition accuracy for continuous Russian speech recognition?
https://aclanthology.org/2020.lrec-1.300/,Can AfriBERT achieve state-of-the-art performance in part-of-speech tagging on Afrikaans text compared to multilingual BERT?
https://aclanthology.org/2020.lrec-1.300/,Does transfer learning from multilingual BERT to AfriBERT improve the accuracy of downstream tasks such as named-entity recognition and dependency parsing?
https://aclanthology.org/2020.lrec-1.301/,"What are the key differences in the performance of FlauBERT models of different sizes when applied to diverse NLP tasks, and how do these differences impact the accuracy of downstream tasks?"
https://aclanthology.org/2020.lrec-1.301/,"Can the use of a unified evaluation protocol for French NLP tasks, such as FLUE, provide a reliable benchmark for assessing the performance of pre-trained language models like FlauBERT?"
https://aclanthology.org/2020.lrec-1.302/,Can efficient implementations of Brown clustering and Exchange clustering be developed to leverage parallel computation and improve the applicability of hierarchical clustering in NLP tasks?
https://aclanthology.org/2020.lrec-1.302/,Does the acceleration of Brown clustering using parallel computation and efficient algorithms lead to clusters that outperform or match the performance of clusters computed using the original methods in NLP applications?
https://aclanthology.org/2020.lrec-1.303/,"What are the effects of rhythm and speech rate on the intelligibility of non-native French speakers and Japanese learners of French, measured by log-likelihood and compared to native speakers?"
https://aclanthology.org/2020.lrec-1.303/,"How do the variability of intersyllabic timing and phonation ratio affect the intelligibility of non-native speakers, specifically Japanese learners, and what is the significance of these factors in comparison to native speakers?"
https://aclanthology.org/2020.lrec-1.304/,"Can an automated conversion tool be developed to convert existing ontological information into the standard Terminology Base eXchange (TBX) format, improving the interoperability of terminologies in the archaeological domain?"
https://aclanthology.org/2020.lrec-1.304/,Can the introduction of semantic enrichment into the TBX format enhance the usability and effectiveness of terminological resources in Computer-Aided Translation tools and multilingual information retrieval systems?
https://aclanthology.org/2020.lrec-1.305/,"Can machine learning models trained on the extended Berkeley FrameNet be used to improve the accuracy of fact-checking tasks, and what evaluation metric would be most suitable to measure this improvement?"
https://aclanthology.org/2020.lrec-1.305/,"Can the provided annotated sentences be used to train a supervised learning model to predict the relevance of factual claims to the extended FrameNet frames, and what type of features would be most useful for this task?"
https://aclanthology.org/2020.lrec-1.306/,"Can bi-directional LSTM models achieve higher accuracy when training on a vocabulary of 1.3 million words derived from a combination of transcribed and oral stories, compared to training solely on transcribed texts?"
https://aclanthology.org/2020.lrec-1.306/,Can the use of word boundary markers on subword sequences improve the performance of deep neural networks in detecting word boundaries in polysynthetic languages like Inuktitut?
https://aclanthology.org/2020.lrec-1.307/,Can the use of country-level population demographics to construct gigaword web corpora improve the representation of under-resourced language varieties in natural language processing tasks?
https://aclanthology.org/2020.lrec-1.307/,Does the development of corpus-aligned word embeddings using country-level population demographics enhance the accuracy of language models trained on these corpora in terms of phonetic and phonological diversity?
https://aclanthology.org/2020.lrec-1.308/,"Can machine translation be used to augment fake news detection datasets for languages with limited annotated data, and does the improvement in machine translation quality for the English-Urdu language pair impact the effectiveness of fake news detection in Urdu?"
https://aclanthology.org/2020.lrec-1.308/,Can supervised machine learning be replaced by machine translation for creating and augmenting annotated corpora for fake news detection in languages with limited annotated data?
https://aclanthology.org/2020.lrec-1.309/,"Does the proposed method of creating Greek word embeddings by incorporating linguistic aspects of the Greek language improve the accuracy of word similarity measurements compared to existing English-based methods, and can the quality of word embeddings be further improved by accounting for morphological complexity and polysemy of the Greek language?"
https://aclanthology.org/2020.lrec-1.310/,"Can we develop an algorithm to predict the missing symbols in damaged Mycenaean inscriptions based on the patterns observed in the entire dataset, and how accurate will it be in terms of estimating the correct sequence?"
https://aclanthology.org/2020.lrec-1.310/,"Can the use of machine learning models trained on the Mycenaean Linear B dataset improve the deciphering of damaged inscriptions compared to traditional methods, and what is the average processing time for such models?"
https://aclanthology.org/2020.lrec-1.311/,Can the proposed Inuktitut-English sentence-aligned corpus improve the accuracy of Inuktitut-English machine translation models by providing a large and diverse dataset for training and testing?
https://aclanthology.org/2020.lrec-1.311/,Can the use of this corpus facilitate the development of more effective statistical and neural machine translation models for Inuktitut-English translation in both directions?
https://aclanthology.org/2020.lrec-1.312/,"Can bilingual word embeddings be trained to achieve competitive results on low-resource language pairs with a minimum corpus size of 300K words, and how does the size of the seed lexicon impact the performance of these embeddings?"
https://aclanthology.org/2020.lrec-1.312/,Can the development of bilingual word embeddings for low-resource languages with limited training data be improved by using a smaller seed lexicon and varying the size of the comparable corpus?
https://aclanthology.org/2020.lrec-1.313/,"Can a morphological analyser implemented using the Helsinki Finite-State Transducer toolkit (HFST) and the lexc formalism achieve high accuracy in processing Evenki texts, measured by the F-score, when compared to existing analysers that achieve less than half coverage of the available Evenki corpora?"
https://aclanthology.org/2020.lrec-1.313/,"Can the development of a morphological analyser for Evenki using the Helsinki Finite-State Transducer toolkit (HFST) and the lexc formalism improve the processing of dialectal features, resulting in higher coverage scores on corpora containing texts in Evenki dialects?"
https://aclanthology.org/2020.lrec-1.314/,"Can a tailored neural word embedding model trained on Amharic data outperform off-the-shelf baselines in word analogy tasks, as measured by accuracy, and can it generalize to Arabic language with comparable performance?"
https://aclanthology.org/2020.lrec-1.314/,"Does the use of morphological preprocessing steps in word embedding construction improve the model's performance on word analogy tasks in Amharic, as indicated by a significant reduction in processing time and improved semantic similarity scores?"
https://aclanthology.org/2020.lrec-1.315/,"Can a transfer learning approach using a transformer-based architecture be trained to detect fake news in Filipino with 96% accuracy, and can it generalize well to different types of news articles? Can the use of auxiliary language modeling losses improve the performance of a transfer learning-based fake news classifier on a low-resource language like Filipino?"
https://aclanthology.org/2020.lrec-1.316/,Can a deep learning-based approach with a Linear Chain CRF and self-attention mechanism improve the accuracy of speech segmentation for neuropsychological language tests in diagnosing cognitive impairments?
https://aclanthology.org/2020.lrec-1.316/,Can a quasi-recurrent neural network layer outperform traditional LSTM layers in segmenting impaired speech transcriptions for narrative analysis?
https://aclanthology.org/2020.lrec-1.317/,"Can neural machine translation models achieve high accuracy in translating Jejueo language using large-scale parallel corpus, and how does the quality of the translation impact the overall user experience of Jejueo language?"
https://aclanthology.org/2020.lrec-1.317/,"Can a deep learning-based speech synthesis model improve the quality of Jejueo single speaker speech recordings, and how does it compare to existing speech synthesis models in terms of processing time?"
https://aclanthology.org/2020.lrec-1.318/,"What is the optimal modeling unit for Ainu language recognition in terms of accuracy and processing time, and how does multilingual training with additional English and Japanese corpora affect the performance of the end-to-end ASR model in speaker-open and speaker-closed settings?"
https://aclanthology.org/2020.lrec-1.318/,"How can the development of annotated language archives for the Ainu language be improved through the use of automatic speech recognition and machine learning techniques, particularly in terms of transcription accuracy and efficiency?"
https://aclanthology.org/2020.lrec-1.319/,Is the development of a Guarani - Spanish parallel corpus with sentence-level alignment a feasible approach to improve the translation accuracy of machine translation models trained on this corpus?
https://aclanthology.org/2020.lrec-1.319/,Can the use of a semi-automatic process to align the Guarani and Spanish sentences in the corpus significantly impact the processing time of machine learning algorithms for text classification tasks?
https://aclanthology.org/2020.lrec-1.320/,Can an unsupervised corpus-based approach using COALS algorithm and summation vector model effectively evaluate the similarity between teacher and student answers in Arabic language for automatic short answer grading?
https://aclanthology.org/2020.lrec-1.320/,"Can the use of Arabic Dataset for automatic short answer grading, with variations in file formats, impact the accuracy of the grading model's performance in evaluating student answers?"
https://aclanthology.org/2020.lrec-1.321/,"Can a machine learning model using manually created lexical analysis and rich annotation be used to generate effective communication boards for under-resourced languages like Dolgan, measured by user satisfaction and AAC system usability? Can the use of standard formats for AAC communication boards facilitate their applicability to various languages and settings, such as multilingual hospitals or diverse user groups?"
https://aclanthology.org/2020.lrec-1.322/,What are the effects of using a Transformer-based architecture on the syntactic correctness of Nisvai narratives when compared to a rule-based approach in machine translation from Nisvai to French?
https://aclanthology.org/2020.lrec-1.322/,Can the development of a corpus of annotated Nisvai narratives improve the accuracy of Nisvai-French lexicalization and enable more effective language documentation for the Nisvai community?
https://aclanthology.org/2020.lrec-1.323/,"How do the standardized formats and conventions in the DoReCo project improve the accessibility of audio recordings for linguistic research, specifically in terms of the processing time required to transcribe and analyze the data?"
https://aclanthology.org/2020.lrec-1.323/,Can the use of segmental alignments with WebMAUS enhance the accuracy of time-aligned transcriptions in the DoReCo project for under-resourced languages?
https://aclanthology.org/2020.lrec-1.324/,"Can statistical machine translation systems be improved by incorporating additional data sources, such as user-generated dictionaries, to enhance performance on low-resource languages like Somali and Swahili?"
https://aclanthology.org/2020.lrec-1.324/,Can neural machine translation systems achieve better performance on low-resource languages by leveraging large-scale web-based bilingual text and careful tuning of model parameters?
https://aclanthology.org/2020.lrec-1.325/,What is the impact of incorporating Paradigm Function Morphology (PFM) theory on the accuracy of a finite-state morphological analyzer for St. Lawrence Island Yupik language?
https://aclanthology.org/2020.lrec-1.325/,How does the re-implementation of a finite-state morphological analyzer using PFM theory compare to the original implementation in terms of coverage rate across different datasets?
https://aclanthology.org/2020.lrec-1.326/,"Can the proposed Character-Based Statistical Machine Translation approach be improved for better handling of phonetic evolution in Zamboanga Chabacano, and can it be combined with other spell checking technologies to achieve higher accuracy in correcting spelling errors in ZC?"
https://aclanthology.org/2020.lrec-1.326/,Can the proposed ontology for a spelling error taxonomy in Zamboanga Chabacano be used to develop a more accurate and user-friendly spell checking system for this variety of language?
https://aclanthology.org/2020.lrec-1.327/,Can a Convolutional Neural Network (CNN) model achieve higher accuracy in sentiment analysis for Algerian language than traditional machine learning algorithms when trained on a large corpus of code-switched user-generated comments?
https://aclanthology.org/2020.lrec-1.327/,"Does the integration of sentiment lexicons into a CNN model improve its performance on minority sentiment classes, and if so, what is the expected gain in F-score when injecting these lexicons as background knowledge?"
https://aclanthology.org/2020.lrec-1.328/,"What is the most effective way to use web scraping to generate large text corpora in low-resource languages, and how can the SwissCrawl corpus be adapted for use in multilingual NLP tasks?"
https://aclanthology.org/2020.lrec-1.328/,"Can machine learning algorithms trained on the SwissCrawl corpus achieve comparable language modeling performance to state-of-the-art models trained on larger, more established corpora?"
https://aclanthology.org/2020.lrec-1.329/,Can sub-word embeddings be used to create cross-lingual word embeddings that effectively handle out-of-vocabulary words in low-resource languages?
https://aclanthology.org/2020.lrec-1.329/,Can sub-word embeddings be used to form cross-lingual embeddings for OOV words in language pairs covering several language families?
https://aclanthology.org/2020.lrec-1.330/,Can a transformer-based phoneme to grapheme model trained on a Swiss German-High German dictionary with phonetic transcriptions be able to accurately generate novel Swiss German writings with high fidelity?
https://aclanthology.org/2020.lrec-1.330/,Can the inverse mapping from graphemes to phonemes using a transformer trained on the same dictionary achieve state-of-the-art performance in phonetic transcription of previously unknown Swiss German words?
https://aclanthology.org/2020.lrec-1.331/,Can the Banque de Données Langue Corse project improve the availability of resources and tools for the Corsican language by developing a consultation interface (concordancer) and a language detection tool?
https://aclanthology.org/2020.lrec-1.331/,Can the development of a part-of-speech tagger and an electronic dictionary enhance the completeness of the Corsican language Basic Language Ressource Kit (BLARK)?
https://aclanthology.org/2020.lrec-1.332/,What is the impact of incorporating sub-word information on the performance of RNN language models in Mi'kmaq language modelling?
https://aclanthology.org/2020.lrec-1.332/,How effective are cross-lingual word embeddings in improving the performance of language models for low-resource languages like Mi'kmaq?
https://aclanthology.org/2020.lrec-1.333/,"How can the use of word2vec and Linguistica tools improve the processing and representation of Choctaw language in a multimodal corpus, and what are the implications for language preservation and revitalization efforts?"
https://aclanthology.org/2020.lrec-1.333/,Can the implementation of word2vec and Linguistica on a small corpus of Choctaw texts lead to accurate and meaningful language representations that can inform the development of effective language learning tools and materials?
https://aclanthology.org/2020.lrec-1.334/,Can deep learning architectures learn effective word embeddings for low-resourced languages using unannotated texts from online multilingual resources?
https://aclanthology.org/2020.lrec-1.334/,Can the quality of word embeddings improve when using curated corpora and language-dependent processing for low-resourced languages?
https://aclanthology.org/2020.lrec-1.335/,"Is it possible to leverage machine learning algorithms to improve the annotation accuracy of Turkish PropBank v2.0, measured by the F1-score, and if so, what is the optimal model architecture for this task? Can the use of transfer learning from English PropBank v1.0 improve the annotation efficiency of Turkish PropBank v2.0, as measured by the processing time, and how does the use of transfer learning affect the annotation accuracy?"
https://aclanthology.org/2020.lrec-1.336/,What is the potential for machine translation systems to improve the consistency of law terminology using the Romanian legislative corpus and how will this impact the quality of translations for under-resourced languages?
https://aclanthology.org/2020.lrec-1.336/,How can the annotated documents in the Romanian legislative corpus be used to train and evaluate supervised classification models for law terminology extraction and classification?
https://aclanthology.org/2020.lrec-1.337/,"What are the most common annotation conventions used in endangered language corpora, and how do they compare to existing formats like ELAN and Toolbox in terms of data standardization?"
https://aclanthology.org/2020.lrec-1.337/,Can transcription and aligned translation tiers be used as a benchmark for evaluating the effectiveness of morpheme-by-morpheme glosses and named references in language documentation projects?
https://aclanthology.org/2020.lrec-1.338/,"Can a supervised learning approach using the proposed affective words from the annotated corpus improve the accuracy of Odia sentiment analysis compared to the existing sentiment lexicon, and can the proposed approach handle out-of-vocabulary words in the target language?"
https://aclanthology.org/2020.lrec-1.338/,"Can the proposed corpus of annotated Odia sentences be used to train a machine learning model to classify sentiment in news articles from the Odia language, and what is the effect of using this model on the accuracy of sentiment analysis in this domain?"
https://aclanthology.org/2020.lrec-1.339/,What is the effectiveness of using Basque projected data in conjunction with rich-resource languages data for intent classification in task-oriented dialog systems?
https://aclanthology.org/2020.lrec-1.339/,How do the accuracies of slot filling tasks compare when models are trained exclusively on Basque projected data versus combined Basque projected and rich-resource languages data?
https://aclanthology.org/2020.lrec-1.340/,What is the most effective method for aligning parallel sentences in the French-Wolof corpus to ensure accurate machine translation results?
https://aclanthology.org/2020.lrec-1.340/,How can the existing corpus be used to improve the performance of neural machine translation models for translating French to Wolof?
https://aclanthology.org/2020.lrec-1.341/,Can the proposed wordnet for Scottish Gaelic be used to improve the accuracy of natural language processing tasks such as sentiment analysis and machine translation for this minority language?
https://aclanthology.org/2020.lrec-1.341/,Does the integration of the new wordnet with existing natural language processing models and tools enhance the overall performance in tasks requiring linguistic knowledge of Scottish Gaelic?
https://aclanthology.org/2020.lrec-1.342/,"Is it possible to design a low-cost, user-friendly platform for collecting labelled speech data from low-income communities, and what are the potential benefits and challenges of using crowdsourced speech data in machine learning models? Can machine learning models trained on crowdsourced speech data from low-income communities achieve comparable performance to those trained on traditional data from university students?"
https://aclanthology.org/2020.lrec-1.343/,Can morphological analysis using the UniMorph schema improve the accuracy of lemmatization in San Juan Quiahije Chatino language?
https://aclanthology.org/2020.lrec-1.343/,Can the morphological inflection tables of 198 lemmata contribute to the development of more accurate NLP models for tonal mesoamerican languages?
https://aclanthology.org/2020.lrec-1.344/,"What is the most effective method for collecting data for low-resource languages using technology-driven methods, and how can these methods be adapted for large-scale data collection in tribal languages like Gondi?"
https://aclanthology.org/2020.lrec-1.344/,"Can linguistic resources such as dictionaries and children's stories contribute to the revival of a low-resource language like Gondi, and what impact can they have on community members' awareness and engagement with the language?"
https://aclanthology.org/2020.lrec-1.345/,"Can a bidirectional LSTM network with attention mechanism outperform the state-of-the-art method on Persian language text data in detecting irony, as measured by accuracy, and what is the effect of using emoji prediction in pretraining the model on its performance?"
https://aclanthology.org/2020.lrec-1.346/,Can the computational resource grammars for Runyankore and Rukiga languages be used to improve the accuracy of Natural Language Processing tasks for under-resourced languages?
https://aclanthology.org/2020.lrec-1.346/,"Can a data-driven approach using the computational resource grammars be used to generate multilingual corpora for R&R languages, and what is the expected impact on language learning outcomes?"
https://aclanthology.org/2020.lrec-1.347/,Can LDA sampling improve the efficiency of sentiment analysis in Persian language using MirasOpinion dataset compared to other active learning strategies in terms of the amount of labeled data required to achieve the baseline performance of the model?
https://aclanthology.org/2020.lrec-1.347/,Can LDA sampling achieve competitive performance in sentiment analysis of Persian language using MirasOpinion dataset in comparison with other active learning approaches?
https://aclanthology.org/2020.lrec-1.348/,"What are the linguistic features that can be extracted from Bangla text data to effectively identify fake news, and how do they compare to traditional methods in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.348/,"Can neural network-based methods be used to effectively detect Bangla fake news with a dataset of approximately 50K annotated examples, and what are the key factors that influence their performance in this language?"
https://aclanthology.org/2020.lrec-1.349/,"Can machine learning models achieve high accuracy in speech recognition for Mapudungun, given the polysynthetic nature of the language and its potential for code-switching, and how does this compare to existing speech recognition systems?"
https://aclanthology.org/2020.lrec-1.349/,How do linguistic features and annotations provided in the corpus influence the performance of machine translation models from Spanish to Mapudungun?
https://aclanthology.org/2020.lrec-1.350/,"Can an automated system be trained to accurately parse interlinear glossed text from scanned page images with a precision and recall of at least 0.95, and what are the key challenges that hinder the development of such a system?"
https://aclanthology.org/2020.lrec-1.350/,"Can the proposed technology be applied to improve the accessibility of linguistic data for less-resourced and endangered languages, and what are the potential benefits and limitations of using this technology for such purposes?"
https://aclanthology.org/2020.lrec-1.351/,"Can the proposed multilingual corpus, Johns Hopkins University Bible Corpus (JHUBC), be used to investigate the relationship between linguistic features and their representation across languages, and what typological features are most underrepresented in the corpus?"
https://aclanthology.org/2020.lrec-1.351/,"Can the proposed multilingual corpus, Johns Hopkins University Bible Corpus (JHUBC), be used to develop a machine learning model that can accurately project pronoun features like clusivity across languages that do not mark the distinction?"
https://aclanthology.org/2020.lrec-1.352/,Can ASR4LD be improved to achieve higher performance in phoneme recognition for endangered languages with varying phonetic characteristics compared to European languages?
https://aclanthology.org/2020.lrec-1.352/,Can the recording mismatch issue in ASR4LD be addressed by incorporating domain-specific acoustic models for the target languages being documented?
https://aclanthology.org/2020.lrec-1.353/,Can a hybrid approach combining machine learning and rule-based methods be evaluated for its effectiveness in analyzing and documenting lesser-resourced languages in a way that maximizes vocabulary unification while maintaining openness to future resource integration? Does the use of a graph-based data structure to represent linguistic relationships facilitate the discovery of new linguistic patterns and improve the accuracy of language documentation?
https://aclanthology.org/2020.lrec-1.354/,Can speech recognition algorithms be improved for spoken Hong Kong Cantonese by leveraging the corpus's phonemic transcription and Chinese characters transcription features?
https://aclanthology.org/2020.lrec-1.354/,"Can the use of controlled elicitation tasks, similar to the HCRC MapTask corpus, enhance the accuracy of phonology and semantics analysis of Cantonese language?"
https://aclanthology.org/2020.lrec-1.355/,"Can machine learning models be trained to accurately process and extract text from educational PDF files of endangered languages, such as Shipibo-konibo, Ashaninka, Yanesha and Yine, with minimal human intervention?"
https://aclanthology.org/2020.lrec-1.355/,Can the proposed method for creating monolingual corpora for low-resource languages be evaluated using language modelling and character-level perplexity metrics to assess its effectiveness in noisy pages and low-structured content?
https://aclanthology.org/2020.lrec-1.356/,"Can the proposed parallel Icelandic dependency treebank based on Universal Dependencies improve the accuracy of Icelandic language processing tasks, such as machine translation and named entity recognition, compared to existing resources? Does the use of freely available tools and resources facilitate the creation of a high-quality, small dependency treebank from scratch for Icelandic?"
https://aclanthology.org/2020.lrec-1.357/,Can the application of the Universal Dependencies framework in conjunction with agile annotation and pre-processing tools improve the efficiency and accuracy of Occitan language treebank creation? Does the use of delexicalized cross-lingual parsing approach enhance the annotation quality of the Occitan language corpus?
https://aclanthology.org/2020.lrec-1.358/,"Is the 'expansion' approach to building wordnets feasible for creating high-quality, human-curated lexical resources in languages with limited digital content?"
https://aclanthology.org/2020.lrec-1.358/,Can the use of Princeton Wordnet's core synsets and scientific names improve the semantic hierarchy of the Old Javanese Wordnet and enhance its linguistic research applications?
https://aclanthology.org/2020.lrec-1.359/,"Can machine learning algorithms be used to develop a model that can accurately detect and transcribe indigenous languages spoken in Mexico, and if so, what would be the optimal approach for handling dialectal and orthographic variations?"
https://aclanthology.org/2020.lrec-1.359/,"Can the CPLM corpus be used to analyze and compare the linguistic features of the six aligned languages, and if so, what evaluation metrics would be most suitable for assessing the effectiveness of the corpus in detecting linguistic phenomena in low-resourced languages?"
https://aclanthology.org/2020.lrec-1.360/,Can a supervised machine learning approach using a bi-directional long-short term memory (Bi-LSTM) model improve the accuracy of named entity recognition in Sindhi language compared to a conditional random field (CRF) model?
https://aclanthology.org/2020.lrec-1.360/,Can the use of character-level representations enhance the performance of a bi-directional long-short term memory (Bi-LSTM) model for named entity recognition in Sindhi language compared to a CRF model?
https://aclanthology.org/2020.lrec-1.361/,"Can the proposed lexicon improve the accuracy of AMR event extraction by reducing the number of aligned senses per frame, and how does this impact the performance of word sense disambiguation tasks on Chinese text? Can the proposed lexicon be used to develop a more accurate semantic role labeling model for Chinese sentences using a supervised learning approach?"
https://aclanthology.org/2020.lrec-1.362/,"How do multi-lingual and bilingual Multi-word expressions (MWEs) extracted from root parallel corpora impact the performance of Machine Translation (MT) systems on different language pairs, and what are the specific evaluation metrics used to measure this impact?"
https://aclanthology.org/2020.lrec-1.362/,"Can the extraction of high-quality bilingual MWEs from large parallel corpora improve the generalization performance of MT models on unseen language pairs, and if so, what are the key factors influencing this improvement?"
https://aclanthology.org/2020.lrec-1.363/,"Can a machine learning model trained on a large dataset of Myanmar-English transliteration instances achieve high accuracy in transliterating English words borrowed in the Myanmar language, as measured by the BLEU score, and how does the choice of processing unit affect the model's performance? Can the use of a neural network approach improve the transliteration quality compared to statistical models?"
https://aclanthology.org/2020.lrec-1.364/,"Can the embedding of word-level analogical reasoning using E-HowNet effectively capture morphological and named entity relations, and how can this be evaluated using metrics such as semantic similarity or concept hierarchy alignment?"
https://aclanthology.org/2020.lrec-1.364/,"Can the CA-EHN dataset be used to improve the performance of end-to-end models in generalizing inference beyond training corpora by incorporating commonsense knowledge, and what are the potential improvements in accuracy or processing time expected?"
https://aclanthology.org/2020.lrec-1.365/,Can the semagram-based knowledge model be generalized to a larger number of concepts using supervised learning methods and what features from different sources would be most beneficial for this task?
https://aclanthology.org/2020.lrec-1.365/,Can the proposed semagram-based knowledge model outperform existing word embeddings in a semantic similarity task for a large dataset with diverse concepts?
https://aclanthology.org/2020.lrec-1.366/,"Can machine learning-based word embeddings effectively distinguish between cognates and deceptive cognates in a set of Romance languages, and how can this be evaluated using a measure of falseness? Can the proposed method be extended to low-resource languages with limited bilingual dictionaries?"
https://aclanthology.org/2020.lrec-1.367/,How can the integration of morphological and morpho-syntactic information into the WordNet resource improve the accuracy of machine translation and natural language generation tasks for Swedish and Bulgarian languages?
https://aclanthology.org/2020.lrec-1.367/,Can the use of word-level alignment with closest translations in both languages enhance the effectiveness of machine translation systems in handling linguistic nuances and idiomatic expressions?
https://aclanthology.org/2020.lrec-1.368/,"What is the feasibility of using ENGLAWI as a dataset for training a supervised learning model to predict the semantic meaning of words based on their definitions, and how does the model's performance compare to a baseline model trained on a smaller dataset of word embeddings?"
https://aclanthology.org/2020.lrec-1.368/,How do the morphological and phonological features extracted from ENGLAWI contribute to the accuracy of lexicographic word embeddings computed from the dictionary's definitions?
https://aclanthology.org/2020.lrec-1.369/,What are the methods used to annotate the Romance Verbal Inflection Dataset 2.0 for consistency and accuracy?
https://aclanthology.org/2020.lrec-1.369/,How can the multilingual nature of the dataset be utilized to test linguistic hypotheses about the evolution of inflectional paradigms in Romance languages?
https://aclanthology.org/2020.lrec-1.370/,"Can word2word's dataset be used to develop a machine learning model for predicting word translations in low-resource language pairs, and if so, what metrics should be used to evaluate the model's performance? Can the top-k word translations provided by word2word be used to improve the performance of a sequence-to-sequence model for cross-lingual text translation?"
https://aclanthology.org/2020.lrec-1.371/,"Can lexical masks be used to standardize the number of forms in lexicon databases for a specific language, and how would this impact the interoperability of NLP applications?"
https://aclanthology.org/2020.lrec-1.371/,"Does the use of lexical masks affect the level of precision in evaluating lexical entries in terms of features associated with these forms, and what evaluation metrics would be required to measure this impact?"
https://aclanthology.org/2020.lrec-1.372/,"Can the frequency-based readability measures developed from the lexicon accurately capture the nuances of Modern Standard Arabic's regional variations in readability, and how do these variations impact the performance of readability metrics in different contexts? Does the frequency-based approach accurately predict the readability levels of texts from various regions, and what are the implications for language teaching and learning?"
https://aclanthology.org/2020.lrec-1.373/,"Can machine learning algorithms be used to retro-convert historical printed dictionaries into easily accessible lexical databases while minimizing the cost of full-text conversion, and what are the potential applications of such databases in the study of Old French? Can the use of existing dictionaries and lexical networks, such as GermaNet and WordNet, improve the accuracy of the retro-conversion process and the subsequent annotation and exploitation of Old French text corpora?"
https://aclanthology.org/2020.lrec-1.374/,"How can Cifu's phonological and orthographic information be used to improve the accuracy of Hong Kong Cantonese language models, and what are the implications for NLP applications and psycholinguistics experiments?"
https://aclanthology.org/2020.lrec-1.374/,"What are the differences in lexical diversity and word frequency correlations between child-directed and written Hong Kong Cantonese speech, and how can these findings inform the design of future NLP and psycholinguistics studies?"
https://aclanthology.org/2020.lrec-1.375/,"Can sentiment lexicons for ancient languages be developed using modern methods, and what are the implications for the evaluation of their accuracy in capturing the nuances of ancient texts?"
https://aclanthology.org/2020.lrec-1.375/,"How do semantic and derivational relations contribute to the development of high-quality sentiment lexicons for ancient languages, and what is the impact on the application of these lexicons to various text types?"
https://aclanthology.org/2020.lrec-1.376/,"How do changes in word frequency impact the degree of natural selection in word representation over time in the WordWars dataset, and what are the specific changes in word features contributing to these impacts?"
https://aclanthology.org/2020.lrec-1.376/,What are the differences in predominant word features between the early 1800s and the early 2000s in the WordWars dataset?
https://aclanthology.org/2020.lrec-1.377/,Can a machine learning approach using linked Indian language Wordnets be used to effectively identify cognates across language pairs with high accuracy and precision in a computationally efficient manner?
https://aclanthology.org/2020.lrec-1.377/,How does the quality of the cognate detection approach impact the performance of Machine Translation and Cross-lingual Sense Disambiguation tasks when using cognate datasets for Indian languages?
https://aclanthology.org/2020.lrec-1.378/,"Can word embeddings be used to effectively capture the nuances of personality traits, and how can the weights calculated from large-scale responses be applied to improve personality assessments in real-world applications? Can a personality dictionary constructed from word embeddings with psychological evidence provide a more accurate and reliable representation of individual personality traits?"
https://aclanthology.org/2020.lrec-1.379/,"Can a rule-based algorithm using manually constructed lists of hedge words, booster words, and hedging phrases effectively identify sentence-level hedges in informal conversations such as survivor interviews?"
https://aclanthology.org/2020.lrec-1.379/,Can the proposed algorithm achieve high accuracy in detecting hedges in a dataset of 3000 sentences with a Hedge and Non-hedge annotation?
https://aclanthology.org/2020.lrec-1.380/,Can the proposed method using the word complexity estimator and the simplified synonym lexicon achieve better performance in Japanese lexical simplification compared to existing methods?
https://aclanthology.org/2020.lrec-1.380/,"How can the proposed toolkit be used to develop and benchmark a comprehensive lexical simplification system for Japanese, considering the lack of language resources in the field?"
https://aclanthology.org/2020.lrec-1.381/,Can semantic tagging be used to improve the performance of machine translation tasks by incorporating privative attributes and subsective attributes into the translation models? Can large-scale word representation data be used to develop a hybrid approach that combines supervised and unsupervised learning methods for semantic tagging of out-of-vocabulary words?
https://aclanthology.org/2020.lrec-1.382/,"What is the most efficient method for adding live data to existing corpora in LexiDB, considering the trade-off between data storage and query performance?"
https://aclanthology.org/2020.lrec-1.382/,"Can LexiDB's scalability be evaluated using the number of queries performed and the time taken to retrieve results, compared to Corpus Workbench and Lucene?"
https://aclanthology.org/2020.lrec-1.383/,"Does a large-coverage valency lexicon that integrates reflexivity and reciprocity be able to detect reflexive and reciprocal constructions using grammatical constraints on verb morphology and semantic properties, and how can the list of identified verbs be validated and annotated using word embeddings?"
https://aclanthology.org/2020.lrec-1.383/,"Can the automatic detection of reflexive and reciprocal verbs in corpus data be improved by incorporating linguistic and semantic features, such as verb meaning and grammatical function, into the word embedding models?"
https://aclanthology.org/2020.lrec-1.384/,"Can machine learning algorithms be used to create a comprehensive dictionary of Classical Armenian words based on existing resources, with a focus on improving the language's lexicographical completeness and accuracy? Can the development of new digital tools and technologies on the Calfa platform enhance the preservation and usage of Classical Armenian, ultimately increasing its relevance in modern language and cultural contexts?"
https://aclanthology.org/2020.lrec-1.385/,Can the proposed frame-based approach to semantic role labeling for the NPMJ corpus effectively integrate both numbered and conventional semantic role labels in a way that preserves semantic consistency across related predicates?
https://aclanthology.org/2020.lrec-1.385/,Can the use of a hierarchical frame structure enable the development of more accurate semantic parsing models for Japanese using machine learning approaches?
https://aclanthology.org/2020.lrec-1.386/,How do cross-lingual referential corpora facilitate the analysis of framing in different languages and across different texts?
https://aclanthology.org/2020.lrec-1.386/,Can automated data generation enable a more comprehensive capture of linguistic framing variation compared to traditional approaches?
https://aclanthology.org/2020.lrec-1.387/,"What are the methods used to encode etymological and diachronic data in the new part 3 of the ISO standard ISO 24613-3, and how do they differ from the encoding used in part 4, which includes a TEI serialization of all prior parts of the model?"
https://aclanthology.org/2020.lrec-1.387/,"How do the use of UML and TEI serialization in the encoding of the examples from the Grande Dicionário Houaiss da Língua Portuguesa affect the analysis of different, heterogeneously encoded, Portuguese lexical resources?"
https://aclanthology.org/2020.lrec-1.388/,Can the TUFS Basic Vocabulary Modules be effectively linked with the Open Multilingual Wordnet to improve the accuracy of semantic relation extraction for languages with limited online resources?
https://aclanthology.org/2020.lrec-1.388/,"How can the linking of TUFS modules with Open Multilingual Wordnet facilitate the creation of new open wordnets for underserved languages like Khmer, Korean, Lao, Mongolian, Russian, Tagalog, Urdu, and Vietnamese?"
https://aclanthology.org/2020.lrec-1.389/,"Can the proposed LMF format for the Open Multilingual Wordnet be successfully integrated with existing wordnets to incorporate new extensions such as confidence and corpus frequency, and how will this integration impact the display of this new information?"
https://aclanthology.org/2020.lrec-1.389/,Can the new Open Multilingual Wordnet's compatibility with multiple wordnets be evaluated using a set of tools that test the introduced extensions and ensure the integrity of the Collaborative Interlingual Index?
https://aclanthology.org/2020.lrec-1.390/,"Can a unified database of Russian dictionary and statistical collocations be developed to improve the accuracy of machine learning models for NLP tasks, and how can the overlap between different collocation lists be minimized? Can a corpus-based approach to extracting collocations be compared to dictionary-based approaches in terms of accuracy and comprehensiveness of collocations?"
https://aclanthology.org/2020.lrec-1.391/,What are the fine-grained etymological relations that can be used to represent the evolution of a word over time in the creation and update phases of an etymological lexicon?
https://aclanthology.org/2020.lrec-1.391/,"How can the dissemination and exploitation of an etymological database, such as EtymDB 2.0, be optimized for use in low resource languages for machine translation and other NLP tasks?"
https://aclanthology.org/2020.lrec-1.392/,How can the semi-automatic lexical enrichment process using word embeddings improve the accuracy of OFrLex for Old French part-of-speech tagging and dependency parsing tasks?
https://aclanthology.org/2020.lrec-1.392/,Can the semi-automatic procedure for extracting structured information from heterogeneous language resources be replicated and validated using OFrLex as a testbed for natural language processing tasks?
https://aclanthology.org/2020.lrec-1.393/,Can a machine learning approach using sequence labeling be used to accurately reconstruct uncertain Latin words from incomplete cognate sets in Romance languages with high accuracy and efficiency?
https://aclanthology.org/2020.lrec-1.393/,Can an ensemble-based method be developed to aggregate and re-rank word productions from multiple languages to improve the quality of cognate pairs and proto-words in historical linguistics?
https://aclanthology.org/2020.lrec-1.394/,"Can a machine learning approach utilizing a deep learning model be developed to improve the accuracy of sense alignment across multiple languages and resources, with a focus on evaluating the performance using metrics such as precision and recall?"
https://aclanthology.org/2020.lrec-1.394/,"Can the use of semantic relationships such as broadness, narrowness, relatedness, and equivalence enhance the alignment of word senses, and if so, how can these relationships be effectively integrated into a neural network architecture?"
https://aclanthology.org/2020.lrec-1.395/,"Can COLLIE-V's ability to derive new ontological concepts and lexical entries from parsing dictionary definitions and examples be further improved by incorporating multimodal input data such as images or audio, and how would this impact the accuracy of the technique?"
https://aclanthology.org/2020.lrec-1.395/,"Can the integration of COLLIE-V with other natural language processing models, such as transformer-based architectures, enhance the coverage and accuracy of verb-based lexical resources in a multimodal setting?"
https://aclanthology.org/2020.lrec-1.396/,"Can a machine learning model improve the prediction of word etymology across languages using Wiktionary data, and what is the optimal feature set for this task?"
https://aclanthology.org/2020.lrec-1.396/,"Can etymology modeling be used to explain the emergence of new words in language, and how can it be applied to predict linguistic trends?"
https://aclanthology.org/2020.lrec-1.397/,"Can the proposed dataset improve the accuracy of bilingual word sense disambiguation tasks in NLP, measured by the precision of the models using a supervised learning approach with a strong equivalence link as the target relation, and what is the effect of the three types of equivalence links on the performance of the models in this task?"
https://aclanthology.org/2020.lrec-1.398/,Can machine learning methods be applied to improve the accuracy of transliteration from Cyrillic to Latin characters for languages with limited availability of public data?
https://aclanthology.org/2020.lrec-1.398/,Can a deep learning approach using a transformer-based architecture be used to improve the detection of person and geolocation names in transliterated names with an accuracy of 95% or higher?
https://aclanthology.org/2020.lrec-1.399/,"Can word embeddings capture the nuances of subjectivity in Brazilian Portuguese using the proposed lexicons, and what are the optimal dimensions to use for this task?"
https://aclanthology.org/2020.lrec-1.399/,"Do the proposed lexicons improve the performance of automated essay scoring in Brazilian Portuguese, and how do they compare to existing methods?"
https://aclanthology.org/2020.lrec-1.400/,Can the ACoLi Dictionary Graph's RDF representation improve the accuracy of translation inference tasks when compared to the tabular data format?
https://aclanthology.org/2020.lrec-1.400/,Can the unified representation of the ACoLi Dictionary Graph facilitate the development of more accurate and efficient machine translation models using OntoLex-Lemon vocabulary?
https://aclanthology.org/2020.lrec-1.401/,"How can the availability of a large and representative corpus in Romanian improve the accuracy of language-dependent theories in Linguistics, and what evaluation metrics can be used to assess the effectiveness of such a corpus in facilitating linguistic research?"
https://aclanthology.org/2020.lrec-1.401/,"What are the key characteristics of the Romanian language that make it a challenging task to create a reliable corpus, and how can these challenges be addressed through the development of the corpus?"
https://aclanthology.org/2020.lrec-1.402/,"How can a Danish Language Technology Committee effectively collaborate with users, suppliers, developers, and researchers to establish a comprehensive language technology strategy for the Danish language, measured by the improvement in language technology tools and services provided to the public?"
https://aclanthology.org/2020.lrec-1.402/,"What are the specific steps that can be taken to implement the Danish government's language technology strategy, focusing on the development of a robust and user-centered language technology infrastructure, as measured by the increase in syntactic correctness and processing time?"
https://aclanthology.org/2020.lrec-1.403/,Is the use of typography and image information in machine learning models for readability assessment and text simplification more beneficial than the use of text alone?
https://aclanthology.org/2020.lrec-1.403/,Can a machine learning model trained on monolingual-only data for text simplification achieve higher accuracy when back-translation is applied as a data augmentation technique?
https://aclanthology.org/2020.lrec-1.404/,"Can a supervised machine learning approach using a transformer-based architecture improve the accuracy of sign language recognition for individuals with language disabilities, measured by the percentage of correctly identified signs?"
https://aclanthology.org/2020.lrec-1.404/,"Can the proposed K-Centre for Atypical Communication Expertise (ACE) ensure GDPR-compliant data storage and management for language archives, as demonstrated through a comparison of data storage costs and processing times?"
https://aclanthology.org/2020.lrec-1.405/,"Can the GDPR provide sufficient legal grounds for processing corpus disordered speech for clinical applications, taking into account issues of consent and public interest, and how can these grounds be determined and evaluated?"
https://aclanthology.org/2020.lrec-1.405/,"Can the GDPR permit the processing of corpus disordered speech from legacy data of Polish hearing-impaired children, considering the implications for data protection and intellectual property rights?"
https://aclanthology.org/2020.lrec-1.406/,"What are the most effective methods to integrate AI in European language technologies to improve cross-lingual and cross-cultural communication in business settings, considering the current fragmentation of language technologies in the EU?"
https://aclanthology.org/2020.lrec-1.406/,How can the development of language technologies be evaluated and measured in terms of accuracy and processing time to ensure effective communication in multilingual contexts?
https://aclanthology.org/2020.lrec-1.407/,"Can a proposed extension to the BCP 47 standard using a privateuse sub-tag effectively address the limitations in representing lesser-known languages and regional varieties, and how does this extension impact the development of multilingual Linked Data on the Semantic Web?"
https://aclanthology.org/2020.lrec-1.407/,"Can the use of a URI shortcode for the extended sub-tag improve the encoding and decoding of language tags, ensuring compliance with the BCP 47 standard and facilitating the creation of a comprehensive linguistic database?"
https://aclanthology.org/2020.lrec-1.408/,Can the new Gigafida corpus of standard Slovene improve the accuracy of Slovene lexicographic resources such as the collocations dictionary and the thesaurus by providing a more comprehensive dataset?
https://aclanthology.org/2020.lrec-1.408/,Does the transformation of the Gigafida corpus to standard Slovene language facilitate the creation of new corpora dedicated to non-standard language variants?
https://aclanthology.org/2020.lrec-1.409/,"Can the CQLF Metamodel be effectively integrated into existing information systems without requiring significant modifications to the underlying data structures, and what is the expected impact on data consistency and query performance?"
https://aclanthology.org/2020.lrec-1.409/,"Will the CQLF Ontology be able to provide a common language for representing and querying complex semantic relationships in heterogeneous data sources, and what are the implications for data integration and knowledge discovery?"
https://aclanthology.org/2020.lrec-1.410/,"Can a machine learning-based approach using speech recognition algorithms improve the accuracy of transcription for non-technical users of the portal, while ensuring compliance with data protection regulations and minimizing costs?"
https://aclanthology.org/2020.lrec-1.410/,"Can the use of ASR in a research context be optimized for better quality and efficiency, particularly in handling diverse languages and dialects, and what strategies can be employed to address privacy concerns?"
https://aclanthology.org/2020.lrec-1.411/,"Can the casual annotation paradigm improve the productivity of annotators compared to traditional annotation methods, measured by the percentage of annotated data completed within a given timeframe, and can it be successfully applied to other annotation tasks beyond sentiment analysis?"
https://aclanthology.org/2020.lrec-1.411/,"Can the Ellogon Casual Annotation Tool effectively reduce the annotation bottleneck by automatically pre-training annotators for a given task, and can it be integrated with existing annotation infrastructure to streamline the annotation process?"
https://aclanthology.org/2020.lrec-1.412/,"Can the European Language Grid improve the accessibility and usability of Language Technologies for non-commercial SMEs in Europe, as measured by a 20% increase in the number of deployed tools and services within the first year of operation? Can the ELG facilitate the collaboration and sharing of Language Technologies among European SMEs and large players, as measured by a 30% reduction in the time taken to develop and deploy new language-related projects?"
https://aclanthology.org/2020.lrec-1.413/,Can machine learning-based approaches to improve European language technology innovation be more effective in scaling up market dominance compared to North American and Asian models?
https://aclanthology.org/2020.lrec-1.413/,Is the availability and accessibility of open data a significant factor in hindering EU competitiveness in cross-lingual search and speech technology?
https://aclanthology.org/2020.lrec-1.414/,Can the custom segmentation tool used in the corpus construction process achieve a segmentation accuracy of 95% or higher in segmenting Islamic Hadith texts with similar complexity to the one used in the article?
https://aclanthology.org/2020.lrec-1.414/,"Can the use of a bilingual parallel corpus of Islamic Hadith improve the performance of machine learning models in natural language processing tasks, particularly in sentiment analysis and text classification?"
https://aclanthology.org/2020.lrec-1.415/,"Can the use of a KWIC engine powered by the Swedish Korp tool improve the efficiency of text analysis in the Icelandic Gigaword Corpus, measured by the reduction in processing time?"
https://aclanthology.org/2020.lrec-1.415/,"Does the use of pre-trained word embeddings models, such as word2vec, GloVe, fastText, and ELMo, improve the accuracy of n-gram based analysis in the Icelandic Gigaword Corpus?"
https://aclanthology.org/2020.lrec-1.416/,Can the CLARIN infrastructure be integrated with the European Open Science Cloud to improve the sharing and collaboration of language resources among researchers in the humanities and social sciences?
https://aclanthology.org/2020.lrec-1.416/,Can the interoperability of CLARIN with other SSH domains be measured through the use of standardized performance metrics and data curation practices?
https://aclanthology.org/2020.lrec-1.417/,"Can the use of open-source language resources and software improve the accuracy of speech recognition systems for Icelandic, and if so, how can the speech synthesis capabilities be enhanced to match the nuances of the Icelandic language?"
https://aclanthology.org/2020.lrec-1.418/,"Can a privacy-aware approach to language resource development be designed and implemented through the entire project lifecycle, and if so, what are the most effective methods for ensuring data protection principles are embedded in language resources, such as dictionaries and thesauri?"
https://aclanthology.org/2020.lrec-1.418/,"How can machine learning-based approaches to language processing be modified to ensure that they are compliant with the General Data Protection Regulation's requirements for data protection by design, and what are the implications for data controllers and users of these systems?"
https://aclanthology.org/2020.lrec-1.419/,Is it possible to evaluate the effectiveness of the ELG-SHARE metadata schema in improving the discoverability and reusability of Language Resources and Technologies in the European Language Grid platform?
https://aclanthology.org/2020.lrec-1.419/,"Can the use of ELG-SHARE schema facilitate the creation of a standardized vocabulary for describing and linking related entities such as organizations, projects, and supporting documents in the Language Technology ecosystem?"
https://aclanthology.org/2020.lrec-1.420/,Can the proposed Related Works schema improve the efficiency of data entry by reducing the time required for populating the LDC Catalog database with relation data?
https://aclanthology.org/2020.lrec-1.420/,Can the use of controlled terms for relations in the Related Works schema enhance the accuracy of the LDC Catalog's metadata by reducing errors in relation classification?
https://aclanthology.org/2020.lrec-1.421/,Is the lack of appreciation for the value of language data a significant barrier to the development of modern language technologies in EU Member States? How can language data management practices be improved to address the legal concerns and ensure the sharing of language data across European countries?
https://aclanthology.org/2020.lrec-1.422/,"Can the use of machine learning algorithms improve the annotation of linguistic corpora, and what specific metrics should be used to evaluate the effectiveness of these methods? Can the deployment of a data center to support language technology research communities increase the availability and accessibility of linguistic resources, and what benefits does this bring to the research process?"
https://aclanthology.org/2020.lrec-1.423/,"Can language resources collected by smaller local institutions in South Tyrol be effectively integrated into the CLARIN infrastructure, and how can this integration be measured in terms of accuracy and completeness of the resources?"
https://aclanthology.org/2020.lrec-1.423/,How can the documentation and distribution of local language actors' landscape be improved to increase user engagement and facilitate collaboration among smaller institutions and the CLARIN infrastructure?
https://aclanthology.org/2020.lrec-1.424/,"What are the factors that contribute to the success of crowd-sourcing campaigns for speech data collection, as demonstrated by the Samrómur project's rapid data collection and demographic diversity of the resulting dataset?"
https://aclanthology.org/2020.lrec-1.424/,"How can marketing strategies and media coverage impact the effectiveness of crowd-sourcing efforts, particularly in terms of the quality and representativeness of the collected data?"
https://aclanthology.org/2020.lrec-1.425/,"Can the use of batch-wise semi-supervised training improve the performance of under-resourced, code-switched speech models in South African languages compared to non-batch-wise training methods?"
https://aclanthology.org/2020.lrec-1.425/,Can the effectiveness of bilingual and unified speech recognisers in adding data to sparse training sets be evaluated using pseudolabels generated by the unified system versus those generated by the bilingual systems?
https://aclanthology.org/2020.lrec-1.426/,"Can a class label frequency distance (clfd) approach be used to improve the performance of machine learning methods in detecting fake news, and how does it compare to traditional machine learning methods versus deep learning methods in different dataset sizes?"
https://aclanthology.org/2020.lrec-1.426/,Can a hybrid method that combines clfd-boosted logistic regression and deep learning be used to further improve the performance of fake news detection in large datasets?
https://aclanthology.org/2020.lrec-1.427/,"What is the effectiveness of the proposed unsupervised method in reducing the complexity of Urdu text through lexical simplification compared to the BLEU score, and how does it compare to human evaluations in terms of simplicity and grammaticality?"
https://aclanthology.org/2020.lrec-1.427/,"Can the proposed method incorporating word embeddings and morphological features improve the accuracy of lexical simplification for Urdu text, as measured by the SARI score, and what are the implications for future research in Automatic Text Simplification for low-resource languages?"
https://aclanthology.org/2020.lrec-1.428/,"What are the specific algorithms proposed for increasing the elasticity of budget required for building the vocabulary in Byte-Pair Encoding inspired tokenizers for languages with a broad set of potential characters, and how do they differ from existing approaches?"
https://aclanthology.org/2020.lrec-1.428/,How can the proposed algorithms be applied to support Korean in a multilingual model with minimal additional computational resources and cost?
https://aclanthology.org/2020.lrec-1.429/,"What is the potential of deep learning algorithms in detecting hate speech in Danish language posts on social media platforms, and how do these results compare to the results for English language posts?"
https://aclanthology.org/2020.lrec-1.429/,"Can the proposed automatic classification systems be improved to increase the detection accuracy of targeted offensive language in Danish, by analyzing the relationships between the type of offense and the target of the language?"
https://aclanthology.org/2020.lrec-1.430/,Can a semi-supervised deep learning model be used to improve the coverage of lexical units in FrameNet by detecting and clustering lexical units that cannot fit into existing semantic frames? Can the use of contextualized vector representations and reconstruction error in SDEC-AD improve the accuracy of frame prediction for lexical units that have not been assigned to a frame?
https://aclanthology.org/2020.lrec-1.431/,"Can gradient boosting models be trained to achieve high accuracy in search query language identification, especially for short text queries, using a combination of weak-labeled and human-annotated data? Can a practical approach to creating large-scale query-language pairs for training improve the performance of language identifiers in the cold start problem?"
https://aclanthology.org/2020.lrec-1.432/,"Can a context-aware neural network model accurately transcribe Akkadian syllables with high recall and precision, and how does the model's performance compare to human performance in this task?"
https://aclanthology.org/2020.lrec-1.432/,Does the proposed neural network model's ability to infer inflection from sentence context improve the accuracy of Akkadian logogram transcription?
https://aclanthology.org/2020.lrec-1.433/,"Can the use of LASER sentence embeddings improve the semantic properties of sentence embeddings in the context of complex sentence transformations, and can the dataset's limited scope to Czech hinder the generalizability of the findings?"
https://aclanthology.org/2020.lrec-1.433/,"Does the construction of COSTRA 1.0's dataset provide a feasible approach to identifying topologically interesting ""skeletons"" in the sentence embedding space using multi-lingual sentence embeddings?"
https://aclanthology.org/2020.lrec-1.434/,Can the proposed end-to-end differentiable neural network approach for annotating the WSM Corpus improve the efficiency of manual annotation processes for diseases such as Depression and Parkinson’s disease in real-life situations? Can the proposed method generalize to scenarios where the data is organized in bags but does not meet the standard Multiple Instance Learning (MIL) bag label conditions?
https://aclanthology.org/2020.lrec-1.435/,"Can machine learning algorithms with HTR architectures be used to accurately recognize black letter text in historical documents, and what is the required amount of training data to achieve good OCR results in this context?"
https://aclanthology.org/2020.lrec-1.435/,Can a systematic evaluation framework be developed to compare the performance of different OCR engines and provide informed estimates of data requirements for high-quality OCR in Digital Humanities projects?
https://aclanthology.org/2020.lrec-1.436/,What is the impact of Dirichlet smoothing on the performance of pointwise mutual information (PPMI) word embeddings in low-resource language settings?
https://aclanthology.org/2020.lrec-1.436/,How does the proposed PPMI method compare to the recent state-of-the-art PU-Learning method in word embeddings for low-resource languages?
https://aclanthology.org/2020.lrec-1.437/,"What is the impact of different time pooling strategies on the performance of state-of-the-art representation learning models in language identification tasks, measured by open-set evaluation metrics?"
https://aclanthology.org/2020.lrec-1.437/,"Can simple statistics of local descriptors or more sophisticated approaches be suitable for aggregating local descriptors in speech processing applications, and how do they compare to previous results based on attention only?"
https://aclanthology.org/2020.lrec-1.438/,"What is the performance of the proposed method on POS and lemma disambiguation compared to state-of-the-art supervised models using manually annotated data, in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.438/,Can the proposed method be extended to disambiguate ambiguous words in morphologically rich languages without relying on manually annotated data for training recurrent neural networks?
https://aclanthology.org/2020.lrec-1.439/,Can non-linear mappings using Kernel Canonical Correlation Analysis improve the representation of cross-lingual word embeddings by capturing the complex relationships between languages that linear approaches cannot?
https://aclanthology.org/2020.lrec-1.439/,Does the use of Kernel Canonical Correlation Analysis lead to better performance in supervised and self-learning scenarios for cross-lingual word embeddings compared to linear mapping-based approaches?
https://aclanthology.org/2020.lrec-1.440/,Can speech recognition accuracy be improved for German speech with the addition of a larger corpus of high-quality audio data? Can the quality of sentence alignments for end-to-end German-to-English speech translation be further enhanced by adjusting the automatic alignment cutoff score?
https://aclanthology.org/2020.lrec-1.441/,Can the use of SEDAR in machine translation systems improve performance on financial texts compared to non-domain specific training data?
https://aclanthology.org/2020.lrec-1.441/,Can the characteristics of SEDAR be used to develop more effective domain adaptation methods for neural machine translation in the finance domain?
https://aclanthology.org/2020.lrec-1.442/,Can a pre-trained machine translation model trained with JParaCrawl achieve better performance on Japanese-English translation tasks when fine-tuned on a specific domain compared to training from the initial state?
https://aclanthology.org/2020.lrec-1.442/,Can the use of JParaCrawl for pre-training reduce the training time of a neural machine translation model compared to training from the initial state?
https://aclanthology.org/2020.lrec-1.443/,What is the effect of using Multihead self-attention in neural machine translation for morphological rich Indian languages?
https://aclanthology.org/2020.lrec-1.443/,Can a novel NMT model using pre-trained Byte-Pair-Encoded and MultiBPE embeddings effectively overcome the OOV problem in low resourced languages?
https://aclanthology.org/2020.lrec-1.444/,Can a content-equivalent Japanese-English news corpus improve the performance of neural machine translation systems when trained with noisy data?
https://aclanthology.org/2020.lrec-1.444/,"Does a multi-tagged domain-adaptation method improve the learning of NMT models with mixed data having different features, such as clean and noisy data?"
https://aclanthology.org/2020.lrec-1.445/,What is the effect of using a neural machine translation (NMT) system versus a traditional phrase-based statistical machine translation (PBSMT) system on the accuracy of translations of Brazilian Portuguese sentences from English?
https://aclanthology.org/2020.lrec-1.445/,Can NMT systems with automatic post-editing be more accurate than PBSMT systems in generating translations of Brazilian Portuguese sentences from English?
https://aclanthology.org/2020.lrec-1.446/,"Can a context-aware neural machine translation model accurately resolve zero pronouns in Japanese to English translations using the proposed dataset, and what is the impact of the model's performance on the overall translation quality in terms of accuracy?"
https://aclanthology.org/2020.lrec-1.446/,"Does the proposed dataset provide a reliable evaluation metric for assessing the effectiveness of zero pronoun resolution in machine translation models, and can it be used to improve the translation quality of existing models?"
https://aclanthology.org/2020.lrec-1.447/,"Can the use of stopword removal, lemmatization, and dictionaries improve the performance of end-to-end machine translation systems? Does the integration of traditional linguistic methods with deep learning-based approaches enhance the accuracy of noun phrase alignment in machine translation tasks?"
https://aclanthology.org/2020.lrec-1.448/,Can a framework for parallel corpus mining using machine learning algorithms and cosine similarity be used to generate high-quality Japanese-English lectures translation with improved accuracy when fine-tuned in a multistage approach?
https://aclanthology.org/2020.lrec-1.448/,"Can the use of mined parallel corpora from publicly available lectures at Coursera improve the performance of out-of-domain translation tasks, and what are the key factors affecting the quality of the mined data?"
https://aclanthology.org/2020.lrec-1.449/,Can the use of dynamic sub-word vocabularies significantly improve the performance of many-to-many neural machine translation models when transferring from a multilingual model to an under-resourced child language?
https://aclanthology.org/2020.lrec-1.449/,Can the effectiveness of cold start transfer learning from a multilingual model to an under-resourced child language be improved by using sufficiently large sub-word vocabularies in both translation directions?
https://aclanthology.org/2020.lrec-1.450/,Can machine translation models effectively incorporate section-level topic information to improve the coherence and accuracy of translations in heterogeneous documents?
https://aclanthology.org/2020.lrec-1.450/,Can a cache-based approach outperform a side-constrained method in capturing the topic-specific characteristics of sentences in multilingual Wikipedia biographies?
https://aclanthology.org/2020.lrec-1.451/,"Can machine translation systems improve the translation quality by explicitly modeling the senses of ambiguous words in multilingual text, and how do different sense disambiguation methods impact the overall performance of the translation system?"
https://aclanthology.org/2020.lrec-1.451/,"Can the training data of machine translation systems be used to create a fair evaluation benchmark for word sense disambiguation, and what are the challenges in constructing such a benchmark?"
https://aclanthology.org/2020.lrec-1.452/,"What methods of abstract translation were used by authors in the MEDLINE corpus for the English/Spanish, English/French, and English/Portuguese test sets?"
https://aclanthology.org/2020.lrec-1.452/,How can the characterization of MEDLINE authors' language skills and abstract writing practices inform the design of test sets for future WMT biomedical tasks?
https://aclanthology.org/2020.lrec-1.453/,Can JASS outperform MASS in terms of translation accuracy for low-resource languages and can JASS's incorporation of bunsetsu annotations improve the performance of pre-trained NMT models for ASPEC Japanese-English and News Commentary Japanese-Russian translation tasks?
https://aclanthology.org/2020.lrec-1.454/,"Can neural machine translation systems achieve high-quality translations comparable to human references in the legal domain, and if so, what is the optimal post-editing approach to improve the accuracy of such systems?"
https://aclanthology.org/2020.lrec-1.454/,"Can the post-editing process improve the quality of neural machine translation systems in the legal domain, and if so, how does the quality of the post-editing differ between human and automated post-editing models?"
https://aclanthology.org/2020.lrec-1.455/,"Can a Transformer-based NMT model with linguistic features such as POS tags, lemmas, and morph features outperform the baseline system in Hindi-English translation tasks?"
https://aclanthology.org/2020.lrec-1.455/,Does the incorporation of linguistic knowledge encoded by Hindi phenomena improve the translation accuracy and processing time of the NMT model?
https://aclanthology.org/2020.lrec-1.456/,"Can context-aware machine translation improve the translation of zero pronouns in Japanese-to-English discourse translation, and if so, how does it compare to the approach used in English-to-French discourse translation? Does the use of context-aware neural machine translation improve the overall accuracy of Japanese-to-English discourse translation compared to traditional machine translation methods?"
https://aclanthology.org/2020.lrec-1.457/,"Can a multilingual machine translation model trained on a diverse set of source languages with varying degrees of relatedness be more accurate than one trained on a smaller set of less diverse languages, and what is the optimal number of source languages for a given language pair?"
https://aclanthology.org/2020.lrec-1.457/,"Can the use of related languages in multilingual machine translation training data impact the model's performance, and how can this impact be mitigated in order to improve overall translation accuracy?"
https://aclanthology.org/2020.lrec-1.458/,"Can machine translation models achieve higher accuracy on the Timely Disclosure Documents Corpus (TDDC) by utilizing the parallel sentences aligned in PDF format, and what is the impact of the document format on the translation output?"
https://aclanthology.org/2020.lrec-1.458/,Can the use of the TDDC dataset improve the performance of machine translation models on the Tokyo Stock Exchange-listed companies' timely disclosure documents in terms of processing time and user satisfaction?
https://aclanthology.org/2020.lrec-1.459/,"Can a multilingual speech translation model using a Transformer-based architecture be trained to accurately segment audiovisual content into subtitles with a high degree of precision, measured by the F1-score for subtitle breaks?"
https://aclanthology.org/2020.lrec-1.459/,"Can the proposed method for annotating existing subtitling corpora with subtitle breaks using MuST-Cinema, improve the efficiency of automatic subtitling approaches by incorporating length and form constraints?"
https://aclanthology.org/2020.lrec-1.460/,"What is the optimal context span required for reliable machine translation evaluation, and how does it vary across different domains and target languages?"
https://aclanthology.org/2020.lrec-1.460/,Can a set of general guidelines for context-aware machine translation evaluation be developed based on the common patterns identified in the context spans of various domains and languages?
https://aclanthology.org/2020.lrec-1.461/,How can the use of deep neural network based methods improve the construction of sentence aligned parallel corpora for low-resource languages in India?
https://aclanthology.org/2020.lrec-1.461/,Can the proposed methods for constructing sentence aligned parallel corpora be validated using the provided test corpus for 10 Indian languages to assess their performance and effectiveness?
https://aclanthology.org/2020.lrec-1.462/,"Is the use of inline casing a superior approach to other casing methods in Neural Machine Translation, in terms of preserving case information and improving overall model performance? Can machine translation models trained with different casing methods achieve comparable results on the WMT 2017 English-German and English-Turkish datasets?"
https://aclanthology.org/2020.lrec-1.463/,Can machine learning models be trained to achieve high accuracy in annotating linguistic features of legal documents across multiple languages using the MARCELL corpus?
https://aclanthology.org/2020.lrec-1.463/,Can the integration of IATE and EUROVOC labels in the MARCELL corpus improve the performance of cross-lingual terminological data extraction systems?
https://aclanthology.org/2020.lrec-1.464/,Can a large-scale parallel corpus of patent abstracts can improve the performance of Neural Machine Translation models when compared to monolingual corpora?
https://aclanthology.org/2020.lrec-1.464/,Can the use of Hunalign algorithm for sentence alignment significantly impact the quality of the parallel corpus for training NMT models for multilingual patent text?
https://aclanthology.org/2020.lrec-1.465/,"Can document-level machine translation models capture discourse dependencies across sentences using the Transformer architecture, and what are the benefits of using this approach over traditional sentence-level translation tasks?"
https://aclanthology.org/2020.lrec-1.465/,"Does the implementation of document-level NMT on non-English-centred language pairs, such as Chinese-Portuguese, demonstrate improved universality and effectiveness compared to existing methods?"
https://aclanthology.org/2020.lrec-1.466/,"Can OpusTools efficiently handle large-scale parallel corpus creation using its tools for data filtering and conversion, and what are the computational resources required to process such large datasets?"
https://aclanthology.org/2020.lrec-1.466/,"Can the use of OpusTools for data diagnostics improve the consistency and quality of the OPUS corpus collection, and what metrics can be used to evaluate the effectiveness of this approach?"
https://aclanthology.org/2020.lrec-1.467/,"Are neural machine translation systems able to generate coherent translations on document level, and how do their accuracy and fluency errors co-occur in literary texts?"
https://aclanthology.org/2020.lrec-1.467/,Do the annotation of fluency and accuracy errors in novel translations provide a comprehensive evaluation metric for assessing the quality of neural machine translation systems?
https://aclanthology.org/2020.lrec-1.468/,Can the use of comparable corpora with carefully controlled alignment thresholds and length-difference outliers removal improve the accuracy of Neural Machine Translation models for Basque-Spanish language pairs?
https://aclanthology.org/2020.lrec-1.468/,Can the incorporation of tags identifying comparable data in the training datasets help to mitigate informational imbalance and improve the performance of Neural Machine Translation models for Basque-Spanish language pairs?
https://aclanthology.org/2020.lrec-1.469/,"Can FISKMÖ's approach to creating a massive parallel corpus for Finnish-Swedish machine translation be improved by incorporating more diverse web sources and data from private organizations, and how would this impact the quality and coverage of the translation services?"
https://aclanthology.org/2020.lrec-1.469/,"Can the development of open and freely accessible translation services using pre-trained neural MT models and a self-contained MT plugin for CAT tools enhance the efficiency and accuracy of translation processes, particularly for domain-specific use cases?"
https://aclanthology.org/2020.lrec-1.470/,"Can Neural Machine Translation Architectures be improved by incorporating linguistic resources and annotation for handling of Multiword Expressions in source and target languages, and how does this impact translation accuracy and BLEU scores?"
https://aclanthology.org/2020.lrec-1.470/,"Can a machine learning-based approach be developed to automatically generate Multiword Expressions in target languages, and what features of linguistic resources and MWEs would be most effective in improving MWE generation quality?"
https://aclanthology.org/2020.lrec-1.471/,"Can an improved mapping of the Sejong POS tag set to the UPOS accurately capture the nuances of Korean linguistic features, while maintaining syntactic correctness and achieving a high accuracy rate of 90% or higher?"
https://aclanthology.org/2020.lrec-1.471/,"Does the introduction of a new mapping for the KAIST POS tag set to the UPOS effectively address the need for a more comprehensive Korean POS tag set, resulting in a significant improvement in the accuracy of part-of-speech tagging for Korean language texts?"
https://aclanthology.org/2020.lrec-1.472/,Can the Finite-State Arabic Morphologizer (FSAM) achieve higher accuracy in root extraction from words compared to existing morphologizers like MADAMIRA? Can the FSAM's diacritization capabilities match or surpass those of publicly available morphologizers?
https://aclanthology.org/2020.lrec-1.473/,"Can a finite state transducer-based morphological analyzer be effectively disambiguated using a word2vec model trained on raw untagged corpora, and how does this approach compare to methods relying on manually built tagged corpora?"
https://aclanthology.org/2020.lrec-1.473/,"Can the use of word2vec-based disambiguation improve the accuracy of morphological analysis results, specifically in terms of reducing the number of incorrect analyses and increasing the processing time?"
https://aclanthology.org/2020.lrec-1.474/,"Can LIT methods be as effective as LST methods for downstream NLP tasks when the vocabulary size is small, and what are the implications of using SIF to create word embeddings for multilingual semantic similarity prediction tasks?"
https://aclanthology.org/2020.lrec-1.474/,"Do LIT methods produce valid morphological subwords, and how do they compare to the subword embeddings produced by LST methods in terms of semantic similarity and syntactic relationships?"
https://aclanthology.org/2020.lrec-1.475/,Can a machine learning approach utilizing a transformer-based architecture be applied to improve the accuracy of part-of-speech tagging on social media text in Greek?
https://aclanthology.org/2020.lrec-1.475/,Can the development of a supervised part-of-speech tagger for Greek social text enhance the efficiency of information extraction tasks in NLP applications?
https://aclanthology.org/2020.lrec-1.476/,Can the proposed Bag & Tag'em algorithm outperform state-of-the-art stemming algorithms in handling 3rd person singular forms of verbs in the Dutch language? Can the combination of the tagging module with the BT stemmer improve the accuracy of stemming for irregular words and conjugations compared to current stemming algorithms?
https://aclanthology.org/2020.lrec-1.477/,"Can the GLAWI machine readable dictionary be effectively transformed into a more comprehensive and up-to-date lexicon using automated methods, and what is the impact on the accuracy of the Démonette database?"
https://aclanthology.org/2020.lrec-1.477/,Can the morphological patterns identified from the graph structure of the GLAWI dictionary be used to develop a more accurate and efficient algorithm for deriving French words from their base forms?
https://aclanthology.org/2020.lrec-1.478/,"Can a finite-state transducer be improved to achieve higher accuracy in morphological analysis of Akkadian language by incorporating more extensive and validated corpora, and what impact would this have on the overall performance of the existing model?"
https://aclanthology.org/2020.lrec-1.478/,How can morphological ambiguity in Akkadian word forms be further reduced through context-based techniques and what would be the expected benefits on the analysis results?
https://aclanthology.org/2020.lrec-1.479/,"Does the use of morphological analyzers in Gulf Arabic improve the accuracy of disambiguation tasks when the size of the resources is extremely small, and can morphological analyzers effectively aid in disambiguation when the resources are scaled up, and what are the optimal morphological analyzer combinations for Gulf Arabic and other Arabic dialects in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.480/,Can the use of multilingual inflectional corpora generated from English Wiktionary and annotated morpheme boundaries improve the performance of NLP models in low-resource languages?
https://aclanthology.org/2020.lrec-1.480/,Can the morpheme segmentations from the UniMorph project and the annotated morphological feature tags be used to enhance the quality of a generated multilingual inflectional corpus?
https://aclanthology.org/2020.lrec-1.481/,Can the proposed Conditional Random Fields model with deep neural network features outperform other state-of-the-art tagging methods in terms of accuracy on conversational text datasets?
https://aclanthology.org/2020.lrec-1.481/,Can the proposed tagging scheme with 36 POS tags improve the performance of state-of-the-art tagging methods on Vietnamese POS tagging task?
https://aclanthology.org/2020.lrec-1.482/,Can the proposed Universal Morphology (UniMorph) feature schema be improved by incorporating machine learning techniques to enhance the accuracy of morphological annotation for under-resourced languages?
https://aclanthology.org/2020.lrec-1.482/,How can the UniMorph project's community tools be optimized to facilitate the efficient validation and dissemination of morphological data for diverse languages?
https://aclanthology.org/2020.lrec-1.483/,"Can the use of machine learning algorithms improve the accuracy of sentence segmentation and alignment in the Spanish-Croatian unidirectional parallel corpus, measured by the number of errors in the aligned translation units? Can the lemmatisation and POS-tagging of the corpus in the aTMX format improve the usability of the corpus for research on language units at sentence and lower levels, evaluated by the percentage of correctly identified translation units?"
https://aclanthology.org/2020.lrec-1.484/,"Can a machine learning-based approach be used to automatically identify and group Russian words into derivational families based on their root words, and how can the accuracy of such an approach be evaluated using metrics such as precision and recall? Can the proposed rule-based framework be used to expand the DerivBase.Ru resource to include domain-specific lexicons and handle the rapid growth of new words in different areas of the language?"
https://aclanthology.org/2020.lrec-1.485/,Can the Expectation Maximization algorithm for training unigram subword models outperform the original recursive training algorithm of the Morfessor Baseline model in terms of morphological segmentation accuracy for morphologically complex languages like North Sami?
https://aclanthology.org/2020.lrec-1.485/,"Can the use of lexicon pruning in conjunction with the Expectation Maximization algorithm improve the optimization problem defined by the Morfessor Baseline model, leading to better subword unit segmentation results for languages like Turkish?"
https://aclanthology.org/2020.lrec-1.486/,"Can the use of TreeTagger and spaCy taggers improve the alignment of Serbian morphological dictionaries with the MULTEXT-East and Universal Part-of-Speech tagset, and how does the training set size affect the precision of the PoS-tagging in these models?"
https://aclanthology.org/2020.lrec-1.486/,Will the incorporation of the newly developed models into the Corpus of Contemporary Serbian and the Serbian literary corpus enhance the accuracy of part-of-speech tagging for the Serbian language?
https://aclanthology.org/2020.lrec-1.487/,Can morphosyntactic tools trained on a large number of languages achieve high accuracy in inflectional morphology processing across languages with varying grammatical structures?
https://aclanthology.org/2020.lrec-1.487/,How does the proposed type-to-token evaluation metric impact the generalization of inflectional morphology models across languages with distinct linguistic characteristics?
https://aclanthology.org/2020.lrec-1.488/,"Can machine learning models be trained to accurately recognize and classify Egyptian Arabic code-switching speech with high precision, using the newly introduced corpus and annotation guidelines?"
https://aclanthology.org/2020.lrec-1.488/,Can the use of a pre-trained language model fine-tuned on the Egyptian Arabic code-switching corpus improve the syntactic correctness of code-switching detection in speech recognition systems?
https://aclanthology.org/2020.lrec-1.489/,Can a language model's decoder that uses the states of a language model improve the model's performance in low-resource morphological inflection by 1.5% when combined with existing baselines?
https://aclanthology.org/2020.lrec-1.489/,Does data augmentation of artificially generated word forms improve the average performance of low-resource morphological inflection by 9% when added to a dataset?
https://aclanthology.org/2020.lrec-1.490/,How does the use of diagramming tools in visual modeling of Turkish morphology impact the maintainability of the code generation process?
https://aclanthology.org/2020.lrec-1.490/,Can the public availability of MorTur as a web service and DiaMor as open-source utilities improve the efficiency of natural language processing tasks for Turkic languages?
https://aclanthology.org/2020.lrec-1.491/,How does the performance of the character-based BiLSTM model change when the training data is increased from 2.9 million to 5.8 million unique word forms?
https://aclanthology.org/2020.lrec-1.491/,Does the model's ability to split compound words into their constituent structures improve with the addition of more training data from the Database of Icelandic Morphology?
https://aclanthology.org/2020.lrec-1.492/,Can morphological segmentation models trained on this dataset achieve a high accuracy rate of 90% or above on unseen languages with low resource annotations?
https://aclanthology.org/2020.lrec-1.492/,Can the use of root annotation in morphological analysis lead to the identification of more complex morphological structures in low resource languages?
https://aclanthology.org/2020.lrec-1.493/,"Can a pre-trained language model's performance on a specific task improves when trained on a dataset created using the proposed pipeline, as measured by the F1-score of named entity recognition, compared to a model trained on a dataset created using the original fastText pipeline?"
https://aclanthology.org/2020.lrec-1.493/,"Can the proposed pipeline be able to extract high-quality monolingual datasets from Common Crawl for languages other than English, as evaluated by the number of correctly identified languages in the extracted dataset?"
https://aclanthology.org/2020.lrec-1.494/,"Can cross-lingual word embeddings learned with minimal supervision perform well on noisy text and language pairs with significant linguistic differences, and how do different training corpora and levels of supervision impact their quality?"
https://aclanthology.org/2020.lrec-1.494/,"Do various cross-lingual embedding models exhibit consistent results when compared to a state-of-the-art system, and how do they handle linguistic differences in different target languages?"
https://aclanthology.org/2020.lrec-1.495/,"Can a supervised machine learning approach using deep learning techniques be applied to automatically recognize different sub-sentential translation techniques from bilingual parallel corpora, with a focus on English-Chinese translations?"
https://aclanthology.org/2020.lrec-1.495/,"Can the use of deep learning models improve the accuracy of automatic paraphrase extraction from bilingual parallel corpora, using a dataset of annotated sentence pairs for English-Chinese translations?"
https://aclanthology.org/2020.lrec-1.496/,"Can a dependency-based lexicalist framework be effectively implemented for a language with a complex grammar and a large number of morphological features, and what are the key challenges in annotating such a language using the Universal Dependencies framework?"
https://aclanthology.org/2020.lrec-1.496/,"How can the introduction of new languages and the update of existing treebanks in the Universal Dependencies project be efficiently managed and coordinated, and what tools or methodologies are needed to support this process?"
https://aclanthology.org/2020.lrec-1.497/,"Can the EuroparlTV Multimedia Parallel Corpus be used to evaluate the effectiveness of accessibility features in web content created using subtitles, and how do the formal aspects of the subtitles impact accessibility? Can the EuroparlTV Multimedia Parallel Corpus be used to train a machine learning model to predict the accessibility of institutional multimedia content based on the formal properties of the subtitles?"
https://aclanthology.org/2020.lrec-1.498/,"How do established techniques for aligning monolingual embedding spaces for Turkic languages, such as Turkish, Uzbek, Azeri, Kazakh, and Kyrgyz, perform when utilizing bilingual dictionaries with varying levels of explicit supervision?"
https://aclanthology.org/2020.lrec-1.498/,"Can cross-lingual word embeddings obtained from resource-rich languages be effectively utilized in low-resource languages, as demonstrated by the evaluation of bilingual dictionary induction task and extrinsic sentiment analysis on Uzbek language?"
https://aclanthology.org/2020.lrec-1.499/,Can the proposed pipeline method improve the precision of sentiment detection for low-resource languages using Universal Dependencies?
https://aclanthology.org/2020.lrec-1.499/,Does the use of syntactic structures on Universal Dependencies enable the detection of nuanced sentiment in multilingual scenarios?
https://aclanthology.org/2020.lrec-1.500/,Can word embeddings capture the nuances of word relations in culturally specific languages and how do different embedding methods perform on cross-lingual analogy tasks?
https://aclanthology.org/2020.lrec-1.500/,Can fastText embeddings provide a more accurate representation of word relations across languages and what are the implications for text processing applications?
https://aclanthology.org/2020.lrec-1.501/,"How does the GeBioToolkit's ability to extract multilingual parallel corpora at sentence level impact the accuracy of machine translation models, and what evaluation metrics can be used to assess its effectiveness?"
https://aclanthology.org/2020.lrec-1.501/,"Can the GeBioToolkit's customizable design and post-editing process ensure the creation of high-quality, gender-balanced datasets for machine translation evaluation, and what are the implications for the field of natural language processing?"
https://aclanthology.org/2020.lrec-1.502/,"What are the characteristics of the Cantonese language that make it a typologically distinct pair of languages, and how do these characteristics impact bilingualism research?"
https://aclanthology.org/2020.lrec-1.502/,"How can the SpiCE corpus be used to study cross-language within-speaker phenomena for early Cantonese-English bilinguals, and what specific aspects of phonetic research can be explored?"
https://aclanthology.org/2020.lrec-1.503/,What is the impact of incorporating domain-specific information into fastText embeddings on the accuracy of cognate pair identification in English-Dutch and French-Dutch?
https://aclanthology.org/2020.lrec-1.503/,How does the addition of cross-lingual word embeddings to a multi-layer perceptron improve the performance of cognate pair identification in English-Dutch and French-Dutch?
https://aclanthology.org/2020.lrec-1.504/,Can the use of machine learning algorithms to analyze and quantify translationese in multilingual data accurately capture the nuances of translationese in both English-to-German and English-to-Russian translations?
https://aclanthology.org/2020.lrec-1.504/,Do professional translators exhibit a greater presence of translationese in their work compared to non-professional translators in both English-to-German and English-to-Russian translations?
https://aclanthology.org/2020.lrec-1.505/,"Can UniSent sentiment lexica be used to improve the accuracy of sentiment analysis for low-resource languages, and how does the confidence weighting scheme in DomDrift affect the performance of sentiment prediction in the Twitter domain?"
https://aclanthology.org/2020.lrec-1.505/,"Can emoticon sentiments be reliably predicted in low-resource languages using UniSent and monolingual embeddings, and what is the impact of using UniSent as the sentiment seed for word sentiment prediction in the Twitter domain?"
https://aclanthology.org/2020.lrec-1.506/,Can the semi-automated annotation of the Canberra Vietnamese-English Code-switching corpus using a combination of monolingual toolkits significantly reduce annotation time while maintaining accuracy?
https://aclanthology.org/2020.lrec-1.506/,Can the use of automatic annotations in the Canberra Vietnamese-English Code-switching corpus enable researchers to analyze and identify patterns of language variation and code-switching in bilingual speech with improved precision and reliability?
https://aclanthology.org/2020.lrec-1.507/,Can machine learning models achieve high accuracy in spell-checking Arabic dialects using the Conventional Orthography for Dialectal Arabic (CODA) compared to raw original forms?
https://aclanthology.org/2020.lrec-1.507/,"Does the use of a bootstrapping technique improve the efficiency of CODA annotation for Arabic dialects, and what is the degree of similarity between dialects after CODA annotation?"
https://aclanthology.org/2020.lrec-1.508/,"Can a multilingual news surveillance system like DAnIEL be effective in extracting event information from online news articles, as measured by accuracy, for low-resource languages, and can this effectiveness be compared across different classification approaches? Can the use of unique attributes associated with news reporting, such as repetition and saliency, improve the extraction of event information from news articles?"
https://aclanthology.org/2020.lrec-1.509/,Can the use of the Swiss-AL corpus facilitate the development of more accurate sentiment analysis models for detecting public opinion on climate change in Switzerland?
https://aclanthology.org/2020.lrec-1.509/,"Can the Swiss-AL corpus be effectively utilized to analyze the linguistic patterns and stylistic features of online debates on Swiss politics, particularly in the context of linguistic and cultural differences between German, French, and Italian?"
https://aclanthology.org/2020.lrec-1.510/,Can speech recognition systems using GlobalPhone data be improved by incorporating phonetic overlap analysis to reduce errors in Automatic Speech Recognition for Ethiopian languages?
https://aclanthology.org/2020.lrec-1.510/,"Does the morphological complexity of GlobalPhone data, measured by type to token ratio and out of vocabulary rate, affect the performance of multilingual Automatic Speech Recognition systems?"
https://aclanthology.org/2020.lrec-1.511/,"How can graph convolutional networks trained from separate languages be used to encode the structural properties of multilingual terms and improve their alignment and semantic understanding, and what are the key factors that influence the quality of the term embeddings in this approach?"
https://aclanthology.org/2020.lrec-1.511/,"What are the challenges and limitations of using graph convolutional networks for multilingual term alignment, and how can they be addressed to achieve better results in terms of accuracy and semantic understanding of terminological information?"
https://aclanthology.org/2020.lrec-1.512/,"Can large speech corpora for Ethiopian languages improve the accuracy of Automatic Speech Recognition (ASR) systems, and what specific linguistic features of these corpora contribute to their performance?"
https://aclanthology.org/2020.lrec-1.512/,"How do the characteristics of the speech corpora affect the development of ASR systems for Ethiopian languages, particularly for Oromo and Wolaytta?"
https://aclanthology.org/2020.lrec-1.513/,"Can a deep learning framework be designed to induce courteous behavior in customer care responses in multiple languages, including English and Hindi, and improve customer satisfaction?"
https://aclanthology.org/2020.lrec-1.513/,"Can the proposed model effectively converse with humans in an empathetic manner across languages, ensuring customer retention and satisfaction?"
https://aclanthology.org/2020.lrec-1.514/,Can the use of WikiBank for distant supervision of semantic parsers improve the accuracy of cross-lingual transfer on multilingual datasets?
https://aclanthology.org/2020.lrec-1.514/,Can the integration of WikiBank into an off-the-shelf frame-semantic parser enhance its performance on low-resource languages using distant supervision signals?
https://aclanthology.org/2020.lrec-1.515/,"Can a semi-automated framework for creating multilingual corpora using crawled bilingual websites and topic modeling significantly improve the performance of multilingual semantic similarity tasks, and what are the key factors that affect the quality of the generated corpus? Can a multilingual corpus created using this framework achieve comparable results to existing monolingual corpora in terms of semantic similarity accuracy?"
https://aclanthology.org/2020.lrec-1.516/,Can the proposed CoVoST corpus improve the performance of multilingual end-to-end speech-to-text translation models when compared to existing datasets with limited linguistic and geographical diversity?
https://aclanthology.org/2020.lrec-1.516/,Can the use of CoVoST improve the robustness of multilingual speech recognition models to different accents and speech styles across 11 languages?
https://aclanthology.org/2020.lrec-1.517/,What is the impact of using phrase-to-region supervision on the performance of multilingual image captioning models when compared to phrase-to-phrase supervision in a multilingual dataset like Flickr30k Entities JP?
https://aclanthology.org/2020.lrec-1.517/,Can phrase-to-region and phrase-to-phrase supervision methods improve the fine-grained grounding of language and vision in a multilingual setting using the Flickr30k Entities JP dataset?
https://aclanthology.org/2020.lrec-1.518/,"Can the newly proposed core vocabulary set be effectively used for machine translation tasks, and what is the optimal threshold for determining the coverage of a target concept in thousands of bilingual dictionaries?"
https://aclanthology.org/2020.lrec-1.518/,"Can the cognate prediction method improve the coverage of the core vocabulary set in massively multilingual dictionary construction, and what are the implications for low-resource language dictionaries?"
https://aclanthology.org/2020.lrec-1.519/,Can deep learning models achieve significant improvements in speech recognition accuracy when fine-tuned on the Common Voice corpus for languages with limited available data?
https://aclanthology.org/2020.lrec-1.519/,Can the application of transfer learning from a source language model enhance the performance of Mozilla’s DeepSpeech Speech-to-Text toolkit for languages with diverse linguistic characteristics?
https://aclanthology.org/2020.lrec-1.520/,"Can WikiPron be scaled to extract pronunciation data for an additional 500 languages, and how would the processing time be affected?"
https://aclanthology.org/2020.lrec-1.520/,Can the trained grapheme-to-phoneme models using WikiPron's pronunciation database be applied to improve speech recognition accuracy for multilingual speech recognition systems?
https://aclanthology.org/2020.lrec-1.521/,"Can the use of open-source morphological analysis tools enable the creation of a freely available, accurate, and consistent morphological alignment between Hebrew and Finnish, and between Greek and Finnish, bitexts, and how does this impact the analysis of the Finnish Bible translation?"
https://aclanthology.org/2020.lrec-1.521/,"Can the proposed method of reconstructing morphological alignments from freely available text editions and annotations improve the accuracy and consistency of the cross-lingual morpheme alignments, and what are the implications for the analysis of linguistic features and their distribution across languages?"
https://aclanthology.org/2020.lrec-1.522/,"Can the ArzEn corpus be effectively used to train ASR models that accurately recognize code-switching in Egyptian Arabic-English speech, and if so, what evaluation metric would be most suitable for assessing the performance of such models?"
https://aclanthology.org/2020.lrec-1.522/,What are the key sociological and psychological factors that contribute to the complexity of the ArzEn corpus and potentially impact the development of ASR systems for Arabic-English code-switching?
https://aclanthology.org/2020.lrec-1.523/,Can multilingual Transformer-based models outperform bilingual models in transliteration tasks for less-resourced languages?
https://aclanthology.org/2020.lrec-1.523/,How does the extrinsic evaluation of transliteration via the cross-lingual named entity list search task compare to intrinsic evaluation methods?
https://aclanthology.org/2020.lrec-1.524/,"Can the proposed dataset improve the performance of speech recognition systems in realistic TV viewing scenarios, measured by a 20% increase in accuracy compared to state-of-the-art systems? Can the annotations in the dataset be used to develop more accurate shot boundary detection models, evaluated by a 15% reduction in false positives compared to existing methods?"
https://aclanthology.org/2020.lrec-1.525/,"Can a deep learning model accurately predict the position of images in a multimodal document, considering the relationship between images and text, and evaluate its performance using a metric such as mean average precision or recall?"
https://aclanthology.org/2020.lrec-1.525/,"Can a multimodal system learn to jointly consider multiple images and texts in a document, and assess its ability to understand complex multimodal documents using metrics such as F1 score or precision recall?"
https://aclanthology.org/2020.lrec-1.526/,"Can visual grounding annotations improve the understanding of cooking workflows by providing a clear link between the procedural text and visual observation, and can they enable the estimation of contextual information from an image sequence of recipes?"
https://aclanthology.org/2020.lrec-1.526/,Does the proposed dataset improve the accuracy of estimating contextual information in recipe flow graphs from image sequences of recipes?
https://aclanthology.org/2020.lrec-1.527/,"Can a multimodal approach that combines text and image features effectively improve the performance of Entity Linking on multimedia tweets, as measured by the accuracy of entity disambiguation?"
https://aclanthology.org/2020.lrec-1.527/,"Can the proposed dataset be used to evaluate the effectiveness of different MEL methods in handling ambiguous mentions in social media posts, and what are the key characteristics of the dataset that contribute to its usefulness?"
https://aclanthology.org/2020.lrec-1.528/,"How can the multimodal aspect of this corpus be leveraged to improve the performance of speech-to-text models, specifically in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.528/,Can the proposed annotation protocol and baseline results provide a solid foundation for the development of thematic segmentation models that align speech and text from the slides?
https://aclanthology.org/2020.lrec-1.529/,"Can a machine learning model achieve high accuracy in predicting event appearance labels using only the given game states, and what is the effect of considering temporal relations and appearance probabilities on the performance of the model in predicting event appearance labels?"
https://aclanthology.org/2020.lrec-1.530/,Can a deep learning model trained on a large Portuguese dataset achieve high accuracy in detecting offensive language in videos using word embeddings?
https://aclanthology.org/2020.lrec-1.530/,Can the performance of video classification models using transfer learning be improved when the input is processed through speech-to-text transcription instead of relying on pre-defined features?
https://aclanthology.org/2020.lrec-1.531/,"Can the proposed multimodal corpus effectively capture the nuances of nonverbal communication in political discourse through its annotation of facial displays, hand gestures, and body posture, and can it be scaled up to analyze larger datasets?"
https://aclanthology.org/2020.lrec-1.531/,"Can the proposed multimodal corpus accurately annotate and analyze the relationships between proxemics phenomena and linguistic structures in political interviews, and how do these relationships impact the communication strategy of politicians?"
https://aclanthology.org/2020.lrec-1.532/,"Can the E:Calm resource be effectively used to train and evaluate machine learning models for syntactic parsing of handwritten text, given the variability in handwriting styles and formatting of the primary sources?"
https://aclanthology.org/2020.lrec-1.532/,"Can the E:Calm resource be used to develop a comprehensive POS tagging system that accurately captures the nuances of French language syntax, considering the range of educational contexts represented in the dataset?"
https://aclanthology.org/2020.lrec-1.533/,"Is the acoustic properties of laughter correlated with how humourous a laugh is perceived by the conversational partner in a conversational setting, and what are the specific acoustic features that contribute to this correlation?"
https://aclanthology.org/2020.lrec-1.533/,Do the physiological responses of participants during humourous interactions correlate with their subjective experience of humour and how their conversational partner perceives their humour?
https://aclanthology.org/2020.lrec-1.534/,How can the development of automatic systems that can extract event information from online news articles about flooding disasters using text and images be improved to account for spatiotemporal distance between articles and images?
https://aclanthology.org/2020.lrec-1.534/,Can an automatic classifier be trained to accurately classify text and images of flooding-related news articles based on their spatial and temporal relationships?
https://aclanthology.org/2020.lrec-1.535/,"Can a deep learning-based video question answering model be trained to achieve high accuracy on real-life scenarios using a dataset that consists of 275 video clips and over 2.3k multiple-choice questions, and what evaluation metrics can be used to assess its performance?"
https://aclanthology.org/2020.lrec-1.535/,"Can a video question answering model be able to generalize well to new, unseen scenarios using a model pre-trained on LifeQA and fine-tuned on a smaller, task-specific dataset?"
https://aclanthology.org/2020.lrec-1.536/,"Can the proposed Simple Compound Splitter (Weller-Di Marco, 2017) be evaluated for its ability to accurately identify domain-specific compounds in text, and how does its performance compare to other compound splitting methods in terms of precision and recall?"
https://aclanthology.org/2020.lrec-1.536/,"Can the difficulty ratings provided by human annotators offer a reliable measure of domain-specific compound difficulty, and what are the implications of the observed agreement on a coarse, binary distinction between easy and difficult compounds?"
https://aclanthology.org/2020.lrec-1.537/,Can the proposed GerCo dataset of adjective-noun collocations for German be used to evaluate the performance of machine learning models on the task of automatic collocation identification using static and contextualized word embeddings? Does the use of word embeddings outperform lexical association measures in identifying collocations on the GerCo dataset?
https://aclanthology.org/2020.lrec-1.538/,"Can word2vec and nouns-only dimensionality reductions effectively predict the degree of compositionality of noun compounds, and do these methods exhibit stable results across different datasets and evaluation metrics, and how can these methods be improved to achieve better performance for compositionality prediction?"
https://aclanthology.org/2020.lrec-1.539/,What is the effect of different edge-weighting methods on the performance of a PageRank model for automatic term extraction in domain-specific language?
https://aclanthology.org/2020.lrec-1.539/,Can a vector space representation incorporating meaning shifts from general to domain-specific language improve the termhood strengths of ambiguous words across word senses in a domain-specific English corpus?
https://aclanthology.org/2020.lrec-1.540/,Can the gamified crowdsourcing platform Rigor Mortis effectively improve the accuracy of MWE annotation in French corpora by increasing the recall of non-fixed MWEs among speakers?
https://aclanthology.org/2020.lrec-1.540/,"Can the training phase of the Rigor Mortis platform improve the annotation results of multi-word expressions in French corpora, as measured by the percentage of correctly annotated MWEs in the PARSEME-FR project?"
https://aclanthology.org/2020.lrec-1.541/,Can a distributional model achieve high accuracy in estimating compositionality of Swedish multi-word expressions by considering syntactically complex constructions and formal specifications of expressions?
https://aclanthology.org/2020.lrec-1.541/,Can the evaluation of a system for automatic compositionality estimation be improved by incorporating human annotations and disagreements between annotators into the model?
https://aclanthology.org/2020.lrec-1.542/,"Can a deep learning-based approach improve the performance of noun compound splitting and idiomatic compound detection in German, and how does the proposed approach compare to the current state of the art in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.543/,"Can idiomatic expressions in text data be identified and disambiguated with high accuracy using a machine learning approach that takes into account the frequency of exposure, familiarity, transparency, and imageability of idioms?"
https://aclanthology.org/2020.lrec-1.543/,"Can a set of pre-trained language resources and tools be developed to improve the reliability and efficiency of idiomatic expression analysis in NLP, psycholinguistics, and second language acquisition research?"
https://aclanthology.org/2020.lrec-1.544/,Can the proposed dataset of annotated MWEs with complexity scores help to improve the accuracy of text simplification models by identifying and handling complex MWEs more effectively?
https://aclanthology.org/2020.lrec-1.544/,"Can the types of MWEs that are most problematic for native and non-native readers be identified through the proposed annotation, and what are the implications for language teaching and learning?"
https://aclanthology.org/2020.lrec-1.545/,Is the use of machine learning algorithms to improve the accuracy of named entity recognition in the Romanian language a feasible approach given the existing corpus size and annotated sentence structure?
https://aclanthology.org/2020.lrec-1.545/,Can the development of a supervised classification model using a Transformer-based architecture for named entity recognition in Romanian improve the processing time and user satisfaction for tasks involving the corpus?
https://aclanthology.org/2020.lrec-1.546/,"Can a semi-supervised approach to automatically de-identification of electronic health records improve recall without sacrificing precision, and what are the implications for the annotation process in a protected environment? Does the use of such an approach reduce the need for human annotators with confidentiality agreements?"
https://aclanthology.org/2020.lrec-1.547/,Can a supervised learning approach using a transformer-based architecture improve the accuracy of Chinese fine-grained entity typing when compared to traditional rule-based methods?
https://aclanthology.org/2020.lrec-1.547/,Can the use of cross-lingual transfer learning enhance the performance of Chinese fine-grained entity typing on a dataset that only contains Chinese text?
https://aclanthology.org/2020.lrec-1.548/,"Can the proposed corpus of annotated Czech historical newspapers improve the accuracy of named entity recognition in historical documents using recurrent neural networks, and how do different embedding techniques affect the performance of NER models in this specific domain? Can the F1 score of NER models be further improved by incorporating domain-specific knowledge into the annotation manual for the corpus?"
https://aclanthology.org/2020.lrec-1.549/,"Can a machine learning approach utilizing deep learning algorithms be used to effectively identify and remove personally identifying information from emails in German-language corpora, while maintaining the integrity of the text and preserving the content of the messages?"
https://aclanthology.org/2020.lrec-1.549/,"Can the pseudonymization of emails in German-language corpora be improved by incorporating a combination of natural language processing techniques, such as named entity recognition and part-of-speech tagging, to enhance the accuracy of the de-identification process?"
https://aclanthology.org/2020.lrec-1.550/,Can machine learning models achieve high accuracy in Named Entity Recognition for German court decisions with a high degree of precision in identifying fine-grained semantic classes? Can time expression recognition using TimeML-based annotations improve the overall performance of NER models for legal documents in the EU project Lynx?
https://aclanthology.org/2020.lrec-1.551/,"Can BERT-based sequence labelling models achieve high accuracy in anonymising clinical data by removing sensitive information, and how do they compare to other anonymisation algorithms in terms of processing time? Can pre-trained BERT models be adapted to improve the efficiency of anonymisation tasks for specific domains, such as clinical data in Spanish?"
https://aclanthology.org/2020.lrec-1.552/,Can the proposed corpus be used to develop and evaluate the performance of a machine learning model for Named Entity Recognition in medical case reports using the Stanford CoreNLP toolkit?
https://aclanthology.org/2020.lrec-1.552/,Can the annotated dataset be utilized to assess the effectiveness of rule-based approaches for Relation Extraction in identifying medical entities and their relationships in case reports?
https://aclanthology.org/2020.lrec-1.553/,Can Hedwig's use of BILSTM models for mention detection outperform the performance of state-of-the-art mention detection models like spaCy's language models?
https://aclanthology.org/2020.lrec-1.553/,Can the integration of a global knowledge base derived from Wikidata and Wikipedia improve the entity linking performance of Hedwig compared to a standalone approach?
https://aclanthology.org/2020.lrec-1.554/,"What are the performance metrics for the animal species name detection tools in the ISTEX platform, and how do they compare to existing tools in the field of zoology?"
https://aclanthology.org/2020.lrec-1.554/,How can the enrichment of scientific documents with named entities recognition improve the accessibility of TDM resources for the French scientific community?
https://aclanthology.org/2020.lrec-1.555/,Can an End-to-End neural approach for named entity recognition be more accurate than a traditional pipeline approach using the latest advancements in speech recognition and NER models?
https://aclanthology.org/2020.lrec-1.555/,"Can an E2E system be capable of performing structured named entity recognition, and what are the benefits of using this approach in comparison to the traditional pipeline approach?"
https://aclanthology.org/2020.lrec-1.556/,"Can a deep learning-based approach using a sequence-to-sequence architecture be used to improve the accuracy of location phrase detection in news articles, measured by precision and recall, compared to traditional rule-based methods? Can the proposed Location Phrase Detection task be extended to detect non-English languages and cultures, and what would be the challenges and requirements for adapting the approach to these languages and contexts?"
https://aclanthology.org/2020.lrec-1.557/,"Can a fine-grained semantic classification model, such as BERT, be adapted to achieve high accuracy on dense labeling of semantic classes in the science exam domain, and if so, what are the optimal hyperparameters for achieving this goal?"
https://aclanthology.org/2020.lrec-1.557/,"Can the use of a densely-labeled corpus, such as ScienceExamCER, improve the performance of off-the-shelf named entity recognition models in the science domain, and if so, what are the key factors contributing to this improvement?"
https://aclanthology.org/2020.lrec-1.558/,Can NorNE's manual annotation of written Norwegian language entities improve the performance of neural sequence labeling models for named entity recognition in Bokmål and Nynorsk languages? Does the use of NorNE's annotated corpus with a neural sequence labeling architecture enhance the accuracy of entity recognition in geo-political entities and products compared to a baseline model?
https://aclanthology.org/2020.lrec-1.559/,"Can the BiodivTagger ontology-based Information Extraction pipeline accurately match materials and data parameters to ontological concepts in biodiversity research data, and how can the issues with matching processes and environmental terms be addressed?"
https://aclanthology.org/2020.lrec-1.559/,Can the proposed QEMP corpus provide a reliable evaluation metric for assessing the performance of the BiodivTagger pipeline in biodiversity research data annotation?
https://aclanthology.org/2020.lrec-1.560/,Can machine learning-based named entity recognition models be trained to accurately identify medical conditions such as lung disease using a standardized annotation guideline that does not require specialized medical knowledge?
https://aclanthology.org/2020.lrec-1.560/,Can the proposed annotation guideline for medical documents reduce the processing time and costs associated with manual annotation of large-scale clinical text data?
https://aclanthology.org/2020.lrec-1.561/,"Can a machine learning model trained on the proposed Dutch NER dataset achieve an F1 score of 0.8 or higher for detecting artefacts in archaeological texts, compared to the baseline model trained on the previous dataset? Can the proposed dataset be used to improve the accuracy of NER models in the archaeology domain beyond the observed improvement of 0.19 in F1 score from the previous work?"
https://aclanthology.org/2020.lrec-1.562/,"Can we develop an accurate and efficient method for identifying medication entities in Medical Incident Reports using named entity recognition (NER) techniques, and what is the impact of using different NER models on the accuracy of medication entity recognition in MIRs?"
https://aclanthology.org/2020.lrec-1.563/,"Can machine learning models trained on the ProGene corpus achieve high accuracy in identifying genes and proteins across different biological domains, measured by precision and recall on the evaluation metrics of F1-score and accuracy, using a combination of named entity recognition and classification algorithms? Can the use of transfer learning with pre-trained language models such as BioBert improve the performance of machine learning models in annotating gene and protein entities in the ProGene corpus, as evaluated by the performance of these models on the task of entity classification and named entity recognition?"
https://aclanthology.org/2020.lrec-1.564/,Can multilingual BERT models achieve state-of-the-art performance on Danish named entity recognition when fine-tuned on the DaNE dataset versus when fine-tuned on a larger Bokmål (Norwegian) dataset?
https://aclanthology.org/2020.lrec-1.564/,"Can the Danish BERT model fine-tuned on the DaNE dataset outperform other architectures, including FLAIR and monolingual (Danish) BERT, in supervised named entity recognition tasks?"
https://aclanthology.org/2020.lrec-1.565/,"Can a BERT-based system achieve high accuracy in Named Entity Recognition (NER) on fine-grained labeled data with extended categories, including AGE and LAN(guage), in both in-domain and cross-domain testing?"
https://aclanthology.org/2020.lrec-1.565/,"Can the proposed fine-grained NER inventory be successfully adapted to other languages, including German, and what are the performance differences compared to the 4-category NER inventory on the GermEval 2014 dataset?"
https://aclanthology.org/2020.lrec-1.566/,Can machine learning models achieve high precision and recall for named entity recognition in Finnish texts drawn from diverse domains using the newly introduced Turku NER corpus?
https://aclanthology.org/2020.lrec-1.566/,"Does the use of manually annotated datasets improve the performance of machine learning models for named entity recognition in Finnish, compared to single-domain corpora?"
https://aclanthology.org/2020.lrec-1.567/,Can BiLSTM-CRF neural networks with Word Embeddings and Flair Embeddings outperform the results obtained with Stacked Embeddings in Portuguese NER tasks in the Geology domain?
https://aclanthology.org/2020.lrec-1.567/,Can the use of domain-specific versus generalized Flair Embeddings affect the performance of a BiLSTM-CRF neural network in the Geology domain for Portuguese NER?
https://aclanthology.org/2020.lrec-1.568/,"Can a machine learning approach be developed to improve the accuracy of named entity recognition in the French TreeBank by leveraging the pre-annotated referential information, and what metrics can be used to evaluate its performance in terms of precision and recall?"
https://aclanthology.org/2020.lrec-1.568/,"Can the integration of the pre-annotated referential information into a deep learning model be used to improve the contextual understanding of named entities in the French language, and what impact would this have on downstream applications such as question answering and text summarization?"
https://aclanthology.org/2020.lrec-1.569/,"Can the proposed methodology improve the accuracy of named entity recognition in Chinese text when OCR output is tied to character locations on the page, and how does it compare to traditional re-annotation methods?"
https://aclanthology.org/2020.lrec-1.569/,Does the proposed alignment of OCR output to transcribed text improve the performance of NER systems in terms of processing time and syntactic correctness?
https://aclanthology.org/2020.lrec-1.570/,"Does the use of deep learning methods improve the accuracy of Named Entity Recognition in a type-based corpus, and does the model learn new types of named entities during the training process? Can data curation, randomization, and deduplication improve the performance of the model in annotating new types of named entities?"
https://aclanthology.org/2020.lrec-1.571/,"How can the accuracy of MucLex, a German lexicon for surface realisation, be evaluated using a combination of human annotation and automated metrics, and what features of the lexicon contribute to its effectiveness in generating correct language?"
https://aclanthology.org/2020.lrec-1.571/,"Can the integration of MucLex with other language resources, such as machine learning models or linguistic resources, enhance the quality and efficiency of surface realisation tasks in languages like German with many irregular word forms?"
https://aclanthology.org/2020.lrec-1.572/,How can a GPT-2 based framework effectively incorporate form-specific details into the training process to improve the structural coherence of generated Chinese classical poems?
https://aclanthology.org/2020.lrec-1.572/,"Can the proposed form-stressed weighting method improve the control over the form of generated poems, particularly for those forms with longer body lengths in Chinese classical poetry?"
https://aclanthology.org/2020.lrec-1.573/,"Can the proposed methods for generating Japanese captions that describe human actions achieve high accuracy in identifying the scene, person, and action described in a video, as measured by the F1-score of the named entity recognition task? Can the developed dataset be used as a benchmark for evaluating the performance of caption generation models in capturing the essential details of human actions in Japanese videos?"
https://aclanthology.org/2020.lrec-1.574/,"Can the proposed Decode with Template model effectively disentangle the original sentiment from input sentences by masking explicit sentiment words and utilizing the remaining parts as templates, and does this process preserve the semantic content of the input sentences?"
https://aclanthology.org/2020.lrec-1.574/,Does the bidirectionally guided VAE model used in the proposed method capture both forward and backward contextual information to generate output sentences that preserve the semantic content of the input sentences?
https://aclanthology.org/2020.lrec-1.575/,Can a combination of Best Student Forcing (BSF) and an ensemble of discriminators improve the training stability and diversity of Generative Adversarial Nets (GANs) in Natural Language Generation (NLG) compared to conventional Maximum Likelihood Estimation (MLE) models?
https://aclanthology.org/2020.lrec-1.575/,"Can the proposed BSF training mechanism and ensemble of discriminators effectively capture the sample quality and diversity of generated sequences in NLG, as measured by Fr ́ech ́et Distance?"
https://aclanthology.org/2020.lrec-1.576/,"Can ACCESS model improve the simplification of sentences for different audiences by adjusting the amount of paraphrasing, lexical complexity, and syntactic complexity?"
https://aclanthology.org/2020.lrec-1.576/,"Can ACCESS model achieve better performance on simplification benchmarks by optimizing parameters such as length, paraphrasing, lexical complexity, and syntactic complexity?"
https://aclanthology.org/2020.lrec-1.577/,"What is the most effective way to utilize Natural Language Generation to augment existing clinical datasets for NLP model development, considering the constraints of patient confidentiality and data availability?"
https://aclanthology.org/2020.lrec-1.577/,"How can the proposed methodology of generating sequence-to-sequence patient information be improved to achieve higher performance on downstream clinically relevant tasks, and what are the key challenges that need to be addressed?"
https://aclanthology.org/2020.lrec-1.578/,"Can a Long Short Term Memory (LSTM) network with character embeddings, word embeddings, and POS tag embeddings be used to generate accurate multi-sentenced Mathematical Word Problems (MWPs) in morphologically rich languages such as Sinhala and Tamil?"
https://aclanthology.org/2020.lrec-1.578/,"Can the use of attention mechanisms in LSTM networks improve the accuracy of MWP generation for languages with complex morphological and syntactic features, such as Sinhala and Tamil?"
https://aclanthology.org/2020.lrec-1.579/,"Can the use of Google's Tesseract 4.0 OCR engine improve the accuracy of word embeddings learned from historical news archives, and what is the optimal approach to balancing the trade-off between temporal variability and ideological consistency in word embeddings?"
https://aclanthology.org/2020.lrec-1.579/,"Can the visualization of word embeddings across time and archives using interactive scatter plots provide insights into the evolution of word representation in the left-right political spectrum, and what are the key factors influencing this evolution?"
https://aclanthology.org/2020.lrec-1.580/,"Can GGP model capture more topical and functional information than existing post-processing models by incorporating a glossary in the post-processing stage, and what is the average improvement in word topical/functional similarity when comparing GGP model with state-of-the-art models on six word topical/functional similarity datasets?"
https://aclanthology.org/2020.lrec-1.581/,"Can contextual embeddings improve the performance of text classification tasks when using smaller training sets, and how do the quality of these embeddings compare to baseline non-contextual FastText embeddings in terms of accuracy?"
https://aclanthology.org/2020.lrec-1.581/,"Can the precomputed ELMo embeddings for languages such as Croatian, Estonian, Finnish, Latvian, Lithuanian, Slovenian, and Swedish be improved through the use of larger training sets?"
https://aclanthology.org/2020.lrec-1.582/,Can specialized embeddings improve the performance of universal embeddings for natural language understanding tasks in the biomedical domain compared to using only universal embeddings?
https://aclanthology.org/2020.lrec-1.582/,Do combining specialized embeddings with universal embeddings help achieve better results on topic modeling and named entity disambiguation tasks in the biomedical domain compared to using only universal embeddings?
https://aclanthology.org/2020.lrec-1.583/,Can second-order Recurrent Neural Networks outperform first-order RNNs in character-level recurrent language modeling when the state space and interaction space are adjusted accordingly?
https://aclanthology.org/2020.lrec-1.583/,Does the removal of the first-order terms in a second-order RNN impact its performance in character-level recurrent language modeling when compared to models with the first-order terms?
https://aclanthology.org/2020.lrec-1.584/,"How can word embeddings for Danish be improved to better reflect the distinction between semantic similarity and relatedness, and what evaluation metrics should be used to measure this improvement?"
https://aclanthology.org/2020.lrec-1.584/,"Can a human-generated dataset for Danish word embeddings be designed to effectively capture the nuances of semantic similarity and relatedness, and what are the implications for future research in this area?"
https://aclanthology.org/2020.lrec-1.585/,Can word embeddings trained on Urban Dictionary improve the performance of sentiment analysis tasks on social media data compared to embeddings trained on standard pre-trained embeddings such as GloVe or Word2Vec?
https://aclanthology.org/2020.lrec-1.585/,Do word embeddings trained on Urban Dictionary exhibit comparable performance to those trained on larger pre-trained embeddings like BERT or XLNet in word clustering tasks?
https://aclanthology.org/2020.lrec-1.586/,What is the impact of incorporating semantic networks on the performance of word embeddings in representing out-of-vocabulary words?
https://aclanthology.org/2020.lrec-1.586/,How does the two-stage representation learning approach affect the coverage of words and the performance of neural models in tasks that rely on pre-trained word embeddings?
https://aclanthology.org/2020.lrec-1.587/,"Can monolingual models trained on larger Basque corpora achieve state-of-the-art results in downstream NLP tasks, and what is the impact of the size and quality of the training corpus on the performance of these models?"
https://aclanthology.org/2020.lrec-1.588/,How do different evaluation metrics correlate with each other in predicting the performance of word embeddings on various natural language processing tasks?
https://aclanthology.org/2020.lrec-1.588/,What are the specific aspects of word embeddings that can be quantified and measured using complementary datasets?
https://aclanthology.org/2020.lrec-1.589/,What are the effects of incorporating morphological and syntactic annotations on the performance of a vector space model in answering questions with specific types of elements?
https://aclanthology.org/2020.lrec-1.589/,Can a modified CBOW-tag algorithm that includes representation of original word forms and their annotation simultaneously improve the efficiency of nearest neighbour queries in a corpus with unannotated elements and different annotations?
https://aclanthology.org/2020.lrec-1.590/,"Can a transformer-based architecture be used to identify the location of zero copulas in Hungarian nominal predicates with high precision and recall, and what are the most effective sampling methods for training such a model? Can the proposed tool be used to compile a large corpus of Hungarian sentences with annotated zero copulas for corpus-based linguistic research?"
https://aclanthology.org/2020.lrec-1.591/,"Can the proposed method improve the detection of diachronic semantic shifts in multilingual text data compared to existing methods, using a single, unified model trained on a single language corpus?"
https://aclanthology.org/2020.lrec-1.591/,"Can the proposed method reduce the time complexity of diachronic semantic shift detection by using time-specific word representations generated from BERT embeddings, without requiring large-scale domain adaptation?"
https://aclanthology.org/2020.lrec-1.592/,"How does the use of vetted terminology in neural machine translation affect the accuracy of translations, measured by the F1-score of approved terminological content in MT output?"
https://aclanthology.org/2020.lrec-1.592/,"Can the LSTM attention mechanism improve the injection of approved terminology into NMT alignments during decoding, as evaluated by the precision of matched tokens in the source and target languages?"
https://aclanthology.org/2020.lrec-1.593/,Can Word Embeddings trained on a diverse corpus of 4.9 billion tokens outperform those trained on a less textually diverse corpus in achieving semantic and syntactic relations?
https://aclanthology.org/2020.lrec-1.593/,Do the extrinsic tasks of Named Entity Recognition and Semantic Similarity between Sentences benefit from the use of batch training in Word Embeddings models?
https://aclanthology.org/2020.lrec-1.594/,How can the use of Universal Sentence Encoder for sentence representation impact the performance of classical machine learners in detecting reading absorption in social book reviews?
https://aclanthology.org/2020.lrec-1.594/,Can fine-tuning sentence embedding vector representations improve the accuracy of neural classifiers in recognizing absorption in user-generated reviews?
https://aclanthology.org/2020.lrec-1.595/,Can the proposed Arabic ontology for infectious diseases achieve high accuracy in term extraction using TF-IDF and C-value methods compared to the YAKE method in a quantitative evaluation?
https://aclanthology.org/2020.lrec-1.595/,Can the manual extraction of relations for infectious disease concepts improve the semantic web's ability to monitor the spread of infectious diseases via social media among Arabic-speaking populations?
https://aclanthology.org/2020.lrec-1.596/,"How do different evaluation strategies for aligning Wikipedia articles with WordNet synsets compare in terms of accuracy and processing time, and what are the implications for the creation of new wordnets in other languages?"
https://aclanthology.org/2020.lrec-1.596/,"What are the key sense relations in WordNet that are most relevant to the evaluation of alignments between WordNet and Wikipedia articles, and how do these relations impact the quality of the alignments?"
https://aclanthology.org/2020.lrec-1.597/,"Can the MWN.PT WordNet's construction methodology, which involves a three-step projection, validation with alignment, and completion process, be improved to increase the number of lexical units and enhance the semantic accuracy of the wordnet for Portuguese?"
https://aclanthology.org/2020.lrec-1.597/,"Can the integration of MWN.PT WordNet with other language wordnets, such as English WordNet, enable the development of a more comprehensive and cross-lingually consistent lexical database for the Portuguese language?"
https://aclanthology.org/2020.lrec-1.598/,"Is the proposed Ontology-Style Relation annotation approach beneficial for converting relation annotations to Resource Description Framework triples, and does it improve the performance of neural NER tools when compared to conventional annotations? Can the OSR-RoR corpus be effectively used to develop and evaluate machine learning models for Relation Extraction tasks in the context of traffic rules annotation?"
https://aclanthology.org/2020.lrec-1.599/,"How does the proposed ontology of the Bulgarian Dialects enable efficient information retrieval for dialectologists, and what specific diagnostic features does it model for dialects spoken abroad?"
https://aclanthology.org/2020.lrec-1.599/,"What is the accuracy of the ontology in capturing the geographical distribution of Bulgarian dialects, and how does it relate to the dialects spoken on the territory of the Republic of Bulgaria?"
https://aclanthology.org/2020.lrec-1.600/,"Can the proposed AMR annotation schema effectively capture fine-grained spatial information in Minecraft dialogues, as measured by the accuracy of spatial relations identified in the annotated data?"
https://aclanthology.org/2020.lrec-1.600/,"Does the use of Minecraft's Cartesian coordinate system in grounding spatial language improve the precision of spatial annotation, as evaluated by the correlation between annotated spatial relations and actual object positions?"
https://aclanthology.org/2020.lrec-1.601/,Can the random walk hyperparameters influence the statistical properties of the generated pseudo-corpora in a manner that affects their usability for training taxonomic word embeddings?
https://aclanthology.org/2020.lrec-1.601/,Can the generated pseudo-corpora exhibit varying levels of semantic coherence and semantic diversity based on the chosen random walk parameters?
https://aclanthology.org/2020.lrec-1.602/,"Can the proposed methodology for standardizing the TriMED terminological database using the ISO/TC 37 standards effectively reduce the complexity of medical terminology and improve user satisfaction, as measured by the accuracy of the standardized data categories and the efficiency of the TBX format implementation? Can the developed data category repository and Web application efficiently manage and provide access to the multilingual terminological records in the TriMED database, ensuring the consistency and quality of the terminological data?"
https://aclanthology.org/2020.lrec-1.603/,"Can an Arabic sentiment analysis model be trained to accurately capture the nuances of metaphorical expressions in Arabic language, and how can this be achieved through the development of a new corpus of annotated metaphors and the application of advanced NLP techniques?"
https://aclanthology.org/2020.lrec-1.603/,"Can the incorporation of metaphors into existing Arabic sentiment analysis tools improve their performance on handling Arabic language data, and what are the key features of the models that need to be updated to accommodate the complexities of Arabic metaphors?"
https://aclanthology.org/2020.lrec-1.604/,"What are the key factors that influence the performance of deep learning-based hotel recommendation models, and how can they be effectively addressed in the context of limited datasets?"
https://aclanthology.org/2020.lrec-1.604/,"Can a deep learning-based hotel recommendation model using textual reviews be trained to achieve high accuracy with a dataset of 50 million samples, and what are the computational resources required to support such a task?"
https://aclanthology.org/2020.lrec-1.605/,"What is the relationship between the formality of naming and the stance expressed towards a German politician in online discourse, and how does this relationship differ between left-leaning and right-leaning users? Does the status-indicating function of naming and titling vary in intensity between the two groups?"
https://aclanthology.org/2020.lrec-1.606/,"Can deep transfer-learning methods using self-supervised domain-specific finetuning and supervised task-specific finetuning achieve state-of-the-art performance on Aspect-Target Sentiment Classification tasks, and how do these methods compare to traditional baseline models in real-world robustness and accuracy on cross-domain evaluations?"
https://aclanthology.org/2020.lrec-1.606/,"Can the use of cross-domain adapted BERT language models improve robustness and performance on Aspect-Target Sentiment Classification tasks, and what are the key factors that influence the effectiveness of this approach in real-world applications?"
https://aclanthology.org/2020.lrec-1.607/,"What is the accuracy of a corpus-based scheme that classifies sentences into four evaluation types using classical machine learning methods, with a focus on the reviewer's opinion on the restaurant?"
https://aclanthology.org/2020.lrec-1.607/,How does the deep learning approach compare to the classical machine learning method in classifying sentences into the four evaluation types with a focus on the reviewer's intention?
https://aclanthology.org/2020.lrec-1.608/,"Can a Bi-RNN model accurately capture the degree of subjectivity in news articles across different levels of reporting, and can it be improved by incorporating geographical closeness of reporting as a feature?"
https://aclanthology.org/2020.lrec-1.608/,"Can the focus shift patterns within a global discourse structure for an event be effectively captured and analyzed using a Bi-RNN model, and how does it compare to existing discourse processing work?"
https://aclanthology.org/2020.lrec-1.609/,Can embedding quality be improved for Arabic sentiment analysis by using morphological and syntactic analysis of words and lemmas in addition to traditional word-level embeddings?
https://aclanthology.org/2020.lrec-1.609/,How does the use of different types of corpora affect the sentiment stability of embeddings in embedding spaces for Arabic sentiment analysis tasks?
https://aclanthology.org/2020.lrec-1.610/,"How can natural language processing techniques be used to identify and analyze the attribution of blame in online vaccination debates with high accuracy, and what metrics can be employed to measure the effectiveness of such approaches?"
https://aclanthology.org/2020.lrec-1.610/,"Can machine learning algorithms be applied to classify and contrast the varying perspectives on vaccinations in the Vaccination Corpus, and what features of the text data are most critical in distinguishing between different viewpoints?"
https://aclanthology.org/2020.lrec-1.611/,"Can Aspect On improve the accuracy of aspect extraction in sentiment analysis by reducing the number of user-posted edits, as measured by the F1 score of the extracted aspects, compared to a traditional post-editing approach? Does Aspect On's online learning mechanism enable users to annotate aspects more efficiently, as indicated by the average time taken to annotate aspects, compared to a baseline approach?"
https://aclanthology.org/2020.lrec-1.612/,"Can a word-embedding-based metric be used to identify a source domain that yields a CDSA model with a precision of over 80% for a target domain, and how does it compare to a sentence-embedding-based metric in terms of precision for the same target domain? Can a supervised learning model using a Transformer-based architecture achieve a precision of over 90% in CDSA when using a novel metric for domain adaptability that evaluates the similarity between source and target domains?"
https://aclanthology.org/2020.lrec-1.613/,"Can a machine learning model be trained to accurately classify narrative phrases as containing an inference with a high degree of precision, measured by accuracy, and can it also distinguish between different types of inferences such as logical and pragmatic inferences?"
https://aclanthology.org/2020.lrec-1.613/,"Can the proposed annotation framework for inference detection and opinion mining be extended to automatically classify the topic and polarity of opinion-bearing sentences with a high degree of accuracy, measured by F1-score?"
https://aclanthology.org/2020.lrec-1.614/,Can the use of linguistic features extracted by Charton et. al. (2014) improve the performance of deep neural models utilizing pretrained embeddings in the first task of the DEFT 2013 shared task?
https://aclanthology.org/2020.lrec-1.614/,Can the integration of pretrained CamemBERT embeddings as input and CNN as the hidden layer improve the performance of deep neural models when additional linguistic features are added?
https://aclanthology.org/2020.lrec-1.615/,Can a supervised classifier using both resource-driven features like WordNet relations and data-driven features such as in-context polarity conflicts be effectively used to determine the shifting direction of polarity shifters?
https://aclanthology.org/2020.lrec-1.615/,Can a supervised classifier trained on a large corpus of text data be able to accurately identify whether a polarity shifter is restricted to a single shifting direction or shifts both positive and negative polar expressions?
https://aclanthology.org/2020.lrec-1.616/,Can Aspect-Based Sentiment Analysis models be developed to improve the accuracy of sentiment classification for Telugu language and how can deep learning methods be utilized to enhance the performance of these models?
https://aclanthology.org/2020.lrec-1.616/,"Can Aspect Term Extraction, Aspect Polarity Classification and Aspect Categorization tasks be effectively automated using machine learning algorithms and what are the potential benefits of annotating Telugu language data for these tasks?"
https://aclanthology.org/2020.lrec-1.617/,"Can NoReC_fine, a dataset for fine-grained sentiment analysis in Norwegian, effectively capture the nuances of polar expressions, targets, and holders of opinion in annotated texts, and how does the use of these annotations improve the performance of a sentiment analysis model on this task?"
https://aclanthology.org/2020.lrec-1.617/,"How do the developed annotation guidelines and inter-annotator agreement analysis impact the quality and reliability of the NoReC_fine dataset for fine-grained sentiment analysis in Norwegian, and what implications does this have for future research in this area?"
https://aclanthology.org/2020.lrec-1.618/,"Is it possible to develop a sarcasm detection algorithm that achieves a high accuracy of at least 90% using a Chinese text dataset with a sufficient number of annotated sarcastic and non-sarcastic texts, and can handle the nuances of Chinese language? Can machine learning models be trained to effectively classify Chinese sarcasm using a balanced dataset with a large number of non-sarcastic texts?"
https://aclanthology.org/2020.lrec-1.619/,"Is the proposed target-based sentiment annotation corpus a feasible method for improving the accuracy of sentiment analysis models in financial text classification, and can it be applied to other domains with entities such as products or services? Can the proposed corpus be used to evaluate the effectiveness of different sentiment analysis models in detecting financial entities' sentiment polarity?"
https://aclanthology.org/2020.lrec-1.620/,"Can a deep neural network based framework be developed to achieve high accuracy in sentiment analysis of tweets from various domains, including terrorism, cybersecurity, and social issues, using an ensemble of CNN, LSTM, and GRU models, and what are the key factors that influence the performance of such a framework?"
https://aclanthology.org/2020.lrec-1.620/,"Can a multi-domain tweet sentiment corpus be created using a combination of human annotation and active learning techniques, and how can the annotation quality be evaluated using Cohen's Kappa measurement, and what are the implications of the annotated corpus on the development of a socially intelligent system to provide security to the public and maintain law and order situations?"
https://aclanthology.org/2020.lrec-1.621/,"Can a transformer-based model achieve better performance than the random baseline on the revised dataset, and how does the reproduction of systems with the new data set impact the evaluation metric of accuracy in the Argument Reasoning Comprehension Task?"
https://aclanthology.org/2020.lrec-1.621/,"Does the removal of data artifacts significantly affect the performance of the reproduced systems, and what are the implications of this finding for the task's difficulty and the need for future research?"
https://aclanthology.org/2020.lrec-1.622/,Can SentiEcon improve the performance of a general-language sentiment analysis tool when used in conjunction with a domain-specific sentiment lexicon in a business news dataset?
https://aclanthology.org/2020.lrec-1.622/,Does the inclusion of SentiEcon's comprehensive sentiment lexicon in a sentence classification task improve accuracy when using sentiment words as features?
https://aclanthology.org/2020.lrec-1.623/,Can a linear classifier trained on a bag-of-words text representation be more accurate than a neural network trained on a transformer word embedding model in sentiment analysis of parliamentary debate speeches? Can the use of a transformer-based model combined with a neural classifier improve the performance of sentiment analysis systems for the political domain?
https://aclanthology.org/2020.lrec-1.624/,"Can Brown clustering improve the detection of offensive language when used as the sole feature in a machine learning model, and how does its performance compare to that of standard word embeddings in a convolutional neural network? Does the combination of Brown clusters with words or character n-grams result in more accurate detection of offensive language than using Brown clusters alone?"
https://aclanthology.org/2020.lrec-1.625/,Can the proposed multi-layer annotation scheme improve inter-annotator agreement for hate speech detection compared to binary classification methods?
https://aclanthology.org/2020.lrec-1.625/,"Can the use of a multi-layer annotation scheme mitigate the impact of annotator variability in defining hate speech, as demonstrated by the MaNeCo corpus?"
https://aclanthology.org/2020.lrec-1.626/,"Can the proposed annotation scheme for irony activators in TWITTIRÒ-UD enhance the development of more accurate irony detection models in sentiment analysis, as measured by the F1-score on a blind test dataset?"
https://aclanthology.org/2020.lrec-1.626/,"Can the incorporation of morpho-syntactic features of irony activators in the annotation scheme improve the classification of irony in tweets, as evaluated by the precision of a supervised learning approach using a transformer-based architecture?"
https://aclanthology.org/2020.lrec-1.627/,"What is the feasibility of using a machine learning model to classify tweets as humorous or not based on the proposed corpus of 30,000 annotated tweets, and what is the accuracy of the model when evaluating its performance on the test set?"
https://aclanthology.org/2020.lrec-1.627/,How does the proposed corpus of annotated tweets with humor value and funniness score impact the performance of a supervised learning approach to humor recognition in natural language processing tasks?
https://aclanthology.org/2020.lrec-1.628/,"Can machine learning models achieve high accuracy in detecting aggressive language in Greek tweets by leveraging the Offensive Greek Tweet Dataset, and what is the optimal feature extraction approach for this task, considering the limited availability of linguistic resources for the Greek language?"
https://aclanthology.org/2020.lrec-1.628/,"Can the use of deep learning techniques improve the performance of offensive language detection models on Greek text, specifically in distinguishing between hate speech and non-hate speech, and what are the key factors affecting the accuracy of these models?"
https://aclanthology.org/2020.lrec-1.629/,Does the regular morphology and semantic affixes of Esperanto result in a more regular syntax and higher parsing accuracy when using automatic syntactic and semantic pre-annotation tools?
https://aclanthology.org/2020.lrec-1.629/,"Can the linguistic structure of Esperanto be effectively analyzed and quantified to address typological issues such as word order, auxiliary constructions, and lexical transparency?"
https://aclanthology.org/2020.lrec-1.630/,"What are the core constructions of the Wolof language that the parsing system covers, including noun classes, cleft, copula, causative and applicative sentences, and what types of coordination does it deal with?"
https://aclanthology.org/2020.lrec-1.630/,"Does the parser's parsing coverage evaluate the parser's ability to disambiguate Wolof sentences accurately, and if so, what metrics are used to measure this accuracy?"
https://aclanthology.org/2020.lrec-1.631/,Can the proposed neural network-based syntactic labeler for Vedic Sanskrit achieve a high accuracy in annotating the language's complex syntactic constructions compared to manual annotation methods within a 90% confidence interval? Can the use of the Universal Dependencies scheme for annotating Vedic Sanskrit sentences improve the overall quality of the treebank and facilitate the development of a full syntactic parser for the language?
https://aclanthology.org/2020.lrec-1.632/,"Does the inherent dependency displacement distribution of a transition-based algorithm have a significant correlation with its parsing performance on a specific treebank, and can this correlation be quantified using a measure of syntactic relation distance and direction?"
https://aclanthology.org/2020.lrec-1.632/,Can the inherent dependency displacement distribution of a transition-based algorithm be accurately predicted using a machine learning model that takes into account the predominant sentence lengths in a Universal Dependency treebank?
https://aclanthology.org/2020.lrec-1.633/,"Can machine learning algorithms be trained to improve the accuracy of Turkish dependency parsing using TWT, and what is the impact of incorporating Wikipedia data on the parsing performance of a baseline model?"
https://aclanthology.org/2020.lrec-1.633/,Can the use of TWT's morpho-syntactic annotations improve the performance of Turkish part-of-speech tagging and how does the addition of a dedicated Wikipedia section affect the overall quality of the treebank?
https://aclanthology.org/2020.lrec-1.634/,"Can a supervised machine learning approach using CRFs effectively identify the discourse type (monologue vs. free talk) in spontaneous speech, and what is the impact of corpus size on the accuracy of the results?"
https://aclanthology.org/2020.lrec-1.634/,"Can a supervised machine learning approach using CRFs improve the performance of existing taggers in identifying speech nature (spontaneous vs. prepared) in spoken data, and how does the approach compare to manual correction methods?"
https://aclanthology.org/2020.lrec-1.635/,"What are the differences in annotation requirements and complexity between manually annotated interview data and existing treebanks based on TIGER guidelines, and how do these differences impact model adaptation and corpus-independent tools in the domain of speech and text analysis?"
https://aclanthology.org/2020.lrec-1.635/,"Can the proposed dataset GRAIN-S, with its combination of gold- and silver-standard annotation layers and high-quality syntax trees, effectively serve as a resource for research into techniques for model adaptation and corpus-independent tools in the context of speech and text analysis?"
https://aclanthology.org/2020.lrec-1.636/,"Can Universal Dependencies be successfully applied to the Yoruba language, and what are the challenges associated with annotating its dependency structure?"
https://aclanthology.org/2020.lrec-1.636/,Can the annotation guidelines developed for the Yoruba language be adapted for use with other low-resource languages in the Niger-Congo family?
https://aclanthology.org/2020.lrec-1.637/,"Can deep learning models be used to accurately annotate recipe named entities with high inter-annotator agreement, and what is the optimal architecture for this task?"
https://aclanthology.org/2020.lrec-1.637/,Can a dependency-style parsing procedure be applied to annotate flow graphs of cooking procedures with high accuracy and efficiency?
https://aclanthology.org/2020.lrec-1.638/,"Can the ABC Treebank improve the performance of a semantic parsing system in generating logical representations of Japanese sentences, as measured by the accuracy of logical representations, compared to existing Japanese CG treebanks like Japanese CCGBank? Does the use of a theory-neutral approach in constructing the ABC Treebank lead to more accurate lexical specifications of local dependencies, particularly for passives, causatives, and control/raising predicates, in comparison to existing CG treebanks?"
https://aclanthology.org/2020.lrec-1.639/,"What are the effects of incorporating word embeddings in a transition-based parser on the parsing results for Urdu language, compared to a parser without word embeddings? Can converting existing Urdu treebanks to a Universal Dependencies format improve the performance of dependency parsers on Urdu language?"
https://aclanthology.org/2020.lrec-1.640/,"Can the Prague Dependency Treebank-Consolidated 1.0 dataset be used to train a machine learning model to improve the accuracy of Czech morphological annotation, with a focus on annotating non-standard language segments typed into a web translator?"
https://aclanthology.org/2020.lrec-1.640/,"Can the PDT-C 1.0 dataset be used to develop a supervised classification model that achieves high accuracy in distinguishing between different genres of Czech texts, with a focus on surface syntactic annotation?"
https://aclanthology.org/2020.lrec-1.641/,"What is the effect of using a multitask learning architecture on the accuracy of a transition-based parser trained on the Eukalyptus treebank, and how does it compare to a traditional training approach?"
https://aclanthology.org/2020.lrec-1.641/,Can a transition-based parser trained on a discontinuous constituent treebank using Eukalyptus improve its performance when fine-tuned on a separate treebank with a different annotation model?
https://aclanthology.org/2020.lrec-1.642/,"Can a bidirectional LSTM model implemented with BERT embeddings significantly improve the accuracy of dependency parsing, as demonstrated by the proposed PaT method's outperformance on the state-of-the-art method on UD languages?"
https://aclanthology.org/2020.lrec-1.642/,"Can the use of relative position-based tagging in dependency parsing improve the accuracy of the PaT method, as evidenced by the improved performance on UD languages compared to the state-of-the-art method?"
https://aclanthology.org/2020.lrec-1.643/,"Can the EDGeS corpus be used to develop and train machine learning models for linguistic analysis of complex verb constructions in Germanic languages, and what would be the optimal evaluation metric for such models?"
https://aclanthology.org/2020.lrec-1.643/,"Can the OPUS search infrastructure be used to efficiently manage and provide access to the EDGeS corpus, and what are the technical requirements for a researcher to access the whole corpus behind a login?"
https://aclanthology.org/2020.lrec-1.644/,"Can machine learning models be trained to accurately capture the linguistic phenomena of user-generated texts in web and social media using the Universal Dependencies framework, and if so, what features of these texts should be included in the annotation guidelines to promote consistent treatment of these phenomena? Does the proposed annotation guidelines for user-generated texts in UD lead to improved cross-linguistic consistency in the annotation of these texts?"
https://aclanthology.org/2020.lrec-1.645/,Can the machine learning models used to create the modern subcorpus of TOROT be fine-tuned to improve the accuracy of Old Church Slavonic text classification tasks?
https://aclanthology.org/2020.lrec-1.645/,Can the incorporation of the TOROT treebank be used to develop a more comprehensive model of the historical development of the Russian language?
https://aclanthology.org/2020.lrec-1.646/,Can the extraction algorithm used to create ÆTHEL's types and derivations accurately capture the complex relationships between syntactic and semantic representations of written Dutch?
https://aclanthology.org/2020.lrec-1.646/,Can the semantic compositionality provided by ÆTHEL's types and derivations improve the accuracy of syntactic analyses in the LASSY Small corpus?
https://aclanthology.org/2020.lrec-1.647/,"Can the proposed corpus effectively reduce licensing problems in natural language processing by providing a large, high-quality dataset for annotating English texts, and what is the accuracy of the dependency trees in the corpus compared to state-of-the-art models?"
https://aclanthology.org/2020.lrec-1.648/,"What are the most typical sentence patterns that verbs in Norwegian appear in, and how can these be used to derive valence information for other verbs with limited training data?"
https://aclanthology.org/2020.lrec-1.648/,Can verb fingerprints be used to identify standard valence patterns in German and compare them against the Norwegian valence profile?
https://aclanthology.org/2020.lrec-1.649/,Can a sentence segmentation tool that uses retrained constituency parsers to transform them into sentence segmenters improve the accuracy of downstream tasks in German dependency parsing by identifying and segmenting recursive sentence structures? Can the proposed sentence segmenter be applied to other languages and tasks to achieve similar improvements in accuracy?
https://aclanthology.org/2020.lrec-1.650/,"Can Arborator-Grew improve the annotation efficiency of syntactic treebanks by utilizing the query capabilities of Grew, as measured by the time taken to create and correct treebanks? Can Arborator-Grew enhance the collaboration and access control features of Arborator by integrating complex query tools and parallel annotation modes, as measured by the accuracy of annotations and user satisfaction?"
https://aclanthology.org/2020.lrec-1.651/,Can the ODIL Syntax treebank be used to investigate the relationship between speech disfluencies and syntactic complexity in spontaneous speech?
https://aclanthology.org/2020.lrec-1.651/,Can the ODIL Syntax corpus be used to evaluate the performance of a parser in annotating temporal entities and temporal relations in French speech?
https://aclanthology.org/2020.lrec-1.652/,"Can a semi-automatic annotation procedure using a dependency parser trained on the Polish Dependency Bank improve the accuracy of morphosyntactic annotations in the National Corpus of Polish, and how does it compare to a model trained on a smaller set of gold-standard trees in predicting part-of-speech tags, morphological features, lemmata, and labelled dependency trees? Can the conversion of dependency trees and morphosyntactic annotations to Universal Dependencies improve the overall quality of the annotated part of the National Corpus of Polish?"
https://aclanthology.org/2020.lrec-1.653/,"Can the use of large colonial languages in borrowing phonological segments be correlated with the rate of linguistic diversity among the world's languages, measured by the number of borrowed segments?"
https://aclanthology.org/2020.lrec-1.653/,Can the universals of borrowing in rhotic consonants be identified and generalized across languages using machine learning models trained on the SegBo database?
https://aclanthology.org/2020.lrec-1.654/,Can the proposed acoustic model for speech segmentation of Quebec French be improved by incorporating diphthongization of long vowels and affrication of coronal stops in the training data?
https://aclanthology.org/2020.lrec-1.654/,Can the adaptation of the French lexicon and the development of a QF-specific pronunciation dictionary enhance the accuracy of the speech segmentation process in Quebec French?
https://aclanthology.org/2020.lrec-1.655/,Can a machine learning model trained on the AlloVera dataset achieve higher accuracy in speech recognition for minority languages than for major languages?
https://aclanthology.org/2020.lrec-1.655/,Can the AlloVera resource enable the development of phonetic transcription models that can accurately transcribe languages with non-standard phonetic representations?
https://aclanthology.org/2020.lrec-1.656/,Can a machine learning approach using deep learning techniques improve the accuracy of speech rhythm analysis for Arabic dialects compared to traditional manual annotation methods?
https://aclanthology.org/2020.lrec-1.656/,Can the proposed corpus be used to develop and evaluate a forensic phonetic analysis tool for identifying and classifying Arabic speech patterns in various speaking styles?
https://aclanthology.org/2020.lrec-1.657/,"Can the Levenshtein method outperform the neural LSTM autoencoder network in measuring dialect similarity in Norwegian, as indicated by a reduction in processing time, and can both methods produce accurate dialect maps comparable to those found in the dialect literature?"
https://aclanthology.org/2020.lrec-1.657/,"Can the use of the LSTM autoencoder network improve the dialect similarity measurements by capturing subtle variations in speech patterns, as measured by user satisfaction ratings?"
https://aclanthology.org/2020.lrec-1.658/,"Can non-native speakers' speech samples be accurately classified using a supervised learning approach with a Transformer-based architecture, and how does the accuracy of the classification change when using unseen data versus seen data?"
https://aclanthology.org/2020.lrec-1.658/,"Can autoencoder models with task-specific architectures effectively neutralize non-native accents to make them sound like native accents, and what is the impact of this transformation on the performance of ASR systems?"
https://aclanthology.org/2020.lrec-1.659/,"What are the linguistic features that are commonly used to evaluate the performance of neural Machine Reading Comprehension systems, and how do they impact the quality of the evaluation data?"
https://aclanthology.org/2020.lrec-1.659/,"Can lexical cues be used as a lower bound for the requirement of understanding in Machine Reading Comprehension tasks, and what metrics can be used to quantify their presence and impact?"
https://aclanthology.org/2020.lrec-1.660/,"How can a BERT-based model be fine-tuned to achieve higher accuracy in question classification, and what role do the size and complexity of annotated data play in this process?"
https://aclanthology.org/2020.lrec-1.660/,"What is the potential impact of using question topic predictions from a BERT-based model on the accuracy of a question answering system, and how can this improvement be measured?"
https://aclanthology.org/2020.lrec-1.661/,How do linguistic features extracted from users' answers impact the reputation of users in CQA forums?
https://aclanthology.org/2020.lrec-1.661/,Can syntactic and punctuation marks significantly improve the performance of baseline models predicting users' reputation in CQA forums?
https://aclanthology.org/2020.lrec-1.662/,"Can domain adaptation models learn general linguistic intelligence through multi-task learning of language modeling and reading comprehension, and how can this approach improve the performance of reading comprehension models on out-of-domain datasets?"
https://aclanthology.org/2020.lrec-1.662/,Does sequential learning of language modeling and reading comprehension improve the ability of models to generalize to out-of-domain datasets in unsupervised domain adaptation of reading comprehension?
https://aclanthology.org/2020.lrec-1.663/,"Is the proposed graph neural network, propagate-selector (PS), able to improve the performance of question-answering models by leveraging the intersentential relationship between sentences? Can the proposed iterative attentive aggregation and skip-combine method effectively accumulate information from neighboring nodes in the graph structure to improve the accuracy of sentence understanding?"
https://aclanthology.org/2020.lrec-1.664/,What is the classification accuracy of recent language models in question answering systems for low-resourced languages compared to methods relying on external resources?
https://aclanthology.org/2020.lrec-1.664/,How does the dependency on external resources impact the performance of question classification models in low-resourced languages?
https://aclanthology.org/2020.lrec-1.665/,"What is the effectiveness of the proposed cross-sentence context-aware architecture in capturing contextual information between adjacent word positions, and how does it compare to existing models in terms of semantic matching accuracy?"
https://aclanthology.org/2020.lrec-1.665/,Does the proposed interactive attention mechanism with a pre-trained language model enhance the relevance of answer representations by effectively identifying salient positional representations and accounting for the impact of context information from adjacent word positions?
https://aclanthology.org/2020.lrec-1.666/,"Can existing machine reading comprehension models be made more robust to adversarial perturbations by incorporating unanswerability annotations into their training data, and can the SQuAD2-CR dataset help identify the specific parts of the question that cause a model to mark a question as unanswerable?"
https://aclanthology.org/2020.lrec-1.667/,"Can the proposed role play-based question answering framework effectively utilize user-generated question-answer pairs with meta information to train neural conversational models that can generate utterances reflecting specific emotions, and what are the key factors that influence the accuracy of these models in capturing emotional nuances?"
https://aclanthology.org/2020.lrec-1.667/,"Can the use of meta information such as emotion and intimacy in training neural conversational models lead to more realistic and engaging user interactions, and how can this be evaluated using metrics such as user satisfaction or syntactic correctness?"
https://aclanthology.org/2020.lrec-1.668/,"What are the effects of using unsupervised baselines versus supervised training on the matching of variations with their original questions in the AIA-BDE corpus, in terms of accuracy and computational resources?"
https://aclanthology.org/2020.lrec-1.668/,"Can an Information Retrieval system achieve competitive performance when considering only the first hit in a search result, and what are the implications for FAQ retrieval and automatic question-answering tasks?"
https://aclanthology.org/2020.lrec-1.669/,"What are the most effective granularities for identifying instructional details in screencast tutorial videos, and how can they be evaluated using metrics such as precision, recall, and F1-score in the context of video-question answering tasks?"
https://aclanthology.org/2020.lrec-1.669/,"How can the development of a more comprehensive and diverse dataset for video-question answering tasks, such as TutorialVQA, facilitate the investigation of new algorithms and improve the overall performance of existing models on identifying answer spans in instructional videos?"
https://aclanthology.org/2020.lrec-1.670/,"Can multi-hop inference models learn to generate accurate explanations for complex questions by combining large numbers of facts, as measured by the F1 score of the generated explanations, using the WorldTree corpus of 5,114 standardized science exam questions paired with large detailed multi-fact explanations?"
https://aclanthology.org/2020.lrec-1.670/,"Can the development of high-level science domain inference patterns using the WorldTree corpus improve the performance of multi-hop inference models in generating explanations for complex questions, as evaluated by the accuracy of the generated explanations?"
https://aclanthology.org/2020.lrec-1.671/,"What is the effectiveness of using a sequence-to-sequence chatbot in a voice-based conversational agent compared to a QA system, in terms of user satisfaction and conversational flow?"
https://aclanthology.org/2020.lrec-1.671/,How does the use of coreference resolution improve the chatbot's ability to detect relatedness between questions and provide relevant answers to user queries?
https://aclanthology.org/2020.lrec-1.672/,"Is the proposed dataset collection and annotation tool designed to address the lack of data for non-English languages specifically for downstream tasks like Question Answering, and what metrics will be used to evaluate its effectiveness in annotating French text data? Can the publicly released dataset be used to train and evaluate machine learning models for Question Answering tasks in French with high accuracy and precision?"
https://aclanthology.org/2020.lrec-1.673/,"Can a multilingual BERT model achieve better performance on a Machine Reading Comprehension task on a French dataset than on an English dataset, and what are the key factors that influence this difference?"
https://aclanthology.org/2020.lrec-1.673/,"Can the cross-lingual performance of a BERT model on a Machine Reading Comprehension task be improved by fine-tuning the model on a specific domain, and how does this approach compare to fine-tuning on the language itself?"
https://aclanthology.org/2020.lrec-1.674/,Can a supervised learning approach using a Transformer-based architecture improve the F1 score of the Bi-Directional Attention Flow (BiDAF) network for Reading Comprehension tasks on ScholarlyRead dataset to over 40%?
https://aclanthology.org/2020.lrec-1.674/,Can the semi-automatic construction of the ScholarlyRead dataset using question generation and human annotation impact the accuracy of the proposed BiDAF-based QA system for scientific articles?
https://aclanthology.org/2020.lrec-1.675/,"Does the integration of contextualized word embeddings with the transformer encoder improve the performance of sentence similarity modeling in the answer selection task, and how does fine-tuning a pre-trained transformer encoder model compare to a feature-based approach that incorporates ELMo and BERT embeddings?"
https://aclanthology.org/2020.lrec-1.676/,"Can the Translate Align Retrieve method improve the performance of multilingual question answering systems by translating the Stanford Question Answering Dataset to Spanish, and what is the F1 score achieved by the resulting models on the Spanish MLQA and XQuAD benchmarks?"
https://aclanthology.org/2020.lrec-1.677/,"How can the incorporation of verb semantic information into VQA systems improve their performance on questions that focus on events described by verbs, and what are the most effective methods for training models with semantic role labels, argument types, and frame elements? Can the use of frameNet-based semantic frame elements enhance the accuracy of VQA systems in handling questions that rely on event description via verbs?"
https://aclanthology.org/2020.lrec-1.678/,Can a pre-trained Transformer model fine-tuned on open-domain and biomedical corpora outperform one fine-tuned on a combination of biomedical and clinical corpora on the CliCR dataset?
https://aclanthology.org/2020.lrec-1.678/,Does fine-tuning a Transformer model on SQuAD improve its clinical question-answering performance on the emrQA dataset?
https://aclanthology.org/2020.lrec-1.679/,"Can a collaborative research challenge be designed to effectively promote the reproduction of research results in the field of Computer Science and Information Technology, and if so, what evaluation metric would be most suitable to measure its success? Can the use of collaborative research challenges lead to a reduction in the time and effort required to verify and replicate existing research results?"
https://aclanthology.org/2020.lrec-1.680/,"Can a robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings be effectively applied to languages with low semantic similarity to English, and what are the optimal hyperparameters for achieving this goal?"
https://aclanthology.org/2020.lrec-1.680/,"Can the stability of a self-learning model be evaluated using a grid search approach, and how do the results of this evaluation impact the applicability of the model to real-world language learning tasks?"
https://aclanthology.org/2020.lrec-1.681/,"How does the unsupervised cross-lingual word embeddings mapping method's performance change when using different types of embeddings, such as word2vec and glove?"
https://aclanthology.org/2020.lrec-1.681/,"What is the effect of varying the method's parameters on the final result, particularly in terms of accuracy and processing time?"
https://aclanthology.org/2020.lrec-1.682/,Can a meta-BiLSTM model achieve state-of-the-art results on morphological tagging tasks by integrating sentence-level and single-word context through synchronized training by a meta-model?
https://aclanthology.org/2020.lrec-1.682/,Can the choice of reporting methods and experimental design significantly impact the reliability and reproducibility of the results in NLP research?
https://aclanthology.org/2020.lrec-1.683/,Can a machine learning approach using a supervised learning method with a pre-trained language model be effective in identifying and classifying relations in abstracts from computational linguistics publications?
https://aclanthology.org/2020.lrec-1.683/,"Can the reproduction of top-performing systems on SemEval-2018 Task 7 improve understanding of best practices for NLP tasks, particularly in relation to data preprocessing and feature extraction?"
https://aclanthology.org/2020.lrec-1.684/,"Can a supervised learning approach using a transformer-based architecture be applied to improve the accuracy of sentiment analysis on the Splits2 dataset, and how does the model's performance compare to a traditional rule-based approach? Does the use of transfer learning from a large language model improve the processing time of sentiment analysis on the Splits2 dataset?"
https://aclanthology.org/2020.lrec-1.685/,"Can CombiNMT systems be improved by incorporating more diverse training datasets, and how does the cosine similarity threshold impact the quality of the simplified text, specifically in terms of the number of changes and percentage of correct changes? Can CombiNMT systems achieve higher accuracy when trained on datasets with a higher cosine similarity threshold, and what are the implications for text simplification tasks?"
https://aclanthology.org/2020.lrec-1.686/,Can a model trained on dependency n-grams improve the accuracy of CEFR level classification for multilingual texts using a K-fold cross-validation schema?
https://aclanthology.org/2020.lrec-1.686/,Can the use of syntactic n-grams and classical readability indices be more effective than text length features in cross-lingual CEFR level classification using regression analysis?
https://aclanthology.org/2020.lrec-1.687/,"Can the use of a different implementation of the original AES system improve its performance on a different dataset and language, as measured by the F1-score of automatic essay scoring?"
https://aclanthology.org/2020.lrec-1.687/,"Can the choice of dataset and evaluation metrics used in the original AES system affect the accuracy of the results, as measured by the standard deviation of the F1-scores across different experiments?"
https://aclanthology.org/2020.lrec-1.688/,"Can a feature-based approach achieve higher accuracy in CEFR classification of Czech, German, and Italian texts than a neural network classifier?"
https://aclanthology.org/2020.lrec-1.688/,Can the introduction of adversarial data improve the robustness of neural network classifiers in text datasets?
https://aclanthology.org/2020.lrec-1.689/,"Can the proposed approach to Automatic Essay Scoring be improved for English language by incorporating a larger corpus and retraining the model, and what is the impact on the system's scalability and accuracy?"
https://aclanthology.org/2020.lrec-1.689/,"Does the use of a more advanced algorithm, such as a deep learning model, improve the system's performance on the English language corpus, and can it be applied to other languages?"
https://aclanthology.org/2020.lrec-1.690/,Can neural networks trained with Nematus Neural Machine Translation (NMT) toolkit and Byte Pair Encoding (BPE) produce better results than those using a more granular syntactic and semantic annotation on the EN-FR and EN-DE Europarl aligned corpora?
https://aclanthology.org/2020.lrec-1.690/,Can the use of feature ablation techniques improve the results of neural machine translation models trained with a limited set of syntactic and semantic annotations?
https://aclanthology.org/2020.lrec-1.691/,"Can KGvec2go improve the performance of downstream applications by leveraging pre-trained graph embeddings in a lightweight manner, as measured by the accuracy of semantic benchmark evaluations?"
https://aclanthology.org/2020.lrec-1.691/,"Can the combination of multiple pre-trained graph embeddings in KGvec2go lead to better outcomes than individual models, as measured by the processing time and user satisfaction in downstream applications?"
https://aclanthology.org/2020.lrec-1.692/,"Can machine learning techniques, specifically convolutional neural networks, improve the accuracy of ontology alignment by utilizing character embeddings and superclasses, and how do these results compare to traditional string metrics and structure analysis in terms of performance on different domains? Can the proposed methodology be applied to large-scale ontology alignment tasks with varying degrees of overlap and complexity?"
https://aclanthology.org/2020.lrec-1.693/,Is the proposed approach to validate terminological data from WIKIDATA using the x-bar theory and multidimensional theory of terminology effective in ensuring data accuracy in the Linguistic Linked Open Data cloud? Can the use of CONCEPTNET as a validation tool improve the reliability of the RDF data in the cloud?
https://aclanthology.org/2020.lrec-1.694/,"Can the proposed methodology for building data value chains in Prêt-à-LLOD be applied to other linguistic data domains beyond language resources and language technologies, and what are the challenges that may arise during such applications?"
https://aclanthology.org/2020.lrec-1.694/,"What metrics will be used to evaluate the interoperability of the LLOD data sets and services ported to other infrastructures, and how will the porting process be affected by the differences in semantic technologies used by each infrastructure?"
https://aclanthology.org/2020.lrec-1.695/,"How can the integration of modular, linked ontologies like CLARIN Concept Registry and LexInfo improve the standardization of linguistic annotation schemes in the field of Natural Language Processing?"
https://aclanthology.org/2020.lrec-1.695/,Can the use of Universal Dependencies and UniMorph to create a unified annotation framework for linguistic resources be beneficial for the development of more accurate and efficient NLP models?
https://aclanthology.org/2020.lrec-1.696/,"How can we design and train a machine learning model to accurately resolve location metonymy in large volumes of text, given the constraints of the proposed WiMCor corpus?"
https://aclanthology.org/2020.lrec-1.696/,"Can we develop a deep learning-based approach to improve the coverage and accuracy of metonymy resolution systems using the WiMCor corpus, with a focus on improving the annotation granularity?"
https://aclanthology.org/2020.lrec-1.697/,"Can the use of reified I/O logic to formalize if-then rules in LegalRuleML improve the accuracy of rule-based systems in enforcing GDPR provisions, as measured by the number of correctly identified data breaches?"
https://aclanthology.org/2020.lrec-1.697/,"Does the integration of the D-KB with the Privacy Ontology enhance the expressiveness of deontic statements in LegalRuleML, as evaluated by the number of applicable constraints in the D-KB?"
https://aclanthology.org/2020.lrec-1.698/,What is the effect of using the Decomp toolkit with the Universal Decompositional Semantics (UDS) dataset on the processing time of semantic graph queries using SPARQL?
https://aclanthology.org/2020.lrec-1.698/,Can the UDS dataset improve the accuracy of decompositional semantics-aligned annotation sets by providing a unified semantic graph specification through the Decomp toolkit?
https://aclanthology.org/2020.lrec-1.699/,"Can neural embeddings be improved to match the thematic fit estimation of syntax-based count models by incorporating dependency-based embeddings, and what is the key factor that determines the performance of these models in this task?"
https://aclanthology.org/2020.lrec-1.700/,"Can machine learning models achieve high accuracy in detecting Chinese irony using the Ciron dataset, and what features of the dataset contribute to its effectiveness in this task? Does the use of Ciron improve the performance of machine learning models on irony detection compared to existing benchmark datasets?"
https://aclanthology.org/2020.lrec-1.701/,"Do edits to instructional texts improve their clarity and effectiveness in achieving the intended goal, as measured by user satisfaction and task completion rates, or do they primarily serve to update the style and correctness of the instructions? Can machine learning models be trained to distinguish between sentence-level edits that provide clarifications and those that only update style and correctness?"
https://aclanthology.org/2020.lrec-1.702/,"What is the relationship between the use of modal verbs and the strength of conviction towards vaccination in social media discourse, measured by the frequency of phrases such as 'one must vaccinate' versus 'one should vaccinate'?"
https://aclanthology.org/2020.lrec-1.702/,"How do modal auxiliaries in online blogs and social media influence public perception of vaccine necessity and safety, as evaluated by the proportion of text that uses phrases such as 'too many vaccines at once could hurt my child'?"
https://aclanthology.org/2020.lrec-1.703/,"What is the effect of using Transfer Learning with BERT on the performance of Negation Detection and Scope Resolution in biomedical text, and how does it compare to previous state-of-the-art systems?"
https://aclanthology.org/2020.lrec-1.703/,"Can NegBERT, a model that uses Transfer Learning with BERT, achieve high accuracy in scope resolution on unseen datasets, and what are the implications of its generalizability?"
https://aclanthology.org/2020.lrec-1.704/,Can the proposed methodology efficiently handle lexical ambiguity by categorizing verbs into broad semantic classes before fine-grained spatial similarity judgments?
https://aclanthology.org/2020.lrec-1.704/,Can the large-scale verb resource developed with this methodology be used to improve the performance of NLP systems in terms of accuracy in verb similarity evaluations?
https://aclanthology.org/2020.lrec-1.705/,"Can machine learning algorithms using WordNet and BabelNet be effectively used to automate the sense annotation of a large corpus of text, and what is the most efficient method for integrating these lexical resources into a deep supervised system for Word Sense Disambiguation? Can semi-automatic methods using Wikipedia for sense annotation be as accurate as manual annotation methods for a given dataset?"
https://aclanthology.org/2020.lrec-1.706/,Can the network embedding of a distributional thesaurus improve the accuracy of binary classification tasks such as co-hyponymy vs hypernymy and co-hyponymy vs meronymy in NLP?
https://aclanthology.org/2020.lrec-1.706/,Can the node2vec algorithm on a distributional thesaurus improve the vector representation of words to detect co-hyponymy relations more effectively than existing state-of-the-art models?
https://aclanthology.org/2020.lrec-1.707/,"Can deep learning algorithms effectively detect negation and uncertainty in biomedical texts in Spanish, as validated by the preliminary experiments on the NUBes corpus?"
https://aclanthology.org/2020.lrec-1.707/,"Can the NUBes corpus serve as a valuable resource for training machine learning models that can accurately detect negation and uncertainty in biomedical texts, and what are the implications for future research in this area?"
https://aclanthology.org/2020.lrec-1.708/,"Can a supervised learning approach using SHARel's linguistic and reason-based categories improve the accuracy of paraphrasing detection in a large corpus, as measured by the F1-score? Does the frequency and distribution of linguistic and reason-based phenomena in textual entailment, contradiction, and specificity relations affect the performance of a deep learning-based model on a given task, as evaluated by precision and recall metrics?"
https://aclanthology.org/2020.lrec-1.709/,"Can a supervised machine learning model using a pre-trained language model as a feature extractor accurately predict the most common name for an object from a dataset of 25K images, with a precision of at least 90% and a recall of 80%?"
https://aclanthology.org/2020.lrec-1.709/,"Can the hierarchical variation in naming, such as ""chihuahua"" vs. ""dog"", be modeled using a hierarchical clustering algorithm, with an accuracy of at least 85% and a normalized mutual information of 0.7?"
https://aclanthology.org/2020.lrec-1.710/,Can sense embedding models effectively capture the nuances of polysemy when trained on datasets with a high proportion of single-sense words?
https://aclanthology.org/2020.lrec-1.710/,Can multi-sense models perform better than their single-sense counterparts when evaluated on a benchmark dataset with a high ratio of multi-sense word pairs?
https://aclanthology.org/2020.lrec-1.711/,What is the impact of the proposed approach on reducing the workload on annotators in the task of interpreting verb-noun metaphoric expressions in text?
https://aclanthology.org/2020.lrec-1.711/,"How does the use of external lexical resources, word embeddings, and semantic similarity in the automatic retrieval approach affect the accuracy of metaphor interpretation in tweets?"
https://aclanthology.org/2020.lrec-1.712/,"How do the performance of different French dependency parsers compare when generating distributional thesauri based on frequency, and what is the impact of using these thesauri on identifying relevant subsets among the parsers?"
https://aclanthology.org/2020.lrec-1.712/,Can a distributional benchmark be used to confirm the similarity between parsers identified through frequency-based thesauri generation without reference data?
https://aclanthology.org/2020.lrec-1.713/,"Can a neural semantic parser be trained to accurately translate medical eligibility criteria into executable SQL queries, considering the nuances of order-sensitive, counting-based, and boolean-type queries, and evaluate its performance using metrics such as precision, recall, and F1-score?"
https://aclanthology.org/2020.lrec-1.713/,"Can the proposed neural semantic parser be improved to handle the complexities of clinical trial data, including the need for fast processing times, high accuracy, and adaptability to varying data structures and query languages?"
https://aclanthology.org/2020.lrec-1.714/,"Can a distributional approach based on an attention-based transformer be used to improve the accuracy of relation recognition between two concepts in a text, measured by the F1-score, and how does it compare to a word path model combining convolutional and fully connected language models?"
https://aclanthology.org/2020.lrec-1.714/,"Does combining a distributional approach and a word path model result in improved relation recognition accuracy compared to using each approach separately, as measured by the precision and recall of the model?"
https://aclanthology.org/2020.lrec-1.715/,How can Word2Attr improve the performance of semantic attribute vectors in capturing commonalities and differences among concepts through fine-tuning of attribute representations using supervised lexical entailment tasks?
https://aclanthology.org/2020.lrec-1.715/,Can the proposed Word2Attr method effectively discover valid but not-yet human-annotated attributes and refine the inventory of semantic attributes?
https://aclanthology.org/2020.lrec-1.716/,Can a spatial relation language integrated with Abstract Meaning Representation (AMR) annotation schema be able to capture the fine-grained decomposition of semantics in complex spatial configurations?
https://aclanthology.org/2020.lrec-1.716/,Can the use of a spatial relation language with AMR annotation schema enhance the expressiveness of spatial representation languages for supporting spatial reasoning in natural language understanding?
https://aclanthology.org/2020.lrec-1.717/,Can visual distributional models effectively capture the semantic similarity between verbs using images as input and SimLex-999 as a gold standard resource?
https://aclanthology.org/2020.lrec-1.717/,Can textual distributional models improve the accuracy of verb semantic similarity analysis by leveraging multimodal information from images and SimLex-999?
https://aclanthology.org/2020.lrec-1.718/,"Can the FigAN dataset be used to train a machine learning model to recognize literal and metaphorical meanings of adjective-noun phrases with high accuracy, measured by precision, in a context-dependent manner?"
https://aclanthology.org/2020.lrec-1.718/,"Can the FigSen corpus be used to evaluate the effectiveness of different annotation methods for assigning literal or metaphorical senses to adjective-noun phrases, measured by recall and F1-score?"
https://aclanthology.org/2020.lrec-1.719/,"What is the feasibility of using context-dependent word embeddings for natural language processing tasks, and how can they be evaluated using a continuous measure of meaning similarity?"
https://aclanthology.org/2020.lrec-1.719/,Can context-dependent word embeddings provide a more accurate representation of word meaning in less-resourced languages compared to standard embeddings?
https://aclanthology.org/2020.lrec-1.720/,"Does the French version of the FraCaS test suite accurately reflect the intended semantic inference in natural language, and can it be used as a reliable tool for evaluating the semantic capacity of French speakers?"
https://aclanthology.org/2020.lrec-1.720/,Can the translation of the FraCaS test suite into French be improved to better capture the nuances of French linguistic choices and logical semantics underlying the problems in the test suite?
https://aclanthology.org/2020.lrec-1.721/,"What is the effectiveness of the proposed system in identifying informal or non-academic words or phrases using the Concepts in Context (CoInCO) dataset, measured by precision and recall metrics, and how does it compare to the stratified classifier baseline?"
https://aclanthology.org/2020.lrec-1.721/,"How does the proposed system's paraphrase generation component using PPDB and WordNet resources perform in generating academic candidates, and what is the ranking accuracy of these candidates in context?"
https://aclanthology.org/2020.lrec-1.722/,Can supervised WSD models trained on multilingual data outperform models trained on monolingual data in terms of accuracy and F1-score for the task of word sense disambiguation?
https://aclanthology.org/2020.lrec-1.722/,"Can the creation of large-scale, domain-specific datasets improve the performance of supervised WSD models for multilingual languages, particularly for languages with limited annotated data?"
https://aclanthology.org/2020.lrec-1.723/,Can word embeddings trained on the annotated corpus be used to improve the performance of a named entity recognition model for French text in comparison to a model trained on a non-annotated corpus?
https://aclanthology.org/2020.lrec-1.723/,Can the use of WordNet Unique Beginners as semantic tags lead to more accurate sense induction in French nouns compared to traditional part-of-speech tagging approaches?
https://aclanthology.org/2020.lrec-1.724/,"Can gesture and linguistic descriptions be used to improve the accuracy of referring expression prediction models, and what are the key formal semantic properties that contribute to this improvement?"
https://aclanthology.org/2020.lrec-1.724/,Can the introduction of content into the common ground between a computational speaker and a human viewer enhance the informativeness of referring expressions generated using mixed-modality definite referring expressions?
https://aclanthology.org/2020.lrec-1.725/,"Can we develop a more accurate verb classification model using a more comprehensive set of contextualized word representations, such as BERT, to improve the performance of Metaphor Detection tasks?"
https://aclanthology.org/2020.lrec-1.725/,"Can we design a more efficient data structure, such as a graph-based embedding, to represent visual and textual data in a more effective way for Metaphor Detection tasks?"
https://aclanthology.org/2020.lrec-1.726/,Can a multilingual BERT transformer model be effectively fine-tuned for Hebrew semantic role labeling tasks by leveraging the provided annotated bilingual corpus and aligning English and Hebrew annotations?
https://aclanthology.org/2020.lrec-1.726/,"Can the proposed annotation projection approach from English to Hebrew improve the accuracy of Hebrew semantic role labeling models, and what are the implications for the development of multilingual SRL resources?"
https://aclanthology.org/2020.lrec-1.727/,"Can word embeddings be used to induce a word sense inventory for under-resourced languages without relying on supervised training instances, and can the quality of linguistic knowledge representations be improved by leveraging pre-trained word embeddings?"
https://aclanthology.org/2020.lrec-1.727/,"Can a fully-fledged word sense inventory be developed using a standard pre-trained word embedding model, and what are the implications for word sense disambiguation in context?"
https://aclanthology.org/2020.lrec-1.728/,"Can the ESSG-fr be successfully applied to other languages and domains with varying levels of complexity, and what would be the expected improvement in extraction accuracy compared to existing methods? Can the ESSG-fr be used to extract and reconstruct complex hierarchical networks of concepts in multi-domain corpora?"
https://aclanthology.org/2020.lrec-1.729/,Can the use of a hierarchical scheme based on the Cambridge Advanced Learner's Dictionary improve the accuracy of word sense disambiguation tasks using the Sense Complexity Dataset? Does the inclusion of complexity annotations in the SeCoDa dataset provide a more nuanced understanding of word senses than traditional word sense disambiguation methods?
https://aclanthology.org/2020.lrec-1.730/,"Does the proposed annotation scheme for causal language capture the nuances of German causal events, including the relationships between the cause, effect, actor, and affected party?"
https://aclanthology.org/2020.lrec-1.730/,"Can a machine learning approach be developed to predict the type of causal relationship between two events, such as consequence, motivation, or purpose, with high accuracy using the proposed dataset?"
https://aclanthology.org/2020.lrec-1.731/,Can a shared model that leverages both sense-annotated data and lexical resources improve the performance of word sense disambiguation for less frequently seen words compared to word-specific classifiers?
https://aclanthology.org/2020.lrec-1.731/,"Does the use of shared word embeddings derived from GloVe, ELMo, or BERT improve the overall performance of word sense disambiguation models in terms of F1-score?"
https://aclanthology.org/2020.lrec-1.732/,"Can the proposed framework for annotating adpositions in Mandarin Chinese be adapted to other languages with varying syntactic structures, and how would this impact the development of multilingual disambiguation systems?"
https://aclanthology.org/2020.lrec-1.732/,Can the use of language-independent supersenses for annotating adpositions improve the accuracy of machine translation systems when translating from Mandarin Chinese to English?
https://aclanthology.org/2020.lrec-1.733/,"Can a machine learning approach utilizing a deep learning model be used to automatically project semantic role labels from English to Russian with high accuracy and consistency, and if so, what are the key factors that influence the performance of such an approach?"
https://aclanthology.org/2020.lrec-1.733/,"Can the proposed RuPB resource be effectively used to improve the accuracy of SRL in Russian, specifically in handling sense disambiguation and language-specific issues, and what are the implications for future research in this area?"
https://aclanthology.org/2020.lrec-1.734/,What is the temporal relationship between the onset of overt constructed action and the activation of the head and eyes in Finnish Sign Language narration?
https://aclanthology.org/2020.lrec-1.734/,How do individual differences in temporal order of articulators affect the overall temporal structure of overt constructed action in Finnish Sign Language narration?
https://aclanthology.org/2020.lrec-1.735/,"Can a motion capture system for sign language animation that uses a large corpus of annotated motion data be able to generate realistic and accurate avatars that meet the standards of the deaf community, and what are the key factors that influence the quality of the avatars?"
https://aclanthology.org/2020.lrec-1.735/,"Can the addition of new motion data to an existing LSF corpus improve the range of signs that an avatar can produce, and how can the quality of the new data be evaluated to ensure it is compatible with the existing annotations?"
https://aclanthology.org/2020.lrec-1.736/,Can the proposed method of using OpenPose for human keypoint estimation and Convolutional Neural Networks for end-to-end feature learning improve the accuracy of sign language recognition?
https://aclanthology.org/2020.lrec-1.736/,Can the application of the multi-head attention mechanism from transformers to recognize isolated signs in the Flemish Sign Language corpus improve the performance of sign language recognition systems?
https://aclanthology.org/2020.lrec-1.737/,"Can the proposed automatic text generation system from LIS glosses to Italian be improved by incorporating a more advanced machine learning model, such as a transformer-based architecture, to enhance its accuracy and fluency in capturing the nuances of the sign language and its relation to Italian?"
https://aclanthology.org/2020.lrec-1.737/,"How can the annotation process of LIS fables be optimized to ensure that it is more efficient and reliable, and what are the potential benefits of using automated annotation methods, such as active learning or transfer learning, to reduce the manual labeling effort?"
https://aclanthology.org/2020.lrec-1.738/,"Can a freely available open source library be developed to convert HamNoSys notation into SiGML format, enabling the creation of avatars that can animate sign languages with higher accuracy and efficiency?"
https://aclanthology.org/2020.lrec-1.738/,Can the proposed conversion tool be used to improve the accessibility of online content for the Deaf community by enabling the creation of animations that accurately represent sign languages?
https://aclanthology.org/2020.lrec-1.739/,What are the feasibility and accuracy of a Convolutional-Recurrent Neural Network in recognizing iconic structures in French Sign Language using the Dicta-Sign-LSF-v2 corpus?
https://aclanthology.org/2020.lrec-1.739/,Can a Convolutional-Recurrent Neural Network trained on the Dicta-Sign-LSF-v2 corpus be able to accurately detect iconicity in Sign Language production with a high level of precision and a processing time of under 2 seconds?
https://aclanthology.org/2020.lrec-1.740/,"How can the proposed continuous HMM framework be optimized for better performance on datasets with varying numbers of signs, and what are the key factors that influence its accuracy in sign recognition tasks?"
https://aclanthology.org/2020.lrec-1.740/,"Can the proposed approach be extended to accommodate the challenges of real-time sign recognition in noisy environments, and how would this impact the evaluation of the model's performance in such scenarios?"
https://aclanthology.org/2020.lrec-1.741/,"What are the common semantic elements that link words to each other in abstract language and how do they relate to visual languages like sign languages, and what are the potential applications of a verb classification system based on visual shapes for language learning and comprehension?"
https://aclanthology.org/2020.lrec-1.742/,"Can the MEDIAPI-SKEL database be used to develop an accurate automatic alignment of text and video for sign language recognition, and what metrics can be used to evaluate this task? Can the MEDIAPI-SKEL database be used to develop semantic segmentation models for sign language, and what types of machine learning algorithms would be most suitable for this task?"
https://aclanthology.org/2020.lrec-1.743/,Can a parallel database of Sign Language segments be effectively developed to support the development of a Sign Language concordancer?
https://aclanthology.org/2020.lrec-1.743/,What metrics can be used to evaluate the accuracy of such a database in facilitating the creation of Sign Language translators? 
https://aclanthology.org/2020.lrec-1.743/,"Can a scalable and efficient method be devised to automatically align and update the database with new Sign Language data, such as videos, to support the growth of the database over time?"
https://aclanthology.org/2020.lrec-1.744/,"Can machine learning models achieve high accuracy in recognizing Kazakh-Russian Sign Language signs with varying non-manual components?"
https://aclanthology.org/2020.lrec-1.744/,"Does the incorporation of non-manual components into sign recognition systems improve accuracy?"
https://aclanthology.org/2020.lrec-1.745/,"Can the proposed database be used to develop an accurate gesture recognition system for Russian sign language?"
https://aclanthology.org/2020.lrec-1.745/,"Can the use of Kinect 2.0 device in collecting data for TheRuSLan database improve the accuracy of automatic sign language recognition systems?"
https://aclanthology.org/2020.lrec-1.746/,"Can deep learning-based approaches using transformer architectures be more accurate in detecting fake news than traditional rule-based methods?"
https://aclanthology.org/2020.lrec-1.746/,"Can the use of multimodal features incorporating text, images, and user behavior data improve the accuracy of fake news detection?"
https://aclanthology.org/2020.lrec-1.746/,What is the optimal balance between feature extraction and model complexity for this task?"
https://aclanthology.org/2020.lrec-1.747/,Can a character-based bidirectional language model be used to identify potential rumor sources in early stages of their development by analyzing the textual content of tweets?
https://aclanthology.org/2020.lrec-1.747/,How can multi-layered attention models improve the performance of early rumor detection on social media?
https://aclanthology.org/2020.lrec-1.747/,Can stacked LSTM networks effectively model the propagation patterns of rumors by jointly learning attentive context embeddings from multiple social-temporal contexts of input tweets?
https://aclanthology.org/2020.lrec-1.747/,What is the impact of the proposed model on the detection of unseen rumors on large augmented datasets?
https://aclanthology.org/2020.lrec-1.748/,What is the effectiveness of writer-labeled market sentiment in predicting financial market trends compared to the sentiment of the actual market performance in the financial social media data?
https://aclanthology.org/2020.lrec-1.748/,Can a domain-specific dictionary outperform a general sentiment dictionary in extracting key snippets from financial social media data?
https://aclanthology.org/2020.lrec-1.749/,Can the proposed corpus of annotated Brazilian Portuguese texts be used to develop a machine learning model that can accurately detect early signs of depression in social media posts with a precision of at least 80%?
https://aclanthology.org/2020.lrec-1.749/,Can the temporal analysis of mental health issues in Brazilian Portuguese be improved by incorporating the users' publication history into a supervised classification model that achieves an accuracy of at least 90% in identifying mental health-related topics?
